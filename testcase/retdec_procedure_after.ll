No matching plugins found for 'GCC 11.4.1'
No matching plugins found for 'GCC 3.3.x'
*** IR Dump After Providers initialization ***
source_filename = "test"
*** IR Dump After Input binary to LLVM IR decoding ***
source_filename = "test"
target datalayout = "e-m:e-p:64:64-i64:64-f80:128-n8:16:32:64-S128"

@_asm_program_counter = internal global i64 0
@cf = internal global i1 false
@pf = internal global i1 false
@az = internal global i1 false
@zf = internal global i1 false
@sf = internal global i1 false
@tf = internal global i1 false
@if = internal global i1 false
@df = internal global i1 false
@of = internal global i1 false
@iopl = internal global i2 0
@nt = internal global i1 false
@rf = internal global i1 false
@vm = internal global i1 false
@ac = internal global i1 false
@vif = internal global i1 false
@vip = internal global i1 false
@id = internal global i1 false
@rflags = internal global i64 0
@ss = internal global i16 0
@cs = internal global i16 0
@ds = internal global i16 0
@es = internal global i16 0
@fs = internal global i16 0
@gs = internal global i16 0
@st0 = internal global x86_fp80 0xK00000000000000000000
@st1 = internal global x86_fp80 0xK00000000000000000000
@st2 = internal global x86_fp80 0xK00000000000000000000
@st3 = internal global x86_fp80 0xK00000000000000000000
@st4 = internal global x86_fp80 0xK00000000000000000000
@st5 = internal global x86_fp80 0xK00000000000000000000
@st6 = internal global x86_fp80 0xK00000000000000000000
@st7 = internal global x86_fp80 0xK00000000000000000000
@fpu_stat_IE = internal global i1 false
@fpu_stat_DE = internal global i1 false
@fpu_stat_ZE = internal global i1 false
@fpu_stat_OE = internal global i1 false
@fpu_stat_UE = internal global i1 false
@fpu_stat_PE = internal global i1 false
@fpu_stat_SF = internal global i1 false
@fpu_stat_ES = internal global i1 false
@fpu_stat_C0 = internal global i1 false
@fpu_stat_C1 = internal global i1 false
@fpu_stat_C2 = internal global i1 false
@fpu_stat_C3 = internal global i1 false
@fpu_stat_TOP = internal global i3 0
@fpu_stat_B = internal global i1 false
@fpu_control_IM = internal global i1 false
@fpu_control_DM = internal global i1 false
@fpu_control_ZM = internal global i1 false
@fpu_control_OM = internal global i1 false
@fpu_control_UM = internal global i1 false
@fpu_control_PM = internal global i1 false
@fpu_control_PC = internal global i2 0
@fpu_control_RC = internal global i2 0
@fpu_control_X = internal global i1 false
@fp0 = internal global double 0.000000e+00
@fp1 = internal global double 0.000000e+00
@fp2 = internal global double 0.000000e+00
@fp3 = internal global double 0.000000e+00
@fp4 = internal global double 0.000000e+00
@fp5 = internal global double 0.000000e+00
@fp6 = internal global double 0.000000e+00
@fp7 = internal global double 0.000000e+00
@k0 = internal global i64 0
@k1 = internal global i64 0
@k2 = internal global i64 0
@k3 = internal global i64 0
@k4 = internal global i64 0
@k5 = internal global i64 0
@k6 = internal global i64 0
@k7 = internal global i64 0
@mm0 = internal global i64 0
@mm1 = internal global i64 0
@mm2 = internal global i64 0
@mm3 = internal global i64 0
@mm4 = internal global i64 0
@mm5 = internal global i64 0
@mm6 = internal global i64 0
@mm7 = internal global i64 0
@xmm0 = internal global i128 0
@xmm1 = internal global i128 0
@xmm2 = internal global i128 0
@xmm3 = internal global i128 0
@xmm4 = internal global i128 0
@xmm5 = internal global i128 0
@xmm6 = internal global i128 0
@xmm7 = internal global i128 0
@xmm8 = internal global i128 0
@xmm9 = internal global i128 0
@xmm10 = internal global i128 0
@xmm11 = internal global i128 0
@xmm12 = internal global i128 0
@xmm13 = internal global i128 0
@xmm14 = internal global i128 0
@xmm15 = internal global i128 0
@xmm16 = internal global i128 0
@xmm17 = internal global i128 0
@xmm18 = internal global i128 0
@xmm19 = internal global i128 0
@xmm20 = internal global i128 0
@xmm21 = internal global i128 0
@xmm22 = internal global i128 0
@xmm23 = internal global i128 0
@xmm24 = internal global i128 0
@xmm25 = internal global i128 0
@xmm26 = internal global i128 0
@xmm27 = internal global i128 0
@xmm28 = internal global i128 0
@xmm29 = internal global i128 0
@xmm30 = internal global i128 0
@xmm31 = internal global i128 0
@ymm0 = internal global i256 0
@ymm1 = internal global i256 0
@ymm2 = internal global i256 0
@ymm3 = internal global i256 0
@ymm4 = internal global i256 0
@ymm5 = internal global i256 0
@ymm6 = internal global i256 0
@ymm7 = internal global i256 0
@ymm8 = internal global i256 0
@ymm9 = internal global i256 0
@ymm10 = internal global i256 0
@ymm11 = internal global i256 0
@ymm12 = internal global i256 0
@ymm13 = internal global i256 0
@ymm14 = internal global i256 0
@ymm15 = internal global i256 0
@ymm16 = internal global i256 0
@ymm17 = internal global i256 0
@ymm18 = internal global i256 0
@ymm19 = internal global i256 0
@ymm20 = internal global i256 0
@ymm21 = internal global i256 0
@ymm22 = internal global i256 0
@ymm23 = internal global i256 0
@ymm24 = internal global i256 0
@ymm25 = internal global i256 0
@ymm26 = internal global i256 0
@ymm27 = internal global i256 0
@ymm28 = internal global i256 0
@ymm29 = internal global i256 0
@ymm30 = internal global i256 0
@ymm31 = internal global i256 0
@zmm0 = internal global i512 0
@zmm1 = internal global i512 0
@zmm2 = internal global i512 0
@zmm3 = internal global i512 0
@zmm4 = internal global i512 0
@zmm5 = internal global i512 0
@zmm6 = internal global i512 0
@zmm7 = internal global i512 0
@zmm8 = internal global i512 0
@zmm9 = internal global i512 0
@zmm10 = internal global i512 0
@zmm11 = internal global i512 0
@zmm12 = internal global i512 0
@zmm13 = internal global i512 0
@zmm14 = internal global i512 0
@zmm15 = internal global i512 0
@zmm16 = internal global i512 0
@zmm17 = internal global i512 0
@zmm18 = internal global i512 0
@zmm19 = internal global i512 0
@zmm20 = internal global i512 0
@zmm21 = internal global i512 0
@zmm22 = internal global i512 0
@zmm23 = internal global i512 0
@zmm24 = internal global i512 0
@zmm25 = internal global i512 0
@zmm26 = internal global i512 0
@zmm27 = internal global i512 0
@zmm28 = internal global i512 0
@zmm29 = internal global i512 0
@zmm30 = internal global i512 0
@zmm31 = internal global i512 0
@bnd0 = internal global i128 0
@bnd1 = internal global i128 0
@bnd2 = internal global i128 0
@bnd3 = internal global i128 0
@dr0 = internal global i64 0
@dr1 = internal global i64 0
@dr2 = internal global i64 0
@dr3 = internal global i64 0
@dr4 = internal global i64 0
@dr5 = internal global i64 0
@dr6 = internal global i64 0
@dr7 = internal global i64 0
@dr8 = internal global i64 0
@dr9 = internal global i64 0
@dr10 = internal global i64 0
@dr11 = internal global i64 0
@dr12 = internal global i64 0
@dr13 = internal global i64 0
@dr14 = internal global i64 0
@dr15 = internal global i64 0
@cr0 = internal global i64 0
@cr1 = internal global i64 0
@cr2 = internal global i64 0
@cr3 = internal global i64 0
@cr4 = internal global i64 0
@cr5 = internal global i64 0
@cr6 = internal global i64 0
@cr7 = internal global i64 0
@cr8 = internal global i64 0
@cr9 = internal global i64 0
@cr10 = internal global i64 0
@cr11 = internal global i64 0
@cr12 = internal global i64 0
@cr13 = internal global i64 0
@cr14 = internal global i64 0
@cr15 = internal global i64 0
@fpsw = internal global i64 0
@rax = internal global i64 0
@rcx = internal global i64 0
@rdx = internal global i64 0
@rbx = internal global i64 0
@rsp = internal global i64 0
@rbp = internal global i64 0
@rsi = internal global i64 0
@rdi = internal global i64 0
@r8 = internal global i64 0
@r9 = internal global i64 0
@r10 = internal global i64 0
@r11 = internal global i64 0
@r12 = internal global i64 0
@r13 = internal global i64 0
@r14 = internal global i64 0
@r15 = internal global i64 0
@rip = internal global i64 0
@riz = internal global i64 0

define i64 @_init() {
dec_label_pc_401000:

; 0x401000
  store volatile i64 4198400, i64* @_asm_program_counter

; 0x401004
  store volatile i64 4198404, i64* @_asm_program_counter
  %0 = load i64, i64* @rsp
  %1 = sub i64 %0, 8
  %2 = and i64 %0, 15
  %3 = sub i64 %2, 8
  %4 = icmp ugt i64 %3, 15
  %5 = icmp ult i64 %0, 8
  %6 = xor i64 %0, 8
  %7 = xor i64 %0, %1
  %8 = and i64 %6, %7
  %9 = icmp slt i64 %8, 0
  store i1 %4, i1* @az
  store i1 %5, i1* @cf
  store i1 %9, i1* @of
  %10 = icmp eq i64 %1, 0
  store i1 %10, i1* @zf
  %11 = icmp slt i64 %1, 0
  store i1 %11, i1* @sf
  %12 = trunc i64 %1 to i8
  %13 = call i8 @llvm.ctpop.i8(i8 %12)
  %14 = and i8 %13, 1
  %15 = icmp eq i8 %14, 0
  store i1 %15, i1* @pf
  store i64 %1, i64* @rsp

; 0x401008
  store volatile i64 4198408, i64* @_asm_program_counter
  %16 = load i64, i64* inttoptr (i64 4210672 to i64*)
  store i64 %16, i64* @rax

; 0x40100f
  store volatile i64 4198415, i64* @_asm_program_counter
  %17 = load i64, i64* @rax
  %18 = load i64, i64* @rax
  %19 = and i64 %17, %18
  store i1 false, i1* @az
  store i1 false, i1* @cf
  store i1 false, i1* @of
  %20 = icmp eq i64 %19, 0
  store i1 %20, i1* @zf
  %21 = icmp slt i64 %19, 0
  store i1 %21, i1* @sf
  %22 = trunc i64 %19 to i8
  %23 = call i8 @llvm.ctpop.i8(i8 %22)
  %24 = and i8 %23, 1
  %25 = icmp eq i8 %24, 0
  store i1 %25, i1* @pf

; 0x401012
  store volatile i64 4198418, i64* @_asm_program_counter
  %26 = load i1, i1* @zf
  br i1 %26, label %dec_label_pc_401016, label %dec_label_pc_401014

dec_label_pc_401014:                              ; preds = %dec_label_pc_401000

; 0x401014
  store volatile i64 4198420, i64* @_asm_program_counter
  %27 = call i64 @__gmon_start__()
  store i64 %27, i64* @rax
  br label %dec_label_pc_401016

dec_label_pc_401016:                              ; preds = %dec_label_pc_401014, %dec_label_pc_401000

; 0x401016
  store volatile i64 4198422, i64* @_asm_program_counter
  %28 = load i64, i64* @rsp
  %29 = add i64 %28, 8
  %30 = and i64 %28, 15
  %31 = add i64 %30, 8
  %32 = icmp ugt i64 %31, 15
  %33 = icmp ult i64 %29, %28
  %34 = xor i64 %28, %29
  %35 = xor i64 8, %29
  %36 = and i64 %34, %35
  %37 = icmp slt i64 %36, 0
  store i1 %32, i1* @az
  store i1 %33, i1* @cf
  store i1 %37, i1* @of
  %38 = icmp eq i64 %29, 0
  store i1 %38, i1* @zf
  %39 = icmp slt i64 %29, 0
  store i1 %39, i1* @sf
  %40 = trunc i64 %29 to i8
  %41 = call i8 @llvm.ctpop.i8(i8 %40)
  %42 = and i8 %41, 1
  %43 = icmp eq i8 %42, 0
  store i1 %43, i1* @pf
  store i64 %29, i64* @rsp

; 0x40101a
  store volatile i64 4198426, i64* @_asm_program_counter
  ret i64 undef
}

define i64 @function_401030() {
dec_label_pc_401030:

; 0x401030
  store volatile i64 4198448, i64* @_asm_program_counter
  %0 = call i64 @printf()
  store i64 %0, i64* @rax
  ret i64 undef
}

define i64 @_start() {
dec_label_pc_401040:

; 0x401040
  store volatile i64 4198464, i64* @_asm_program_counter

; 0x401044
  store volatile i64 4198468, i64* @_asm_program_counter
  %0 = load i64, i64* @rbp
  %1 = trunc i64 %0 to i32
  %2 = load i64, i64* @rbp
  %3 = trunc i64 %2 to i32
  %4 = xor i32 %1, %3
  store i1 false, i1* @az
  store i1 false, i1* @cf
  store i1 false, i1* @of
  %5 = icmp eq i32 %4, 0
  store i1 %5, i1* @zf
  %6 = icmp slt i32 %4, 0
  store i1 %6, i1* @sf
  %7 = trunc i32 %4 to i8
  %8 = call i8 @llvm.ctpop.i8(i8 %7)
  %9 = and i8 %8, 1
  %10 = icmp eq i8 %9, 0
  store i1 %10, i1* @pf
  %11 = zext i32 %4 to i64
  store i64 %11, i64* @rbp

; 0x401046
  store volatile i64 4198470, i64* @_asm_program_counter
  %12 = load i64, i64* @rdx
  store i64 %12, i64* @r9

; 0x401049
  store volatile i64 4198473, i64* @_asm_program_counter
  %13 = load i64, i64* @rsp
  %14 = inttoptr i64 %13 to i64*
  %15 = load i64, i64* %14
  store i64 %15, i64* @rsi
  %16 = add i64 %13, 8
  store i64 %16, i64* @rsp

; 0x40104a
  store volatile i64 4198474, i64* @_asm_program_counter
  %17 = load i64, i64* @rsp
  store i64 %17, i64* @rdx

; 0x40104d
  store volatile i64 4198477, i64* @_asm_program_counter
  %18 = load i64, i64* @rsp
  %19 = and i64 %18, -16
  store i1 false, i1* @az
  store i1 false, i1* @cf
  store i1 false, i1* @of
  %20 = icmp eq i64 %19, 0
  store i1 %20, i1* @zf
  %21 = icmp slt i64 %19, 0
  store i1 %21, i1* @sf
  %22 = trunc i64 %19 to i8
  %23 = call i8 @llvm.ctpop.i8(i8 %22)
  %24 = and i8 %23, 1
  %25 = icmp eq i8 %24, 0
  store i1 %25, i1* @pf
  store i64 %19, i64* @rsp

; 0x401051
  store volatile i64 4198481, i64* @_asm_program_counter
  %26 = load i64, i64* @rax
  %27 = load i64, i64* @rsp
  %28 = sub i64 %27, 8
  %29 = inttoptr i64 %28 to i64*
  store i64 %26, i64* %29
  store i64 %28, i64* @rsp

; 0x401052
  store volatile i64 4198482, i64* @_asm_program_counter
  %30 = load i64, i64* @rsp
  %31 = load i64, i64* @rsp
  %32 = sub i64 %31, 8
  %33 = inttoptr i64 %32 to i64*
  store i64 %30, i64* %33
  store i64 %32, i64* @rsp

; 0x401053
  store volatile i64 4198483, i64* @_asm_program_counter
  %34 = load i64, i64* @r8
  %35 = trunc i64 %34 to i32
  %36 = load i64, i64* @r8
  %37 = trunc i64 %36 to i32
  %38 = xor i32 %35, %37
  store i1 false, i1* @az
  store i1 false, i1* @cf
  store i1 false, i1* @of
  %39 = icmp eq i32 %38, 0
  store i1 %39, i1* @zf
  %40 = icmp slt i32 %38, 0
  store i1 %40, i1* @sf
  %41 = trunc i32 %38 to i8
  %42 = call i8 @llvm.ctpop.i8(i8 %41)
  %43 = and i8 %42, 1
  %44 = icmp eq i8 %43, 0
  store i1 %44, i1* @pf
  %45 = zext i32 %38 to i64
  store i64 %45, i64* @r8

; 0x401056
  store volatile i64 4198486, i64* @_asm_program_counter
  %46 = load i64, i64* @rcx
  %47 = trunc i64 %46 to i32
  %48 = load i64, i64* @rcx
  %49 = trunc i64 %48 to i32
  %50 = xor i32 %47, %49
  store i1 false, i1* @az
  store i1 false, i1* @cf
  store i1 false, i1* @of
  %51 = icmp eq i32 %50, 0
  store i1 %51, i1* @zf
  %52 = icmp slt i32 %50, 0
  store i1 %52, i1* @sf
  %53 = trunc i32 %50 to i8
  %54 = call i8 @llvm.ctpop.i8(i8 %53)
  %55 = and i8 %54, 1
  %56 = icmp eq i8 %55, 0
  store i1 %56, i1* @pf
  %57 = zext i32 %50 to i64
  store i64 %57, i64* @rcx

; 0x401058
  store volatile i64 4198488, i64* @_asm_program_counter
  store i64 4198721, i64* @rdi

; 0x40105f
  store volatile i64 4198495, i64* @_asm_program_counter
  %58 = call i64 @__libc_start_main()
  store i64 %58, i64* @rax

; 0x401065
  store volatile i64 4198501, i64* @_asm_program_counter
  call void @__asm_hlt()
  unreachable
}

define i64 @_dl_relocate_static_pie() {
dec_label_pc_401070:

; 0x401070
  store volatile i64 4198512, i64* @_asm_program_counter

; 0x401074
  store volatile i64 4198516, i64* @_asm_program_counter
  ret i64 undef
}

define i64 @deregister_tm_clones() {
dec_label_pc_401080:

; 0x401080
  store volatile i64 4198528, i64* @_asm_program_counter
  store i64 4210728, i64* @rdi

; 0x401087
  store volatile i64 4198535, i64* @_asm_program_counter
  store i64 4210728, i64* @rax

; 0x40108e
  store volatile i64 4198542, i64* @_asm_program_counter
  %0 = load i64, i64* @rax
  %1 = load i64, i64* @rdi
  %2 = sub i64 %0, %1
  %3 = and i64 %0, 15
  %4 = and i64 %1, 15
  %5 = sub i64 %3, %4
  %6 = icmp ugt i64 %5, 15
  %7 = icmp ult i64 %0, %1
  %8 = xor i64 %0, %1
  %9 = xor i64 %0, %2
  %10 = and i64 %8, %9
  %11 = icmp slt i64 %10, 0
  store i1 %6, i1* @az
  store i1 %7, i1* @cf
  store i1 %11, i1* @of
  %12 = icmp eq i64 %2, 0
  store i1 %12, i1* @zf
  %13 = icmp slt i64 %2, 0
  store i1 %13, i1* @sf
  %14 = trunc i64 %2 to i8
  %15 = call i8 @llvm.ctpop.i8(i8 %14)
  %16 = and i8 %15, 1
  %17 = icmp eq i8 %16, 0
  store i1 %17, i1* @pf

; 0x401091
  store volatile i64 4198545, i64* @_asm_program_counter
  %18 = load i1, i1* @zf
  br i1 %18, label %dec_label_pc_4010a8, label %dec_label_pc_401093

dec_label_pc_401093:                              ; preds = %dec_label_pc_401080

; 0x401093
  store volatile i64 4198547, i64* @_asm_program_counter
  %19 = load i64, i64* inttoptr (i64 4210664 to i64*)
  store i64 %19, i64* @rax

; 0x40109a
  store volatile i64 4198554, i64* @_asm_program_counter
  %20 = load i64, i64* @rax
  %21 = load i64, i64* @rax
  %22 = and i64 %20, %21
  store i1 false, i1* @az
  store i1 false, i1* @cf
  store i1 false, i1* @of
  %23 = icmp eq i64 %22, 0
  store i1 %23, i1* @zf
  %24 = icmp slt i64 %22, 0
  store i1 %24, i1* @sf
  %25 = trunc i64 %22 to i8
  %26 = call i8 @llvm.ctpop.i8(i8 %25)
  %27 = and i8 %26, 1
  %28 = icmp eq i8 %27, 0
  store i1 %28, i1* @pf

; 0x40109d
  store volatile i64 4198557, i64* @_asm_program_counter
  %29 = load i1, i1* @zf
  br i1 %29, label %dec_label_pc_4010a8, label %dec_label_pc_40109f

dec_label_pc_40109f:                              ; preds = %dec_label_pc_401093

; 0x40109f
  store volatile i64 4198559, i64* @_asm_program_counter
  %30 = call i64 @_ITM_deregisterTMCloneTable()
  store i64 %30, i64* @rax
  ret i64 undef

dec_label_pc_4010a8:                              ; preds = %dec_label_pc_401093, %dec_label_pc_401080

; 0x4010a8
  store volatile i64 4198568, i64* @_asm_program_counter
  ret i64 undef
}

define i64 @register_tm_clones() {
dec_label_pc_4010b0:

; 0x4010b0
  store volatile i64 4198576, i64* @_asm_program_counter
  store i64 4210728, i64* @rdi

; 0x4010b7
  store volatile i64 4198583, i64* @_asm_program_counter
  store i64 4210728, i64* @rsi

; 0x4010be
  store volatile i64 4198590, i64* @_asm_program_counter
  %0 = load i64, i64* @rsi
  %1 = load i64, i64* @rdi
  %2 = sub i64 %0, %1
  %3 = and i64 %0, 15
  %4 = and i64 %1, 15
  %5 = sub i64 %3, %4
  %6 = icmp ugt i64 %5, 15
  %7 = icmp ult i64 %0, %1
  %8 = xor i64 %0, %1
  %9 = xor i64 %0, %2
  %10 = and i64 %8, %9
  %11 = icmp slt i64 %10, 0
  store i1 %6, i1* @az
  store i1 %7, i1* @cf
  store i1 %11, i1* @of
  %12 = icmp eq i64 %2, 0
  store i1 %12, i1* @zf
  %13 = icmp slt i64 %2, 0
  store i1 %13, i1* @sf
  %14 = trunc i64 %2 to i8
  %15 = call i8 @llvm.ctpop.i8(i8 %14)
  %16 = and i8 %15, 1
  %17 = icmp eq i8 %16, 0
  store i1 %17, i1* @pf
  store i64 %2, i64* @rsi

; 0x4010c1
  store volatile i64 4198593, i64* @_asm_program_counter
  %18 = load i64, i64* @rsi
  store i64 %18, i64* @rax

; 0x4010c4
  store volatile i64 4198596, i64* @_asm_program_counter
  %19 = load i64, i64* @rsi
  %20 = load i1, i1* @of
  %21 = lshr i64 %19, 63
  %22 = icmp eq i64 %21, 0
  store i1 %22, i1* @zf
  %23 = icmp slt i64 %21, 0
  store i1 %23, i1* @sf
  %24 = trunc i64 %21 to i8
  %25 = call i8 @llvm.ctpop.i8(i8 %24)
  %26 = and i8 %25, 1
  %27 = icmp eq i8 %26, 0
  store i1 %27, i1* @pf
  store i64 %21, i64* @rsi
  %28 = and i64 4611686018427387904, %19
  %29 = icmp ne i64 %28, 0
  store i1 %29, i1* @cf
  %30 = icmp slt i64 %19, 0
  %31 = select i1 false, i1 %30, i1 %20
  store i1 %31, i1* @of

; 0x4010c8
  store volatile i64 4198600, i64* @_asm_program_counter
  %32 = load i64, i64* @rax
  %33 = load i1, i1* @of
  %34 = ashr i64 %32, 3
  %35 = icmp eq i64 %34, 0
  store i1 %35, i1* @zf
  %36 = icmp slt i64 %34, 0
  store i1 %36, i1* @sf
  %37 = trunc i64 %34 to i8
  %38 = call i8 @llvm.ctpop.i8(i8 %37)
  %39 = and i8 %38, 1
  %40 = icmp eq i8 %39, 0
  store i1 %40, i1* @pf
  store i64 %34, i64* @rax
  %41 = and i64 4, %32
  %42 = icmp ne i64 %41, 0
  store i1 %42, i1* @cf
  %43 = select i1 false, i1 false, i1 %33
  store i1 %43, i1* @of

; 0x4010cc
  store volatile i64 4198604, i64* @_asm_program_counter
  %44 = load i64, i64* @rsi
  %45 = load i64, i64* @rax
  %46 = add i64 %44, %45
  %47 = and i64 %44, 15
  %48 = and i64 %45, 15
  %49 = add i64 %47, %48
  %50 = icmp ugt i64 %49, 15
  %51 = icmp ult i64 %46, %44
  %52 = xor i64 %44, %46
  %53 = xor i64 %45, %46
  %54 = and i64 %52, %53
  %55 = icmp slt i64 %54, 0
  store i1 %50, i1* @az
  store i1 %51, i1* @cf
  store i1 %55, i1* @of
  %56 = icmp eq i64 %46, 0
  store i1 %56, i1* @zf
  %57 = icmp slt i64 %46, 0
  store i1 %57, i1* @sf
  %58 = trunc i64 %46 to i8
  %59 = call i8 @llvm.ctpop.i8(i8 %58)
  %60 = and i8 %59, 1
  %61 = icmp eq i8 %60, 0
  store i1 %61, i1* @pf
  store i64 %46, i64* @rsi

; 0x4010cf
  store volatile i64 4198607, i64* @_asm_program_counter
  %62 = load i64, i64* @rsi
  %63 = load i1, i1* @of
  %64 = ashr i64 %62, 1
  %65 = icmp eq i64 %64, 0
  store i1 %65, i1* @zf
  %66 = icmp slt i64 %64, 0
  store i1 %66, i1* @sf
  %67 = trunc i64 %64 to i8
  %68 = call i8 @llvm.ctpop.i8(i8 %67)
  %69 = and i8 %68, 1
  %70 = icmp eq i8 %69, 0
  store i1 %70, i1* @pf
  store i64 %64, i64* @rsi
  %71 = and i64 1, %62
  %72 = icmp ne i64 %71, 0
  store i1 %72, i1* @cf
  %73 = select i1 true, i1 false, i1 %63
  store i1 %73, i1* @of

; 0x4010d2
  store volatile i64 4198610, i64* @_asm_program_counter
  %74 = load i1, i1* @zf
  br i1 %74, label %dec_label_pc_4010e8, label %dec_label_pc_4010d4

dec_label_pc_4010d4:                              ; preds = %dec_label_pc_4010b0

; 0x4010d4
  store volatile i64 4198612, i64* @_asm_program_counter
  %75 = load i64, i64* inttoptr (i64 4210680 to i64*)
  store i64 %75, i64* @rax

; 0x4010db
  store volatile i64 4198619, i64* @_asm_program_counter
  %76 = load i64, i64* @rax
  %77 = load i64, i64* @rax
  %78 = and i64 %76, %77
  store i1 false, i1* @az
  store i1 false, i1* @cf
  store i1 false, i1* @of
  %79 = icmp eq i64 %78, 0
  store i1 %79, i1* @zf
  %80 = icmp slt i64 %78, 0
  store i1 %80, i1* @sf
  %81 = trunc i64 %78 to i8
  %82 = call i8 @llvm.ctpop.i8(i8 %81)
  %83 = and i8 %82, 1
  %84 = icmp eq i8 %83, 0
  store i1 %84, i1* @pf

; 0x4010de
  store volatile i64 4198622, i64* @_asm_program_counter
  %85 = load i1, i1* @zf
  br i1 %85, label %dec_label_pc_4010e8, label %dec_label_pc_4010e0

dec_label_pc_4010e0:                              ; preds = %dec_label_pc_4010d4

; 0x4010e0
  store volatile i64 4198624, i64* @_asm_program_counter
  %86 = call i64 @_ITM_registerTMCloneTable()
  store i64 %86, i64* @rax
  ret i64 undef

dec_label_pc_4010e8:                              ; preds = %dec_label_pc_4010d4, %dec_label_pc_4010b0

; 0x4010e8
  store volatile i64 4198632, i64* @_asm_program_counter
  ret i64 undef
}

define i64 @__do_global_dtors_aux() {
dec_label_pc_4010f0:

; 0x4010f0
  store volatile i64 4198640, i64* @_asm_program_counter

; 0x4010f4
  store volatile i64 4198644, i64* @_asm_program_counter
  %0 = load i8, i8* inttoptr (i64 4210724 to i8*)
  %1 = sub i8 %0, 0
  %2 = and i8 %0, 15
  %3 = sub i8 %2, 0
  %4 = icmp ugt i8 %3, 15
  %5 = icmp ult i8 %0, 0
  %6 = xor i8 %0, 0
  %7 = xor i8 %0, %1
  %8 = and i8 %6, %7
  %9 = icmp slt i8 %8, 0
  store i1 %4, i1* @az
  store i1 %5, i1* @cf
  store i1 %9, i1* @of
  %10 = icmp eq i8 %1, 0
  store i1 %10, i1* @zf
  %11 = icmp slt i8 %1, 0
  store i1 %11, i1* @sf
  %12 = call i8 @llvm.ctpop.i8(i8 %1)
  %13 = and i8 %12, 1
  %14 = icmp eq i8 %13, 0
  store i1 %14, i1* @pf

; 0x4010fb
  store volatile i64 4198651, i64* @_asm_program_counter
  %15 = load i1, i1* @zf
  %16 = icmp eq i1 %15, false
  br i1 %16, label %dec_label_pc_401110, label %dec_label_pc_4010fd

dec_label_pc_4010fd:                              ; preds = %dec_label_pc_4010f0

; 0x4010fd
  store volatile i64 4198653, i64* @_asm_program_counter
  %17 = load i64, i64* @rbp
  %18 = load i64, i64* @rsp
  %19 = sub i64 %18, 8
  %20 = inttoptr i64 %19 to i64*
  store i64 %17, i64* %20
  store i64 %19, i64* @rsp

; 0x4010fe
  store volatile i64 4198654, i64* @_asm_program_counter
  %21 = load i64, i64* @rsp
  store i64 %21, i64* @rbp

; 0x401101
  store volatile i64 4198657, i64* @_asm_program_counter
  %22 = call i64 @deregister_tm_clones()
  store i64 %22, i64* @rax

; 0x401106
  store volatile i64 4198662, i64* @_asm_program_counter
  store i8 1, i8* inttoptr (i64 4210724 to i8*)

; 0x40110d
  store volatile i64 4198669, i64* @_asm_program_counter
  %23 = load i64, i64* @rsp
  %24 = inttoptr i64 %23 to i64*
  %25 = load i64, i64* %24
  store i64 %25, i64* @rbp
  %26 = add i64 %23, 8
  store i64 %26, i64* @rsp

; 0x40110e
  store volatile i64 4198670, i64* @_asm_program_counter
  ret i64 undef

dec_label_pc_401110:                              ; preds = %dec_label_pc_4010f0

; 0x401110
  store volatile i64 4198672, i64* @_asm_program_counter
  ret i64 undef
}

define i64 @frame_dummy() {
dec_label_pc_401120:

; 0x401120
  store volatile i64 4198688, i64* @_asm_program_counter

; 0x401124
  store volatile i64 4198692, i64* @_asm_program_counter
  %0 = call i64 @register_tm_clones()
  store i64 %0, i64* @rax
  ret i64 undef
}

define i64 @add() {
dec_label_pc_401126:

; 0x401126
  store volatile i64 4198694, i64* @_asm_program_counter
  %0 = load i64, i64* @rbp
  %1 = load i64, i64* @rsp
  %2 = sub i64 %1, 8
  %3 = inttoptr i64 %2 to i64*
  store i64 %0, i64* %3
  store i64 %2, i64* @rsp

; 0x401127
  store volatile i64 4198695, i64* @_asm_program_counter
  %4 = load i64, i64* @rsp
  store i64 %4, i64* @rbp

; 0x40112a
  store volatile i64 4198698, i64* @_asm_program_counter
  %5 = load i64, i64* @rdi
  %6 = load i64, i64* @rbp
  %7 = add i64 %6, -8
  %8 = inttoptr i64 %7 to i64*
  store i64 %5, i64* %8

; 0x40112e
  store volatile i64 4198702, i64* @_asm_program_counter
  %9 = load i64, i64* @rsi
  %10 = trunc i64 %9 to i32
  %11 = zext i32 %10 to i64
  store i64 %11, i64* @rax

; 0x401130
  store volatile i64 4198704, i64* @_asm_program_counter
  %12 = load i64, i64* @rax
  %13 = trunc i64 %12 to i8
  %14 = load i64, i64* @rbp
  %15 = add i64 %14, -12
  %16 = inttoptr i64 %15 to i8*
  store i8 %13, i8* %16

; 0x401133
  store volatile i64 4198707, i64* @_asm_program_counter
  %17 = load i64, i64* @rbp
  %18 = add i64 %17, -8
  %19 = inttoptr i64 %18 to i64*
  %20 = load i64, i64* %19
  store i64 %20, i64* @rax

; 0x401137
  store volatile i64 4198711, i64* @_asm_program_counter
  %21 = load i64, i64* @rax
  %22 = inttoptr i64 %21 to i32*
  %23 = load i32, i32* %22
  %24 = zext i32 %23 to i64
  store i64 %24, i64* @rdx

; 0x401139
  store volatile i64 4198713, i64* @_asm_program_counter
  %25 = load i64, i64* @rbp
  %26 = add i64 %25, -12
  %27 = inttoptr i64 %26 to i8*
  %28 = load i8, i8* %27
  %29 = sext i8 %28 to i64
  store i64 %29, i64* @rax

; 0x40113d
  store volatile i64 4198717, i64* @_asm_program_counter
  %30 = load i64, i64* @rax
  %31 = trunc i64 %30 to i32
  %32 = load i64, i64* @rdx
  %33 = trunc i64 %32 to i32
  %34 = add i32 %31, %33
  %35 = and i32 %31, 15
  %36 = and i32 %33, 15
  %37 = add i32 %35, %36
  %38 = icmp ugt i32 %37, 15
  %39 = icmp ult i32 %34, %31
  %40 = xor i32 %31, %34
  %41 = xor i32 %33, %34
  %42 = and i32 %40, %41
  %43 = icmp slt i32 %42, 0
  store i1 %38, i1* @az
  store i1 %39, i1* @cf
  store i1 %43, i1* @of
  %44 = icmp eq i32 %34, 0
  store i1 %44, i1* @zf
  %45 = icmp slt i32 %34, 0
  store i1 %45, i1* @sf
  %46 = trunc i32 %34 to i8
  %47 = call i8 @llvm.ctpop.i8(i8 %46)
  %48 = and i8 %47, 1
  %49 = icmp eq i8 %48, 0
  store i1 %49, i1* @pf
  %50 = zext i32 %34 to i64
  store i64 %50, i64* @rax

; 0x40113f
  store volatile i64 4198719, i64* @_asm_program_counter
  %51 = load i64, i64* @rsp
  %52 = inttoptr i64 %51 to i64*
  %53 = load i64, i64* %52
  store i64 %53, i64* @rbp
  %54 = add i64 %51, 8
  store i64 %54, i64* @rsp

; 0x401140
  store volatile i64 4198720, i64* @_asm_program_counter
  ret i64 undef
}

define i64 @main() {
dec_label_pc_401141:

; 0x401141
  store volatile i64 4198721, i64* @_asm_program_counter
  %0 = load i64, i64* @rbp
  %1 = load i64, i64* @rsp
  %2 = sub i64 %1, 8
  %3 = inttoptr i64 %2 to i64*
  store i64 %0, i64* %3
  store i64 %2, i64* @rsp

; 0x401142
  store volatile i64 4198722, i64* @_asm_program_counter
  %4 = load i64, i64* @rsp
  store i64 %4, i64* @rbp

; 0x401145
  store volatile i64 4198725, i64* @_asm_program_counter
  %5 = load i64, i64* @rsp
  %6 = sub i64 %5, 32
  %7 = and i64 %5, 15
  %8 = sub i64 %7, 0
  %9 = icmp ugt i64 %8, 15
  %10 = icmp ult i64 %5, 32
  %11 = xor i64 %5, 32
  %12 = xor i64 %5, %6
  %13 = and i64 %11, %12
  %14 = icmp slt i64 %13, 0
  store i1 %9, i1* @az
  store i1 %10, i1* @cf
  store i1 %14, i1* @of
  %15 = icmp eq i64 %6, 0
  store i1 %15, i1* @zf
  %16 = icmp slt i64 %6, 0
  store i1 %16, i1* @sf
  %17 = trunc i64 %6 to i8
  %18 = call i8 @llvm.ctpop.i8(i8 %17)
  %19 = and i8 %18, 1
  %20 = icmp eq i8 %19, 0
  store i1 %20, i1* @pf
  store i64 %6, i64* @rsp

; 0x401149
  store volatile i64 4198729, i64* @_asm_program_counter
  %21 = load i64, i64* @rbp
  %22 = add i64 %21, -24
  %23 = inttoptr i64 %22 to i32*
  store i32 1, i32* %23

; 0x401150
  store volatile i64 4198736, i64* @_asm_program_counter
  %24 = load i64, i64* @rbp
  %25 = add i64 %24, -1
  %26 = inttoptr i64 %25 to i8*
  store i8 2, i8* %26

; 0x401154
  store volatile i64 4198740, i64* @_asm_program_counter
  %27 = load i64, i64* @rbp
  %28 = add i64 %27, -1
  %29 = inttoptr i64 %28 to i8*
  %30 = load i8, i8* %29
  %31 = sext i8 %30 to i64
  store i64 %31, i64* @rdx

; 0x401158
  store volatile i64 4198744, i64* @_asm_program_counter
  %32 = load i64, i64* @rbp
  %33 = add i64 %32, -24
  store i64 %33, i64* @rax

; 0x40115c
  store volatile i64 4198748, i64* @_asm_program_counter
  %34 = load i64, i64* @rdx
  %35 = trunc i64 %34 to i32
  %36 = zext i32 %35 to i64
  store i64 %36, i64* @rsi

; 0x40115e
  store volatile i64 4198750, i64* @_asm_program_counter
  %37 = load i64, i64* @rax
  store i64 %37, i64* @rdi

; 0x401161
  store volatile i64 4198753, i64* @_asm_program_counter
  %38 = call i64 @add()
  store i64 %38, i64* @rax

; 0x401166
  store volatile i64 4198758, i64* @_asm_program_counter
  %39 = load i64, i64* @rax
  %40 = trunc i64 %39 to i32
  %41 = load i64, i64* @rbp
  %42 = add i64 %41, -8
  %43 = inttoptr i64 %42 to i32*
  store i32 %40, i32* %43

; 0x401169
  store volatile i64 4198761, i64* @_asm_program_counter
  %44 = load i64, i64* @rbp
  %45 = add i64 %44, -24
  store i64 %45, i64* @rax

; 0x40116d
  store volatile i64 4198765, i64* @_asm_program_counter
  %46 = load i64, i64* @rax
  %47 = load i64, i64* @rbp
  %48 = add i64 %47, -16
  %49 = inttoptr i64 %48 to i64*
  store i64 %46, i64* %49

; 0x401171
  store volatile i64 4198769, i64* @_asm_program_counter
  %50 = load i64, i64* @rbp
  %51 = add i64 %50, -1
  %52 = inttoptr i64 %51 to i8*
  %53 = load i8, i8* %52
  %54 = sext i8 %53 to i64
  store i64 %54, i64* @rdx

; 0x401175
  store volatile i64 4198773, i64* @_asm_program_counter
  %55 = load i64, i64* @rbp
  %56 = add i64 %55, -16
  %57 = inttoptr i64 %56 to i64*
  %58 = load i64, i64* %57
  store i64 %58, i64* @rax

; 0x401179
  store volatile i64 4198777, i64* @_asm_program_counter
  %59 = load i64, i64* @rdx
  %60 = trunc i64 %59 to i32
  %61 = zext i32 %60 to i64
  store i64 %61, i64* @rsi

; 0x40117b
  store volatile i64 4198779, i64* @_asm_program_counter
  %62 = load i64, i64* @rax
  store i64 %62, i64* @rdi

; 0x40117e
  store volatile i64 4198782, i64* @_asm_program_counter
  %63 = call i64 @add()
  store i64 %63, i64* @rax

; 0x401183
  store volatile i64 4198787, i64* @_asm_program_counter
  %64 = load i64, i64* @rax
  %65 = trunc i64 %64 to i32
  %66 = load i64, i64* @rbp
  %67 = add i64 %66, -20
  %68 = inttoptr i64 %67 to i32*
  store i32 %65, i32* %68

; 0x401186
  store volatile i64 4198790, i64* @_asm_program_counter
  %69 = load i64, i64* @rbp
  %70 = add i64 %69, -8
  %71 = inttoptr i64 %70 to i32*
  %72 = load i32, i32* %71
  %73 = zext i32 %72 to i64
  store i64 %73, i64* @rax

; 0x401189
  store volatile i64 4198793, i64* @_asm_program_counter
  %74 = load i64, i64* @rax
  %75 = trunc i64 %74 to i32
  %76 = zext i32 %75 to i64
  store i64 %76, i64* @rsi

; 0x40118b
  store volatile i64 4198795, i64* @_asm_program_counter
  store i64 4202512, i64* @rdi

; 0x401190
  store volatile i64 4198800, i64* @_asm_program_counter
  store i64 0, i64* @rax

; 0x401195
  store volatile i64 4198805, i64* @_asm_program_counter
  %77 = call i64 @function_401030()
  store i64 %77, i64* @rax

; 0x40119a
  store volatile i64 4198810, i64* @_asm_program_counter
  store i64 0, i64* @rax

; 0x40119f
  store volatile i64 4198815, i64* @_asm_program_counter
  %78 = load i64, i64* @rbp
  %79 = inttoptr i64 %78 to i64*
  %80 = load i64, i64* %79
  %81 = add i64 %78, 8
  store i64 %80, i64* @rbp
  store i64 %81, i64* @rsp

; 0x4011a0
  store volatile i64 4198816, i64* @_asm_program_counter
  ret i64 undef
}

define i64 @_fini() {
dec_label_pc_4011a4:

; 0x4011a4
  store volatile i64 4198820, i64* @_asm_program_counter

; 0x4011a8
  store volatile i64 4198824, i64* @_asm_program_counter
  %0 = load i64, i64* @rsp
  %1 = sub i64 %0, 8
  %2 = and i64 %0, 15
  %3 = sub i64 %2, 8
  %4 = icmp ugt i64 %3, 15
  %5 = icmp ult i64 %0, 8
  %6 = xor i64 %0, 8
  %7 = xor i64 %0, %1
  %8 = and i64 %6, %7
  %9 = icmp slt i64 %8, 0
  store i1 %4, i1* @az
  store i1 %5, i1* @cf
  store i1 %9, i1* @of
  %10 = icmp eq i64 %1, 0
  store i1 %10, i1* @zf
  %11 = icmp slt i64 %1, 0
  store i1 %11, i1* @sf
  %12 = trunc i64 %1 to i8
  %13 = call i8 @llvm.ctpop.i8(i8 %12)
  %14 = and i8 %13, 1
  %15 = icmp eq i8 %14, 0
  store i1 %15, i1* @pf
  store i64 %1, i64* @rsp

; 0x4011ac
  store volatile i64 4198828, i64* @_asm_program_counter
  %16 = load i64, i64* @rsp
  %17 = add i64 %16, 8
  %18 = and i64 %16, 15
  %19 = add i64 %18, 8
  %20 = icmp ugt i64 %19, 15
  %21 = icmp ult i64 %17, %16
  %22 = xor i64 %16, %17
  %23 = xor i64 8, %17
  %24 = and i64 %22, %23
  %25 = icmp slt i64 %24, 0
  store i1 %20, i1* @az
  store i1 %21, i1* @cf
  store i1 %25, i1* @of
  %26 = icmp eq i64 %17, 0
  store i1 %26, i1* @zf
  %27 = icmp slt i64 %17, 0
  store i1 %27, i1* @sf
  %28 = trunc i64 %17 to i8
  %29 = call i8 @llvm.ctpop.i8(i8 %28)
  %30 = and i8 %29, 1
  %31 = icmp eq i8 %30, 0
  store i1 %31, i1* @pf
  store i64 %17, i64* @rsp

; 0x4011b0
  store volatile i64 4198832, i64* @_asm_program_counter
  ret i64 undef
}

declare i64 @__libc_start_main()

declare i64 @_ITM_deregisterTMCloneTable()

declare i64 @__gmon_start__()

declare i64 @_ITM_registerTMCloneTable()

declare i64 @printf()

declare void @__pseudo_call(i64)

declare void @__pseudo_return(i64)

declare void @__pseudo_branch(i64)

declare void @__pseudo_cond_branch(i1, i64)

declare void @__frontend_reg_store.fpr(i3, x86_fp80)

declare x86_fp80 @__frontend_reg_load.fpr(i3)

; Function Attrs: nounwind readnone speculatable
declare i8 @llvm.ctpop.i8(i8) #0

declare void @__asm_hlt()

attributes #0 = { nounwind readnone speculatable }
*** IR Dump After Module Verifier ***
define i64 @_init() {
dec_label_pc_401000:

; 0x401000
  store volatile i64 4198400, i64* @_asm_program_counter

; 0x401004
  store volatile i64 4198404, i64* @_asm_program_counter
  %0 = load i64, i64* @rsp
  %1 = sub i64 %0, 8
  %2 = and i64 %0, 15
  %3 = sub i64 %2, 8
  %4 = icmp ugt i64 %3, 15
  %5 = icmp ult i64 %0, 8
  %6 = xor i64 %0, 8
  %7 = xor i64 %0, %1
  %8 = and i64 %6, %7
  %9 = icmp slt i64 %8, 0
  store i1 %4, i1* @az
  store i1 %5, i1* @cf
  store i1 %9, i1* @of
  %10 = icmp eq i64 %1, 0
  store i1 %10, i1* @zf
  %11 = icmp slt i64 %1, 0
  store i1 %11, i1* @sf
  %12 = trunc i64 %1 to i8
  %13 = call i8 @llvm.ctpop.i8(i8 %12)
  %14 = and i8 %13, 1
  %15 = icmp eq i8 %14, 0
  store i1 %15, i1* @pf
  store i64 %1, i64* @rsp

; 0x401008
  store volatile i64 4198408, i64* @_asm_program_counter
  %16 = load i64, i64* inttoptr (i64 4210672 to i64*)
  store i64 %16, i64* @rax

; 0x40100f
  store volatile i64 4198415, i64* @_asm_program_counter
  %17 = load i64, i64* @rax
  %18 = load i64, i64* @rax
  %19 = and i64 %17, %18
  store i1 false, i1* @az
  store i1 false, i1* @cf
  store i1 false, i1* @of
  %20 = icmp eq i64 %19, 0
  store i1 %20, i1* @zf
  %21 = icmp slt i64 %19, 0
  store i1 %21, i1* @sf
  %22 = trunc i64 %19 to i8
  %23 = call i8 @llvm.ctpop.i8(i8 %22)
  %24 = and i8 %23, 1
  %25 = icmp eq i8 %24, 0
  store i1 %25, i1* @pf

; 0x401012
  store volatile i64 4198418, i64* @_asm_program_counter
  %26 = load i1, i1* @zf
  br i1 %26, label %dec_label_pc_401016, label %dec_label_pc_401014

dec_label_pc_401014:                              ; preds = %dec_label_pc_401000

; 0x401014
  store volatile i64 4198420, i64* @_asm_program_counter
  %27 = call i64 @__gmon_start__()
  store i64 %27, i64* @rax
  br label %dec_label_pc_401016

dec_label_pc_401016:                              ; preds = %dec_label_pc_401014, %dec_label_pc_401000

; 0x401016
  store volatile i64 4198422, i64* @_asm_program_counter
  %28 = load i64, i64* @rsp
  %29 = add i64 %28, 8
  %30 = and i64 %28, 15
  %31 = add i64 %30, 8
  %32 = icmp ugt i64 %31, 15
  %33 = icmp ult i64 %29, %28
  %34 = xor i64 %28, %29
  %35 = xor i64 8, %29
  %36 = and i64 %34, %35
  %37 = icmp slt i64 %36, 0
  store i1 %32, i1* @az
  store i1 %33, i1* @cf
  store i1 %37, i1* @of
  %38 = icmp eq i64 %29, 0
  store i1 %38, i1* @zf
  %39 = icmp slt i64 %29, 0
  store i1 %39, i1* @sf
  %40 = trunc i64 %29 to i8
  %41 = call i8 @llvm.ctpop.i8(i8 %40)
  %42 = and i8 %41, 1
  %43 = icmp eq i8 %42, 0
  store i1 %43, i1* @pf
  store i64 %29, i64* @rsp

; 0x40101a
  store volatile i64 4198426, i64* @_asm_program_counter
  ret i64 undef
}
*** IR Dump After Module Verifier ***
define i64 @function_401030() {
dec_label_pc_401030:

; 0x401030
  store volatile i64 4198448, i64* @_asm_program_counter
  %0 = call i64 @printf()
  store i64 %0, i64* @rax
  ret i64 undef
}
*** IR Dump After Module Verifier ***
define i64 @_start() {
dec_label_pc_401040:

; 0x401040
  store volatile i64 4198464, i64* @_asm_program_counter

; 0x401044
  store volatile i64 4198468, i64* @_asm_program_counter
  %0 = load i64, i64* @rbp
  %1 = trunc i64 %0 to i32
  %2 = load i64, i64* @rbp
  %3 = trunc i64 %2 to i32
  %4 = xor i32 %1, %3
  store i1 false, i1* @az
  store i1 false, i1* @cf
  store i1 false, i1* @of
  %5 = icmp eq i32 %4, 0
  store i1 %5, i1* @zf
  %6 = icmp slt i32 %4, 0
  store i1 %6, i1* @sf
  %7 = trunc i32 %4 to i8
  %8 = call i8 @llvm.ctpop.i8(i8 %7)
  %9 = and i8 %8, 1
  %10 = icmp eq i8 %9, 0
  store i1 %10, i1* @pf
  %11 = zext i32 %4 to i64
  store i64 %11, i64* @rbp

; 0x401046
  store volatile i64 4198470, i64* @_asm_program_counter
  %12 = load i64, i64* @rdx
  store i64 %12, i64* @r9

; 0x401049
  store volatile i64 4198473, i64* @_asm_program_counter
  %13 = load i64, i64* @rsp
  %14 = inttoptr i64 %13 to i64*
  %15 = load i64, i64* %14
  store i64 %15, i64* @rsi
  %16 = add i64 %13, 8
  store i64 %16, i64* @rsp

; 0x40104a
  store volatile i64 4198474, i64* @_asm_program_counter
  %17 = load i64, i64* @rsp
  store i64 %17, i64* @rdx

; 0x40104d
  store volatile i64 4198477, i64* @_asm_program_counter
  %18 = load i64, i64* @rsp
  %19 = and i64 %18, -16
  store i1 false, i1* @az
  store i1 false, i1* @cf
  store i1 false, i1* @of
  %20 = icmp eq i64 %19, 0
  store i1 %20, i1* @zf
  %21 = icmp slt i64 %19, 0
  store i1 %21, i1* @sf
  %22 = trunc i64 %19 to i8
  %23 = call i8 @llvm.ctpop.i8(i8 %22)
  %24 = and i8 %23, 1
  %25 = icmp eq i8 %24, 0
  store i1 %25, i1* @pf
  store i64 %19, i64* @rsp

; 0x401051
  store volatile i64 4198481, i64* @_asm_program_counter
  %26 = load i64, i64* @rax
  %27 = load i64, i64* @rsp
  %28 = sub i64 %27, 8
  %29 = inttoptr i64 %28 to i64*
  store i64 %26, i64* %29
  store i64 %28, i64* @rsp

; 0x401052
  store volatile i64 4198482, i64* @_asm_program_counter
  %30 = load i64, i64* @rsp
  %31 = load i64, i64* @rsp
  %32 = sub i64 %31, 8
  %33 = inttoptr i64 %32 to i64*
  store i64 %30, i64* %33
  store i64 %32, i64* @rsp

; 0x401053
  store volatile i64 4198483, i64* @_asm_program_counter
  %34 = load i64, i64* @r8
  %35 = trunc i64 %34 to i32
  %36 = load i64, i64* @r8
  %37 = trunc i64 %36 to i32
  %38 = xor i32 %35, %37
  store i1 false, i1* @az
  store i1 false, i1* @cf
  store i1 false, i1* @of
  %39 = icmp eq i32 %38, 0
  store i1 %39, i1* @zf
  %40 = icmp slt i32 %38, 0
  store i1 %40, i1* @sf
  %41 = trunc i32 %38 to i8
  %42 = call i8 @llvm.ctpop.i8(i8 %41)
  %43 = and i8 %42, 1
  %44 = icmp eq i8 %43, 0
  store i1 %44, i1* @pf
  %45 = zext i32 %38 to i64
  store i64 %45, i64* @r8

; 0x401056
  store volatile i64 4198486, i64* @_asm_program_counter
  %46 = load i64, i64* @rcx
  %47 = trunc i64 %46 to i32
  %48 = load i64, i64* @rcx
  %49 = trunc i64 %48 to i32
  %50 = xor i32 %47, %49
  store i1 false, i1* @az
  store i1 false, i1* @cf
  store i1 false, i1* @of
  %51 = icmp eq i32 %50, 0
  store i1 %51, i1* @zf
  %52 = icmp slt i32 %50, 0
  store i1 %52, i1* @sf
  %53 = trunc i32 %50 to i8
  %54 = call i8 @llvm.ctpop.i8(i8 %53)
  %55 = and i8 %54, 1
  %56 = icmp eq i8 %55, 0
  store i1 %56, i1* @pf
  %57 = zext i32 %50 to i64
  store i64 %57, i64* @rcx

; 0x401058
  store volatile i64 4198488, i64* @_asm_program_counter
  store i64 4198721, i64* @rdi

; 0x40105f
  store volatile i64 4198495, i64* @_asm_program_counter
  %58 = call i64 @__libc_start_main()
  store i64 %58, i64* @rax

; 0x401065
  store volatile i64 4198501, i64* @_asm_program_counter
  call void @__asm_hlt()
  unreachable
}
*** IR Dump After Module Verifier ***
define i64 @_dl_relocate_static_pie() {
dec_label_pc_401070:

; 0x401070
  store volatile i64 4198512, i64* @_asm_program_counter

; 0x401074
  store volatile i64 4198516, i64* @_asm_program_counter
  ret i64 undef
}
*** IR Dump After Module Verifier ***
define i64 @deregister_tm_clones() {
dec_label_pc_401080:

; 0x401080
  store volatile i64 4198528, i64* @_asm_program_counter
  store i64 4210728, i64* @rdi

; 0x401087
  store volatile i64 4198535, i64* @_asm_program_counter
  store i64 4210728, i64* @rax

; 0x40108e
  store volatile i64 4198542, i64* @_asm_program_counter
  %0 = load i64, i64* @rax
  %1 = load i64, i64* @rdi
  %2 = sub i64 %0, %1
  %3 = and i64 %0, 15
  %4 = and i64 %1, 15
  %5 = sub i64 %3, %4
  %6 = icmp ugt i64 %5, 15
  %7 = icmp ult i64 %0, %1
  %8 = xor i64 %0, %1
  %9 = xor i64 %0, %2
  %10 = and i64 %8, %9
  %11 = icmp slt i64 %10, 0
  store i1 %6, i1* @az
  store i1 %7, i1* @cf
  store i1 %11, i1* @of
  %12 = icmp eq i64 %2, 0
  store i1 %12, i1* @zf
  %13 = icmp slt i64 %2, 0
  store i1 %13, i1* @sf
  %14 = trunc i64 %2 to i8
  %15 = call i8 @llvm.ctpop.i8(i8 %14)
  %16 = and i8 %15, 1
  %17 = icmp eq i8 %16, 0
  store i1 %17, i1* @pf

; 0x401091
  store volatile i64 4198545, i64* @_asm_program_counter
  %18 = load i1, i1* @zf
  br i1 %18, label %dec_label_pc_4010a8, label %dec_label_pc_401093

dec_label_pc_401093:                              ; preds = %dec_label_pc_401080

; 0x401093
  store volatile i64 4198547, i64* @_asm_program_counter
  %19 = load i64, i64* inttoptr (i64 4210664 to i64*)
  store i64 %19, i64* @rax

; 0x40109a
  store volatile i64 4198554, i64* @_asm_program_counter
  %20 = load i64, i64* @rax
  %21 = load i64, i64* @rax
  %22 = and i64 %20, %21
  store i1 false, i1* @az
  store i1 false, i1* @cf
  store i1 false, i1* @of
  %23 = icmp eq i64 %22, 0
  store i1 %23, i1* @zf
  %24 = icmp slt i64 %22, 0
  store i1 %24, i1* @sf
  %25 = trunc i64 %22 to i8
  %26 = call i8 @llvm.ctpop.i8(i8 %25)
  %27 = and i8 %26, 1
  %28 = icmp eq i8 %27, 0
  store i1 %28, i1* @pf

; 0x40109d
  store volatile i64 4198557, i64* @_asm_program_counter
  %29 = load i1, i1* @zf
  br i1 %29, label %dec_label_pc_4010a8, label %dec_label_pc_40109f

dec_label_pc_40109f:                              ; preds = %dec_label_pc_401093

; 0x40109f
  store volatile i64 4198559, i64* @_asm_program_counter
  %30 = call i64 @_ITM_deregisterTMCloneTable()
  store i64 %30, i64* @rax
  ret i64 undef

dec_label_pc_4010a8:                              ; preds = %dec_label_pc_401093, %dec_label_pc_401080

; 0x4010a8
  store volatile i64 4198568, i64* @_asm_program_counter
  ret i64 undef
}
*** IR Dump After Module Verifier ***
define i64 @register_tm_clones() {
dec_label_pc_4010b0:

; 0x4010b0
  store volatile i64 4198576, i64* @_asm_program_counter
  store i64 4210728, i64* @rdi

; 0x4010b7
  store volatile i64 4198583, i64* @_asm_program_counter
  store i64 4210728, i64* @rsi

; 0x4010be
  store volatile i64 4198590, i64* @_asm_program_counter
  %0 = load i64, i64* @rsi
  %1 = load i64, i64* @rdi
  %2 = sub i64 %0, %1
  %3 = and i64 %0, 15
  %4 = and i64 %1, 15
  %5 = sub i64 %3, %4
  %6 = icmp ugt i64 %5, 15
  %7 = icmp ult i64 %0, %1
  %8 = xor i64 %0, %1
  %9 = xor i64 %0, %2
  %10 = and i64 %8, %9
  %11 = icmp slt i64 %10, 0
  store i1 %6, i1* @az
  store i1 %7, i1* @cf
  store i1 %11, i1* @of
  %12 = icmp eq i64 %2, 0
  store i1 %12, i1* @zf
  %13 = icmp slt i64 %2, 0
  store i1 %13, i1* @sf
  %14 = trunc i64 %2 to i8
  %15 = call i8 @llvm.ctpop.i8(i8 %14)
  %16 = and i8 %15, 1
  %17 = icmp eq i8 %16, 0
  store i1 %17, i1* @pf
  store i64 %2, i64* @rsi

; 0x4010c1
  store volatile i64 4198593, i64* @_asm_program_counter
  %18 = load i64, i64* @rsi
  store i64 %18, i64* @rax

; 0x4010c4
  store volatile i64 4198596, i64* @_asm_program_counter
  %19 = load i64, i64* @rsi
  %20 = load i1, i1* @of
  %21 = lshr i64 %19, 63
  %22 = icmp eq i64 %21, 0
  store i1 %22, i1* @zf
  %23 = icmp slt i64 %21, 0
  store i1 %23, i1* @sf
  %24 = trunc i64 %21 to i8
  %25 = call i8 @llvm.ctpop.i8(i8 %24)
  %26 = and i8 %25, 1
  %27 = icmp eq i8 %26, 0
  store i1 %27, i1* @pf
  store i64 %21, i64* @rsi
  %28 = and i64 4611686018427387904, %19
  %29 = icmp ne i64 %28, 0
  store i1 %29, i1* @cf
  %30 = icmp slt i64 %19, 0
  %31 = select i1 false, i1 %30, i1 %20
  store i1 %31, i1* @of

; 0x4010c8
  store volatile i64 4198600, i64* @_asm_program_counter
  %32 = load i64, i64* @rax
  %33 = load i1, i1* @of
  %34 = ashr i64 %32, 3
  %35 = icmp eq i64 %34, 0
  store i1 %35, i1* @zf
  %36 = icmp slt i64 %34, 0
  store i1 %36, i1* @sf
  %37 = trunc i64 %34 to i8
  %38 = call i8 @llvm.ctpop.i8(i8 %37)
  %39 = and i8 %38, 1
  %40 = icmp eq i8 %39, 0
  store i1 %40, i1* @pf
  store i64 %34, i64* @rax
  %41 = and i64 4, %32
  %42 = icmp ne i64 %41, 0
  store i1 %42, i1* @cf
  %43 = select i1 false, i1 false, i1 %33
  store i1 %43, i1* @of

; 0x4010cc
  store volatile i64 4198604, i64* @_asm_program_counter
  %44 = load i64, i64* @rsi
  %45 = load i64, i64* @rax
  %46 = add i64 %44, %45
  %47 = and i64 %44, 15
  %48 = and i64 %45, 15
  %49 = add i64 %47, %48
  %50 = icmp ugt i64 %49, 15
  %51 = icmp ult i64 %46, %44
  %52 = xor i64 %44, %46
  %53 = xor i64 %45, %46
  %54 = and i64 %52, %53
  %55 = icmp slt i64 %54, 0
  store i1 %50, i1* @az
  store i1 %51, i1* @cf
  store i1 %55, i1* @of
  %56 = icmp eq i64 %46, 0
  store i1 %56, i1* @zf
  %57 = icmp slt i64 %46, 0
  store i1 %57, i1* @sf
  %58 = trunc i64 %46 to i8
  %59 = call i8 @llvm.ctpop.i8(i8 %58)
  %60 = and i8 %59, 1
  %61 = icmp eq i8 %60, 0
  store i1 %61, i1* @pf
  store i64 %46, i64* @rsi

; 0x4010cf
  store volatile i64 4198607, i64* @_asm_program_counter
  %62 = load i64, i64* @rsi
  %63 = load i1, i1* @of
  %64 = ashr i64 %62, 1
  %65 = icmp eq i64 %64, 0
  store i1 %65, i1* @zf
  %66 = icmp slt i64 %64, 0
  store i1 %66, i1* @sf
  %67 = trunc i64 %64 to i8
  %68 = call i8 @llvm.ctpop.i8(i8 %67)
  %69 = and i8 %68, 1
  %70 = icmp eq i8 %69, 0
  store i1 %70, i1* @pf
  store i64 %64, i64* @rsi
  %71 = and i64 1, %62
  %72 = icmp ne i64 %71, 0
  store i1 %72, i1* @cf
  %73 = select i1 true, i1 false, i1 %63
  store i1 %73, i1* @of

; 0x4010d2
  store volatile i64 4198610, i64* @_asm_program_counter
  %74 = load i1, i1* @zf
  br i1 %74, label %dec_label_pc_4010e8, label %dec_label_pc_4010d4

dec_label_pc_4010d4:                              ; preds = %dec_label_pc_4010b0

; 0x4010d4
  store volatile i64 4198612, i64* @_asm_program_counter
  %75 = load i64, i64* inttoptr (i64 4210680 to i64*)
  store i64 %75, i64* @rax

; 0x4010db
  store volatile i64 4198619, i64* @_asm_program_counter
  %76 = load i64, i64* @rax
  %77 = load i64, i64* @rax
  %78 = and i64 %76, %77
  store i1 false, i1* @az
  store i1 false, i1* @cf
  store i1 false, i1* @of
  %79 = icmp eq i64 %78, 0
  store i1 %79, i1* @zf
  %80 = icmp slt i64 %78, 0
  store i1 %80, i1* @sf
  %81 = trunc i64 %78 to i8
  %82 = call i8 @llvm.ctpop.i8(i8 %81)
  %83 = and i8 %82, 1
  %84 = icmp eq i8 %83, 0
  store i1 %84, i1* @pf

; 0x4010de
  store volatile i64 4198622, i64* @_asm_program_counter
  %85 = load i1, i1* @zf
  br i1 %85, label %dec_label_pc_4010e8, label %dec_label_pc_4010e0

dec_label_pc_4010e0:                              ; preds = %dec_label_pc_4010d4

; 0x4010e0
  store volatile i64 4198624, i64* @_asm_program_counter
  %86 = call i64 @_ITM_registerTMCloneTable()
  store i64 %86, i64* @rax
  ret i64 undef

dec_label_pc_4010e8:                              ; preds = %dec_label_pc_4010d4, %dec_label_pc_4010b0

; 0x4010e8
  store volatile i64 4198632, i64* @_asm_program_counter
  ret i64 undef
}
*** IR Dump After Module Verifier ***
define i64 @__do_global_dtors_aux() {
dec_label_pc_4010f0:

; 0x4010f0
  store volatile i64 4198640, i64* @_asm_program_counter

; 0x4010f4
  store volatile i64 4198644, i64* @_asm_program_counter
  %0 = load i8, i8* inttoptr (i64 4210724 to i8*)
  %1 = sub i8 %0, 0
  %2 = and i8 %0, 15
  %3 = sub i8 %2, 0
  %4 = icmp ugt i8 %3, 15
  %5 = icmp ult i8 %0, 0
  %6 = xor i8 %0, 0
  %7 = xor i8 %0, %1
  %8 = and i8 %6, %7
  %9 = icmp slt i8 %8, 0
  store i1 %4, i1* @az
  store i1 %5, i1* @cf
  store i1 %9, i1* @of
  %10 = icmp eq i8 %1, 0
  store i1 %10, i1* @zf
  %11 = icmp slt i8 %1, 0
  store i1 %11, i1* @sf
  %12 = call i8 @llvm.ctpop.i8(i8 %1)
  %13 = and i8 %12, 1
  %14 = icmp eq i8 %13, 0
  store i1 %14, i1* @pf

; 0x4010fb
  store volatile i64 4198651, i64* @_asm_program_counter
  %15 = load i1, i1* @zf
  %16 = icmp eq i1 %15, false
  br i1 %16, label %dec_label_pc_401110, label %dec_label_pc_4010fd

dec_label_pc_4010fd:                              ; preds = %dec_label_pc_4010f0

; 0x4010fd
  store volatile i64 4198653, i64* @_asm_program_counter
  %17 = load i64, i64* @rbp
  %18 = load i64, i64* @rsp
  %19 = sub i64 %18, 8
  %20 = inttoptr i64 %19 to i64*
  store i64 %17, i64* %20
  store i64 %19, i64* @rsp

; 0x4010fe
  store volatile i64 4198654, i64* @_asm_program_counter
  %21 = load i64, i64* @rsp
  store i64 %21, i64* @rbp

; 0x401101
  store volatile i64 4198657, i64* @_asm_program_counter
  %22 = call i64 @deregister_tm_clones()
  store i64 %22, i64* @rax

; 0x401106
  store volatile i64 4198662, i64* @_asm_program_counter
  store i8 1, i8* inttoptr (i64 4210724 to i8*)

; 0x40110d
  store volatile i64 4198669, i64* @_asm_program_counter
  %23 = load i64, i64* @rsp
  %24 = inttoptr i64 %23 to i64*
  %25 = load i64, i64* %24
  store i64 %25, i64* @rbp
  %26 = add i64 %23, 8
  store i64 %26, i64* @rsp

; 0x40110e
  store volatile i64 4198670, i64* @_asm_program_counter
  ret i64 undef

dec_label_pc_401110:                              ; preds = %dec_label_pc_4010f0

; 0x401110
  store volatile i64 4198672, i64* @_asm_program_counter
  ret i64 undef
}
*** IR Dump After Module Verifier ***
define i64 @frame_dummy() {
dec_label_pc_401120:

; 0x401120
  store volatile i64 4198688, i64* @_asm_program_counter

; 0x401124
  store volatile i64 4198692, i64* @_asm_program_counter
  %0 = call i64 @register_tm_clones()
  store i64 %0, i64* @rax
  ret i64 undef
}
*** IR Dump After Module Verifier ***
define i64 @add() {
dec_label_pc_401126:

; 0x401126
  store volatile i64 4198694, i64* @_asm_program_counter
  %0 = load i64, i64* @rbp
  %1 = load i64, i64* @rsp
  %2 = sub i64 %1, 8
  %3 = inttoptr i64 %2 to i64*
  store i64 %0, i64* %3
  store i64 %2, i64* @rsp

; 0x401127
  store volatile i64 4198695, i64* @_asm_program_counter
  %4 = load i64, i64* @rsp
  store i64 %4, i64* @rbp

; 0x40112a
  store volatile i64 4198698, i64* @_asm_program_counter
  %5 = load i64, i64* @rdi
  %6 = load i64, i64* @rbp
  %7 = add i64 %6, -8
  %8 = inttoptr i64 %7 to i64*
  store i64 %5, i64* %8

; 0x40112e
  store volatile i64 4198702, i64* @_asm_program_counter
  %9 = load i64, i64* @rsi
  %10 = trunc i64 %9 to i32
  %11 = zext i32 %10 to i64
  store i64 %11, i64* @rax

; 0x401130
  store volatile i64 4198704, i64* @_asm_program_counter
  %12 = load i64, i64* @rax
  %13 = trunc i64 %12 to i8
  %14 = load i64, i64* @rbp
  %15 = add i64 %14, -12
  %16 = inttoptr i64 %15 to i8*
  store i8 %13, i8* %16

; 0x401133
  store volatile i64 4198707, i64* @_asm_program_counter
  %17 = load i64, i64* @rbp
  %18 = add i64 %17, -8
  %19 = inttoptr i64 %18 to i64*
  %20 = load i64, i64* %19
  store i64 %20, i64* @rax

; 0x401137
  store volatile i64 4198711, i64* @_asm_program_counter
  %21 = load i64, i64* @rax
  %22 = inttoptr i64 %21 to i32*
  %23 = load i32, i32* %22
  %24 = zext i32 %23 to i64
  store i64 %24, i64* @rdx

; 0x401139
  store volatile i64 4198713, i64* @_asm_program_counter
  %25 = load i64, i64* @rbp
  %26 = add i64 %25, -12
  %27 = inttoptr i64 %26 to i8*
  %28 = load i8, i8* %27
  %29 = sext i8 %28 to i64
  store i64 %29, i64* @rax

; 0x40113d
  store volatile i64 4198717, i64* @_asm_program_counter
  %30 = load i64, i64* @rax
  %31 = trunc i64 %30 to i32
  %32 = load i64, i64* @rdx
  %33 = trunc i64 %32 to i32
  %34 = add i32 %31, %33
  %35 = and i32 %31, 15
  %36 = and i32 %33, 15
  %37 = add i32 %35, %36
  %38 = icmp ugt i32 %37, 15
  %39 = icmp ult i32 %34, %31
  %40 = xor i32 %31, %34
  %41 = xor i32 %33, %34
  %42 = and i32 %40, %41
  %43 = icmp slt i32 %42, 0
  store i1 %38, i1* @az
  store i1 %39, i1* @cf
  store i1 %43, i1* @of
  %44 = icmp eq i32 %34, 0
  store i1 %44, i1* @zf
  %45 = icmp slt i32 %34, 0
  store i1 %45, i1* @sf
  %46 = trunc i32 %34 to i8
  %47 = call i8 @llvm.ctpop.i8(i8 %46)
  %48 = and i8 %47, 1
  %49 = icmp eq i8 %48, 0
  store i1 %49, i1* @pf
  %50 = zext i32 %34 to i64
  store i64 %50, i64* @rax

; 0x40113f
  store volatile i64 4198719, i64* @_asm_program_counter
  %51 = load i64, i64* @rsp
  %52 = inttoptr i64 %51 to i64*
  %53 = load i64, i64* %52
  store i64 %53, i64* @rbp
  %54 = add i64 %51, 8
  store i64 %54, i64* @rsp

; 0x401140
  store volatile i64 4198720, i64* @_asm_program_counter
  ret i64 undef
}
*** IR Dump After Module Verifier ***
define i64 @main() {
dec_label_pc_401141:

; 0x401141
  store volatile i64 4198721, i64* @_asm_program_counter
  %0 = load i64, i64* @rbp
  %1 = load i64, i64* @rsp
  %2 = sub i64 %1, 8
  %3 = inttoptr i64 %2 to i64*
  store i64 %0, i64* %3
  store i64 %2, i64* @rsp

; 0x401142
  store volatile i64 4198722, i64* @_asm_program_counter
  %4 = load i64, i64* @rsp
  store i64 %4, i64* @rbp

; 0x401145
  store volatile i64 4198725, i64* @_asm_program_counter
  %5 = load i64, i64* @rsp
  %6 = sub i64 %5, 32
  %7 = and i64 %5, 15
  %8 = sub i64 %7, 0
  %9 = icmp ugt i64 %8, 15
  %10 = icmp ult i64 %5, 32
  %11 = xor i64 %5, 32
  %12 = xor i64 %5, %6
  %13 = and i64 %11, %12
  %14 = icmp slt i64 %13, 0
  store i1 %9, i1* @az
  store i1 %10, i1* @cf
  store i1 %14, i1* @of
  %15 = icmp eq i64 %6, 0
  store i1 %15, i1* @zf
  %16 = icmp slt i64 %6, 0
  store i1 %16, i1* @sf
  %17 = trunc i64 %6 to i8
  %18 = call i8 @llvm.ctpop.i8(i8 %17)
  %19 = and i8 %18, 1
  %20 = icmp eq i8 %19, 0
  store i1 %20, i1* @pf
  store i64 %6, i64* @rsp

; 0x401149
  store volatile i64 4198729, i64* @_asm_program_counter
  %21 = load i64, i64* @rbp
  %22 = add i64 %21, -24
  %23 = inttoptr i64 %22 to i32*
  store i32 1, i32* %23

; 0x401150
  store volatile i64 4198736, i64* @_asm_program_counter
  %24 = load i64, i64* @rbp
  %25 = add i64 %24, -1
  %26 = inttoptr i64 %25 to i8*
  store i8 2, i8* %26

; 0x401154
  store volatile i64 4198740, i64* @_asm_program_counter
  %27 = load i64, i64* @rbp
  %28 = add i64 %27, -1
  %29 = inttoptr i64 %28 to i8*
  %30 = load i8, i8* %29
  %31 = sext i8 %30 to i64
  store i64 %31, i64* @rdx

; 0x401158
  store volatile i64 4198744, i64* @_asm_program_counter
  %32 = load i64, i64* @rbp
  %33 = add i64 %32, -24
  store i64 %33, i64* @rax

; 0x40115c
  store volatile i64 4198748, i64* @_asm_program_counter
  %34 = load i64, i64* @rdx
  %35 = trunc i64 %34 to i32
  %36 = zext i32 %35 to i64
  store i64 %36, i64* @rsi

; 0x40115e
  store volatile i64 4198750, i64* @_asm_program_counter
  %37 = load i64, i64* @rax
  store i64 %37, i64* @rdi

; 0x401161
  store volatile i64 4198753, i64* @_asm_program_counter
  %38 = call i64 @add()
  store i64 %38, i64* @rax

; 0x401166
  store volatile i64 4198758, i64* @_asm_program_counter
  %39 = load i64, i64* @rax
  %40 = trunc i64 %39 to i32
  %41 = load i64, i64* @rbp
  %42 = add i64 %41, -8
  %43 = inttoptr i64 %42 to i32*
  store i32 %40, i32* %43

; 0x401169
  store volatile i64 4198761, i64* @_asm_program_counter
  %44 = load i64, i64* @rbp
  %45 = add i64 %44, -24
  store i64 %45, i64* @rax

; 0x40116d
  store volatile i64 4198765, i64* @_asm_program_counter
  %46 = load i64, i64* @rax
  %47 = load i64, i64* @rbp
  %48 = add i64 %47, -16
  %49 = inttoptr i64 %48 to i64*
  store i64 %46, i64* %49

; 0x401171
  store volatile i64 4198769, i64* @_asm_program_counter
  %50 = load i64, i64* @rbp
  %51 = add i64 %50, -1
  %52 = inttoptr i64 %51 to i8*
  %53 = load i8, i8* %52
  %54 = sext i8 %53 to i64
  store i64 %54, i64* @rdx

; 0x401175
  store volatile i64 4198773, i64* @_asm_program_counter
  %55 = load i64, i64* @rbp
  %56 = add i64 %55, -16
  %57 = inttoptr i64 %56 to i64*
  %58 = load i64, i64* %57
  store i64 %58, i64* @rax

; 0x401179
  store volatile i64 4198777, i64* @_asm_program_counter
  %59 = load i64, i64* @rdx
  %60 = trunc i64 %59 to i32
  %61 = zext i32 %60 to i64
  store i64 %61, i64* @rsi

; 0x40117b
  store volatile i64 4198779, i64* @_asm_program_counter
  %62 = load i64, i64* @rax
  store i64 %62, i64* @rdi

; 0x40117e
  store volatile i64 4198782, i64* @_asm_program_counter
  %63 = call i64 @add()
  store i64 %63, i64* @rax

; 0x401183
  store volatile i64 4198787, i64* @_asm_program_counter
  %64 = load i64, i64* @rax
  %65 = trunc i64 %64 to i32
  %66 = load i64, i64* @rbp
  %67 = add i64 %66, -20
  %68 = inttoptr i64 %67 to i32*
  store i32 %65, i32* %68

; 0x401186
  store volatile i64 4198790, i64* @_asm_program_counter
  %69 = load i64, i64* @rbp
  %70 = add i64 %69, -8
  %71 = inttoptr i64 %70 to i32*
  %72 = load i32, i32* %71
  %73 = zext i32 %72 to i64
  store i64 %73, i64* @rax

; 0x401189
  store volatile i64 4198793, i64* @_asm_program_counter
  %74 = load i64, i64* @rax
  %75 = trunc i64 %74 to i32
  %76 = zext i32 %75 to i64
  store i64 %76, i64* @rsi

; 0x40118b
  store volatile i64 4198795, i64* @_asm_program_counter
  store i64 4202512, i64* @rdi

; 0x401190
  store volatile i64 4198800, i64* @_asm_program_counter
  store i64 0, i64* @rax

; 0x401195
  store volatile i64 4198805, i64* @_asm_program_counter
  %77 = call i64 @function_401030()
  store i64 %77, i64* @rax

; 0x40119a
  store volatile i64 4198810, i64* @_asm_program_counter
  store i64 0, i64* @rax

; 0x40119f
  store volatile i64 4198815, i64* @_asm_program_counter
  %78 = load i64, i64* @rbp
  %79 = inttoptr i64 %78 to i64*
  %80 = load i64, i64* %79
  %81 = add i64 %78, 8
  store i64 %80, i64* @rbp
  store i64 %81, i64* @rsp

; 0x4011a0
  store volatile i64 4198816, i64* @_asm_program_counter
  ret i64 undef
}
*** IR Dump After Module Verifier ***
define i64 @_fini() {
dec_label_pc_4011a4:

; 0x4011a4
  store volatile i64 4198820, i64* @_asm_program_counter

; 0x4011a8
  store volatile i64 4198824, i64* @_asm_program_counter
  %0 = load i64, i64* @rsp
  %1 = sub i64 %0, 8
  %2 = and i64 %0, 15
  %3 = sub i64 %2, 8
  %4 = icmp ugt i64 %3, 15
  %5 = icmp ult i64 %0, 8
  %6 = xor i64 %0, 8
  %7 = xor i64 %0, %1
  %8 = and i64 %6, %7
  %9 = icmp slt i64 %8, 0
  store i1 %4, i1* @az
  store i1 %5, i1* @cf
  store i1 %9, i1* @of
  %10 = icmp eq i64 %1, 0
  store i1 %10, i1* @zf
  %11 = icmp slt i64 %1, 0
  store i1 %11, i1* @sf
  %12 = trunc i64 %1 to i8
  %13 = call i8 @llvm.ctpop.i8(i8 %12)
  %14 = and i8 %13, 1
  %15 = icmp eq i8 %14, 0
  store i1 %15, i1* @pf
  store i64 %1, i64* @rsp

; 0x4011ac
  store volatile i64 4198828, i64* @_asm_program_counter
  %16 = load i64, i64* @rsp
  %17 = add i64 %16, 8
  %18 = and i64 %16, 15
  %19 = add i64 %18, 8
  %20 = icmp ugt i64 %19, 15
  %21 = icmp ult i64 %17, %16
  %22 = xor i64 %16, %17
  %23 = xor i64 8, %17
  %24 = and i64 %22, %23
  %25 = icmp slt i64 %24, 0
  store i1 %20, i1* @az
  store i1 %21, i1* @cf
  store i1 %25, i1* @of
  %26 = icmp eq i64 %17, 0
  store i1 %26, i1* @zf
  %27 = icmp slt i64 %17, 0
  store i1 %27, i1* @sf
  %28 = trunc i64 %17 to i8
  %29 = call i8 @llvm.ctpop.i8(i8 %28)
  %30 = and i8 %29, 1
  %31 = icmp eq i8 %30, 0
  store i1 %31, i1* @pf
  store i64 %17, i64* @rsp

; 0x4011b0
  store volatile i64 4198832, i64* @_asm_program_counter
  ret i64 undef
}
*** IR Dump After x86 address spaces optimization ***
source_filename = "test"
target datalayout = "e-m:e-p:64:64-i64:64-f80:128-n8:16:32:64-S128"

@_asm_program_counter = internal global i64 0
@cf = internal global i1 false
@pf = internal global i1 false
@az = internal global i1 false
@zf = internal global i1 false
@sf = internal global i1 false
@tf = internal global i1 false
@if = internal global i1 false
@df = internal global i1 false
@of = internal global i1 false
@iopl = internal global i2 0
@nt = internal global i1 false
@rf = internal global i1 false
@vm = internal global i1 false
@ac = internal global i1 false
@vif = internal global i1 false
@vip = internal global i1 false
@id = internal global i1 false
@rflags = internal global i64 0
@ss = internal global i16 0
@cs = internal global i16 0
@ds = internal global i16 0
@es = internal global i16 0
@fs = internal global i16 0
@gs = internal global i16 0
@st0 = internal global x86_fp80 0xK00000000000000000000
@st1 = internal global x86_fp80 0xK00000000000000000000
@st2 = internal global x86_fp80 0xK00000000000000000000
@st3 = internal global x86_fp80 0xK00000000000000000000
@st4 = internal global x86_fp80 0xK00000000000000000000
@st5 = internal global x86_fp80 0xK00000000000000000000
@st6 = internal global x86_fp80 0xK00000000000000000000
@st7 = internal global x86_fp80 0xK00000000000000000000
@fpu_stat_IE = internal global i1 false
@fpu_stat_DE = internal global i1 false
@fpu_stat_ZE = internal global i1 false
@fpu_stat_OE = internal global i1 false
@fpu_stat_UE = internal global i1 false
@fpu_stat_PE = internal global i1 false
@fpu_stat_SF = internal global i1 false
@fpu_stat_ES = internal global i1 false
@fpu_stat_C0 = internal global i1 false
@fpu_stat_C1 = internal global i1 false
@fpu_stat_C2 = internal global i1 false
@fpu_stat_C3 = internal global i1 false
@fpu_stat_TOP = internal global i3 0
@fpu_stat_B = internal global i1 false
@fpu_control_IM = internal global i1 false
@fpu_control_DM = internal global i1 false
@fpu_control_ZM = internal global i1 false
@fpu_control_OM = internal global i1 false
@fpu_control_UM = internal global i1 false
@fpu_control_PM = internal global i1 false
@fpu_control_PC = internal global i2 0
@fpu_control_RC = internal global i2 0
@fpu_control_X = internal global i1 false
@fp0 = internal global double 0.000000e+00
@fp1 = internal global double 0.000000e+00
@fp2 = internal global double 0.000000e+00
@fp3 = internal global double 0.000000e+00
@fp4 = internal global double 0.000000e+00
@fp5 = internal global double 0.000000e+00
@fp6 = internal global double 0.000000e+00
@fp7 = internal global double 0.000000e+00
@k0 = internal global i64 0
@k1 = internal global i64 0
@k2 = internal global i64 0
@k3 = internal global i64 0
@k4 = internal global i64 0
@k5 = internal global i64 0
@k6 = internal global i64 0
@k7 = internal global i64 0
@mm0 = internal global i64 0
@mm1 = internal global i64 0
@mm2 = internal global i64 0
@mm3 = internal global i64 0
@mm4 = internal global i64 0
@mm5 = internal global i64 0
@mm6 = internal global i64 0
@mm7 = internal global i64 0
@xmm0 = internal global i128 0
@xmm1 = internal global i128 0
@xmm2 = internal global i128 0
@xmm3 = internal global i128 0
@xmm4 = internal global i128 0
@xmm5 = internal global i128 0
@xmm6 = internal global i128 0
@xmm7 = internal global i128 0
@xmm8 = internal global i128 0
@xmm9 = internal global i128 0
@xmm10 = internal global i128 0
@xmm11 = internal global i128 0
@xmm12 = internal global i128 0
@xmm13 = internal global i128 0
@xmm14 = internal global i128 0
@xmm15 = internal global i128 0
@xmm16 = internal global i128 0
@xmm17 = internal global i128 0
@xmm18 = internal global i128 0
@xmm19 = internal global i128 0
@xmm20 = internal global i128 0
@xmm21 = internal global i128 0
@xmm22 = internal global i128 0
@xmm23 = internal global i128 0
@xmm24 = internal global i128 0
@xmm25 = internal global i128 0
@xmm26 = internal global i128 0
@xmm27 = internal global i128 0
@xmm28 = internal global i128 0
@xmm29 = internal global i128 0
@xmm30 = internal global i128 0
@xmm31 = internal global i128 0
@ymm0 = internal global i256 0
@ymm1 = internal global i256 0
@ymm2 = internal global i256 0
@ymm3 = internal global i256 0
@ymm4 = internal global i256 0
@ymm5 = internal global i256 0
@ymm6 = internal global i256 0
@ymm7 = internal global i256 0
@ymm8 = internal global i256 0
@ymm9 = internal global i256 0
@ymm10 = internal global i256 0
@ymm11 = internal global i256 0
@ymm12 = internal global i256 0
@ymm13 = internal global i256 0
@ymm14 = internal global i256 0
@ymm15 = internal global i256 0
@ymm16 = internal global i256 0
@ymm17 = internal global i256 0
@ymm18 = internal global i256 0
@ymm19 = internal global i256 0
@ymm20 = internal global i256 0
@ymm21 = internal global i256 0
@ymm22 = internal global i256 0
@ymm23 = internal global i256 0
@ymm24 = internal global i256 0
@ymm25 = internal global i256 0
@ymm26 = internal global i256 0
@ymm27 = internal global i256 0
@ymm28 = internal global i256 0
@ymm29 = internal global i256 0
@ymm30 = internal global i256 0
@ymm31 = internal global i256 0
@zmm0 = internal global i512 0
@zmm1 = internal global i512 0
@zmm2 = internal global i512 0
@zmm3 = internal global i512 0
@zmm4 = internal global i512 0
@zmm5 = internal global i512 0
@zmm6 = internal global i512 0
@zmm7 = internal global i512 0
@zmm8 = internal global i512 0
@zmm9 = internal global i512 0
@zmm10 = internal global i512 0
@zmm11 = internal global i512 0
@zmm12 = internal global i512 0
@zmm13 = internal global i512 0
@zmm14 = internal global i512 0
@zmm15 = internal global i512 0
@zmm16 = internal global i512 0
@zmm17 = internal global i512 0
@zmm18 = internal global i512 0
@zmm19 = internal global i512 0
@zmm20 = internal global i512 0
@zmm21 = internal global i512 0
@zmm22 = internal global i512 0
@zmm23 = internal global i512 0
@zmm24 = internal global i512 0
@zmm25 = internal global i512 0
@zmm26 = internal global i512 0
@zmm27 = internal global i512 0
@zmm28 = internal global i512 0
@zmm29 = internal global i512 0
@zmm30 = internal global i512 0
@zmm31 = internal global i512 0
@bnd0 = internal global i128 0
@bnd1 = internal global i128 0
@bnd2 = internal global i128 0
@bnd3 = internal global i128 0
@dr0 = internal global i64 0
@dr1 = internal global i64 0
@dr2 = internal global i64 0
@dr3 = internal global i64 0
@dr4 = internal global i64 0
@dr5 = internal global i64 0
@dr6 = internal global i64 0
@dr7 = internal global i64 0
@dr8 = internal global i64 0
@dr9 = internal global i64 0
@dr10 = internal global i64 0
@dr11 = internal global i64 0
@dr12 = internal global i64 0
@dr13 = internal global i64 0
@dr14 = internal global i64 0
@dr15 = internal global i64 0
@cr0 = internal global i64 0
@cr1 = internal global i64 0
@cr2 = internal global i64 0
@cr3 = internal global i64 0
@cr4 = internal global i64 0
@cr5 = internal global i64 0
@cr6 = internal global i64 0
@cr7 = internal global i64 0
@cr8 = internal global i64 0
@cr9 = internal global i64 0
@cr10 = internal global i64 0
@cr11 = internal global i64 0
@cr12 = internal global i64 0
@cr13 = internal global i64 0
@cr14 = internal global i64 0
@cr15 = internal global i64 0
@fpsw = internal global i64 0
@rax = internal global i64 0
@rcx = internal global i64 0
@rdx = internal global i64 0
@rbx = internal global i64 0
@rsp = internal global i64 0
@rbp = internal global i64 0
@rsi = internal global i64 0
@rdi = internal global i64 0
@r8 = internal global i64 0
@r9 = internal global i64 0
@r10 = internal global i64 0
@r11 = internal global i64 0
@r12 = internal global i64 0
@r13 = internal global i64 0
@r14 = internal global i64 0
@r15 = internal global i64 0
@rip = internal global i64 0
@riz = internal global i64 0

define i64 @_init() {
dec_label_pc_401000:

; 0x401000
  store volatile i64 4198400, i64* @_asm_program_counter

; 0x401004
  store volatile i64 4198404, i64* @_asm_program_counter
  %0 = load i64, i64* @rsp
  %1 = sub i64 %0, 8
  %2 = and i64 %0, 15
  %3 = sub i64 %2, 8
  %4 = icmp ugt i64 %3, 15
  %5 = icmp ult i64 %0, 8
  %6 = xor i64 %0, 8
  %7 = xor i64 %0, %1
  %8 = and i64 %6, %7
  %9 = icmp slt i64 %8, 0
  store i1 %4, i1* @az
  store i1 %5, i1* @cf
  store i1 %9, i1* @of
  %10 = icmp eq i64 %1, 0
  store i1 %10, i1* @zf
  %11 = icmp slt i64 %1, 0
  store i1 %11, i1* @sf
  %12 = trunc i64 %1 to i8
  %13 = call i8 @llvm.ctpop.i8(i8 %12)
  %14 = and i8 %13, 1
  %15 = icmp eq i8 %14, 0
  store i1 %15, i1* @pf
  store i64 %1, i64* @rsp

; 0x401008
  store volatile i64 4198408, i64* @_asm_program_counter
  %16 = load i64, i64* inttoptr (i64 4210672 to i64*)
  store i64 %16, i64* @rax

; 0x40100f
  store volatile i64 4198415, i64* @_asm_program_counter
  %17 = load i64, i64* @rax
  %18 = load i64, i64* @rax
  %19 = and i64 %17, %18
  store i1 false, i1* @az
  store i1 false, i1* @cf
  store i1 false, i1* @of
  %20 = icmp eq i64 %19, 0
  store i1 %20, i1* @zf
  %21 = icmp slt i64 %19, 0
  store i1 %21, i1* @sf
  %22 = trunc i64 %19 to i8
  %23 = call i8 @llvm.ctpop.i8(i8 %22)
  %24 = and i8 %23, 1
  %25 = icmp eq i8 %24, 0
  store i1 %25, i1* @pf

; 0x401012
  store volatile i64 4198418, i64* @_asm_program_counter
  %26 = load i1, i1* @zf
  br i1 %26, label %dec_label_pc_401016, label %dec_label_pc_401014

dec_label_pc_401014:                              ; preds = %dec_label_pc_401000

; 0x401014
  store volatile i64 4198420, i64* @_asm_program_counter
  %27 = call i64 @__gmon_start__()
  store i64 %27, i64* @rax
  br label %dec_label_pc_401016

dec_label_pc_401016:                              ; preds = %dec_label_pc_401014, %dec_label_pc_401000

; 0x401016
  store volatile i64 4198422, i64* @_asm_program_counter
  %28 = load i64, i64* @rsp
  %29 = add i64 %28, 8
  %30 = and i64 %28, 15
  %31 = add i64 %30, 8
  %32 = icmp ugt i64 %31, 15
  %33 = icmp ult i64 %29, %28
  %34 = xor i64 %28, %29
  %35 = xor i64 8, %29
  %36 = and i64 %34, %35
  %37 = icmp slt i64 %36, 0
  store i1 %32, i1* @az
  store i1 %33, i1* @cf
  store i1 %37, i1* @of
  %38 = icmp eq i64 %29, 0
  store i1 %38, i1* @zf
  %39 = icmp slt i64 %29, 0
  store i1 %39, i1* @sf
  %40 = trunc i64 %29 to i8
  %41 = call i8 @llvm.ctpop.i8(i8 %40)
  %42 = and i8 %41, 1
  %43 = icmp eq i8 %42, 0
  store i1 %43, i1* @pf
  store i64 %29, i64* @rsp

; 0x40101a
  store volatile i64 4198426, i64* @_asm_program_counter
  ret i64 undef
}

define i64 @function_401030() {
dec_label_pc_401030:

; 0x401030
  store volatile i64 4198448, i64* @_asm_program_counter
  %0 = call i64 @printf()
  store i64 %0, i64* @rax
  ret i64 undef
}

define i64 @_start() {
dec_label_pc_401040:

; 0x401040
  store volatile i64 4198464, i64* @_asm_program_counter

; 0x401044
  store volatile i64 4198468, i64* @_asm_program_counter
  %0 = load i64, i64* @rbp
  %1 = trunc i64 %0 to i32
  %2 = load i64, i64* @rbp
  %3 = trunc i64 %2 to i32
  %4 = xor i32 %1, %3
  store i1 false, i1* @az
  store i1 false, i1* @cf
  store i1 false, i1* @of
  %5 = icmp eq i32 %4, 0
  store i1 %5, i1* @zf
  %6 = icmp slt i32 %4, 0
  store i1 %6, i1* @sf
  %7 = trunc i32 %4 to i8
  %8 = call i8 @llvm.ctpop.i8(i8 %7)
  %9 = and i8 %8, 1
  %10 = icmp eq i8 %9, 0
  store i1 %10, i1* @pf
  %11 = zext i32 %4 to i64
  store i64 %11, i64* @rbp

; 0x401046
  store volatile i64 4198470, i64* @_asm_program_counter
  %12 = load i64, i64* @rdx
  store i64 %12, i64* @r9

; 0x401049
  store volatile i64 4198473, i64* @_asm_program_counter
  %13 = load i64, i64* @rsp
  %14 = inttoptr i64 %13 to i64*
  %15 = load i64, i64* %14
  store i64 %15, i64* @rsi
  %16 = add i64 %13, 8
  store i64 %16, i64* @rsp

; 0x40104a
  store volatile i64 4198474, i64* @_asm_program_counter
  %17 = load i64, i64* @rsp
  store i64 %17, i64* @rdx

; 0x40104d
  store volatile i64 4198477, i64* @_asm_program_counter
  %18 = load i64, i64* @rsp
  %19 = and i64 %18, -16
  store i1 false, i1* @az
  store i1 false, i1* @cf
  store i1 false, i1* @of
  %20 = icmp eq i64 %19, 0
  store i1 %20, i1* @zf
  %21 = icmp slt i64 %19, 0
  store i1 %21, i1* @sf
  %22 = trunc i64 %19 to i8
  %23 = call i8 @llvm.ctpop.i8(i8 %22)
  %24 = and i8 %23, 1
  %25 = icmp eq i8 %24, 0
  store i1 %25, i1* @pf
  store i64 %19, i64* @rsp

; 0x401051
  store volatile i64 4198481, i64* @_asm_program_counter
  %26 = load i64, i64* @rax
  %27 = load i64, i64* @rsp
  %28 = sub i64 %27, 8
  %29 = inttoptr i64 %28 to i64*
  store i64 %26, i64* %29
  store i64 %28, i64* @rsp

; 0x401052
  store volatile i64 4198482, i64* @_asm_program_counter
  %30 = load i64, i64* @rsp
  %31 = load i64, i64* @rsp
  %32 = sub i64 %31, 8
  %33 = inttoptr i64 %32 to i64*
  store i64 %30, i64* %33
  store i64 %32, i64* @rsp

; 0x401053
  store volatile i64 4198483, i64* @_asm_program_counter
  %34 = load i64, i64* @r8
  %35 = trunc i64 %34 to i32
  %36 = load i64, i64* @r8
  %37 = trunc i64 %36 to i32
  %38 = xor i32 %35, %37
  store i1 false, i1* @az
  store i1 false, i1* @cf
  store i1 false, i1* @of
  %39 = icmp eq i32 %38, 0
  store i1 %39, i1* @zf
  %40 = icmp slt i32 %38, 0
  store i1 %40, i1* @sf
  %41 = trunc i32 %38 to i8
  %42 = call i8 @llvm.ctpop.i8(i8 %41)
  %43 = and i8 %42, 1
  %44 = icmp eq i8 %43, 0
  store i1 %44, i1* @pf
  %45 = zext i32 %38 to i64
  store i64 %45, i64* @r8

; 0x401056
  store volatile i64 4198486, i64* @_asm_program_counter
  %46 = load i64, i64* @rcx
  %47 = trunc i64 %46 to i32
  %48 = load i64, i64* @rcx
  %49 = trunc i64 %48 to i32
  %50 = xor i32 %47, %49
  store i1 false, i1* @az
  store i1 false, i1* @cf
  store i1 false, i1* @of
  %51 = icmp eq i32 %50, 0
  store i1 %51, i1* @zf
  %52 = icmp slt i32 %50, 0
  store i1 %52, i1* @sf
  %53 = trunc i32 %50 to i8
  %54 = call i8 @llvm.ctpop.i8(i8 %53)
  %55 = and i8 %54, 1
  %56 = icmp eq i8 %55, 0
  store i1 %56, i1* @pf
  %57 = zext i32 %50 to i64
  store i64 %57, i64* @rcx

; 0x401058
  store volatile i64 4198488, i64* @_asm_program_counter
  store i64 4198721, i64* @rdi

; 0x40105f
  store volatile i64 4198495, i64* @_asm_program_counter
  %58 = call i64 @__libc_start_main()
  store i64 %58, i64* @rax

; 0x401065
  store volatile i64 4198501, i64* @_asm_program_counter
  call void @__asm_hlt()
  unreachable
}

define i64 @_dl_relocate_static_pie() {
dec_label_pc_401070:

; 0x401070
  store volatile i64 4198512, i64* @_asm_program_counter

; 0x401074
  store volatile i64 4198516, i64* @_asm_program_counter
  ret i64 undef
}

define i64 @deregister_tm_clones() {
dec_label_pc_401080:

; 0x401080
  store volatile i64 4198528, i64* @_asm_program_counter
  store i64 4210728, i64* @rdi

; 0x401087
  store volatile i64 4198535, i64* @_asm_program_counter
  store i64 4210728, i64* @rax

; 0x40108e
  store volatile i64 4198542, i64* @_asm_program_counter
  %0 = load i64, i64* @rax
  %1 = load i64, i64* @rdi
  %2 = sub i64 %0, %1
  %3 = and i64 %0, 15
  %4 = and i64 %1, 15
  %5 = sub i64 %3, %4
  %6 = icmp ugt i64 %5, 15
  %7 = icmp ult i64 %0, %1
  %8 = xor i64 %0, %1
  %9 = xor i64 %0, %2
  %10 = and i64 %8, %9
  %11 = icmp slt i64 %10, 0
  store i1 %6, i1* @az
  store i1 %7, i1* @cf
  store i1 %11, i1* @of
  %12 = icmp eq i64 %2, 0
  store i1 %12, i1* @zf
  %13 = icmp slt i64 %2, 0
  store i1 %13, i1* @sf
  %14 = trunc i64 %2 to i8
  %15 = call i8 @llvm.ctpop.i8(i8 %14)
  %16 = and i8 %15, 1
  %17 = icmp eq i8 %16, 0
  store i1 %17, i1* @pf

; 0x401091
  store volatile i64 4198545, i64* @_asm_program_counter
  %18 = load i1, i1* @zf
  br i1 %18, label %dec_label_pc_4010a8, label %dec_label_pc_401093

dec_label_pc_401093:                              ; preds = %dec_label_pc_401080

; 0x401093
  store volatile i64 4198547, i64* @_asm_program_counter
  %19 = load i64, i64* inttoptr (i64 4210664 to i64*)
  store i64 %19, i64* @rax

; 0x40109a
  store volatile i64 4198554, i64* @_asm_program_counter
  %20 = load i64, i64* @rax
  %21 = load i64, i64* @rax
  %22 = and i64 %20, %21
  store i1 false, i1* @az
  store i1 false, i1* @cf
  store i1 false, i1* @of
  %23 = icmp eq i64 %22, 0
  store i1 %23, i1* @zf
  %24 = icmp slt i64 %22, 0
  store i1 %24, i1* @sf
  %25 = trunc i64 %22 to i8
  %26 = call i8 @llvm.ctpop.i8(i8 %25)
  %27 = and i8 %26, 1
  %28 = icmp eq i8 %27, 0
  store i1 %28, i1* @pf

; 0x40109d
  store volatile i64 4198557, i64* @_asm_program_counter
  %29 = load i1, i1* @zf
  br i1 %29, label %dec_label_pc_4010a8, label %dec_label_pc_40109f

dec_label_pc_40109f:                              ; preds = %dec_label_pc_401093

; 0x40109f
  store volatile i64 4198559, i64* @_asm_program_counter
  %30 = call i64 @_ITM_deregisterTMCloneTable()
  store i64 %30, i64* @rax
  ret i64 undef

dec_label_pc_4010a8:                              ; preds = %dec_label_pc_401093, %dec_label_pc_401080

; 0x4010a8
  store volatile i64 4198568, i64* @_asm_program_counter
  ret i64 undef
}

define i64 @register_tm_clones() {
dec_label_pc_4010b0:

; 0x4010b0
  store volatile i64 4198576, i64* @_asm_program_counter
  store i64 4210728, i64* @rdi

; 0x4010b7
  store volatile i64 4198583, i64* @_asm_program_counter
  store i64 4210728, i64* @rsi

; 0x4010be
  store volatile i64 4198590, i64* @_asm_program_counter
  %0 = load i64, i64* @rsi
  %1 = load i64, i64* @rdi
  %2 = sub i64 %0, %1
  %3 = and i64 %0, 15
  %4 = and i64 %1, 15
  %5 = sub i64 %3, %4
  %6 = icmp ugt i64 %5, 15
  %7 = icmp ult i64 %0, %1
  %8 = xor i64 %0, %1
  %9 = xor i64 %0, %2
  %10 = and i64 %8, %9
  %11 = icmp slt i64 %10, 0
  store i1 %6, i1* @az
  store i1 %7, i1* @cf
  store i1 %11, i1* @of
  %12 = icmp eq i64 %2, 0
  store i1 %12, i1* @zf
  %13 = icmp slt i64 %2, 0
  store i1 %13, i1* @sf
  %14 = trunc i64 %2 to i8
  %15 = call i8 @llvm.ctpop.i8(i8 %14)
  %16 = and i8 %15, 1
  %17 = icmp eq i8 %16, 0
  store i1 %17, i1* @pf
  store i64 %2, i64* @rsi

; 0x4010c1
  store volatile i64 4198593, i64* @_asm_program_counter
  %18 = load i64, i64* @rsi
  store i64 %18, i64* @rax

; 0x4010c4
  store volatile i64 4198596, i64* @_asm_program_counter
  %19 = load i64, i64* @rsi
  %20 = load i1, i1* @of
  %21 = lshr i64 %19, 63
  %22 = icmp eq i64 %21, 0
  store i1 %22, i1* @zf
  %23 = icmp slt i64 %21, 0
  store i1 %23, i1* @sf
  %24 = trunc i64 %21 to i8
  %25 = call i8 @llvm.ctpop.i8(i8 %24)
  %26 = and i8 %25, 1
  %27 = icmp eq i8 %26, 0
  store i1 %27, i1* @pf
  store i64 %21, i64* @rsi
  %28 = and i64 4611686018427387904, %19
  %29 = icmp ne i64 %28, 0
  store i1 %29, i1* @cf
  %30 = icmp slt i64 %19, 0
  %31 = select i1 false, i1 %30, i1 %20
  store i1 %31, i1* @of

; 0x4010c8
  store volatile i64 4198600, i64* @_asm_program_counter
  %32 = load i64, i64* @rax
  %33 = load i1, i1* @of
  %34 = ashr i64 %32, 3
  %35 = icmp eq i64 %34, 0
  store i1 %35, i1* @zf
  %36 = icmp slt i64 %34, 0
  store i1 %36, i1* @sf
  %37 = trunc i64 %34 to i8
  %38 = call i8 @llvm.ctpop.i8(i8 %37)
  %39 = and i8 %38, 1
  %40 = icmp eq i8 %39, 0
  store i1 %40, i1* @pf
  store i64 %34, i64* @rax
  %41 = and i64 4, %32
  %42 = icmp ne i64 %41, 0
  store i1 %42, i1* @cf
  %43 = select i1 false, i1 false, i1 %33
  store i1 %43, i1* @of

; 0x4010cc
  store volatile i64 4198604, i64* @_asm_program_counter
  %44 = load i64, i64* @rsi
  %45 = load i64, i64* @rax
  %46 = add i64 %44, %45
  %47 = and i64 %44, 15
  %48 = and i64 %45, 15
  %49 = add i64 %47, %48
  %50 = icmp ugt i64 %49, 15
  %51 = icmp ult i64 %46, %44
  %52 = xor i64 %44, %46
  %53 = xor i64 %45, %46
  %54 = and i64 %52, %53
  %55 = icmp slt i64 %54, 0
  store i1 %50, i1* @az
  store i1 %51, i1* @cf
  store i1 %55, i1* @of
  %56 = icmp eq i64 %46, 0
  store i1 %56, i1* @zf
  %57 = icmp slt i64 %46, 0
  store i1 %57, i1* @sf
  %58 = trunc i64 %46 to i8
  %59 = call i8 @llvm.ctpop.i8(i8 %58)
  %60 = and i8 %59, 1
  %61 = icmp eq i8 %60, 0
  store i1 %61, i1* @pf
  store i64 %46, i64* @rsi

; 0x4010cf
  store volatile i64 4198607, i64* @_asm_program_counter
  %62 = load i64, i64* @rsi
  %63 = load i1, i1* @of
  %64 = ashr i64 %62, 1
  %65 = icmp eq i64 %64, 0
  store i1 %65, i1* @zf
  %66 = icmp slt i64 %64, 0
  store i1 %66, i1* @sf
  %67 = trunc i64 %64 to i8
  %68 = call i8 @llvm.ctpop.i8(i8 %67)
  %69 = and i8 %68, 1
  %70 = icmp eq i8 %69, 0
  store i1 %70, i1* @pf
  store i64 %64, i64* @rsi
  %71 = and i64 1, %62
  %72 = icmp ne i64 %71, 0
  store i1 %72, i1* @cf
  %73 = select i1 true, i1 false, i1 %63
  store i1 %73, i1* @of

; 0x4010d2
  store volatile i64 4198610, i64* @_asm_program_counter
  %74 = load i1, i1* @zf
  br i1 %74, label %dec_label_pc_4010e8, label %dec_label_pc_4010d4

dec_label_pc_4010d4:                              ; preds = %dec_label_pc_4010b0

; 0x4010d4
  store volatile i64 4198612, i64* @_asm_program_counter
  %75 = load i64, i64* inttoptr (i64 4210680 to i64*)
  store i64 %75, i64* @rax

; 0x4010db
  store volatile i64 4198619, i64* @_asm_program_counter
  %76 = load i64, i64* @rax
  %77 = load i64, i64* @rax
  %78 = and i64 %76, %77
  store i1 false, i1* @az
  store i1 false, i1* @cf
  store i1 false, i1* @of
  %79 = icmp eq i64 %78, 0
  store i1 %79, i1* @zf
  %80 = icmp slt i64 %78, 0
  store i1 %80, i1* @sf
  %81 = trunc i64 %78 to i8
  %82 = call i8 @llvm.ctpop.i8(i8 %81)
  %83 = and i8 %82, 1
  %84 = icmp eq i8 %83, 0
  store i1 %84, i1* @pf

; 0x4010de
  store volatile i64 4198622, i64* @_asm_program_counter
  %85 = load i1, i1* @zf
  br i1 %85, label %dec_label_pc_4010e8, label %dec_label_pc_4010e0

dec_label_pc_4010e0:                              ; preds = %dec_label_pc_4010d4

; 0x4010e0
  store volatile i64 4198624, i64* @_asm_program_counter
  %86 = call i64 @_ITM_registerTMCloneTable()
  store i64 %86, i64* @rax
  ret i64 undef

dec_label_pc_4010e8:                              ; preds = %dec_label_pc_4010d4, %dec_label_pc_4010b0

; 0x4010e8
  store volatile i64 4198632, i64* @_asm_program_counter
  ret i64 undef
}

define i64 @__do_global_dtors_aux() {
dec_label_pc_4010f0:

; 0x4010f0
  store volatile i64 4198640, i64* @_asm_program_counter

; 0x4010f4
  store volatile i64 4198644, i64* @_asm_program_counter
  %0 = load i8, i8* inttoptr (i64 4210724 to i8*)
  %1 = sub i8 %0, 0
  %2 = and i8 %0, 15
  %3 = sub i8 %2, 0
  %4 = icmp ugt i8 %3, 15
  %5 = icmp ult i8 %0, 0
  %6 = xor i8 %0, 0
  %7 = xor i8 %0, %1
  %8 = and i8 %6, %7
  %9 = icmp slt i8 %8, 0
  store i1 %4, i1* @az
  store i1 %5, i1* @cf
  store i1 %9, i1* @of
  %10 = icmp eq i8 %1, 0
  store i1 %10, i1* @zf
  %11 = icmp slt i8 %1, 0
  store i1 %11, i1* @sf
  %12 = call i8 @llvm.ctpop.i8(i8 %1)
  %13 = and i8 %12, 1
  %14 = icmp eq i8 %13, 0
  store i1 %14, i1* @pf

; 0x4010fb
  store volatile i64 4198651, i64* @_asm_program_counter
  %15 = load i1, i1* @zf
  %16 = icmp eq i1 %15, false
  br i1 %16, label %dec_label_pc_401110, label %dec_label_pc_4010fd

dec_label_pc_4010fd:                              ; preds = %dec_label_pc_4010f0

; 0x4010fd
  store volatile i64 4198653, i64* @_asm_program_counter
  %17 = load i64, i64* @rbp
  %18 = load i64, i64* @rsp
  %19 = sub i64 %18, 8
  %20 = inttoptr i64 %19 to i64*
  store i64 %17, i64* %20
  store i64 %19, i64* @rsp

; 0x4010fe
  store volatile i64 4198654, i64* @_asm_program_counter
  %21 = load i64, i64* @rsp
  store i64 %21, i64* @rbp

; 0x401101
  store volatile i64 4198657, i64* @_asm_program_counter
  %22 = call i64 @deregister_tm_clones()
  store i64 %22, i64* @rax

; 0x401106
  store volatile i64 4198662, i64* @_asm_program_counter
  store i8 1, i8* inttoptr (i64 4210724 to i8*)

; 0x40110d
  store volatile i64 4198669, i64* @_asm_program_counter
  %23 = load i64, i64* @rsp
  %24 = inttoptr i64 %23 to i64*
  %25 = load i64, i64* %24
  store i64 %25, i64* @rbp
  %26 = add i64 %23, 8
  store i64 %26, i64* @rsp

; 0x40110e
  store volatile i64 4198670, i64* @_asm_program_counter
  ret i64 undef

dec_label_pc_401110:                              ; preds = %dec_label_pc_4010f0

; 0x401110
  store volatile i64 4198672, i64* @_asm_program_counter
  ret i64 undef
}

define i64 @frame_dummy() {
dec_label_pc_401120:

; 0x401120
  store volatile i64 4198688, i64* @_asm_program_counter

; 0x401124
  store volatile i64 4198692, i64* @_asm_program_counter
  %0 = call i64 @register_tm_clones()
  store i64 %0, i64* @rax
  ret i64 undef
}

define i64 @add() {
dec_label_pc_401126:

; 0x401126
  store volatile i64 4198694, i64* @_asm_program_counter
  %0 = load i64, i64* @rbp
  %1 = load i64, i64* @rsp
  %2 = sub i64 %1, 8
  %3 = inttoptr i64 %2 to i64*
  store i64 %0, i64* %3
  store i64 %2, i64* @rsp

; 0x401127
  store volatile i64 4198695, i64* @_asm_program_counter
  %4 = load i64, i64* @rsp
  store i64 %4, i64* @rbp

; 0x40112a
  store volatile i64 4198698, i64* @_asm_program_counter
  %5 = load i64, i64* @rdi
  %6 = load i64, i64* @rbp
  %7 = add i64 %6, -8
  %8 = inttoptr i64 %7 to i64*
  store i64 %5, i64* %8

; 0x40112e
  store volatile i64 4198702, i64* @_asm_program_counter
  %9 = load i64, i64* @rsi
  %10 = trunc i64 %9 to i32
  %11 = zext i32 %10 to i64
  store i64 %11, i64* @rax

; 0x401130
  store volatile i64 4198704, i64* @_asm_program_counter
  %12 = load i64, i64* @rax
  %13 = trunc i64 %12 to i8
  %14 = load i64, i64* @rbp
  %15 = add i64 %14, -12
  %16 = inttoptr i64 %15 to i8*
  store i8 %13, i8* %16

; 0x401133
  store volatile i64 4198707, i64* @_asm_program_counter
  %17 = load i64, i64* @rbp
  %18 = add i64 %17, -8
  %19 = inttoptr i64 %18 to i64*
  %20 = load i64, i64* %19
  store i64 %20, i64* @rax

; 0x401137
  store volatile i64 4198711, i64* @_asm_program_counter
  %21 = load i64, i64* @rax
  %22 = inttoptr i64 %21 to i32*
  %23 = load i32, i32* %22
  %24 = zext i32 %23 to i64
  store i64 %24, i64* @rdx

; 0x401139
  store volatile i64 4198713, i64* @_asm_program_counter
  %25 = load i64, i64* @rbp
  %26 = add i64 %25, -12
  %27 = inttoptr i64 %26 to i8*
  %28 = load i8, i8* %27
  %29 = sext i8 %28 to i64
  store i64 %29, i64* @rax

; 0x40113d
  store volatile i64 4198717, i64* @_asm_program_counter
  %30 = load i64, i64* @rax
  %31 = trunc i64 %30 to i32
  %32 = load i64, i64* @rdx
  %33 = trunc i64 %32 to i32
  %34 = add i32 %31, %33
  %35 = and i32 %31, 15
  %36 = and i32 %33, 15
  %37 = add i32 %35, %36
  %38 = icmp ugt i32 %37, 15
  %39 = icmp ult i32 %34, %31
  %40 = xor i32 %31, %34
  %41 = xor i32 %33, %34
  %42 = and i32 %40, %41
  %43 = icmp slt i32 %42, 0
  store i1 %38, i1* @az
  store i1 %39, i1* @cf
  store i1 %43, i1* @of
  %44 = icmp eq i32 %34, 0
  store i1 %44, i1* @zf
  %45 = icmp slt i32 %34, 0
  store i1 %45, i1* @sf
  %46 = trunc i32 %34 to i8
  %47 = call i8 @llvm.ctpop.i8(i8 %46)
  %48 = and i8 %47, 1
  %49 = icmp eq i8 %48, 0
  store i1 %49, i1* @pf
  %50 = zext i32 %34 to i64
  store i64 %50, i64* @rax

; 0x40113f
  store volatile i64 4198719, i64* @_asm_program_counter
  %51 = load i64, i64* @rsp
  %52 = inttoptr i64 %51 to i64*
  %53 = load i64, i64* %52
  store i64 %53, i64* @rbp
  %54 = add i64 %51, 8
  store i64 %54, i64* @rsp

; 0x401140
  store volatile i64 4198720, i64* @_asm_program_counter
  ret i64 undef
}

define i64 @main() {
dec_label_pc_401141:

; 0x401141
  store volatile i64 4198721, i64* @_asm_program_counter
  %0 = load i64, i64* @rbp
  %1 = load i64, i64* @rsp
  %2 = sub i64 %1, 8
  %3 = inttoptr i64 %2 to i64*
  store i64 %0, i64* %3
  store i64 %2, i64* @rsp

; 0x401142
  store volatile i64 4198722, i64* @_asm_program_counter
  %4 = load i64, i64* @rsp
  store i64 %4, i64* @rbp

; 0x401145
  store volatile i64 4198725, i64* @_asm_program_counter
  %5 = load i64, i64* @rsp
  %6 = sub i64 %5, 32
  %7 = and i64 %5, 15
  %8 = sub i64 %7, 0
  %9 = icmp ugt i64 %8, 15
  %10 = icmp ult i64 %5, 32
  %11 = xor i64 %5, 32
  %12 = xor i64 %5, %6
  %13 = and i64 %11, %12
  %14 = icmp slt i64 %13, 0
  store i1 %9, i1* @az
  store i1 %10, i1* @cf
  store i1 %14, i1* @of
  %15 = icmp eq i64 %6, 0
  store i1 %15, i1* @zf
  %16 = icmp slt i64 %6, 0
  store i1 %16, i1* @sf
  %17 = trunc i64 %6 to i8
  %18 = call i8 @llvm.ctpop.i8(i8 %17)
  %19 = and i8 %18, 1
  %20 = icmp eq i8 %19, 0
  store i1 %20, i1* @pf
  store i64 %6, i64* @rsp

; 0x401149
  store volatile i64 4198729, i64* @_asm_program_counter
  %21 = load i64, i64* @rbp
  %22 = add i64 %21, -24
  %23 = inttoptr i64 %22 to i32*
  store i32 1, i32* %23

; 0x401150
  store volatile i64 4198736, i64* @_asm_program_counter
  %24 = load i64, i64* @rbp
  %25 = add i64 %24, -1
  %26 = inttoptr i64 %25 to i8*
  store i8 2, i8* %26

; 0x401154
  store volatile i64 4198740, i64* @_asm_program_counter
  %27 = load i64, i64* @rbp
  %28 = add i64 %27, -1
  %29 = inttoptr i64 %28 to i8*
  %30 = load i8, i8* %29
  %31 = sext i8 %30 to i64
  store i64 %31, i64* @rdx

; 0x401158
  store volatile i64 4198744, i64* @_asm_program_counter
  %32 = load i64, i64* @rbp
  %33 = add i64 %32, -24
  store i64 %33, i64* @rax

; 0x40115c
  store volatile i64 4198748, i64* @_asm_program_counter
  %34 = load i64, i64* @rdx
  %35 = trunc i64 %34 to i32
  %36 = zext i32 %35 to i64
  store i64 %36, i64* @rsi

; 0x40115e
  store volatile i64 4198750, i64* @_asm_program_counter
  %37 = load i64, i64* @rax
  store i64 %37, i64* @rdi

; 0x401161
  store volatile i64 4198753, i64* @_asm_program_counter
  %38 = call i64 @add()
  store i64 %38, i64* @rax

; 0x401166
  store volatile i64 4198758, i64* @_asm_program_counter
  %39 = load i64, i64* @rax
  %40 = trunc i64 %39 to i32
  %41 = load i64, i64* @rbp
  %42 = add i64 %41, -8
  %43 = inttoptr i64 %42 to i32*
  store i32 %40, i32* %43

; 0x401169
  store volatile i64 4198761, i64* @_asm_program_counter
  %44 = load i64, i64* @rbp
  %45 = add i64 %44, -24
  store i64 %45, i64* @rax

; 0x40116d
  store volatile i64 4198765, i64* @_asm_program_counter
  %46 = load i64, i64* @rax
  %47 = load i64, i64* @rbp
  %48 = add i64 %47, -16
  %49 = inttoptr i64 %48 to i64*
  store i64 %46, i64* %49

; 0x401171
  store volatile i64 4198769, i64* @_asm_program_counter
  %50 = load i64, i64* @rbp
  %51 = add i64 %50, -1
  %52 = inttoptr i64 %51 to i8*
  %53 = load i8, i8* %52
  %54 = sext i8 %53 to i64
  store i64 %54, i64* @rdx

; 0x401175
  store volatile i64 4198773, i64* @_asm_program_counter
  %55 = load i64, i64* @rbp
  %56 = add i64 %55, -16
  %57 = inttoptr i64 %56 to i64*
  %58 = load i64, i64* %57
  store i64 %58, i64* @rax

; 0x401179
  store volatile i64 4198777, i64* @_asm_program_counter
  %59 = load i64, i64* @rdx
  %60 = trunc i64 %59 to i32
  %61 = zext i32 %60 to i64
  store i64 %61, i64* @rsi

; 0x40117b
  store volatile i64 4198779, i64* @_asm_program_counter
  %62 = load i64, i64* @rax
  store i64 %62, i64* @rdi

; 0x40117e
  store volatile i64 4198782, i64* @_asm_program_counter
  %63 = call i64 @add()
  store i64 %63, i64* @rax

; 0x401183
  store volatile i64 4198787, i64* @_asm_program_counter
  %64 = load i64, i64* @rax
  %65 = trunc i64 %64 to i32
  %66 = load i64, i64* @rbp
  %67 = add i64 %66, -20
  %68 = inttoptr i64 %67 to i32*
  store i32 %65, i32* %68

; 0x401186
  store volatile i64 4198790, i64* @_asm_program_counter
  %69 = load i64, i64* @rbp
  %70 = add i64 %69, -8
  %71 = inttoptr i64 %70 to i32*
  %72 = load i32, i32* %71
  %73 = zext i32 %72 to i64
  store i64 %73, i64* @rax

; 0x401189
  store volatile i64 4198793, i64* @_asm_program_counter
  %74 = load i64, i64* @rax
  %75 = trunc i64 %74 to i32
  %76 = zext i32 %75 to i64
  store i64 %76, i64* @rsi

; 0x40118b
  store volatile i64 4198795, i64* @_asm_program_counter
  store i64 4202512, i64* @rdi

; 0x401190
  store volatile i64 4198800, i64* @_asm_program_counter
  store i64 0, i64* @rax

; 0x401195
  store volatile i64 4198805, i64* @_asm_program_counter
  %77 = call i64 @function_401030()
  store i64 %77, i64* @rax

; 0x40119a
  store volatile i64 4198810, i64* @_asm_program_counter
  store i64 0, i64* @rax

; 0x40119f
  store volatile i64 4198815, i64* @_asm_program_counter
  %78 = load i64, i64* @rbp
  %79 = inttoptr i64 %78 to i64*
  %80 = load i64, i64* %79
  %81 = add i64 %78, 8
  store i64 %80, i64* @rbp
  store i64 %81, i64* @rsp

; 0x4011a0
  store volatile i64 4198816, i64* @_asm_program_counter
  ret i64 undef
}

define i64 @_fini() {
dec_label_pc_4011a4:

; 0x4011a4
  store volatile i64 4198820, i64* @_asm_program_counter

; 0x4011a8
  store volatile i64 4198824, i64* @_asm_program_counter
  %0 = load i64, i64* @rsp
  %1 = sub i64 %0, 8
  %2 = and i64 %0, 15
  %3 = sub i64 %2, 8
  %4 = icmp ugt i64 %3, 15
  %5 = icmp ult i64 %0, 8
  %6 = xor i64 %0, 8
  %7 = xor i64 %0, %1
  %8 = and i64 %6, %7
  %9 = icmp slt i64 %8, 0
  store i1 %4, i1* @az
  store i1 %5, i1* @cf
  store i1 %9, i1* @of
  %10 = icmp eq i64 %1, 0
  store i1 %10, i1* @zf
  %11 = icmp slt i64 %1, 0
  store i1 %11, i1* @sf
  %12 = trunc i64 %1 to i8
  %13 = call i8 @llvm.ctpop.i8(i8 %12)
  %14 = and i8 %13, 1
  %15 = icmp eq i8 %14, 0
  store i1 %15, i1* @pf
  store i64 %1, i64* @rsp

; 0x4011ac
  store volatile i64 4198828, i64* @_asm_program_counter
  %16 = load i64, i64* @rsp
  %17 = add i64 %16, 8
  %18 = and i64 %16, 15
  %19 = add i64 %18, 8
  %20 = icmp ugt i64 %19, 15
  %21 = icmp ult i64 %17, %16
  %22 = xor i64 %16, %17
  %23 = xor i64 8, %17
  %24 = and i64 %22, %23
  %25 = icmp slt i64 %24, 0
  store i1 %20, i1* @az
  store i1 %21, i1* @cf
  store i1 %25, i1* @of
  %26 = icmp eq i64 %17, 0
  store i1 %26, i1* @zf
  %27 = icmp slt i64 %17, 0
  store i1 %27, i1* @sf
  %28 = trunc i64 %17 to i8
  %29 = call i8 @llvm.ctpop.i8(i8 %28)
  %30 = and i8 %29, 1
  %31 = icmp eq i8 %30, 0
  store i1 %31, i1* @pf
  store i64 %17, i64* @rsp

; 0x4011b0
  store volatile i64 4198832, i64* @_asm_program_counter
  ret i64 undef
}

declare i64 @__libc_start_main()

declare i64 @_ITM_deregisterTMCloneTable()

declare i64 @__gmon_start__()

declare i64 @_ITM_registerTMCloneTable()

declare i64 @printf()

declare void @__pseudo_call(i64)

declare void @__pseudo_return(i64)

declare void @__pseudo_branch(i64)

declare void @__pseudo_cond_branch(i1, i64)

declare void @__frontend_reg_store.fpr(i3, x86_fp80)

declare x86_fp80 @__frontend_reg_load.fpr(i3)

; Function Attrs: nounwind readnone speculatable
declare i8 @llvm.ctpop.i8(i8) #0

declare void @__asm_hlt()

attributes #0 = { nounwind readnone speculatable }
*** IR Dump After x87 fpu register analysis ***
source_filename = "test"
target datalayout = "e-m:e-p:64:64-i64:64-f80:128-n8:16:32:64-S128"

@_asm_program_counter = internal global i64 0
@cf = internal global i1 false
@pf = internal global i1 false
@az = internal global i1 false
@zf = internal global i1 false
@sf = internal global i1 false
@tf = internal global i1 false
@if = internal global i1 false
@df = internal global i1 false
@of = internal global i1 false
@iopl = internal global i2 0
@nt = internal global i1 false
@rf = internal global i1 false
@vm = internal global i1 false
@ac = internal global i1 false
@vif = internal global i1 false
@vip = internal global i1 false
@id = internal global i1 false
@rflags = internal global i64 0
@ss = internal global i16 0
@cs = internal global i16 0
@ds = internal global i16 0
@es = internal global i16 0
@fs = internal global i16 0
@gs = internal global i16 0
@st0 = internal global x86_fp80 0xK00000000000000000000
@st1 = internal global x86_fp80 0xK00000000000000000000
@st2 = internal global x86_fp80 0xK00000000000000000000
@st3 = internal global x86_fp80 0xK00000000000000000000
@st4 = internal global x86_fp80 0xK00000000000000000000
@st5 = internal global x86_fp80 0xK00000000000000000000
@st6 = internal global x86_fp80 0xK00000000000000000000
@st7 = internal global x86_fp80 0xK00000000000000000000
@fpu_stat_IE = internal global i1 false
@fpu_stat_DE = internal global i1 false
@fpu_stat_ZE = internal global i1 false
@fpu_stat_OE = internal global i1 false
@fpu_stat_UE = internal global i1 false
@fpu_stat_PE = internal global i1 false
@fpu_stat_SF = internal global i1 false
@fpu_stat_ES = internal global i1 false
@fpu_stat_C0 = internal global i1 false
@fpu_stat_C1 = internal global i1 false
@fpu_stat_C2 = internal global i1 false
@fpu_stat_C3 = internal global i1 false
@fpu_stat_TOP = internal global i3 0
@fpu_stat_B = internal global i1 false
@fpu_control_IM = internal global i1 false
@fpu_control_DM = internal global i1 false
@fpu_control_ZM = internal global i1 false
@fpu_control_OM = internal global i1 false
@fpu_control_UM = internal global i1 false
@fpu_control_PM = internal global i1 false
@fpu_control_PC = internal global i2 0
@fpu_control_RC = internal global i2 0
@fpu_control_X = internal global i1 false
@fp0 = internal global double 0.000000e+00
@fp1 = internal global double 0.000000e+00
@fp2 = internal global double 0.000000e+00
@fp3 = internal global double 0.000000e+00
@fp4 = internal global double 0.000000e+00
@fp5 = internal global double 0.000000e+00
@fp6 = internal global double 0.000000e+00
@fp7 = internal global double 0.000000e+00
@k0 = internal global i64 0
@k1 = internal global i64 0
@k2 = internal global i64 0
@k3 = internal global i64 0
@k4 = internal global i64 0
@k5 = internal global i64 0
@k6 = internal global i64 0
@k7 = internal global i64 0
@mm0 = internal global i64 0
@mm1 = internal global i64 0
@mm2 = internal global i64 0
@mm3 = internal global i64 0
@mm4 = internal global i64 0
@mm5 = internal global i64 0
@mm6 = internal global i64 0
@mm7 = internal global i64 0
@xmm0 = internal global i128 0
@xmm1 = internal global i128 0
@xmm2 = internal global i128 0
@xmm3 = internal global i128 0
@xmm4 = internal global i128 0
@xmm5 = internal global i128 0
@xmm6 = internal global i128 0
@xmm7 = internal global i128 0
@xmm8 = internal global i128 0
@xmm9 = internal global i128 0
@xmm10 = internal global i128 0
@xmm11 = internal global i128 0
@xmm12 = internal global i128 0
@xmm13 = internal global i128 0
@xmm14 = internal global i128 0
@xmm15 = internal global i128 0
@xmm16 = internal global i128 0
@xmm17 = internal global i128 0
@xmm18 = internal global i128 0
@xmm19 = internal global i128 0
@xmm20 = internal global i128 0
@xmm21 = internal global i128 0
@xmm22 = internal global i128 0
@xmm23 = internal global i128 0
@xmm24 = internal global i128 0
@xmm25 = internal global i128 0
@xmm26 = internal global i128 0
@xmm27 = internal global i128 0
@xmm28 = internal global i128 0
@xmm29 = internal global i128 0
@xmm30 = internal global i128 0
@xmm31 = internal global i128 0
@ymm0 = internal global i256 0
@ymm1 = internal global i256 0
@ymm2 = internal global i256 0
@ymm3 = internal global i256 0
@ymm4 = internal global i256 0
@ymm5 = internal global i256 0
@ymm6 = internal global i256 0
@ymm7 = internal global i256 0
@ymm8 = internal global i256 0
@ymm9 = internal global i256 0
@ymm10 = internal global i256 0
@ymm11 = internal global i256 0
@ymm12 = internal global i256 0
@ymm13 = internal global i256 0
@ymm14 = internal global i256 0
@ymm15 = internal global i256 0
@ymm16 = internal global i256 0
@ymm17 = internal global i256 0
@ymm18 = internal global i256 0
@ymm19 = internal global i256 0
@ymm20 = internal global i256 0
@ymm21 = internal global i256 0
@ymm22 = internal global i256 0
@ymm23 = internal global i256 0
@ymm24 = internal global i256 0
@ymm25 = internal global i256 0
@ymm26 = internal global i256 0
@ymm27 = internal global i256 0
@ymm28 = internal global i256 0
@ymm29 = internal global i256 0
@ymm30 = internal global i256 0
@ymm31 = internal global i256 0
@zmm0 = internal global i512 0
@zmm1 = internal global i512 0
@zmm2 = internal global i512 0
@zmm3 = internal global i512 0
@zmm4 = internal global i512 0
@zmm5 = internal global i512 0
@zmm6 = internal global i512 0
@zmm7 = internal global i512 0
@zmm8 = internal global i512 0
@zmm9 = internal global i512 0
@zmm10 = internal global i512 0
@zmm11 = internal global i512 0
@zmm12 = internal global i512 0
@zmm13 = internal global i512 0
@zmm14 = internal global i512 0
@zmm15 = internal global i512 0
@zmm16 = internal global i512 0
@zmm17 = internal global i512 0
@zmm18 = internal global i512 0
@zmm19 = internal global i512 0
@zmm20 = internal global i512 0
@zmm21 = internal global i512 0
@zmm22 = internal global i512 0
@zmm23 = internal global i512 0
@zmm24 = internal global i512 0
@zmm25 = internal global i512 0
@zmm26 = internal global i512 0
@zmm27 = internal global i512 0
@zmm28 = internal global i512 0
@zmm29 = internal global i512 0
@zmm30 = internal global i512 0
@zmm31 = internal global i512 0
@bnd0 = internal global i128 0
@bnd1 = internal global i128 0
@bnd2 = internal global i128 0
@bnd3 = internal global i128 0
@dr0 = internal global i64 0
@dr1 = internal global i64 0
@dr2 = internal global i64 0
@dr3 = internal global i64 0
@dr4 = internal global i64 0
@dr5 = internal global i64 0
@dr6 = internal global i64 0
@dr7 = internal global i64 0
@dr8 = internal global i64 0
@dr9 = internal global i64 0
@dr10 = internal global i64 0
@dr11 = internal global i64 0
@dr12 = internal global i64 0
@dr13 = internal global i64 0
@dr14 = internal global i64 0
@dr15 = internal global i64 0
@cr0 = internal global i64 0
@cr1 = internal global i64 0
@cr2 = internal global i64 0
@cr3 = internal global i64 0
@cr4 = internal global i64 0
@cr5 = internal global i64 0
@cr6 = internal global i64 0
@cr7 = internal global i64 0
@cr8 = internal global i64 0
@cr9 = internal global i64 0
@cr10 = internal global i64 0
@cr11 = internal global i64 0
@cr12 = internal global i64 0
@cr13 = internal global i64 0
@cr14 = internal global i64 0
@cr15 = internal global i64 0
@fpsw = internal global i64 0
@rax = internal global i64 0
@rcx = internal global i64 0
@rdx = internal global i64 0
@rbx = internal global i64 0
@rsp = internal global i64 0
@rbp = internal global i64 0
@rsi = internal global i64 0
@rdi = internal global i64 0
@r8 = internal global i64 0
@r9 = internal global i64 0
@r10 = internal global i64 0
@r11 = internal global i64 0
@r12 = internal global i64 0
@r13 = internal global i64 0
@r14 = internal global i64 0
@r15 = internal global i64 0
@rip = internal global i64 0
@riz = internal global i64 0

define i64 @_init() {
dec_label_pc_401000:

; 0x401000
  store volatile i64 4198400, i64* @_asm_program_counter

; 0x401004
  store volatile i64 4198404, i64* @_asm_program_counter
  %0 = load i64, i64* @rsp
  %1 = sub i64 %0, 8
  %2 = and i64 %0, 15
  %3 = sub i64 %2, 8
  %4 = icmp ugt i64 %3, 15
  %5 = icmp ult i64 %0, 8
  %6 = xor i64 %0, 8
  %7 = xor i64 %0, %1
  %8 = and i64 %6, %7
  %9 = icmp slt i64 %8, 0
  store i1 %4, i1* @az
  store i1 %5, i1* @cf
  store i1 %9, i1* @of
  %10 = icmp eq i64 %1, 0
  store i1 %10, i1* @zf
  %11 = icmp slt i64 %1, 0
  store i1 %11, i1* @sf
  %12 = trunc i64 %1 to i8
  %13 = call i8 @llvm.ctpop.i8(i8 %12)
  %14 = and i8 %13, 1
  %15 = icmp eq i8 %14, 0
  store i1 %15, i1* @pf
  store i64 %1, i64* @rsp

; 0x401008
  store volatile i64 4198408, i64* @_asm_program_counter
  %16 = load i64, i64* inttoptr (i64 4210672 to i64*)
  store i64 %16, i64* @rax

; 0x40100f
  store volatile i64 4198415, i64* @_asm_program_counter
  %17 = load i64, i64* @rax
  %18 = load i64, i64* @rax
  %19 = and i64 %17, %18
  store i1 false, i1* @az
  store i1 false, i1* @cf
  store i1 false, i1* @of
  %20 = icmp eq i64 %19, 0
  store i1 %20, i1* @zf
  %21 = icmp slt i64 %19, 0
  store i1 %21, i1* @sf
  %22 = trunc i64 %19 to i8
  %23 = call i8 @llvm.ctpop.i8(i8 %22)
  %24 = and i8 %23, 1
  %25 = icmp eq i8 %24, 0
  store i1 %25, i1* @pf

; 0x401012
  store volatile i64 4198418, i64* @_asm_program_counter
  %26 = load i1, i1* @zf
  br i1 %26, label %dec_label_pc_401016, label %dec_label_pc_401014

dec_label_pc_401014:                              ; preds = %dec_label_pc_401000

; 0x401014
  store volatile i64 4198420, i64* @_asm_program_counter
  %27 = call i64 @__gmon_start__()
  store i64 %27, i64* @rax
  br label %dec_label_pc_401016

dec_label_pc_401016:                              ; preds = %dec_label_pc_401014, %dec_label_pc_401000

; 0x401016
  store volatile i64 4198422, i64* @_asm_program_counter
  %28 = load i64, i64* @rsp
  %29 = add i64 %28, 8
  %30 = and i64 %28, 15
  %31 = add i64 %30, 8
  %32 = icmp ugt i64 %31, 15
  %33 = icmp ult i64 %29, %28
  %34 = xor i64 %28, %29
  %35 = xor i64 8, %29
  %36 = and i64 %34, %35
  %37 = icmp slt i64 %36, 0
  store i1 %32, i1* @az
  store i1 %33, i1* @cf
  store i1 %37, i1* @of
  %38 = icmp eq i64 %29, 0
  store i1 %38, i1* @zf
  %39 = icmp slt i64 %29, 0
  store i1 %39, i1* @sf
  %40 = trunc i64 %29 to i8
  %41 = call i8 @llvm.ctpop.i8(i8 %40)
  %42 = and i8 %41, 1
  %43 = icmp eq i8 %42, 0
  store i1 %43, i1* @pf
  store i64 %29, i64* @rsp

; 0x40101a
  store volatile i64 4198426, i64* @_asm_program_counter
  ret i64 undef
}

define i64 @function_401030() {
dec_label_pc_401030:

; 0x401030
  store volatile i64 4198448, i64* @_asm_program_counter
  %0 = call i64 @printf()
  store i64 %0, i64* @rax
  ret i64 undef
}

define i64 @_start() {
dec_label_pc_401040:

; 0x401040
  store volatile i64 4198464, i64* @_asm_program_counter

; 0x401044
  store volatile i64 4198468, i64* @_asm_program_counter
  %0 = load i64, i64* @rbp
  %1 = trunc i64 %0 to i32
  %2 = load i64, i64* @rbp
  %3 = trunc i64 %2 to i32
  %4 = xor i32 %1, %3
  store i1 false, i1* @az
  store i1 false, i1* @cf
  store i1 false, i1* @of
  %5 = icmp eq i32 %4, 0
  store i1 %5, i1* @zf
  %6 = icmp slt i32 %4, 0
  store i1 %6, i1* @sf
  %7 = trunc i32 %4 to i8
  %8 = call i8 @llvm.ctpop.i8(i8 %7)
  %9 = and i8 %8, 1
  %10 = icmp eq i8 %9, 0
  store i1 %10, i1* @pf
  %11 = zext i32 %4 to i64
  store i64 %11, i64* @rbp

; 0x401046
  store volatile i64 4198470, i64* @_asm_program_counter
  %12 = load i64, i64* @rdx
  store i64 %12, i64* @r9

; 0x401049
  store volatile i64 4198473, i64* @_asm_program_counter
  %13 = load i64, i64* @rsp
  %14 = inttoptr i64 %13 to i64*
  %15 = load i64, i64* %14
  store i64 %15, i64* @rsi
  %16 = add i64 %13, 8
  store i64 %16, i64* @rsp

; 0x40104a
  store volatile i64 4198474, i64* @_asm_program_counter
  %17 = load i64, i64* @rsp
  store i64 %17, i64* @rdx

; 0x40104d
  store volatile i64 4198477, i64* @_asm_program_counter
  %18 = load i64, i64* @rsp
  %19 = and i64 %18, -16
  store i1 false, i1* @az
  store i1 false, i1* @cf
  store i1 false, i1* @of
  %20 = icmp eq i64 %19, 0
  store i1 %20, i1* @zf
  %21 = icmp slt i64 %19, 0
  store i1 %21, i1* @sf
  %22 = trunc i64 %19 to i8
  %23 = call i8 @llvm.ctpop.i8(i8 %22)
  %24 = and i8 %23, 1
  %25 = icmp eq i8 %24, 0
  store i1 %25, i1* @pf
  store i64 %19, i64* @rsp

; 0x401051
  store volatile i64 4198481, i64* @_asm_program_counter
  %26 = load i64, i64* @rax
  %27 = load i64, i64* @rsp
  %28 = sub i64 %27, 8
  %29 = inttoptr i64 %28 to i64*
  store i64 %26, i64* %29
  store i64 %28, i64* @rsp

; 0x401052
  store volatile i64 4198482, i64* @_asm_program_counter
  %30 = load i64, i64* @rsp
  %31 = load i64, i64* @rsp
  %32 = sub i64 %31, 8
  %33 = inttoptr i64 %32 to i64*
  store i64 %30, i64* %33
  store i64 %32, i64* @rsp

; 0x401053
  store volatile i64 4198483, i64* @_asm_program_counter
  %34 = load i64, i64* @r8
  %35 = trunc i64 %34 to i32
  %36 = load i64, i64* @r8
  %37 = trunc i64 %36 to i32
  %38 = xor i32 %35, %37
  store i1 false, i1* @az
  store i1 false, i1* @cf
  store i1 false, i1* @of
  %39 = icmp eq i32 %38, 0
  store i1 %39, i1* @zf
  %40 = icmp slt i32 %38, 0
  store i1 %40, i1* @sf
  %41 = trunc i32 %38 to i8
  %42 = call i8 @llvm.ctpop.i8(i8 %41)
  %43 = and i8 %42, 1
  %44 = icmp eq i8 %43, 0
  store i1 %44, i1* @pf
  %45 = zext i32 %38 to i64
  store i64 %45, i64* @r8

; 0x401056
  store volatile i64 4198486, i64* @_asm_program_counter
  %46 = load i64, i64* @rcx
  %47 = trunc i64 %46 to i32
  %48 = load i64, i64* @rcx
  %49 = trunc i64 %48 to i32
  %50 = xor i32 %47, %49
  store i1 false, i1* @az
  store i1 false, i1* @cf
  store i1 false, i1* @of
  %51 = icmp eq i32 %50, 0
  store i1 %51, i1* @zf
  %52 = icmp slt i32 %50, 0
  store i1 %52, i1* @sf
  %53 = trunc i32 %50 to i8
  %54 = call i8 @llvm.ctpop.i8(i8 %53)
  %55 = and i8 %54, 1
  %56 = icmp eq i8 %55, 0
  store i1 %56, i1* @pf
  %57 = zext i32 %50 to i64
  store i64 %57, i64* @rcx

; 0x401058
  store volatile i64 4198488, i64* @_asm_program_counter
  store i64 4198721, i64* @rdi

; 0x40105f
  store volatile i64 4198495, i64* @_asm_program_counter
  %58 = call i64 @__libc_start_main()
  store i64 %58, i64* @rax

; 0x401065
  store volatile i64 4198501, i64* @_asm_program_counter
  call void @__asm_hlt()
  unreachable
}

define i64 @_dl_relocate_static_pie() {
dec_label_pc_401070:

; 0x401070
  store volatile i64 4198512, i64* @_asm_program_counter

; 0x401074
  store volatile i64 4198516, i64* @_asm_program_counter
  ret i64 undef
}

define i64 @deregister_tm_clones() {
dec_label_pc_401080:

; 0x401080
  store volatile i64 4198528, i64* @_asm_program_counter
  store i64 4210728, i64* @rdi

; 0x401087
  store volatile i64 4198535, i64* @_asm_program_counter
  store i64 4210728, i64* @rax

; 0x40108e
  store volatile i64 4198542, i64* @_asm_program_counter
  %0 = load i64, i64* @rax
  %1 = load i64, i64* @rdi
  %2 = sub i64 %0, %1
  %3 = and i64 %0, 15
  %4 = and i64 %1, 15
  %5 = sub i64 %3, %4
  %6 = icmp ugt i64 %5, 15
  %7 = icmp ult i64 %0, %1
  %8 = xor i64 %0, %1
  %9 = xor i64 %0, %2
  %10 = and i64 %8, %9
  %11 = icmp slt i64 %10, 0
  store i1 %6, i1* @az
  store i1 %7, i1* @cf
  store i1 %11, i1* @of
  %12 = icmp eq i64 %2, 0
  store i1 %12, i1* @zf
  %13 = icmp slt i64 %2, 0
  store i1 %13, i1* @sf
  %14 = trunc i64 %2 to i8
  %15 = call i8 @llvm.ctpop.i8(i8 %14)
  %16 = and i8 %15, 1
  %17 = icmp eq i8 %16, 0
  store i1 %17, i1* @pf

; 0x401091
  store volatile i64 4198545, i64* @_asm_program_counter
  %18 = load i1, i1* @zf
  br i1 %18, label %dec_label_pc_4010a8, label %dec_label_pc_401093

dec_label_pc_401093:                              ; preds = %dec_label_pc_401080

; 0x401093
  store volatile i64 4198547, i64* @_asm_program_counter
  %19 = load i64, i64* inttoptr (i64 4210664 to i64*)
  store i64 %19, i64* @rax

; 0x40109a
  store volatile i64 4198554, i64* @_asm_program_counter
  %20 = load i64, i64* @rax
  %21 = load i64, i64* @rax
  %22 = and i64 %20, %21
  store i1 false, i1* @az
  store i1 false, i1* @cf
  store i1 false, i1* @of
  %23 = icmp eq i64 %22, 0
  store i1 %23, i1* @zf
  %24 = icmp slt i64 %22, 0
  store i1 %24, i1* @sf
  %25 = trunc i64 %22 to i8
  %26 = call i8 @llvm.ctpop.i8(i8 %25)
  %27 = and i8 %26, 1
  %28 = icmp eq i8 %27, 0
  store i1 %28, i1* @pf

; 0x40109d
  store volatile i64 4198557, i64* @_asm_program_counter
  %29 = load i1, i1* @zf
  br i1 %29, label %dec_label_pc_4010a8, label %dec_label_pc_40109f

dec_label_pc_40109f:                              ; preds = %dec_label_pc_401093

; 0x40109f
  store volatile i64 4198559, i64* @_asm_program_counter
  %30 = call i64 @_ITM_deregisterTMCloneTable()
  store i64 %30, i64* @rax
  ret i64 undef

dec_label_pc_4010a8:                              ; preds = %dec_label_pc_401093, %dec_label_pc_401080

; 0x4010a8
  store volatile i64 4198568, i64* @_asm_program_counter
  ret i64 undef
}

define i64 @register_tm_clones() {
dec_label_pc_4010b0:

; 0x4010b0
  store volatile i64 4198576, i64* @_asm_program_counter
  store i64 4210728, i64* @rdi

; 0x4010b7
  store volatile i64 4198583, i64* @_asm_program_counter
  store i64 4210728, i64* @rsi

; 0x4010be
  store volatile i64 4198590, i64* @_asm_program_counter
  %0 = load i64, i64* @rsi
  %1 = load i64, i64* @rdi
  %2 = sub i64 %0, %1
  %3 = and i64 %0, 15
  %4 = and i64 %1, 15
  %5 = sub i64 %3, %4
  %6 = icmp ugt i64 %5, 15
  %7 = icmp ult i64 %0, %1
  %8 = xor i64 %0, %1
  %9 = xor i64 %0, %2
  %10 = and i64 %8, %9
  %11 = icmp slt i64 %10, 0
  store i1 %6, i1* @az
  store i1 %7, i1* @cf
  store i1 %11, i1* @of
  %12 = icmp eq i64 %2, 0
  store i1 %12, i1* @zf
  %13 = icmp slt i64 %2, 0
  store i1 %13, i1* @sf
  %14 = trunc i64 %2 to i8
  %15 = call i8 @llvm.ctpop.i8(i8 %14)
  %16 = and i8 %15, 1
  %17 = icmp eq i8 %16, 0
  store i1 %17, i1* @pf
  store i64 %2, i64* @rsi

; 0x4010c1
  store volatile i64 4198593, i64* @_asm_program_counter
  %18 = load i64, i64* @rsi
  store i64 %18, i64* @rax

; 0x4010c4
  store volatile i64 4198596, i64* @_asm_program_counter
  %19 = load i64, i64* @rsi
  %20 = load i1, i1* @of
  %21 = lshr i64 %19, 63
  %22 = icmp eq i64 %21, 0
  store i1 %22, i1* @zf
  %23 = icmp slt i64 %21, 0
  store i1 %23, i1* @sf
  %24 = trunc i64 %21 to i8
  %25 = call i8 @llvm.ctpop.i8(i8 %24)
  %26 = and i8 %25, 1
  %27 = icmp eq i8 %26, 0
  store i1 %27, i1* @pf
  store i64 %21, i64* @rsi
  %28 = and i64 4611686018427387904, %19
  %29 = icmp ne i64 %28, 0
  store i1 %29, i1* @cf
  %30 = icmp slt i64 %19, 0
  %31 = select i1 false, i1 %30, i1 %20
  store i1 %31, i1* @of

; 0x4010c8
  store volatile i64 4198600, i64* @_asm_program_counter
  %32 = load i64, i64* @rax
  %33 = load i1, i1* @of
  %34 = ashr i64 %32, 3
  %35 = icmp eq i64 %34, 0
  store i1 %35, i1* @zf
  %36 = icmp slt i64 %34, 0
  store i1 %36, i1* @sf
  %37 = trunc i64 %34 to i8
  %38 = call i8 @llvm.ctpop.i8(i8 %37)
  %39 = and i8 %38, 1
  %40 = icmp eq i8 %39, 0
  store i1 %40, i1* @pf
  store i64 %34, i64* @rax
  %41 = and i64 4, %32
  %42 = icmp ne i64 %41, 0
  store i1 %42, i1* @cf
  %43 = select i1 false, i1 false, i1 %33
  store i1 %43, i1* @of

; 0x4010cc
  store volatile i64 4198604, i64* @_asm_program_counter
  %44 = load i64, i64* @rsi
  %45 = load i64, i64* @rax
  %46 = add i64 %44, %45
  %47 = and i64 %44, 15
  %48 = and i64 %45, 15
  %49 = add i64 %47, %48
  %50 = icmp ugt i64 %49, 15
  %51 = icmp ult i64 %46, %44
  %52 = xor i64 %44, %46
  %53 = xor i64 %45, %46
  %54 = and i64 %52, %53
  %55 = icmp slt i64 %54, 0
  store i1 %50, i1* @az
  store i1 %51, i1* @cf
  store i1 %55, i1* @of
  %56 = icmp eq i64 %46, 0
  store i1 %56, i1* @zf
  %57 = icmp slt i64 %46, 0
  store i1 %57, i1* @sf
  %58 = trunc i64 %46 to i8
  %59 = call i8 @llvm.ctpop.i8(i8 %58)
  %60 = and i8 %59, 1
  %61 = icmp eq i8 %60, 0
  store i1 %61, i1* @pf
  store i64 %46, i64* @rsi

; 0x4010cf
  store volatile i64 4198607, i64* @_asm_program_counter
  %62 = load i64, i64* @rsi
  %63 = load i1, i1* @of
  %64 = ashr i64 %62, 1
  %65 = icmp eq i64 %64, 0
  store i1 %65, i1* @zf
  %66 = icmp slt i64 %64, 0
  store i1 %66, i1* @sf
  %67 = trunc i64 %64 to i8
  %68 = call i8 @llvm.ctpop.i8(i8 %67)
  %69 = and i8 %68, 1
  %70 = icmp eq i8 %69, 0
  store i1 %70, i1* @pf
  store i64 %64, i64* @rsi
  %71 = and i64 1, %62
  %72 = icmp ne i64 %71, 0
  store i1 %72, i1* @cf
  %73 = select i1 true, i1 false, i1 %63
  store i1 %73, i1* @of

; 0x4010d2
  store volatile i64 4198610, i64* @_asm_program_counter
  %74 = load i1, i1* @zf
  br i1 %74, label %dec_label_pc_4010e8, label %dec_label_pc_4010d4

dec_label_pc_4010d4:                              ; preds = %dec_label_pc_4010b0

; 0x4010d4
  store volatile i64 4198612, i64* @_asm_program_counter
  %75 = load i64, i64* inttoptr (i64 4210680 to i64*)
  store i64 %75, i64* @rax

; 0x4010db
  store volatile i64 4198619, i64* @_asm_program_counter
  %76 = load i64, i64* @rax
  %77 = load i64, i64* @rax
  %78 = and i64 %76, %77
  store i1 false, i1* @az
  store i1 false, i1* @cf
  store i1 false, i1* @of
  %79 = icmp eq i64 %78, 0
  store i1 %79, i1* @zf
  %80 = icmp slt i64 %78, 0
  store i1 %80, i1* @sf
  %81 = trunc i64 %78 to i8
  %82 = call i8 @llvm.ctpop.i8(i8 %81)
  %83 = and i8 %82, 1
  %84 = icmp eq i8 %83, 0
  store i1 %84, i1* @pf

; 0x4010de
  store volatile i64 4198622, i64* @_asm_program_counter
  %85 = load i1, i1* @zf
  br i1 %85, label %dec_label_pc_4010e8, label %dec_label_pc_4010e0

dec_label_pc_4010e0:                              ; preds = %dec_label_pc_4010d4

; 0x4010e0
  store volatile i64 4198624, i64* @_asm_program_counter
  %86 = call i64 @_ITM_registerTMCloneTable()
  store i64 %86, i64* @rax
  ret i64 undef

dec_label_pc_4010e8:                              ; preds = %dec_label_pc_4010d4, %dec_label_pc_4010b0

; 0x4010e8
  store volatile i64 4198632, i64* @_asm_program_counter
  ret i64 undef
}

define i64 @__do_global_dtors_aux() {
dec_label_pc_4010f0:

; 0x4010f0
  store volatile i64 4198640, i64* @_asm_program_counter

; 0x4010f4
  store volatile i64 4198644, i64* @_asm_program_counter
  %0 = load i8, i8* inttoptr (i64 4210724 to i8*)
  %1 = sub i8 %0, 0
  %2 = and i8 %0, 15
  %3 = sub i8 %2, 0
  %4 = icmp ugt i8 %3, 15
  %5 = icmp ult i8 %0, 0
  %6 = xor i8 %0, 0
  %7 = xor i8 %0, %1
  %8 = and i8 %6, %7
  %9 = icmp slt i8 %8, 0
  store i1 %4, i1* @az
  store i1 %5, i1* @cf
  store i1 %9, i1* @of
  %10 = icmp eq i8 %1, 0
  store i1 %10, i1* @zf
  %11 = icmp slt i8 %1, 0
  store i1 %11, i1* @sf
  %12 = call i8 @llvm.ctpop.i8(i8 %1)
  %13 = and i8 %12, 1
  %14 = icmp eq i8 %13, 0
  store i1 %14, i1* @pf

; 0x4010fb
  store volatile i64 4198651, i64* @_asm_program_counter
  %15 = load i1, i1* @zf
  %16 = icmp eq i1 %15, false
  br i1 %16, label %dec_label_pc_401110, label %dec_label_pc_4010fd

dec_label_pc_4010fd:                              ; preds = %dec_label_pc_4010f0

; 0x4010fd
  store volatile i64 4198653, i64* @_asm_program_counter
  %17 = load i64, i64* @rbp
  %18 = load i64, i64* @rsp
  %19 = sub i64 %18, 8
  %20 = inttoptr i64 %19 to i64*
  store i64 %17, i64* %20
  store i64 %19, i64* @rsp

; 0x4010fe
  store volatile i64 4198654, i64* @_asm_program_counter
  %21 = load i64, i64* @rsp
  store i64 %21, i64* @rbp

; 0x401101
  store volatile i64 4198657, i64* @_asm_program_counter
  %22 = call i64 @deregister_tm_clones()
  store i64 %22, i64* @rax

; 0x401106
  store volatile i64 4198662, i64* @_asm_program_counter
  store i8 1, i8* inttoptr (i64 4210724 to i8*)

; 0x40110d
  store volatile i64 4198669, i64* @_asm_program_counter
  %23 = load i64, i64* @rsp
  %24 = inttoptr i64 %23 to i64*
  %25 = load i64, i64* %24
  store i64 %25, i64* @rbp
  %26 = add i64 %23, 8
  store i64 %26, i64* @rsp

; 0x40110e
  store volatile i64 4198670, i64* @_asm_program_counter
  ret i64 undef

dec_label_pc_401110:                              ; preds = %dec_label_pc_4010f0

; 0x401110
  store volatile i64 4198672, i64* @_asm_program_counter
  ret i64 undef
}

define i64 @frame_dummy() {
dec_label_pc_401120:

; 0x401120
  store volatile i64 4198688, i64* @_asm_program_counter

; 0x401124
  store volatile i64 4198692, i64* @_asm_program_counter
  %0 = call i64 @register_tm_clones()
  store i64 %0, i64* @rax
  ret i64 undef
}

define i64 @add() {
dec_label_pc_401126:

; 0x401126
  store volatile i64 4198694, i64* @_asm_program_counter
  %0 = load i64, i64* @rbp
  %1 = load i64, i64* @rsp
  %2 = sub i64 %1, 8
  %3 = inttoptr i64 %2 to i64*
  store i64 %0, i64* %3
  store i64 %2, i64* @rsp

; 0x401127
  store volatile i64 4198695, i64* @_asm_program_counter
  %4 = load i64, i64* @rsp
  store i64 %4, i64* @rbp

; 0x40112a
  store volatile i64 4198698, i64* @_asm_program_counter
  %5 = load i64, i64* @rdi
  %6 = load i64, i64* @rbp
  %7 = add i64 %6, -8
  %8 = inttoptr i64 %7 to i64*
  store i64 %5, i64* %8

; 0x40112e
  store volatile i64 4198702, i64* @_asm_program_counter
  %9 = load i64, i64* @rsi
  %10 = trunc i64 %9 to i32
  %11 = zext i32 %10 to i64
  store i64 %11, i64* @rax

; 0x401130
  store volatile i64 4198704, i64* @_asm_program_counter
  %12 = load i64, i64* @rax
  %13 = trunc i64 %12 to i8
  %14 = load i64, i64* @rbp
  %15 = add i64 %14, -12
  %16 = inttoptr i64 %15 to i8*
  store i8 %13, i8* %16

; 0x401133
  store volatile i64 4198707, i64* @_asm_program_counter
  %17 = load i64, i64* @rbp
  %18 = add i64 %17, -8
  %19 = inttoptr i64 %18 to i64*
  %20 = load i64, i64* %19
  store i64 %20, i64* @rax

; 0x401137
  store volatile i64 4198711, i64* @_asm_program_counter
  %21 = load i64, i64* @rax
  %22 = inttoptr i64 %21 to i32*
  %23 = load i32, i32* %22
  %24 = zext i32 %23 to i64
  store i64 %24, i64* @rdx

; 0x401139
  store volatile i64 4198713, i64* @_asm_program_counter
  %25 = load i64, i64* @rbp
  %26 = add i64 %25, -12
  %27 = inttoptr i64 %26 to i8*
  %28 = load i8, i8* %27
  %29 = sext i8 %28 to i64
  store i64 %29, i64* @rax

; 0x40113d
  store volatile i64 4198717, i64* @_asm_program_counter
  %30 = load i64, i64* @rax
  %31 = trunc i64 %30 to i32
  %32 = load i64, i64* @rdx
  %33 = trunc i64 %32 to i32
  %34 = add i32 %31, %33
  %35 = and i32 %31, 15
  %36 = and i32 %33, 15
  %37 = add i32 %35, %36
  %38 = icmp ugt i32 %37, 15
  %39 = icmp ult i32 %34, %31
  %40 = xor i32 %31, %34
  %41 = xor i32 %33, %34
  %42 = and i32 %40, %41
  %43 = icmp slt i32 %42, 0
  store i1 %38, i1* @az
  store i1 %39, i1* @cf
  store i1 %43, i1* @of
  %44 = icmp eq i32 %34, 0
  store i1 %44, i1* @zf
  %45 = icmp slt i32 %34, 0
  store i1 %45, i1* @sf
  %46 = trunc i32 %34 to i8
  %47 = call i8 @llvm.ctpop.i8(i8 %46)
  %48 = and i8 %47, 1
  %49 = icmp eq i8 %48, 0
  store i1 %49, i1* @pf
  %50 = zext i32 %34 to i64
  store i64 %50, i64* @rax

; 0x40113f
  store volatile i64 4198719, i64* @_asm_program_counter
  %51 = load i64, i64* @rsp
  %52 = inttoptr i64 %51 to i64*
  %53 = load i64, i64* %52
  store i64 %53, i64* @rbp
  %54 = add i64 %51, 8
  store i64 %54, i64* @rsp

; 0x401140
  store volatile i64 4198720, i64* @_asm_program_counter
  ret i64 undef
}

define i64 @main() {
dec_label_pc_401141:

; 0x401141
  store volatile i64 4198721, i64* @_asm_program_counter
  %0 = load i64, i64* @rbp
  %1 = load i64, i64* @rsp
  %2 = sub i64 %1, 8
  %3 = inttoptr i64 %2 to i64*
  store i64 %0, i64* %3
  store i64 %2, i64* @rsp

; 0x401142
  store volatile i64 4198722, i64* @_asm_program_counter
  %4 = load i64, i64* @rsp
  store i64 %4, i64* @rbp

; 0x401145
  store volatile i64 4198725, i64* @_asm_program_counter
  %5 = load i64, i64* @rsp
  %6 = sub i64 %5, 32
  %7 = and i64 %5, 15
  %8 = sub i64 %7, 0
  %9 = icmp ugt i64 %8, 15
  %10 = icmp ult i64 %5, 32
  %11 = xor i64 %5, 32
  %12 = xor i64 %5, %6
  %13 = and i64 %11, %12
  %14 = icmp slt i64 %13, 0
  store i1 %9, i1* @az
  store i1 %10, i1* @cf
  store i1 %14, i1* @of
  %15 = icmp eq i64 %6, 0
  store i1 %15, i1* @zf
  %16 = icmp slt i64 %6, 0
  store i1 %16, i1* @sf
  %17 = trunc i64 %6 to i8
  %18 = call i8 @llvm.ctpop.i8(i8 %17)
  %19 = and i8 %18, 1
  %20 = icmp eq i8 %19, 0
  store i1 %20, i1* @pf
  store i64 %6, i64* @rsp

; 0x401149
  store volatile i64 4198729, i64* @_asm_program_counter
  %21 = load i64, i64* @rbp
  %22 = add i64 %21, -24
  %23 = inttoptr i64 %22 to i32*
  store i32 1, i32* %23

; 0x401150
  store volatile i64 4198736, i64* @_asm_program_counter
  %24 = load i64, i64* @rbp
  %25 = add i64 %24, -1
  %26 = inttoptr i64 %25 to i8*
  store i8 2, i8* %26

; 0x401154
  store volatile i64 4198740, i64* @_asm_program_counter
  %27 = load i64, i64* @rbp
  %28 = add i64 %27, -1
  %29 = inttoptr i64 %28 to i8*
  %30 = load i8, i8* %29
  %31 = sext i8 %30 to i64
  store i64 %31, i64* @rdx

; 0x401158
  store volatile i64 4198744, i64* @_asm_program_counter
  %32 = load i64, i64* @rbp
  %33 = add i64 %32, -24
  store i64 %33, i64* @rax

; 0x40115c
  store volatile i64 4198748, i64* @_asm_program_counter
  %34 = load i64, i64* @rdx
  %35 = trunc i64 %34 to i32
  %36 = zext i32 %35 to i64
  store i64 %36, i64* @rsi

; 0x40115e
  store volatile i64 4198750, i64* @_asm_program_counter
  %37 = load i64, i64* @rax
  store i64 %37, i64* @rdi

; 0x401161
  store volatile i64 4198753, i64* @_asm_program_counter
  %38 = call i64 @add()
  store i64 %38, i64* @rax

; 0x401166
  store volatile i64 4198758, i64* @_asm_program_counter
  %39 = load i64, i64* @rax
  %40 = trunc i64 %39 to i32
  %41 = load i64, i64* @rbp
  %42 = add i64 %41, -8
  %43 = inttoptr i64 %42 to i32*
  store i32 %40, i32* %43

; 0x401169
  store volatile i64 4198761, i64* @_asm_program_counter
  %44 = load i64, i64* @rbp
  %45 = add i64 %44, -24
  store i64 %45, i64* @rax

; 0x40116d
  store volatile i64 4198765, i64* @_asm_program_counter
  %46 = load i64, i64* @rax
  %47 = load i64, i64* @rbp
  %48 = add i64 %47, -16
  %49 = inttoptr i64 %48 to i64*
  store i64 %46, i64* %49

; 0x401171
  store volatile i64 4198769, i64* @_asm_program_counter
  %50 = load i64, i64* @rbp
  %51 = add i64 %50, -1
  %52 = inttoptr i64 %51 to i8*
  %53 = load i8, i8* %52
  %54 = sext i8 %53 to i64
  store i64 %54, i64* @rdx

; 0x401175
  store volatile i64 4198773, i64* @_asm_program_counter
  %55 = load i64, i64* @rbp
  %56 = add i64 %55, -16
  %57 = inttoptr i64 %56 to i64*
  %58 = load i64, i64* %57
  store i64 %58, i64* @rax

; 0x401179
  store volatile i64 4198777, i64* @_asm_program_counter
  %59 = load i64, i64* @rdx
  %60 = trunc i64 %59 to i32
  %61 = zext i32 %60 to i64
  store i64 %61, i64* @rsi

; 0x40117b
  store volatile i64 4198779, i64* @_asm_program_counter
  %62 = load i64, i64* @rax
  store i64 %62, i64* @rdi

; 0x40117e
  store volatile i64 4198782, i64* @_asm_program_counter
  %63 = call i64 @add()
  store i64 %63, i64* @rax

; 0x401183
  store volatile i64 4198787, i64* @_asm_program_counter
  %64 = load i64, i64* @rax
  %65 = trunc i64 %64 to i32
  %66 = load i64, i64* @rbp
  %67 = add i64 %66, -20
  %68 = inttoptr i64 %67 to i32*
  store i32 %65, i32* %68

; 0x401186
  store volatile i64 4198790, i64* @_asm_program_counter
  %69 = load i64, i64* @rbp
  %70 = add i64 %69, -8
  %71 = inttoptr i64 %70 to i32*
  %72 = load i32, i32* %71
  %73 = zext i32 %72 to i64
  store i64 %73, i64* @rax

; 0x401189
  store volatile i64 4198793, i64* @_asm_program_counter
  %74 = load i64, i64* @rax
  %75 = trunc i64 %74 to i32
  %76 = zext i32 %75 to i64
  store i64 %76, i64* @rsi

; 0x40118b
  store volatile i64 4198795, i64* @_asm_program_counter
  store i64 4202512, i64* @rdi

; 0x401190
  store volatile i64 4198800, i64* @_asm_program_counter
  store i64 0, i64* @rax

; 0x401195
  store volatile i64 4198805, i64* @_asm_program_counter
  %77 = call i64 @function_401030()
  store i64 %77, i64* @rax

; 0x40119a
  store volatile i64 4198810, i64* @_asm_program_counter
  store i64 0, i64* @rax

; 0x40119f
  store volatile i64 4198815, i64* @_asm_program_counter
  %78 = load i64, i64* @rbp
  %79 = inttoptr i64 %78 to i64*
  %80 = load i64, i64* %79
  %81 = add i64 %78, 8
  store i64 %80, i64* @rbp
  store i64 %81, i64* @rsp

; 0x4011a0
  store volatile i64 4198816, i64* @_asm_program_counter
  ret i64 undef
}

define i64 @_fini() {
dec_label_pc_4011a4:

; 0x4011a4
  store volatile i64 4198820, i64* @_asm_program_counter

; 0x4011a8
  store volatile i64 4198824, i64* @_asm_program_counter
  %0 = load i64, i64* @rsp
  %1 = sub i64 %0, 8
  %2 = and i64 %0, 15
  %3 = sub i64 %2, 8
  %4 = icmp ugt i64 %3, 15
  %5 = icmp ult i64 %0, 8
  %6 = xor i64 %0, 8
  %7 = xor i64 %0, %1
  %8 = and i64 %6, %7
  %9 = icmp slt i64 %8, 0
  store i1 %4, i1* @az
  store i1 %5, i1* @cf
  store i1 %9, i1* @of
  %10 = icmp eq i64 %1, 0
  store i1 %10, i1* @zf
  %11 = icmp slt i64 %1, 0
  store i1 %11, i1* @sf
  %12 = trunc i64 %1 to i8
  %13 = call i8 @llvm.ctpop.i8(i8 %12)
  %14 = and i8 %13, 1
  %15 = icmp eq i8 %14, 0
  store i1 %15, i1* @pf
  store i64 %1, i64* @rsp

; 0x4011ac
  store volatile i64 4198828, i64* @_asm_program_counter
  %16 = load i64, i64* @rsp
  %17 = add i64 %16, 8
  %18 = and i64 %16, 15
  %19 = add i64 %18, 8
  %20 = icmp ugt i64 %19, 15
  %21 = icmp ult i64 %17, %16
  %22 = xor i64 %16, %17
  %23 = xor i64 8, %17
  %24 = and i64 %22, %23
  %25 = icmp slt i64 %24, 0
  store i1 %20, i1* @az
  store i1 %21, i1* @cf
  store i1 %25, i1* @of
  %26 = icmp eq i64 %17, 0
  store i1 %26, i1* @zf
  %27 = icmp slt i64 %17, 0
  store i1 %27, i1* @sf
  %28 = trunc i64 %17 to i8
  %29 = call i8 @llvm.ctpop.i8(i8 %28)
  %30 = and i8 %29, 1
  %31 = icmp eq i8 %30, 0
  store i1 %31, i1* @pf
  store i64 %17, i64* @rsp

; 0x4011b0
  store volatile i64 4198832, i64* @_asm_program_counter
  ret i64 undef
}

declare i64 @__libc_start_main()

declare i64 @_ITM_deregisterTMCloneTable()

declare i64 @__gmon_start__()

declare i64 @_ITM_registerTMCloneTable()

declare i64 @printf()

declare void @__pseudo_call(i64)

declare void @__pseudo_return(i64)

declare void @__pseudo_branch(i64)

declare void @__pseudo_cond_branch(i1, i64)

declare void @__frontend_reg_store.fpr(i3, x86_fp80)

declare x86_fp80 @__frontend_reg_load.fpr(i3)

; Function Attrs: nounwind readnone speculatable
declare i8 @llvm.ctpop.i8(i8) #0

declare void @__asm_hlt()

attributes #0 = { nounwind readnone speculatable }
*** IR Dump After Main function identification optimization ***
source_filename = "test"
target datalayout = "e-m:e-p:64:64-i64:64-f80:128-n8:16:32:64-S128"

@_asm_program_counter = internal global i64 0
@cf = internal global i1 false
@pf = internal global i1 false
@az = internal global i1 false
@zf = internal global i1 false
@sf = internal global i1 false
@tf = internal global i1 false
@if = internal global i1 false
@df = internal global i1 false
@of = internal global i1 false
@iopl = internal global i2 0
@nt = internal global i1 false
@rf = internal global i1 false
@vm = internal global i1 false
@ac = internal global i1 false
@vif = internal global i1 false
@vip = internal global i1 false
@id = internal global i1 false
@rflags = internal global i64 0
@ss = internal global i16 0
@cs = internal global i16 0
@ds = internal global i16 0
@es = internal global i16 0
@fs = internal global i16 0
@gs = internal global i16 0
@st0 = internal global x86_fp80 0xK00000000000000000000
@st1 = internal global x86_fp80 0xK00000000000000000000
@st2 = internal global x86_fp80 0xK00000000000000000000
@st3 = internal global x86_fp80 0xK00000000000000000000
@st4 = internal global x86_fp80 0xK00000000000000000000
@st5 = internal global x86_fp80 0xK00000000000000000000
@st6 = internal global x86_fp80 0xK00000000000000000000
@st7 = internal global x86_fp80 0xK00000000000000000000
@fpu_stat_IE = internal global i1 false
@fpu_stat_DE = internal global i1 false
@fpu_stat_ZE = internal global i1 false
@fpu_stat_OE = internal global i1 false
@fpu_stat_UE = internal global i1 false
@fpu_stat_PE = internal global i1 false
@fpu_stat_SF = internal global i1 false
@fpu_stat_ES = internal global i1 false
@fpu_stat_C0 = internal global i1 false
@fpu_stat_C1 = internal global i1 false
@fpu_stat_C2 = internal global i1 false
@fpu_stat_C3 = internal global i1 false
@fpu_stat_TOP = internal global i3 0
@fpu_stat_B = internal global i1 false
@fpu_control_IM = internal global i1 false
@fpu_control_DM = internal global i1 false
@fpu_control_ZM = internal global i1 false
@fpu_control_OM = internal global i1 false
@fpu_control_UM = internal global i1 false
@fpu_control_PM = internal global i1 false
@fpu_control_PC = internal global i2 0
@fpu_control_RC = internal global i2 0
@fpu_control_X = internal global i1 false
@fp0 = internal global double 0.000000e+00
@fp1 = internal global double 0.000000e+00
@fp2 = internal global double 0.000000e+00
@fp3 = internal global double 0.000000e+00
@fp4 = internal global double 0.000000e+00
@fp5 = internal global double 0.000000e+00
@fp6 = internal global double 0.000000e+00
@fp7 = internal global double 0.000000e+00
@k0 = internal global i64 0
@k1 = internal global i64 0
@k2 = internal global i64 0
@k3 = internal global i64 0
@k4 = internal global i64 0
@k5 = internal global i64 0
@k6 = internal global i64 0
@k7 = internal global i64 0
@mm0 = internal global i64 0
@mm1 = internal global i64 0
@mm2 = internal global i64 0
@mm3 = internal global i64 0
@mm4 = internal global i64 0
@mm5 = internal global i64 0
@mm6 = internal global i64 0
@mm7 = internal global i64 0
@xmm0 = internal global i128 0
@xmm1 = internal global i128 0
@xmm2 = internal global i128 0
@xmm3 = internal global i128 0
@xmm4 = internal global i128 0
@xmm5 = internal global i128 0
@xmm6 = internal global i128 0
@xmm7 = internal global i128 0
@xmm8 = internal global i128 0
@xmm9 = internal global i128 0
@xmm10 = internal global i128 0
@xmm11 = internal global i128 0
@xmm12 = internal global i128 0
@xmm13 = internal global i128 0
@xmm14 = internal global i128 0
@xmm15 = internal global i128 0
@xmm16 = internal global i128 0
@xmm17 = internal global i128 0
@xmm18 = internal global i128 0
@xmm19 = internal global i128 0
@xmm20 = internal global i128 0
@xmm21 = internal global i128 0
@xmm22 = internal global i128 0
@xmm23 = internal global i128 0
@xmm24 = internal global i128 0
@xmm25 = internal global i128 0
@xmm26 = internal global i128 0
@xmm27 = internal global i128 0
@xmm28 = internal global i128 0
@xmm29 = internal global i128 0
@xmm30 = internal global i128 0
@xmm31 = internal global i128 0
@ymm0 = internal global i256 0
@ymm1 = internal global i256 0
@ymm2 = internal global i256 0
@ymm3 = internal global i256 0
@ymm4 = internal global i256 0
@ymm5 = internal global i256 0
@ymm6 = internal global i256 0
@ymm7 = internal global i256 0
@ymm8 = internal global i256 0
@ymm9 = internal global i256 0
@ymm10 = internal global i256 0
@ymm11 = internal global i256 0
@ymm12 = internal global i256 0
@ymm13 = internal global i256 0
@ymm14 = internal global i256 0
@ymm15 = internal global i256 0
@ymm16 = internal global i256 0
@ymm17 = internal global i256 0
@ymm18 = internal global i256 0
@ymm19 = internal global i256 0
@ymm20 = internal global i256 0
@ymm21 = internal global i256 0
@ymm22 = internal global i256 0
@ymm23 = internal global i256 0
@ymm24 = internal global i256 0
@ymm25 = internal global i256 0
@ymm26 = internal global i256 0
@ymm27 = internal global i256 0
@ymm28 = internal global i256 0
@ymm29 = internal global i256 0
@ymm30 = internal global i256 0
@ymm31 = internal global i256 0
@zmm0 = internal global i512 0
@zmm1 = internal global i512 0
@zmm2 = internal global i512 0
@zmm3 = internal global i512 0
@zmm4 = internal global i512 0
@zmm5 = internal global i512 0
@zmm6 = internal global i512 0
@zmm7 = internal global i512 0
@zmm8 = internal global i512 0
@zmm9 = internal global i512 0
@zmm10 = internal global i512 0
@zmm11 = internal global i512 0
@zmm12 = internal global i512 0
@zmm13 = internal global i512 0
@zmm14 = internal global i512 0
@zmm15 = internal global i512 0
@zmm16 = internal global i512 0
@zmm17 = internal global i512 0
@zmm18 = internal global i512 0
@zmm19 = internal global i512 0
@zmm20 = internal global i512 0
@zmm21 = internal global i512 0
@zmm22 = internal global i512 0
@zmm23 = internal global i512 0
@zmm24 = internal global i512 0
@zmm25 = internal global i512 0
@zmm26 = internal global i512 0
@zmm27 = internal global i512 0
@zmm28 = internal global i512 0
@zmm29 = internal global i512 0
@zmm30 = internal global i512 0
@zmm31 = internal global i512 0
@bnd0 = internal global i128 0
@bnd1 = internal global i128 0
@bnd2 = internal global i128 0
@bnd3 = internal global i128 0
@dr0 = internal global i64 0
@dr1 = internal global i64 0
@dr2 = internal global i64 0
@dr3 = internal global i64 0
@dr4 = internal global i64 0
@dr5 = internal global i64 0
@dr6 = internal global i64 0
@dr7 = internal global i64 0
@dr8 = internal global i64 0
@dr9 = internal global i64 0
@dr10 = internal global i64 0
@dr11 = internal global i64 0
@dr12 = internal global i64 0
@dr13 = internal global i64 0
@dr14 = internal global i64 0
@dr15 = internal global i64 0
@cr0 = internal global i64 0
@cr1 = internal global i64 0
@cr2 = internal global i64 0
@cr3 = internal global i64 0
@cr4 = internal global i64 0
@cr5 = internal global i64 0
@cr6 = internal global i64 0
@cr7 = internal global i64 0
@cr8 = internal global i64 0
@cr9 = internal global i64 0
@cr10 = internal global i64 0
@cr11 = internal global i64 0
@cr12 = internal global i64 0
@cr13 = internal global i64 0
@cr14 = internal global i64 0
@cr15 = internal global i64 0
@fpsw = internal global i64 0
@rax = internal global i64 0
@rcx = internal global i64 0
@rdx = internal global i64 0
@rbx = internal global i64 0
@rsp = internal global i64 0
@rbp = internal global i64 0
@rsi = internal global i64 0
@rdi = internal global i64 0
@r8 = internal global i64 0
@r9 = internal global i64 0
@r10 = internal global i64 0
@r11 = internal global i64 0
@r12 = internal global i64 0
@r13 = internal global i64 0
@r14 = internal global i64 0
@r15 = internal global i64 0
@rip = internal global i64 0
@riz = internal global i64 0

define i64 @_init() {
dec_label_pc_401000:

; 0x401000
  store volatile i64 4198400, i64* @_asm_program_counter

; 0x401004
  store volatile i64 4198404, i64* @_asm_program_counter
  %0 = load i64, i64* @rsp
  %1 = sub i64 %0, 8
  %2 = and i64 %0, 15
  %3 = sub i64 %2, 8
  %4 = icmp ugt i64 %3, 15
  %5 = icmp ult i64 %0, 8
  %6 = xor i64 %0, 8
  %7 = xor i64 %0, %1
  %8 = and i64 %6, %7
  %9 = icmp slt i64 %8, 0
  store i1 %4, i1* @az
  store i1 %5, i1* @cf
  store i1 %9, i1* @of
  %10 = icmp eq i64 %1, 0
  store i1 %10, i1* @zf
  %11 = icmp slt i64 %1, 0
  store i1 %11, i1* @sf
  %12 = trunc i64 %1 to i8
  %13 = call i8 @llvm.ctpop.i8(i8 %12)
  %14 = and i8 %13, 1
  %15 = icmp eq i8 %14, 0
  store i1 %15, i1* @pf
  store i64 %1, i64* @rsp

; 0x401008
  store volatile i64 4198408, i64* @_asm_program_counter
  %16 = load i64, i64* inttoptr (i64 4210672 to i64*)
  store i64 %16, i64* @rax

; 0x40100f
  store volatile i64 4198415, i64* @_asm_program_counter
  %17 = load i64, i64* @rax
  %18 = load i64, i64* @rax
  %19 = and i64 %17, %18
  store i1 false, i1* @az
  store i1 false, i1* @cf
  store i1 false, i1* @of
  %20 = icmp eq i64 %19, 0
  store i1 %20, i1* @zf
  %21 = icmp slt i64 %19, 0
  store i1 %21, i1* @sf
  %22 = trunc i64 %19 to i8
  %23 = call i8 @llvm.ctpop.i8(i8 %22)
  %24 = and i8 %23, 1
  %25 = icmp eq i8 %24, 0
  store i1 %25, i1* @pf

; 0x401012
  store volatile i64 4198418, i64* @_asm_program_counter
  %26 = load i1, i1* @zf
  br i1 %26, label %dec_label_pc_401016, label %dec_label_pc_401014

dec_label_pc_401014:                              ; preds = %dec_label_pc_401000

; 0x401014
  store volatile i64 4198420, i64* @_asm_program_counter
  %27 = call i64 @__gmon_start__()
  store i64 %27, i64* @rax
  br label %dec_label_pc_401016

dec_label_pc_401016:                              ; preds = %dec_label_pc_401014, %dec_label_pc_401000

; 0x401016
  store volatile i64 4198422, i64* @_asm_program_counter
  %28 = load i64, i64* @rsp
  %29 = add i64 %28, 8
  %30 = and i64 %28, 15
  %31 = add i64 %30, 8
  %32 = icmp ugt i64 %31, 15
  %33 = icmp ult i64 %29, %28
  %34 = xor i64 %28, %29
  %35 = xor i64 8, %29
  %36 = and i64 %34, %35
  %37 = icmp slt i64 %36, 0
  store i1 %32, i1* @az
  store i1 %33, i1* @cf
  store i1 %37, i1* @of
  %38 = icmp eq i64 %29, 0
  store i1 %38, i1* @zf
  %39 = icmp slt i64 %29, 0
  store i1 %39, i1* @sf
  %40 = trunc i64 %29 to i8
  %41 = call i8 @llvm.ctpop.i8(i8 %40)
  %42 = and i8 %41, 1
  %43 = icmp eq i8 %42, 0
  store i1 %43, i1* @pf
  store i64 %29, i64* @rsp

; 0x40101a
  store volatile i64 4198426, i64* @_asm_program_counter
  ret i64 undef
}

define i64 @function_401030() {
dec_label_pc_401030:

; 0x401030
  store volatile i64 4198448, i64* @_asm_program_counter
  %0 = call i64 @printf()
  store i64 %0, i64* @rax
  ret i64 undef
}

define i64 @_start() {
dec_label_pc_401040:

; 0x401040
  store volatile i64 4198464, i64* @_asm_program_counter

; 0x401044
  store volatile i64 4198468, i64* @_asm_program_counter
  %0 = load i64, i64* @rbp
  %1 = trunc i64 %0 to i32
  %2 = load i64, i64* @rbp
  %3 = trunc i64 %2 to i32
  %4 = xor i32 %1, %3
  store i1 false, i1* @az
  store i1 false, i1* @cf
  store i1 false, i1* @of
  %5 = icmp eq i32 %4, 0
  store i1 %5, i1* @zf
  %6 = icmp slt i32 %4, 0
  store i1 %6, i1* @sf
  %7 = trunc i32 %4 to i8
  %8 = call i8 @llvm.ctpop.i8(i8 %7)
  %9 = and i8 %8, 1
  %10 = icmp eq i8 %9, 0
  store i1 %10, i1* @pf
  %11 = zext i32 %4 to i64
  store i64 %11, i64* @rbp

; 0x401046
  store volatile i64 4198470, i64* @_asm_program_counter
  %12 = load i64, i64* @rdx
  store i64 %12, i64* @r9

; 0x401049
  store volatile i64 4198473, i64* @_asm_program_counter
  %13 = load i64, i64* @rsp
  %14 = inttoptr i64 %13 to i64*
  %15 = load i64, i64* %14
  store i64 %15, i64* @rsi
  %16 = add i64 %13, 8
  store i64 %16, i64* @rsp

; 0x40104a
  store volatile i64 4198474, i64* @_asm_program_counter
  %17 = load i64, i64* @rsp
  store i64 %17, i64* @rdx

; 0x40104d
  store volatile i64 4198477, i64* @_asm_program_counter
  %18 = load i64, i64* @rsp
  %19 = and i64 %18, -16
  store i1 false, i1* @az
  store i1 false, i1* @cf
  store i1 false, i1* @of
  %20 = icmp eq i64 %19, 0
  store i1 %20, i1* @zf
  %21 = icmp slt i64 %19, 0
  store i1 %21, i1* @sf
  %22 = trunc i64 %19 to i8
  %23 = call i8 @llvm.ctpop.i8(i8 %22)
  %24 = and i8 %23, 1
  %25 = icmp eq i8 %24, 0
  store i1 %25, i1* @pf
  store i64 %19, i64* @rsp

; 0x401051
  store volatile i64 4198481, i64* @_asm_program_counter
  %26 = load i64, i64* @rax
  %27 = load i64, i64* @rsp
  %28 = sub i64 %27, 8
  %29 = inttoptr i64 %28 to i64*
  store i64 %26, i64* %29
  store i64 %28, i64* @rsp

; 0x401052
  store volatile i64 4198482, i64* @_asm_program_counter
  %30 = load i64, i64* @rsp
  %31 = load i64, i64* @rsp
  %32 = sub i64 %31, 8
  %33 = inttoptr i64 %32 to i64*
  store i64 %30, i64* %33
  store i64 %32, i64* @rsp

; 0x401053
  store volatile i64 4198483, i64* @_asm_program_counter
  %34 = load i64, i64* @r8
  %35 = trunc i64 %34 to i32
  %36 = load i64, i64* @r8
  %37 = trunc i64 %36 to i32
  %38 = xor i32 %35, %37
  store i1 false, i1* @az
  store i1 false, i1* @cf
  store i1 false, i1* @of
  %39 = icmp eq i32 %38, 0
  store i1 %39, i1* @zf
  %40 = icmp slt i32 %38, 0
  store i1 %40, i1* @sf
  %41 = trunc i32 %38 to i8
  %42 = call i8 @llvm.ctpop.i8(i8 %41)
  %43 = and i8 %42, 1
  %44 = icmp eq i8 %43, 0
  store i1 %44, i1* @pf
  %45 = zext i32 %38 to i64
  store i64 %45, i64* @r8

; 0x401056
  store volatile i64 4198486, i64* @_asm_program_counter
  %46 = load i64, i64* @rcx
  %47 = trunc i64 %46 to i32
  %48 = load i64, i64* @rcx
  %49 = trunc i64 %48 to i32
  %50 = xor i32 %47, %49
  store i1 false, i1* @az
  store i1 false, i1* @cf
  store i1 false, i1* @of
  %51 = icmp eq i32 %50, 0
  store i1 %51, i1* @zf
  %52 = icmp slt i32 %50, 0
  store i1 %52, i1* @sf
  %53 = trunc i32 %50 to i8
  %54 = call i8 @llvm.ctpop.i8(i8 %53)
  %55 = and i8 %54, 1
  %56 = icmp eq i8 %55, 0
  store i1 %56, i1* @pf
  %57 = zext i32 %50 to i64
  store i64 %57, i64* @rcx

; 0x401058
  store volatile i64 4198488, i64* @_asm_program_counter
  store i64 4198721, i64* @rdi

; 0x40105f
  store volatile i64 4198495, i64* @_asm_program_counter
  %58 = call i64 @__libc_start_main()
  store i64 %58, i64* @rax

; 0x401065
  store volatile i64 4198501, i64* @_asm_program_counter
  call void @__asm_hlt()
  unreachable
}

define i64 @_dl_relocate_static_pie() {
dec_label_pc_401070:

; 0x401070
  store volatile i64 4198512, i64* @_asm_program_counter

; 0x401074
  store volatile i64 4198516, i64* @_asm_program_counter
  ret i64 undef
}

define i64 @deregister_tm_clones() {
dec_label_pc_401080:

; 0x401080
  store volatile i64 4198528, i64* @_asm_program_counter
  store i64 4210728, i64* @rdi

; 0x401087
  store volatile i64 4198535, i64* @_asm_program_counter
  store i64 4210728, i64* @rax

; 0x40108e
  store volatile i64 4198542, i64* @_asm_program_counter
  %0 = load i64, i64* @rax
  %1 = load i64, i64* @rdi
  %2 = sub i64 %0, %1
  %3 = and i64 %0, 15
  %4 = and i64 %1, 15
  %5 = sub i64 %3, %4
  %6 = icmp ugt i64 %5, 15
  %7 = icmp ult i64 %0, %1
  %8 = xor i64 %0, %1
  %9 = xor i64 %0, %2
  %10 = and i64 %8, %9
  %11 = icmp slt i64 %10, 0
  store i1 %6, i1* @az
  store i1 %7, i1* @cf
  store i1 %11, i1* @of
  %12 = icmp eq i64 %2, 0
  store i1 %12, i1* @zf
  %13 = icmp slt i64 %2, 0
  store i1 %13, i1* @sf
  %14 = trunc i64 %2 to i8
  %15 = call i8 @llvm.ctpop.i8(i8 %14)
  %16 = and i8 %15, 1
  %17 = icmp eq i8 %16, 0
  store i1 %17, i1* @pf

; 0x401091
  store volatile i64 4198545, i64* @_asm_program_counter
  %18 = load i1, i1* @zf
  br i1 %18, label %dec_label_pc_4010a8, label %dec_label_pc_401093

dec_label_pc_401093:                              ; preds = %dec_label_pc_401080

; 0x401093
  store volatile i64 4198547, i64* @_asm_program_counter
  %19 = load i64, i64* inttoptr (i64 4210664 to i64*)
  store i64 %19, i64* @rax

; 0x40109a
  store volatile i64 4198554, i64* @_asm_program_counter
  %20 = load i64, i64* @rax
  %21 = load i64, i64* @rax
  %22 = and i64 %20, %21
  store i1 false, i1* @az
  store i1 false, i1* @cf
  store i1 false, i1* @of
  %23 = icmp eq i64 %22, 0
  store i1 %23, i1* @zf
  %24 = icmp slt i64 %22, 0
  store i1 %24, i1* @sf
  %25 = trunc i64 %22 to i8
  %26 = call i8 @llvm.ctpop.i8(i8 %25)
  %27 = and i8 %26, 1
  %28 = icmp eq i8 %27, 0
  store i1 %28, i1* @pf

; 0x40109d
  store volatile i64 4198557, i64* @_asm_program_counter
  %29 = load i1, i1* @zf
  br i1 %29, label %dec_label_pc_4010a8, label %dec_label_pc_40109f

dec_label_pc_40109f:                              ; preds = %dec_label_pc_401093

; 0x40109f
  store volatile i64 4198559, i64* @_asm_program_counter
  %30 = call i64 @_ITM_deregisterTMCloneTable()
  store i64 %30, i64* @rax
  ret i64 undef

dec_label_pc_4010a8:                              ; preds = %dec_label_pc_401093, %dec_label_pc_401080

; 0x4010a8
  store volatile i64 4198568, i64* @_asm_program_counter
  ret i64 undef
}

define i64 @register_tm_clones() {
dec_label_pc_4010b0:

; 0x4010b0
  store volatile i64 4198576, i64* @_asm_program_counter
  store i64 4210728, i64* @rdi

; 0x4010b7
  store volatile i64 4198583, i64* @_asm_program_counter
  store i64 4210728, i64* @rsi

; 0x4010be
  store volatile i64 4198590, i64* @_asm_program_counter
  %0 = load i64, i64* @rsi
  %1 = load i64, i64* @rdi
  %2 = sub i64 %0, %1
  %3 = and i64 %0, 15
  %4 = and i64 %1, 15
  %5 = sub i64 %3, %4
  %6 = icmp ugt i64 %5, 15
  %7 = icmp ult i64 %0, %1
  %8 = xor i64 %0, %1
  %9 = xor i64 %0, %2
  %10 = and i64 %8, %9
  %11 = icmp slt i64 %10, 0
  store i1 %6, i1* @az
  store i1 %7, i1* @cf
  store i1 %11, i1* @of
  %12 = icmp eq i64 %2, 0
  store i1 %12, i1* @zf
  %13 = icmp slt i64 %2, 0
  store i1 %13, i1* @sf
  %14 = trunc i64 %2 to i8
  %15 = call i8 @llvm.ctpop.i8(i8 %14)
  %16 = and i8 %15, 1
  %17 = icmp eq i8 %16, 0
  store i1 %17, i1* @pf
  store i64 %2, i64* @rsi

; 0x4010c1
  store volatile i64 4198593, i64* @_asm_program_counter
  %18 = load i64, i64* @rsi
  store i64 %18, i64* @rax

; 0x4010c4
  store volatile i64 4198596, i64* @_asm_program_counter
  %19 = load i64, i64* @rsi
  %20 = load i1, i1* @of
  %21 = lshr i64 %19, 63
  %22 = icmp eq i64 %21, 0
  store i1 %22, i1* @zf
  %23 = icmp slt i64 %21, 0
  store i1 %23, i1* @sf
  %24 = trunc i64 %21 to i8
  %25 = call i8 @llvm.ctpop.i8(i8 %24)
  %26 = and i8 %25, 1
  %27 = icmp eq i8 %26, 0
  store i1 %27, i1* @pf
  store i64 %21, i64* @rsi
  %28 = and i64 4611686018427387904, %19
  %29 = icmp ne i64 %28, 0
  store i1 %29, i1* @cf
  %30 = icmp slt i64 %19, 0
  %31 = select i1 false, i1 %30, i1 %20
  store i1 %31, i1* @of

; 0x4010c8
  store volatile i64 4198600, i64* @_asm_program_counter
  %32 = load i64, i64* @rax
  %33 = load i1, i1* @of
  %34 = ashr i64 %32, 3
  %35 = icmp eq i64 %34, 0
  store i1 %35, i1* @zf
  %36 = icmp slt i64 %34, 0
  store i1 %36, i1* @sf
  %37 = trunc i64 %34 to i8
  %38 = call i8 @llvm.ctpop.i8(i8 %37)
  %39 = and i8 %38, 1
  %40 = icmp eq i8 %39, 0
  store i1 %40, i1* @pf
  store i64 %34, i64* @rax
  %41 = and i64 4, %32
  %42 = icmp ne i64 %41, 0
  store i1 %42, i1* @cf
  %43 = select i1 false, i1 false, i1 %33
  store i1 %43, i1* @of

; 0x4010cc
  store volatile i64 4198604, i64* @_asm_program_counter
  %44 = load i64, i64* @rsi
  %45 = load i64, i64* @rax
  %46 = add i64 %44, %45
  %47 = and i64 %44, 15
  %48 = and i64 %45, 15
  %49 = add i64 %47, %48
  %50 = icmp ugt i64 %49, 15
  %51 = icmp ult i64 %46, %44
  %52 = xor i64 %44, %46
  %53 = xor i64 %45, %46
  %54 = and i64 %52, %53
  %55 = icmp slt i64 %54, 0
  store i1 %50, i1* @az
  store i1 %51, i1* @cf
  store i1 %55, i1* @of
  %56 = icmp eq i64 %46, 0
  store i1 %56, i1* @zf
  %57 = icmp slt i64 %46, 0
  store i1 %57, i1* @sf
  %58 = trunc i64 %46 to i8
  %59 = call i8 @llvm.ctpop.i8(i8 %58)
  %60 = and i8 %59, 1
  %61 = icmp eq i8 %60, 0
  store i1 %61, i1* @pf
  store i64 %46, i64* @rsi

; 0x4010cf
  store volatile i64 4198607, i64* @_asm_program_counter
  %62 = load i64, i64* @rsi
  %63 = load i1, i1* @of
  %64 = ashr i64 %62, 1
  %65 = icmp eq i64 %64, 0
  store i1 %65, i1* @zf
  %66 = icmp slt i64 %64, 0
  store i1 %66, i1* @sf
  %67 = trunc i64 %64 to i8
  %68 = call i8 @llvm.ctpop.i8(i8 %67)
  %69 = and i8 %68, 1
  %70 = icmp eq i8 %69, 0
  store i1 %70, i1* @pf
  store i64 %64, i64* @rsi
  %71 = and i64 1, %62
  %72 = icmp ne i64 %71, 0
  store i1 %72, i1* @cf
  %73 = select i1 true, i1 false, i1 %63
  store i1 %73, i1* @of

; 0x4010d2
  store volatile i64 4198610, i64* @_asm_program_counter
  %74 = load i1, i1* @zf
  br i1 %74, label %dec_label_pc_4010e8, label %dec_label_pc_4010d4

dec_label_pc_4010d4:                              ; preds = %dec_label_pc_4010b0

; 0x4010d4
  store volatile i64 4198612, i64* @_asm_program_counter
  %75 = load i64, i64* inttoptr (i64 4210680 to i64*)
  store i64 %75, i64* @rax

; 0x4010db
  store volatile i64 4198619, i64* @_asm_program_counter
  %76 = load i64, i64* @rax
  %77 = load i64, i64* @rax
  %78 = and i64 %76, %77
  store i1 false, i1* @az
  store i1 false, i1* @cf
  store i1 false, i1* @of
  %79 = icmp eq i64 %78, 0
  store i1 %79, i1* @zf
  %80 = icmp slt i64 %78, 0
  store i1 %80, i1* @sf
  %81 = trunc i64 %78 to i8
  %82 = call i8 @llvm.ctpop.i8(i8 %81)
  %83 = and i8 %82, 1
  %84 = icmp eq i8 %83, 0
  store i1 %84, i1* @pf

; 0x4010de
  store volatile i64 4198622, i64* @_asm_program_counter
  %85 = load i1, i1* @zf
  br i1 %85, label %dec_label_pc_4010e8, label %dec_label_pc_4010e0

dec_label_pc_4010e0:                              ; preds = %dec_label_pc_4010d4

; 0x4010e0
  store volatile i64 4198624, i64* @_asm_program_counter
  %86 = call i64 @_ITM_registerTMCloneTable()
  store i64 %86, i64* @rax
  ret i64 undef

dec_label_pc_4010e8:                              ; preds = %dec_label_pc_4010d4, %dec_label_pc_4010b0

; 0x4010e8
  store volatile i64 4198632, i64* @_asm_program_counter
  ret i64 undef
}

define i64 @__do_global_dtors_aux() {
dec_label_pc_4010f0:

; 0x4010f0
  store volatile i64 4198640, i64* @_asm_program_counter

; 0x4010f4
  store volatile i64 4198644, i64* @_asm_program_counter
  %0 = load i8, i8* inttoptr (i64 4210724 to i8*)
  %1 = sub i8 %0, 0
  %2 = and i8 %0, 15
  %3 = sub i8 %2, 0
  %4 = icmp ugt i8 %3, 15
  %5 = icmp ult i8 %0, 0
  %6 = xor i8 %0, 0
  %7 = xor i8 %0, %1
  %8 = and i8 %6, %7
  %9 = icmp slt i8 %8, 0
  store i1 %4, i1* @az
  store i1 %5, i1* @cf
  store i1 %9, i1* @of
  %10 = icmp eq i8 %1, 0
  store i1 %10, i1* @zf
  %11 = icmp slt i8 %1, 0
  store i1 %11, i1* @sf
  %12 = call i8 @llvm.ctpop.i8(i8 %1)
  %13 = and i8 %12, 1
  %14 = icmp eq i8 %13, 0
  store i1 %14, i1* @pf

; 0x4010fb
  store volatile i64 4198651, i64* @_asm_program_counter
  %15 = load i1, i1* @zf
  %16 = icmp eq i1 %15, false
  br i1 %16, label %dec_label_pc_401110, label %dec_label_pc_4010fd

dec_label_pc_4010fd:                              ; preds = %dec_label_pc_4010f0

; 0x4010fd
  store volatile i64 4198653, i64* @_asm_program_counter
  %17 = load i64, i64* @rbp
  %18 = load i64, i64* @rsp
  %19 = sub i64 %18, 8
  %20 = inttoptr i64 %19 to i64*
  store i64 %17, i64* %20
  store i64 %19, i64* @rsp

; 0x4010fe
  store volatile i64 4198654, i64* @_asm_program_counter
  %21 = load i64, i64* @rsp
  store i64 %21, i64* @rbp

; 0x401101
  store volatile i64 4198657, i64* @_asm_program_counter
  %22 = call i64 @deregister_tm_clones()
  store i64 %22, i64* @rax

; 0x401106
  store volatile i64 4198662, i64* @_asm_program_counter
  store i8 1, i8* inttoptr (i64 4210724 to i8*)

; 0x40110d
  store volatile i64 4198669, i64* @_asm_program_counter
  %23 = load i64, i64* @rsp
  %24 = inttoptr i64 %23 to i64*
  %25 = load i64, i64* %24
  store i64 %25, i64* @rbp
  %26 = add i64 %23, 8
  store i64 %26, i64* @rsp

; 0x40110e
  store volatile i64 4198670, i64* @_asm_program_counter
  ret i64 undef

dec_label_pc_401110:                              ; preds = %dec_label_pc_4010f0

; 0x401110
  store volatile i64 4198672, i64* @_asm_program_counter
  ret i64 undef
}

define i64 @frame_dummy() {
dec_label_pc_401120:

; 0x401120
  store volatile i64 4198688, i64* @_asm_program_counter

; 0x401124
  store volatile i64 4198692, i64* @_asm_program_counter
  %0 = call i64 @register_tm_clones()
  store i64 %0, i64* @rax
  ret i64 undef
}

define i64 @add() {
dec_label_pc_401126:

; 0x401126
  store volatile i64 4198694, i64* @_asm_program_counter
  %0 = load i64, i64* @rbp
  %1 = load i64, i64* @rsp
  %2 = sub i64 %1, 8
  %3 = inttoptr i64 %2 to i64*
  store i64 %0, i64* %3
  store i64 %2, i64* @rsp

; 0x401127
  store volatile i64 4198695, i64* @_asm_program_counter
  %4 = load i64, i64* @rsp
  store i64 %4, i64* @rbp

; 0x40112a
  store volatile i64 4198698, i64* @_asm_program_counter
  %5 = load i64, i64* @rdi
  %6 = load i64, i64* @rbp
  %7 = add i64 %6, -8
  %8 = inttoptr i64 %7 to i64*
  store i64 %5, i64* %8

; 0x40112e
  store volatile i64 4198702, i64* @_asm_program_counter
  %9 = load i64, i64* @rsi
  %10 = trunc i64 %9 to i32
  %11 = zext i32 %10 to i64
  store i64 %11, i64* @rax

; 0x401130
  store volatile i64 4198704, i64* @_asm_program_counter
  %12 = load i64, i64* @rax
  %13 = trunc i64 %12 to i8
  %14 = load i64, i64* @rbp
  %15 = add i64 %14, -12
  %16 = inttoptr i64 %15 to i8*
  store i8 %13, i8* %16

; 0x401133
  store volatile i64 4198707, i64* @_asm_program_counter
  %17 = load i64, i64* @rbp
  %18 = add i64 %17, -8
  %19 = inttoptr i64 %18 to i64*
  %20 = load i64, i64* %19
  store i64 %20, i64* @rax

; 0x401137
  store volatile i64 4198711, i64* @_asm_program_counter
  %21 = load i64, i64* @rax
  %22 = inttoptr i64 %21 to i32*
  %23 = load i32, i32* %22
  %24 = zext i32 %23 to i64
  store i64 %24, i64* @rdx

; 0x401139
  store volatile i64 4198713, i64* @_asm_program_counter
  %25 = load i64, i64* @rbp
  %26 = add i64 %25, -12
  %27 = inttoptr i64 %26 to i8*
  %28 = load i8, i8* %27
  %29 = sext i8 %28 to i64
  store i64 %29, i64* @rax

; 0x40113d
  store volatile i64 4198717, i64* @_asm_program_counter
  %30 = load i64, i64* @rax
  %31 = trunc i64 %30 to i32
  %32 = load i64, i64* @rdx
  %33 = trunc i64 %32 to i32
  %34 = add i32 %31, %33
  %35 = and i32 %31, 15
  %36 = and i32 %33, 15
  %37 = add i32 %35, %36
  %38 = icmp ugt i32 %37, 15
  %39 = icmp ult i32 %34, %31
  %40 = xor i32 %31, %34
  %41 = xor i32 %33, %34
  %42 = and i32 %40, %41
  %43 = icmp slt i32 %42, 0
  store i1 %38, i1* @az
  store i1 %39, i1* @cf
  store i1 %43, i1* @of
  %44 = icmp eq i32 %34, 0
  store i1 %44, i1* @zf
  %45 = icmp slt i32 %34, 0
  store i1 %45, i1* @sf
  %46 = trunc i32 %34 to i8
  %47 = call i8 @llvm.ctpop.i8(i8 %46)
  %48 = and i8 %47, 1
  %49 = icmp eq i8 %48, 0
  store i1 %49, i1* @pf
  %50 = zext i32 %34 to i64
  store i64 %50, i64* @rax

; 0x40113f
  store volatile i64 4198719, i64* @_asm_program_counter
  %51 = load i64, i64* @rsp
  %52 = inttoptr i64 %51 to i64*
  %53 = load i64, i64* %52
  store i64 %53, i64* @rbp
  %54 = add i64 %51, 8
  store i64 %54, i64* @rsp

; 0x401140
  store volatile i64 4198720, i64* @_asm_program_counter
  ret i64 undef
}

define i64 @main() {
dec_label_pc_401141:

; 0x401141
  store volatile i64 4198721, i64* @_asm_program_counter
  %0 = load i64, i64* @rbp
  %1 = load i64, i64* @rsp
  %2 = sub i64 %1, 8
  %3 = inttoptr i64 %2 to i64*
  store i64 %0, i64* %3
  store i64 %2, i64* @rsp

; 0x401142
  store volatile i64 4198722, i64* @_asm_program_counter
  %4 = load i64, i64* @rsp
  store i64 %4, i64* @rbp

; 0x401145
  store volatile i64 4198725, i64* @_asm_program_counter
  %5 = load i64, i64* @rsp
  %6 = sub i64 %5, 32
  %7 = and i64 %5, 15
  %8 = sub i64 %7, 0
  %9 = icmp ugt i64 %8, 15
  %10 = icmp ult i64 %5, 32
  %11 = xor i64 %5, 32
  %12 = xor i64 %5, %6
  %13 = and i64 %11, %12
  %14 = icmp slt i64 %13, 0
  store i1 %9, i1* @az
  store i1 %10, i1* @cf
  store i1 %14, i1* @of
  %15 = icmp eq i64 %6, 0
  store i1 %15, i1* @zf
  %16 = icmp slt i64 %6, 0
  store i1 %16, i1* @sf
  %17 = trunc i64 %6 to i8
  %18 = call i8 @llvm.ctpop.i8(i8 %17)
  %19 = and i8 %18, 1
  %20 = icmp eq i8 %19, 0
  store i1 %20, i1* @pf
  store i64 %6, i64* @rsp

; 0x401149
  store volatile i64 4198729, i64* @_asm_program_counter
  %21 = load i64, i64* @rbp
  %22 = add i64 %21, -24
  %23 = inttoptr i64 %22 to i32*
  store i32 1, i32* %23

; 0x401150
  store volatile i64 4198736, i64* @_asm_program_counter
  %24 = load i64, i64* @rbp
  %25 = add i64 %24, -1
  %26 = inttoptr i64 %25 to i8*
  store i8 2, i8* %26

; 0x401154
  store volatile i64 4198740, i64* @_asm_program_counter
  %27 = load i64, i64* @rbp
  %28 = add i64 %27, -1
  %29 = inttoptr i64 %28 to i8*
  %30 = load i8, i8* %29
  %31 = sext i8 %30 to i64
  store i64 %31, i64* @rdx

; 0x401158
  store volatile i64 4198744, i64* @_asm_program_counter
  %32 = load i64, i64* @rbp
  %33 = add i64 %32, -24
  store i64 %33, i64* @rax

; 0x40115c
  store volatile i64 4198748, i64* @_asm_program_counter
  %34 = load i64, i64* @rdx
  %35 = trunc i64 %34 to i32
  %36 = zext i32 %35 to i64
  store i64 %36, i64* @rsi

; 0x40115e
  store volatile i64 4198750, i64* @_asm_program_counter
  %37 = load i64, i64* @rax
  store i64 %37, i64* @rdi

; 0x401161
  store volatile i64 4198753, i64* @_asm_program_counter
  %38 = call i64 @add()
  store i64 %38, i64* @rax

; 0x401166
  store volatile i64 4198758, i64* @_asm_program_counter
  %39 = load i64, i64* @rax
  %40 = trunc i64 %39 to i32
  %41 = load i64, i64* @rbp
  %42 = add i64 %41, -8
  %43 = inttoptr i64 %42 to i32*
  store i32 %40, i32* %43

; 0x401169
  store volatile i64 4198761, i64* @_asm_program_counter
  %44 = load i64, i64* @rbp
  %45 = add i64 %44, -24
  store i64 %45, i64* @rax

; 0x40116d
  store volatile i64 4198765, i64* @_asm_program_counter
  %46 = load i64, i64* @rax
  %47 = load i64, i64* @rbp
  %48 = add i64 %47, -16
  %49 = inttoptr i64 %48 to i64*
  store i64 %46, i64* %49

; 0x401171
  store volatile i64 4198769, i64* @_asm_program_counter
  %50 = load i64, i64* @rbp
  %51 = add i64 %50, -1
  %52 = inttoptr i64 %51 to i8*
  %53 = load i8, i8* %52
  %54 = sext i8 %53 to i64
  store i64 %54, i64* @rdx

; 0x401175
  store volatile i64 4198773, i64* @_asm_program_counter
  %55 = load i64, i64* @rbp
  %56 = add i64 %55, -16
  %57 = inttoptr i64 %56 to i64*
  %58 = load i64, i64* %57
  store i64 %58, i64* @rax

; 0x401179
  store volatile i64 4198777, i64* @_asm_program_counter
  %59 = load i64, i64* @rdx
  %60 = trunc i64 %59 to i32
  %61 = zext i32 %60 to i64
  store i64 %61, i64* @rsi

; 0x40117b
  store volatile i64 4198779, i64* @_asm_program_counter
  %62 = load i64, i64* @rax
  store i64 %62, i64* @rdi

; 0x40117e
  store volatile i64 4198782, i64* @_asm_program_counter
  %63 = call i64 @add()
  store i64 %63, i64* @rax

; 0x401183
  store volatile i64 4198787, i64* @_asm_program_counter
  %64 = load i64, i64* @rax
  %65 = trunc i64 %64 to i32
  %66 = load i64, i64* @rbp
  %67 = add i64 %66, -20
  %68 = inttoptr i64 %67 to i32*
  store i32 %65, i32* %68

; 0x401186
  store volatile i64 4198790, i64* @_asm_program_counter
  %69 = load i64, i64* @rbp
  %70 = add i64 %69, -8
  %71 = inttoptr i64 %70 to i32*
  %72 = load i32, i32* %71
  %73 = zext i32 %72 to i64
  store i64 %73, i64* @rax

; 0x401189
  store volatile i64 4198793, i64* @_asm_program_counter
  %74 = load i64, i64* @rax
  %75 = trunc i64 %74 to i32
  %76 = zext i32 %75 to i64
  store i64 %76, i64* @rsi

; 0x40118b
  store volatile i64 4198795, i64* @_asm_program_counter
  store i64 4202512, i64* @rdi

; 0x401190
  store volatile i64 4198800, i64* @_asm_program_counter
  store i64 0, i64* @rax

; 0x401195
  store volatile i64 4198805, i64* @_asm_program_counter
  %77 = call i64 @function_401030()
  store i64 %77, i64* @rax

; 0x40119a
  store volatile i64 4198810, i64* @_asm_program_counter
  store i64 0, i64* @rax

; 0x40119f
  store volatile i64 4198815, i64* @_asm_program_counter
  %78 = load i64, i64* @rbp
  %79 = inttoptr i64 %78 to i64*
  %80 = load i64, i64* %79
  %81 = add i64 %78, 8
  store i64 %80, i64* @rbp
  store i64 %81, i64* @rsp

; 0x4011a0
  store volatile i64 4198816, i64* @_asm_program_counter
  ret i64 undef
}

define i64 @_fini() {
dec_label_pc_4011a4:

; 0x4011a4
  store volatile i64 4198820, i64* @_asm_program_counter

; 0x4011a8
  store volatile i64 4198824, i64* @_asm_program_counter
  %0 = load i64, i64* @rsp
  %1 = sub i64 %0, 8
  %2 = and i64 %0, 15
  %3 = sub i64 %2, 8
  %4 = icmp ugt i64 %3, 15
  %5 = icmp ult i64 %0, 8
  %6 = xor i64 %0, 8
  %7 = xor i64 %0, %1
  %8 = and i64 %6, %7
  %9 = icmp slt i64 %8, 0
  store i1 %4, i1* @az
  store i1 %5, i1* @cf
  store i1 %9, i1* @of
  %10 = icmp eq i64 %1, 0
  store i1 %10, i1* @zf
  %11 = icmp slt i64 %1, 0
  store i1 %11, i1* @sf
  %12 = trunc i64 %1 to i8
  %13 = call i8 @llvm.ctpop.i8(i8 %12)
  %14 = and i8 %13, 1
  %15 = icmp eq i8 %14, 0
  store i1 %15, i1* @pf
  store i64 %1, i64* @rsp

; 0x4011ac
  store volatile i64 4198828, i64* @_asm_program_counter
  %16 = load i64, i64* @rsp
  %17 = add i64 %16, 8
  %18 = and i64 %16, 15
  %19 = add i64 %18, 8
  %20 = icmp ugt i64 %19, 15
  %21 = icmp ult i64 %17, %16
  %22 = xor i64 %16, %17
  %23 = xor i64 8, %17
  %24 = and i64 %22, %23
  %25 = icmp slt i64 %24, 0
  store i1 %20, i1* @az
  store i1 %21, i1* @cf
  store i1 %25, i1* @of
  %26 = icmp eq i64 %17, 0
  store i1 %26, i1* @zf
  %27 = icmp slt i64 %17, 0
  store i1 %27, i1* @sf
  %28 = trunc i64 %17 to i8
  %29 = call i8 @llvm.ctpop.i8(i8 %28)
  %30 = and i8 %29, 1
  %31 = icmp eq i8 %30, 0
  store i1 %31, i1* @pf
  store i64 %17, i64* @rsp

; 0x4011b0
  store volatile i64 4198832, i64* @_asm_program_counter
  ret i64 undef
}

declare i64 @__libc_start_main()

declare i64 @_ITM_deregisterTMCloneTable()

declare i64 @__gmon_start__()

declare i64 @_ITM_registerTMCloneTable()

declare i64 @printf()

declare void @__pseudo_call(i64)

declare void @__pseudo_return(i64)

declare void @__pseudo_branch(i64)

declare void @__pseudo_cond_branch(i1, i64)

declare void @__frontend_reg_store.fpr(i3, x86_fp80)

declare x86_fp80 @__frontend_reg_load.fpr(i3)

; Function Attrs: nounwind readnone speculatable
declare i8 @llvm.ctpop.i8(i8) #0

declare void @__asm_hlt()

attributes #0 = { nounwind readnone speculatable }
*** IR Dump After Libgcc idioms optimization ***
source_filename = "test"
target datalayout = "e-m:e-p:64:64-i64:64-f80:128-n8:16:32:64-S128"

@_asm_program_counter = internal global i64 0
@cf = internal global i1 false
@pf = internal global i1 false
@az = internal global i1 false
@zf = internal global i1 false
@sf = internal global i1 false
@tf = internal global i1 false
@if = internal global i1 false
@df = internal global i1 false
@of = internal global i1 false
@iopl = internal global i2 0
@nt = internal global i1 false
@rf = internal global i1 false
@vm = internal global i1 false
@ac = internal global i1 false
@vif = internal global i1 false
@vip = internal global i1 false
@id = internal global i1 false
@rflags = internal global i64 0
@ss = internal global i16 0
@cs = internal global i16 0
@ds = internal global i16 0
@es = internal global i16 0
@fs = internal global i16 0
@gs = internal global i16 0
@st0 = internal global x86_fp80 0xK00000000000000000000
@st1 = internal global x86_fp80 0xK00000000000000000000
@st2 = internal global x86_fp80 0xK00000000000000000000
@st3 = internal global x86_fp80 0xK00000000000000000000
@st4 = internal global x86_fp80 0xK00000000000000000000
@st5 = internal global x86_fp80 0xK00000000000000000000
@st6 = internal global x86_fp80 0xK00000000000000000000
@st7 = internal global x86_fp80 0xK00000000000000000000
@fpu_stat_IE = internal global i1 false
@fpu_stat_DE = internal global i1 false
@fpu_stat_ZE = internal global i1 false
@fpu_stat_OE = internal global i1 false
@fpu_stat_UE = internal global i1 false
@fpu_stat_PE = internal global i1 false
@fpu_stat_SF = internal global i1 false
@fpu_stat_ES = internal global i1 false
@fpu_stat_C0 = internal global i1 false
@fpu_stat_C1 = internal global i1 false
@fpu_stat_C2 = internal global i1 false
@fpu_stat_C3 = internal global i1 false
@fpu_stat_TOP = internal global i3 0
@fpu_stat_B = internal global i1 false
@fpu_control_IM = internal global i1 false
@fpu_control_DM = internal global i1 false
@fpu_control_ZM = internal global i1 false
@fpu_control_OM = internal global i1 false
@fpu_control_UM = internal global i1 false
@fpu_control_PM = internal global i1 false
@fpu_control_PC = internal global i2 0
@fpu_control_RC = internal global i2 0
@fpu_control_X = internal global i1 false
@fp0 = internal global double 0.000000e+00
@fp1 = internal global double 0.000000e+00
@fp2 = internal global double 0.000000e+00
@fp3 = internal global double 0.000000e+00
@fp4 = internal global double 0.000000e+00
@fp5 = internal global double 0.000000e+00
@fp6 = internal global double 0.000000e+00
@fp7 = internal global double 0.000000e+00
@k0 = internal global i64 0
@k1 = internal global i64 0
@k2 = internal global i64 0
@k3 = internal global i64 0
@k4 = internal global i64 0
@k5 = internal global i64 0
@k6 = internal global i64 0
@k7 = internal global i64 0
@mm0 = internal global i64 0
@mm1 = internal global i64 0
@mm2 = internal global i64 0
@mm3 = internal global i64 0
@mm4 = internal global i64 0
@mm5 = internal global i64 0
@mm6 = internal global i64 0
@mm7 = internal global i64 0
@xmm0 = internal global i128 0
@xmm1 = internal global i128 0
@xmm2 = internal global i128 0
@xmm3 = internal global i128 0
@xmm4 = internal global i128 0
@xmm5 = internal global i128 0
@xmm6 = internal global i128 0
@xmm7 = internal global i128 0
@xmm8 = internal global i128 0
@xmm9 = internal global i128 0
@xmm10 = internal global i128 0
@xmm11 = internal global i128 0
@xmm12 = internal global i128 0
@xmm13 = internal global i128 0
@xmm14 = internal global i128 0
@xmm15 = internal global i128 0
@xmm16 = internal global i128 0
@xmm17 = internal global i128 0
@xmm18 = internal global i128 0
@xmm19 = internal global i128 0
@xmm20 = internal global i128 0
@xmm21 = internal global i128 0
@xmm22 = internal global i128 0
@xmm23 = internal global i128 0
@xmm24 = internal global i128 0
@xmm25 = internal global i128 0
@xmm26 = internal global i128 0
@xmm27 = internal global i128 0
@xmm28 = internal global i128 0
@xmm29 = internal global i128 0
@xmm30 = internal global i128 0
@xmm31 = internal global i128 0
@ymm0 = internal global i256 0
@ymm1 = internal global i256 0
@ymm2 = internal global i256 0
@ymm3 = internal global i256 0
@ymm4 = internal global i256 0
@ymm5 = internal global i256 0
@ymm6 = internal global i256 0
@ymm7 = internal global i256 0
@ymm8 = internal global i256 0
@ymm9 = internal global i256 0
@ymm10 = internal global i256 0
@ymm11 = internal global i256 0
@ymm12 = internal global i256 0
@ymm13 = internal global i256 0
@ymm14 = internal global i256 0
@ymm15 = internal global i256 0
@ymm16 = internal global i256 0
@ymm17 = internal global i256 0
@ymm18 = internal global i256 0
@ymm19 = internal global i256 0
@ymm20 = internal global i256 0
@ymm21 = internal global i256 0
@ymm22 = internal global i256 0
@ymm23 = internal global i256 0
@ymm24 = internal global i256 0
@ymm25 = internal global i256 0
@ymm26 = internal global i256 0
@ymm27 = internal global i256 0
@ymm28 = internal global i256 0
@ymm29 = internal global i256 0
@ymm30 = internal global i256 0
@ymm31 = internal global i256 0
@zmm0 = internal global i512 0
@zmm1 = internal global i512 0
@zmm2 = internal global i512 0
@zmm3 = internal global i512 0
@zmm4 = internal global i512 0
@zmm5 = internal global i512 0
@zmm6 = internal global i512 0
@zmm7 = internal global i512 0
@zmm8 = internal global i512 0
@zmm9 = internal global i512 0
@zmm10 = internal global i512 0
@zmm11 = internal global i512 0
@zmm12 = internal global i512 0
@zmm13 = internal global i512 0
@zmm14 = internal global i512 0
@zmm15 = internal global i512 0
@zmm16 = internal global i512 0
@zmm17 = internal global i512 0
@zmm18 = internal global i512 0
@zmm19 = internal global i512 0
@zmm20 = internal global i512 0
@zmm21 = internal global i512 0
@zmm22 = internal global i512 0
@zmm23 = internal global i512 0
@zmm24 = internal global i512 0
@zmm25 = internal global i512 0
@zmm26 = internal global i512 0
@zmm27 = internal global i512 0
@zmm28 = internal global i512 0
@zmm29 = internal global i512 0
@zmm30 = internal global i512 0
@zmm31 = internal global i512 0
@bnd0 = internal global i128 0
@bnd1 = internal global i128 0
@bnd2 = internal global i128 0
@bnd3 = internal global i128 0
@dr0 = internal global i64 0
@dr1 = internal global i64 0
@dr2 = internal global i64 0
@dr3 = internal global i64 0
@dr4 = internal global i64 0
@dr5 = internal global i64 0
@dr6 = internal global i64 0
@dr7 = internal global i64 0
@dr8 = internal global i64 0
@dr9 = internal global i64 0
@dr10 = internal global i64 0
@dr11 = internal global i64 0
@dr12 = internal global i64 0
@dr13 = internal global i64 0
@dr14 = internal global i64 0
@dr15 = internal global i64 0
@cr0 = internal global i64 0
@cr1 = internal global i64 0
@cr2 = internal global i64 0
@cr3 = internal global i64 0
@cr4 = internal global i64 0
@cr5 = internal global i64 0
@cr6 = internal global i64 0
@cr7 = internal global i64 0
@cr8 = internal global i64 0
@cr9 = internal global i64 0
@cr10 = internal global i64 0
@cr11 = internal global i64 0
@cr12 = internal global i64 0
@cr13 = internal global i64 0
@cr14 = internal global i64 0
@cr15 = internal global i64 0
@fpsw = internal global i64 0
@rax = internal global i64 0
@rcx = internal global i64 0
@rdx = internal global i64 0
@rbx = internal global i64 0
@rsp = internal global i64 0
@rbp = internal global i64 0
@rsi = internal global i64 0
@rdi = internal global i64 0
@r8 = internal global i64 0
@r9 = internal global i64 0
@r10 = internal global i64 0
@r11 = internal global i64 0
@r12 = internal global i64 0
@r13 = internal global i64 0
@r14 = internal global i64 0
@r15 = internal global i64 0
@rip = internal global i64 0
@riz = internal global i64 0

define i64 @_init() {
dec_label_pc_401000:

; 0x401000
  store volatile i64 4198400, i64* @_asm_program_counter

; 0x401004
  store volatile i64 4198404, i64* @_asm_program_counter
  %0 = load i64, i64* @rsp
  %1 = sub i64 %0, 8
  %2 = and i64 %0, 15
  %3 = sub i64 %2, 8
  %4 = icmp ugt i64 %3, 15
  %5 = icmp ult i64 %0, 8
  %6 = xor i64 %0, 8
  %7 = xor i64 %0, %1
  %8 = and i64 %6, %7
  %9 = icmp slt i64 %8, 0
  store i1 %4, i1* @az
  store i1 %5, i1* @cf
  store i1 %9, i1* @of
  %10 = icmp eq i64 %1, 0
  store i1 %10, i1* @zf
  %11 = icmp slt i64 %1, 0
  store i1 %11, i1* @sf
  %12 = trunc i64 %1 to i8
  %13 = call i8 @llvm.ctpop.i8(i8 %12)
  %14 = and i8 %13, 1
  %15 = icmp eq i8 %14, 0
  store i1 %15, i1* @pf
  store i64 %1, i64* @rsp

; 0x401008
  store volatile i64 4198408, i64* @_asm_program_counter
  %16 = load i64, i64* inttoptr (i64 4210672 to i64*)
  store i64 %16, i64* @rax

; 0x40100f
  store volatile i64 4198415, i64* @_asm_program_counter
  %17 = load i64, i64* @rax
  %18 = load i64, i64* @rax
  %19 = and i64 %17, %18
  store i1 false, i1* @az
  store i1 false, i1* @cf
  store i1 false, i1* @of
  %20 = icmp eq i64 %19, 0
  store i1 %20, i1* @zf
  %21 = icmp slt i64 %19, 0
  store i1 %21, i1* @sf
  %22 = trunc i64 %19 to i8
  %23 = call i8 @llvm.ctpop.i8(i8 %22)
  %24 = and i8 %23, 1
  %25 = icmp eq i8 %24, 0
  store i1 %25, i1* @pf

; 0x401012
  store volatile i64 4198418, i64* @_asm_program_counter
  %26 = load i1, i1* @zf
  br i1 %26, label %dec_label_pc_401016, label %dec_label_pc_401014

dec_label_pc_401014:                              ; preds = %dec_label_pc_401000

; 0x401014
  store volatile i64 4198420, i64* @_asm_program_counter
  %27 = call i64 @__gmon_start__()
  store i64 %27, i64* @rax
  br label %dec_label_pc_401016

dec_label_pc_401016:                              ; preds = %dec_label_pc_401014, %dec_label_pc_401000

; 0x401016
  store volatile i64 4198422, i64* @_asm_program_counter
  %28 = load i64, i64* @rsp
  %29 = add i64 %28, 8
  %30 = and i64 %28, 15
  %31 = add i64 %30, 8
  %32 = icmp ugt i64 %31, 15
  %33 = icmp ult i64 %29, %28
  %34 = xor i64 %28, %29
  %35 = xor i64 8, %29
  %36 = and i64 %34, %35
  %37 = icmp slt i64 %36, 0
  store i1 %32, i1* @az
  store i1 %33, i1* @cf
  store i1 %37, i1* @of
  %38 = icmp eq i64 %29, 0
  store i1 %38, i1* @zf
  %39 = icmp slt i64 %29, 0
  store i1 %39, i1* @sf
  %40 = trunc i64 %29 to i8
  %41 = call i8 @llvm.ctpop.i8(i8 %40)
  %42 = and i8 %41, 1
  %43 = icmp eq i8 %42, 0
  store i1 %43, i1* @pf
  store i64 %29, i64* @rsp

; 0x40101a
  store volatile i64 4198426, i64* @_asm_program_counter
  ret i64 undef
}

define i64 @function_401030() {
dec_label_pc_401030:

; 0x401030
  store volatile i64 4198448, i64* @_asm_program_counter
  %0 = call i64 @printf()
  store i64 %0, i64* @rax
  ret i64 undef
}

define i64 @_start() {
dec_label_pc_401040:

; 0x401040
  store volatile i64 4198464, i64* @_asm_program_counter

; 0x401044
  store volatile i64 4198468, i64* @_asm_program_counter
  %0 = load i64, i64* @rbp
  %1 = trunc i64 %0 to i32
  %2 = load i64, i64* @rbp
  %3 = trunc i64 %2 to i32
  %4 = xor i32 %1, %3
  store i1 false, i1* @az
  store i1 false, i1* @cf
  store i1 false, i1* @of
  %5 = icmp eq i32 %4, 0
  store i1 %5, i1* @zf
  %6 = icmp slt i32 %4, 0
  store i1 %6, i1* @sf
  %7 = trunc i32 %4 to i8
  %8 = call i8 @llvm.ctpop.i8(i8 %7)
  %9 = and i8 %8, 1
  %10 = icmp eq i8 %9, 0
  store i1 %10, i1* @pf
  %11 = zext i32 %4 to i64
  store i64 %11, i64* @rbp

; 0x401046
  store volatile i64 4198470, i64* @_asm_program_counter
  %12 = load i64, i64* @rdx
  store i64 %12, i64* @r9

; 0x401049
  store volatile i64 4198473, i64* @_asm_program_counter
  %13 = load i64, i64* @rsp
  %14 = inttoptr i64 %13 to i64*
  %15 = load i64, i64* %14
  store i64 %15, i64* @rsi
  %16 = add i64 %13, 8
  store i64 %16, i64* @rsp

; 0x40104a
  store volatile i64 4198474, i64* @_asm_program_counter
  %17 = load i64, i64* @rsp
  store i64 %17, i64* @rdx

; 0x40104d
  store volatile i64 4198477, i64* @_asm_program_counter
  %18 = load i64, i64* @rsp
  %19 = and i64 %18, -16
  store i1 false, i1* @az
  store i1 false, i1* @cf
  store i1 false, i1* @of
  %20 = icmp eq i64 %19, 0
  store i1 %20, i1* @zf
  %21 = icmp slt i64 %19, 0
  store i1 %21, i1* @sf
  %22 = trunc i64 %19 to i8
  %23 = call i8 @llvm.ctpop.i8(i8 %22)
  %24 = and i8 %23, 1
  %25 = icmp eq i8 %24, 0
  store i1 %25, i1* @pf
  store i64 %19, i64* @rsp

; 0x401051
  store volatile i64 4198481, i64* @_asm_program_counter
  %26 = load i64, i64* @rax
  %27 = load i64, i64* @rsp
  %28 = sub i64 %27, 8
  %29 = inttoptr i64 %28 to i64*
  store i64 %26, i64* %29
  store i64 %28, i64* @rsp

; 0x401052
  store volatile i64 4198482, i64* @_asm_program_counter
  %30 = load i64, i64* @rsp
  %31 = load i64, i64* @rsp
  %32 = sub i64 %31, 8
  %33 = inttoptr i64 %32 to i64*
  store i64 %30, i64* %33
  store i64 %32, i64* @rsp

; 0x401053
  store volatile i64 4198483, i64* @_asm_program_counter
  %34 = load i64, i64* @r8
  %35 = trunc i64 %34 to i32
  %36 = load i64, i64* @r8
  %37 = trunc i64 %36 to i32
  %38 = xor i32 %35, %37
  store i1 false, i1* @az
  store i1 false, i1* @cf
  store i1 false, i1* @of
  %39 = icmp eq i32 %38, 0
  store i1 %39, i1* @zf
  %40 = icmp slt i32 %38, 0
  store i1 %40, i1* @sf
  %41 = trunc i32 %38 to i8
  %42 = call i8 @llvm.ctpop.i8(i8 %41)
  %43 = and i8 %42, 1
  %44 = icmp eq i8 %43, 0
  store i1 %44, i1* @pf
  %45 = zext i32 %38 to i64
  store i64 %45, i64* @r8

; 0x401056
  store volatile i64 4198486, i64* @_asm_program_counter
  %46 = load i64, i64* @rcx
  %47 = trunc i64 %46 to i32
  %48 = load i64, i64* @rcx
  %49 = trunc i64 %48 to i32
  %50 = xor i32 %47, %49
  store i1 false, i1* @az
  store i1 false, i1* @cf
  store i1 false, i1* @of
  %51 = icmp eq i32 %50, 0
  store i1 %51, i1* @zf
  %52 = icmp slt i32 %50, 0
  store i1 %52, i1* @sf
  %53 = trunc i32 %50 to i8
  %54 = call i8 @llvm.ctpop.i8(i8 %53)
  %55 = and i8 %54, 1
  %56 = icmp eq i8 %55, 0
  store i1 %56, i1* @pf
  %57 = zext i32 %50 to i64
  store i64 %57, i64* @rcx

; 0x401058
  store volatile i64 4198488, i64* @_asm_program_counter
  store i64 4198721, i64* @rdi

; 0x40105f
  store volatile i64 4198495, i64* @_asm_program_counter
  %58 = call i64 @__libc_start_main()
  store i64 %58, i64* @rax

; 0x401065
  store volatile i64 4198501, i64* @_asm_program_counter
  call void @__asm_hlt()
  unreachable
}

define i64 @_dl_relocate_static_pie() {
dec_label_pc_401070:

; 0x401070
  store volatile i64 4198512, i64* @_asm_program_counter

; 0x401074
  store volatile i64 4198516, i64* @_asm_program_counter
  ret i64 undef
}

define i64 @deregister_tm_clones() {
dec_label_pc_401080:

; 0x401080
  store volatile i64 4198528, i64* @_asm_program_counter
  store i64 4210728, i64* @rdi

; 0x401087
  store volatile i64 4198535, i64* @_asm_program_counter
  store i64 4210728, i64* @rax

; 0x40108e
  store volatile i64 4198542, i64* @_asm_program_counter
  %0 = load i64, i64* @rax
  %1 = load i64, i64* @rdi
  %2 = sub i64 %0, %1
  %3 = and i64 %0, 15
  %4 = and i64 %1, 15
  %5 = sub i64 %3, %4
  %6 = icmp ugt i64 %5, 15
  %7 = icmp ult i64 %0, %1
  %8 = xor i64 %0, %1
  %9 = xor i64 %0, %2
  %10 = and i64 %8, %9
  %11 = icmp slt i64 %10, 0
  store i1 %6, i1* @az
  store i1 %7, i1* @cf
  store i1 %11, i1* @of
  %12 = icmp eq i64 %2, 0
  store i1 %12, i1* @zf
  %13 = icmp slt i64 %2, 0
  store i1 %13, i1* @sf
  %14 = trunc i64 %2 to i8
  %15 = call i8 @llvm.ctpop.i8(i8 %14)
  %16 = and i8 %15, 1
  %17 = icmp eq i8 %16, 0
  store i1 %17, i1* @pf

; 0x401091
  store volatile i64 4198545, i64* @_asm_program_counter
  %18 = load i1, i1* @zf
  br i1 %18, label %dec_label_pc_4010a8, label %dec_label_pc_401093

dec_label_pc_401093:                              ; preds = %dec_label_pc_401080

; 0x401093
  store volatile i64 4198547, i64* @_asm_program_counter
  %19 = load i64, i64* inttoptr (i64 4210664 to i64*)
  store i64 %19, i64* @rax

; 0x40109a
  store volatile i64 4198554, i64* @_asm_program_counter
  %20 = load i64, i64* @rax
  %21 = load i64, i64* @rax
  %22 = and i64 %20, %21
  store i1 false, i1* @az
  store i1 false, i1* @cf
  store i1 false, i1* @of
  %23 = icmp eq i64 %22, 0
  store i1 %23, i1* @zf
  %24 = icmp slt i64 %22, 0
  store i1 %24, i1* @sf
  %25 = trunc i64 %22 to i8
  %26 = call i8 @llvm.ctpop.i8(i8 %25)
  %27 = and i8 %26, 1
  %28 = icmp eq i8 %27, 0
  store i1 %28, i1* @pf

; 0x40109d
  store volatile i64 4198557, i64* @_asm_program_counter
  %29 = load i1, i1* @zf
  br i1 %29, label %dec_label_pc_4010a8, label %dec_label_pc_40109f

dec_label_pc_40109f:                              ; preds = %dec_label_pc_401093

; 0x40109f
  store volatile i64 4198559, i64* @_asm_program_counter
  %30 = call i64 @_ITM_deregisterTMCloneTable()
  store i64 %30, i64* @rax
  ret i64 undef

dec_label_pc_4010a8:                              ; preds = %dec_label_pc_401093, %dec_label_pc_401080

; 0x4010a8
  store volatile i64 4198568, i64* @_asm_program_counter
  ret i64 undef
}

define i64 @register_tm_clones() {
dec_label_pc_4010b0:

; 0x4010b0
  store volatile i64 4198576, i64* @_asm_program_counter
  store i64 4210728, i64* @rdi

; 0x4010b7
  store volatile i64 4198583, i64* @_asm_program_counter
  store i64 4210728, i64* @rsi

; 0x4010be
  store volatile i64 4198590, i64* @_asm_program_counter
  %0 = load i64, i64* @rsi
  %1 = load i64, i64* @rdi
  %2 = sub i64 %0, %1
  %3 = and i64 %0, 15
  %4 = and i64 %1, 15
  %5 = sub i64 %3, %4
  %6 = icmp ugt i64 %5, 15
  %7 = icmp ult i64 %0, %1
  %8 = xor i64 %0, %1
  %9 = xor i64 %0, %2
  %10 = and i64 %8, %9
  %11 = icmp slt i64 %10, 0
  store i1 %6, i1* @az
  store i1 %7, i1* @cf
  store i1 %11, i1* @of
  %12 = icmp eq i64 %2, 0
  store i1 %12, i1* @zf
  %13 = icmp slt i64 %2, 0
  store i1 %13, i1* @sf
  %14 = trunc i64 %2 to i8
  %15 = call i8 @llvm.ctpop.i8(i8 %14)
  %16 = and i8 %15, 1
  %17 = icmp eq i8 %16, 0
  store i1 %17, i1* @pf
  store i64 %2, i64* @rsi

; 0x4010c1
  store volatile i64 4198593, i64* @_asm_program_counter
  %18 = load i64, i64* @rsi
  store i64 %18, i64* @rax

; 0x4010c4
  store volatile i64 4198596, i64* @_asm_program_counter
  %19 = load i64, i64* @rsi
  %20 = load i1, i1* @of
  %21 = lshr i64 %19, 63
  %22 = icmp eq i64 %21, 0
  store i1 %22, i1* @zf
  %23 = icmp slt i64 %21, 0
  store i1 %23, i1* @sf
  %24 = trunc i64 %21 to i8
  %25 = call i8 @llvm.ctpop.i8(i8 %24)
  %26 = and i8 %25, 1
  %27 = icmp eq i8 %26, 0
  store i1 %27, i1* @pf
  store i64 %21, i64* @rsi
  %28 = and i64 4611686018427387904, %19
  %29 = icmp ne i64 %28, 0
  store i1 %29, i1* @cf
  %30 = icmp slt i64 %19, 0
  %31 = select i1 false, i1 %30, i1 %20
  store i1 %31, i1* @of

; 0x4010c8
  store volatile i64 4198600, i64* @_asm_program_counter
  %32 = load i64, i64* @rax
  %33 = load i1, i1* @of
  %34 = ashr i64 %32, 3
  %35 = icmp eq i64 %34, 0
  store i1 %35, i1* @zf
  %36 = icmp slt i64 %34, 0
  store i1 %36, i1* @sf
  %37 = trunc i64 %34 to i8
  %38 = call i8 @llvm.ctpop.i8(i8 %37)
  %39 = and i8 %38, 1
  %40 = icmp eq i8 %39, 0
  store i1 %40, i1* @pf
  store i64 %34, i64* @rax
  %41 = and i64 4, %32
  %42 = icmp ne i64 %41, 0
  store i1 %42, i1* @cf
  %43 = select i1 false, i1 false, i1 %33
  store i1 %43, i1* @of

; 0x4010cc
  store volatile i64 4198604, i64* @_asm_program_counter
  %44 = load i64, i64* @rsi
  %45 = load i64, i64* @rax
  %46 = add i64 %44, %45
  %47 = and i64 %44, 15
  %48 = and i64 %45, 15
  %49 = add i64 %47, %48
  %50 = icmp ugt i64 %49, 15
  %51 = icmp ult i64 %46, %44
  %52 = xor i64 %44, %46
  %53 = xor i64 %45, %46
  %54 = and i64 %52, %53
  %55 = icmp slt i64 %54, 0
  store i1 %50, i1* @az
  store i1 %51, i1* @cf
  store i1 %55, i1* @of
  %56 = icmp eq i64 %46, 0
  store i1 %56, i1* @zf
  %57 = icmp slt i64 %46, 0
  store i1 %57, i1* @sf
  %58 = trunc i64 %46 to i8
  %59 = call i8 @llvm.ctpop.i8(i8 %58)
  %60 = and i8 %59, 1
  %61 = icmp eq i8 %60, 0
  store i1 %61, i1* @pf
  store i64 %46, i64* @rsi

; 0x4010cf
  store volatile i64 4198607, i64* @_asm_program_counter
  %62 = load i64, i64* @rsi
  %63 = load i1, i1* @of
  %64 = ashr i64 %62, 1
  %65 = icmp eq i64 %64, 0
  store i1 %65, i1* @zf
  %66 = icmp slt i64 %64, 0
  store i1 %66, i1* @sf
  %67 = trunc i64 %64 to i8
  %68 = call i8 @llvm.ctpop.i8(i8 %67)
  %69 = and i8 %68, 1
  %70 = icmp eq i8 %69, 0
  store i1 %70, i1* @pf
  store i64 %64, i64* @rsi
  %71 = and i64 1, %62
  %72 = icmp ne i64 %71, 0
  store i1 %72, i1* @cf
  %73 = select i1 true, i1 false, i1 %63
  store i1 %73, i1* @of

; 0x4010d2
  store volatile i64 4198610, i64* @_asm_program_counter
  %74 = load i1, i1* @zf
  br i1 %74, label %dec_label_pc_4010e8, label %dec_label_pc_4010d4

dec_label_pc_4010d4:                              ; preds = %dec_label_pc_4010b0

; 0x4010d4
  store volatile i64 4198612, i64* @_asm_program_counter
  %75 = load i64, i64* inttoptr (i64 4210680 to i64*)
  store i64 %75, i64* @rax

; 0x4010db
  store volatile i64 4198619, i64* @_asm_program_counter
  %76 = load i64, i64* @rax
  %77 = load i64, i64* @rax
  %78 = and i64 %76, %77
  store i1 false, i1* @az
  store i1 false, i1* @cf
  store i1 false, i1* @of
  %79 = icmp eq i64 %78, 0
  store i1 %79, i1* @zf
  %80 = icmp slt i64 %78, 0
  store i1 %80, i1* @sf
  %81 = trunc i64 %78 to i8
  %82 = call i8 @llvm.ctpop.i8(i8 %81)
  %83 = and i8 %82, 1
  %84 = icmp eq i8 %83, 0
  store i1 %84, i1* @pf

; 0x4010de
  store volatile i64 4198622, i64* @_asm_program_counter
  %85 = load i1, i1* @zf
  br i1 %85, label %dec_label_pc_4010e8, label %dec_label_pc_4010e0

dec_label_pc_4010e0:                              ; preds = %dec_label_pc_4010d4

; 0x4010e0
  store volatile i64 4198624, i64* @_asm_program_counter
  %86 = call i64 @_ITM_registerTMCloneTable()
  store i64 %86, i64* @rax
  ret i64 undef

dec_label_pc_4010e8:                              ; preds = %dec_label_pc_4010d4, %dec_label_pc_4010b0

; 0x4010e8
  store volatile i64 4198632, i64* @_asm_program_counter
  ret i64 undef
}

define i64 @__do_global_dtors_aux() {
dec_label_pc_4010f0:

; 0x4010f0
  store volatile i64 4198640, i64* @_asm_program_counter

; 0x4010f4
  store volatile i64 4198644, i64* @_asm_program_counter
  %0 = load i8, i8* inttoptr (i64 4210724 to i8*)
  %1 = sub i8 %0, 0
  %2 = and i8 %0, 15
  %3 = sub i8 %2, 0
  %4 = icmp ugt i8 %3, 15
  %5 = icmp ult i8 %0, 0
  %6 = xor i8 %0, 0
  %7 = xor i8 %0, %1
  %8 = and i8 %6, %7
  %9 = icmp slt i8 %8, 0
  store i1 %4, i1* @az
  store i1 %5, i1* @cf
  store i1 %9, i1* @of
  %10 = icmp eq i8 %1, 0
  store i1 %10, i1* @zf
  %11 = icmp slt i8 %1, 0
  store i1 %11, i1* @sf
  %12 = call i8 @llvm.ctpop.i8(i8 %1)
  %13 = and i8 %12, 1
  %14 = icmp eq i8 %13, 0
  store i1 %14, i1* @pf

; 0x4010fb
  store volatile i64 4198651, i64* @_asm_program_counter
  %15 = load i1, i1* @zf
  %16 = icmp eq i1 %15, false
  br i1 %16, label %dec_label_pc_401110, label %dec_label_pc_4010fd

dec_label_pc_4010fd:                              ; preds = %dec_label_pc_4010f0

; 0x4010fd
  store volatile i64 4198653, i64* @_asm_program_counter
  %17 = load i64, i64* @rbp
  %18 = load i64, i64* @rsp
  %19 = sub i64 %18, 8
  %20 = inttoptr i64 %19 to i64*
  store i64 %17, i64* %20
  store i64 %19, i64* @rsp

; 0x4010fe
  store volatile i64 4198654, i64* @_asm_program_counter
  %21 = load i64, i64* @rsp
  store i64 %21, i64* @rbp

; 0x401101
  store volatile i64 4198657, i64* @_asm_program_counter
  %22 = call i64 @deregister_tm_clones()
  store i64 %22, i64* @rax

; 0x401106
  store volatile i64 4198662, i64* @_asm_program_counter
  store i8 1, i8* inttoptr (i64 4210724 to i8*)

; 0x40110d
  store volatile i64 4198669, i64* @_asm_program_counter
  %23 = load i64, i64* @rsp
  %24 = inttoptr i64 %23 to i64*
  %25 = load i64, i64* %24
  store i64 %25, i64* @rbp
  %26 = add i64 %23, 8
  store i64 %26, i64* @rsp

; 0x40110e
  store volatile i64 4198670, i64* @_asm_program_counter
  ret i64 undef

dec_label_pc_401110:                              ; preds = %dec_label_pc_4010f0

; 0x401110
  store volatile i64 4198672, i64* @_asm_program_counter
  ret i64 undef
}

define i64 @frame_dummy() {
dec_label_pc_401120:

; 0x401120
  store volatile i64 4198688, i64* @_asm_program_counter

; 0x401124
  store volatile i64 4198692, i64* @_asm_program_counter
  %0 = call i64 @register_tm_clones()
  store i64 %0, i64* @rax
  ret i64 undef
}

define i64 @add() {
dec_label_pc_401126:

; 0x401126
  store volatile i64 4198694, i64* @_asm_program_counter
  %0 = load i64, i64* @rbp
  %1 = load i64, i64* @rsp
  %2 = sub i64 %1, 8
  %3 = inttoptr i64 %2 to i64*
  store i64 %0, i64* %3
  store i64 %2, i64* @rsp

; 0x401127
  store volatile i64 4198695, i64* @_asm_program_counter
  %4 = load i64, i64* @rsp
  store i64 %4, i64* @rbp

; 0x40112a
  store volatile i64 4198698, i64* @_asm_program_counter
  %5 = load i64, i64* @rdi
  %6 = load i64, i64* @rbp
  %7 = add i64 %6, -8
  %8 = inttoptr i64 %7 to i64*
  store i64 %5, i64* %8

; 0x40112e
  store volatile i64 4198702, i64* @_asm_program_counter
  %9 = load i64, i64* @rsi
  %10 = trunc i64 %9 to i32
  %11 = zext i32 %10 to i64
  store i64 %11, i64* @rax

; 0x401130
  store volatile i64 4198704, i64* @_asm_program_counter
  %12 = load i64, i64* @rax
  %13 = trunc i64 %12 to i8
  %14 = load i64, i64* @rbp
  %15 = add i64 %14, -12
  %16 = inttoptr i64 %15 to i8*
  store i8 %13, i8* %16

; 0x401133
  store volatile i64 4198707, i64* @_asm_program_counter
  %17 = load i64, i64* @rbp
  %18 = add i64 %17, -8
  %19 = inttoptr i64 %18 to i64*
  %20 = load i64, i64* %19
  store i64 %20, i64* @rax

; 0x401137
  store volatile i64 4198711, i64* @_asm_program_counter
  %21 = load i64, i64* @rax
  %22 = inttoptr i64 %21 to i32*
  %23 = load i32, i32* %22
  %24 = zext i32 %23 to i64
  store i64 %24, i64* @rdx

; 0x401139
  store volatile i64 4198713, i64* @_asm_program_counter
  %25 = load i64, i64* @rbp
  %26 = add i64 %25, -12
  %27 = inttoptr i64 %26 to i8*
  %28 = load i8, i8* %27
  %29 = sext i8 %28 to i64
  store i64 %29, i64* @rax

; 0x40113d
  store volatile i64 4198717, i64* @_asm_program_counter
  %30 = load i64, i64* @rax
  %31 = trunc i64 %30 to i32
  %32 = load i64, i64* @rdx
  %33 = trunc i64 %32 to i32
  %34 = add i32 %31, %33
  %35 = and i32 %31, 15
  %36 = and i32 %33, 15
  %37 = add i32 %35, %36
  %38 = icmp ugt i32 %37, 15
  %39 = icmp ult i32 %34, %31
  %40 = xor i32 %31, %34
  %41 = xor i32 %33, %34
  %42 = and i32 %40, %41
  %43 = icmp slt i32 %42, 0
  store i1 %38, i1* @az
  store i1 %39, i1* @cf
  store i1 %43, i1* @of
  %44 = icmp eq i32 %34, 0
  store i1 %44, i1* @zf
  %45 = icmp slt i32 %34, 0
  store i1 %45, i1* @sf
  %46 = trunc i32 %34 to i8
  %47 = call i8 @llvm.ctpop.i8(i8 %46)
  %48 = and i8 %47, 1
  %49 = icmp eq i8 %48, 0
  store i1 %49, i1* @pf
  %50 = zext i32 %34 to i64
  store i64 %50, i64* @rax

; 0x40113f
  store volatile i64 4198719, i64* @_asm_program_counter
  %51 = load i64, i64* @rsp
  %52 = inttoptr i64 %51 to i64*
  %53 = load i64, i64* %52
  store i64 %53, i64* @rbp
  %54 = add i64 %51, 8
  store i64 %54, i64* @rsp

; 0x401140
  store volatile i64 4198720, i64* @_asm_program_counter
  ret i64 undef
}

define i64 @main() {
dec_label_pc_401141:

; 0x401141
  store volatile i64 4198721, i64* @_asm_program_counter
  %0 = load i64, i64* @rbp
  %1 = load i64, i64* @rsp
  %2 = sub i64 %1, 8
  %3 = inttoptr i64 %2 to i64*
  store i64 %0, i64* %3
  store i64 %2, i64* @rsp

; 0x401142
  store volatile i64 4198722, i64* @_asm_program_counter
  %4 = load i64, i64* @rsp
  store i64 %4, i64* @rbp

; 0x401145
  store volatile i64 4198725, i64* @_asm_program_counter
  %5 = load i64, i64* @rsp
  %6 = sub i64 %5, 32
  %7 = and i64 %5, 15
  %8 = sub i64 %7, 0
  %9 = icmp ugt i64 %8, 15
  %10 = icmp ult i64 %5, 32
  %11 = xor i64 %5, 32
  %12 = xor i64 %5, %6
  %13 = and i64 %11, %12
  %14 = icmp slt i64 %13, 0
  store i1 %9, i1* @az
  store i1 %10, i1* @cf
  store i1 %14, i1* @of
  %15 = icmp eq i64 %6, 0
  store i1 %15, i1* @zf
  %16 = icmp slt i64 %6, 0
  store i1 %16, i1* @sf
  %17 = trunc i64 %6 to i8
  %18 = call i8 @llvm.ctpop.i8(i8 %17)
  %19 = and i8 %18, 1
  %20 = icmp eq i8 %19, 0
  store i1 %20, i1* @pf
  store i64 %6, i64* @rsp

; 0x401149
  store volatile i64 4198729, i64* @_asm_program_counter
  %21 = load i64, i64* @rbp
  %22 = add i64 %21, -24
  %23 = inttoptr i64 %22 to i32*
  store i32 1, i32* %23

; 0x401150
  store volatile i64 4198736, i64* @_asm_program_counter
  %24 = load i64, i64* @rbp
  %25 = add i64 %24, -1
  %26 = inttoptr i64 %25 to i8*
  store i8 2, i8* %26

; 0x401154
  store volatile i64 4198740, i64* @_asm_program_counter
  %27 = load i64, i64* @rbp
  %28 = add i64 %27, -1
  %29 = inttoptr i64 %28 to i8*
  %30 = load i8, i8* %29
  %31 = sext i8 %30 to i64
  store i64 %31, i64* @rdx

; 0x401158
  store volatile i64 4198744, i64* @_asm_program_counter
  %32 = load i64, i64* @rbp
  %33 = add i64 %32, -24
  store i64 %33, i64* @rax

; 0x40115c
  store volatile i64 4198748, i64* @_asm_program_counter
  %34 = load i64, i64* @rdx
  %35 = trunc i64 %34 to i32
  %36 = zext i32 %35 to i64
  store i64 %36, i64* @rsi

; 0x40115e
  store volatile i64 4198750, i64* @_asm_program_counter
  %37 = load i64, i64* @rax
  store i64 %37, i64* @rdi

; 0x401161
  store volatile i64 4198753, i64* @_asm_program_counter
  %38 = call i64 @add()
  store i64 %38, i64* @rax

; 0x401166
  store volatile i64 4198758, i64* @_asm_program_counter
  %39 = load i64, i64* @rax
  %40 = trunc i64 %39 to i32
  %41 = load i64, i64* @rbp
  %42 = add i64 %41, -8
  %43 = inttoptr i64 %42 to i32*
  store i32 %40, i32* %43

; 0x401169
  store volatile i64 4198761, i64* @_asm_program_counter
  %44 = load i64, i64* @rbp
  %45 = add i64 %44, -24
  store i64 %45, i64* @rax

; 0x40116d
  store volatile i64 4198765, i64* @_asm_program_counter
  %46 = load i64, i64* @rax
  %47 = load i64, i64* @rbp
  %48 = add i64 %47, -16
  %49 = inttoptr i64 %48 to i64*
  store i64 %46, i64* %49

; 0x401171
  store volatile i64 4198769, i64* @_asm_program_counter
  %50 = load i64, i64* @rbp
  %51 = add i64 %50, -1
  %52 = inttoptr i64 %51 to i8*
  %53 = load i8, i8* %52
  %54 = sext i8 %53 to i64
  store i64 %54, i64* @rdx

; 0x401175
  store volatile i64 4198773, i64* @_asm_program_counter
  %55 = load i64, i64* @rbp
  %56 = add i64 %55, -16
  %57 = inttoptr i64 %56 to i64*
  %58 = load i64, i64* %57
  store i64 %58, i64* @rax

; 0x401179
  store volatile i64 4198777, i64* @_asm_program_counter
  %59 = load i64, i64* @rdx
  %60 = trunc i64 %59 to i32
  %61 = zext i32 %60 to i64
  store i64 %61, i64* @rsi

; 0x40117b
  store volatile i64 4198779, i64* @_asm_program_counter
  %62 = load i64, i64* @rax
  store i64 %62, i64* @rdi

; 0x40117e
  store volatile i64 4198782, i64* @_asm_program_counter
  %63 = call i64 @add()
  store i64 %63, i64* @rax

; 0x401183
  store volatile i64 4198787, i64* @_asm_program_counter
  %64 = load i64, i64* @rax
  %65 = trunc i64 %64 to i32
  %66 = load i64, i64* @rbp
  %67 = add i64 %66, -20
  %68 = inttoptr i64 %67 to i32*
  store i32 %65, i32* %68

; 0x401186
  store volatile i64 4198790, i64* @_asm_program_counter
  %69 = load i64, i64* @rbp
  %70 = add i64 %69, -8
  %71 = inttoptr i64 %70 to i32*
  %72 = load i32, i32* %71
  %73 = zext i32 %72 to i64
  store i64 %73, i64* @rax

; 0x401189
  store volatile i64 4198793, i64* @_asm_program_counter
  %74 = load i64, i64* @rax
  %75 = trunc i64 %74 to i32
  %76 = zext i32 %75 to i64
  store i64 %76, i64* @rsi

; 0x40118b
  store volatile i64 4198795, i64* @_asm_program_counter
  store i64 4202512, i64* @rdi

; 0x401190
  store volatile i64 4198800, i64* @_asm_program_counter
  store i64 0, i64* @rax

; 0x401195
  store volatile i64 4198805, i64* @_asm_program_counter
  %77 = call i64 @function_401030()
  store i64 %77, i64* @rax

; 0x40119a
  store volatile i64 4198810, i64* @_asm_program_counter
  store i64 0, i64* @rax

; 0x40119f
  store volatile i64 4198815, i64* @_asm_program_counter
  %78 = load i64, i64* @rbp
  %79 = inttoptr i64 %78 to i64*
  %80 = load i64, i64* %79
  %81 = add i64 %78, 8
  store i64 %80, i64* @rbp
  store i64 %81, i64* @rsp

; 0x4011a0
  store volatile i64 4198816, i64* @_asm_program_counter
  ret i64 undef
}

define i64 @_fini() {
dec_label_pc_4011a4:

; 0x4011a4
  store volatile i64 4198820, i64* @_asm_program_counter

; 0x4011a8
  store volatile i64 4198824, i64* @_asm_program_counter
  %0 = load i64, i64* @rsp
  %1 = sub i64 %0, 8
  %2 = and i64 %0, 15
  %3 = sub i64 %2, 8
  %4 = icmp ugt i64 %3, 15
  %5 = icmp ult i64 %0, 8
  %6 = xor i64 %0, 8
  %7 = xor i64 %0, %1
  %8 = and i64 %6, %7
  %9 = icmp slt i64 %8, 0
  store i1 %4, i1* @az
  store i1 %5, i1* @cf
  store i1 %9, i1* @of
  %10 = icmp eq i64 %1, 0
  store i1 %10, i1* @zf
  %11 = icmp slt i64 %1, 0
  store i1 %11, i1* @sf
  %12 = trunc i64 %1 to i8
  %13 = call i8 @llvm.ctpop.i8(i8 %12)
  %14 = and i8 %13, 1
  %15 = icmp eq i8 %14, 0
  store i1 %15, i1* @pf
  store i64 %1, i64* @rsp

; 0x4011ac
  store volatile i64 4198828, i64* @_asm_program_counter
  %16 = load i64, i64* @rsp
  %17 = add i64 %16, 8
  %18 = and i64 %16, 15
  %19 = add i64 %18, 8
  %20 = icmp ugt i64 %19, 15
  %21 = icmp ult i64 %17, %16
  %22 = xor i64 %16, %17
  %23 = xor i64 8, %17
  %24 = and i64 %22, %23
  %25 = icmp slt i64 %24, 0
  store i1 %20, i1* @az
  store i1 %21, i1* @cf
  store i1 %25, i1* @of
  %26 = icmp eq i64 %17, 0
  store i1 %26, i1* @zf
  %27 = icmp slt i64 %17, 0
  store i1 %27, i1* @sf
  %28 = trunc i64 %17 to i8
  %29 = call i8 @llvm.ctpop.i8(i8 %28)
  %30 = and i8 %29, 1
  %31 = icmp eq i8 %30, 0
  store i1 %31, i1* @pf
  store i64 %17, i64* @rsp

; 0x4011b0
  store volatile i64 4198832, i64* @_asm_program_counter
  ret i64 undef
}

declare i64 @__libc_start_main()

declare i64 @_ITM_deregisterTMCloneTable()

declare i64 @__gmon_start__()

declare i64 @_ITM_registerTMCloneTable()

declare i64 @printf()

declare void @__pseudo_call(i64)

declare void @__pseudo_return(i64)

declare void @__pseudo_branch(i64)

declare void @__pseudo_cond_branch(i1, i64)

declare void @__frontend_reg_store.fpr(i3, x86_fp80)

declare x86_fp80 @__frontend_reg_load.fpr(i3)

; Function Attrs: nounwind readnone speculatable
declare i8 @llvm.ctpop.i8(i8) #0

declare void @__asm_hlt()

attributes #0 = { nounwind readnone speculatable }
*** IR Dump After LLVM instruction optimization ***
source_filename = "test"
target datalayout = "e-m:e-p:64:64-i64:64-f80:128-n8:16:32:64-S128"

@_asm_program_counter = internal global i64 0
@cf = internal global i1 false
@pf = internal global i1 false
@az = internal global i1 false
@zf = internal global i1 false
@sf = internal global i1 false
@tf = internal global i1 false
@if = internal global i1 false
@df = internal global i1 false
@of = internal global i1 false
@iopl = internal global i2 0
@nt = internal global i1 false
@rf = internal global i1 false
@vm = internal global i1 false
@ac = internal global i1 false
@vif = internal global i1 false
@vip = internal global i1 false
@id = internal global i1 false
@rflags = internal global i64 0
@ss = internal global i16 0
@cs = internal global i16 0
@ds = internal global i16 0
@es = internal global i16 0
@fs = internal global i16 0
@gs = internal global i16 0
@st0 = internal global x86_fp80 0xK00000000000000000000
@st1 = internal global x86_fp80 0xK00000000000000000000
@st2 = internal global x86_fp80 0xK00000000000000000000
@st3 = internal global x86_fp80 0xK00000000000000000000
@st4 = internal global x86_fp80 0xK00000000000000000000
@st5 = internal global x86_fp80 0xK00000000000000000000
@st6 = internal global x86_fp80 0xK00000000000000000000
@st7 = internal global x86_fp80 0xK00000000000000000000
@fpu_stat_IE = internal global i1 false
@fpu_stat_DE = internal global i1 false
@fpu_stat_ZE = internal global i1 false
@fpu_stat_OE = internal global i1 false
@fpu_stat_UE = internal global i1 false
@fpu_stat_PE = internal global i1 false
@fpu_stat_SF = internal global i1 false
@fpu_stat_ES = internal global i1 false
@fpu_stat_C0 = internal global i1 false
@fpu_stat_C1 = internal global i1 false
@fpu_stat_C2 = internal global i1 false
@fpu_stat_C3 = internal global i1 false
@fpu_stat_TOP = internal global i3 0
@fpu_stat_B = internal global i1 false
@fpu_control_IM = internal global i1 false
@fpu_control_DM = internal global i1 false
@fpu_control_ZM = internal global i1 false
@fpu_control_OM = internal global i1 false
@fpu_control_UM = internal global i1 false
@fpu_control_PM = internal global i1 false
@fpu_control_PC = internal global i2 0
@fpu_control_RC = internal global i2 0
@fpu_control_X = internal global i1 false
@fp0 = internal global double 0.000000e+00
@fp1 = internal global double 0.000000e+00
@fp2 = internal global double 0.000000e+00
@fp3 = internal global double 0.000000e+00
@fp4 = internal global double 0.000000e+00
@fp5 = internal global double 0.000000e+00
@fp6 = internal global double 0.000000e+00
@fp7 = internal global double 0.000000e+00
@k0 = internal global i64 0
@k1 = internal global i64 0
@k2 = internal global i64 0
@k3 = internal global i64 0
@k4 = internal global i64 0
@k5 = internal global i64 0
@k6 = internal global i64 0
@k7 = internal global i64 0
@mm0 = internal global i64 0
@mm1 = internal global i64 0
@mm2 = internal global i64 0
@mm3 = internal global i64 0
@mm4 = internal global i64 0
@mm5 = internal global i64 0
@mm6 = internal global i64 0
@mm7 = internal global i64 0
@xmm0 = internal global i128 0
@xmm1 = internal global i128 0
@xmm2 = internal global i128 0
@xmm3 = internal global i128 0
@xmm4 = internal global i128 0
@xmm5 = internal global i128 0
@xmm6 = internal global i128 0
@xmm7 = internal global i128 0
@xmm8 = internal global i128 0
@xmm9 = internal global i128 0
@xmm10 = internal global i128 0
@xmm11 = internal global i128 0
@xmm12 = internal global i128 0
@xmm13 = internal global i128 0
@xmm14 = internal global i128 0
@xmm15 = internal global i128 0
@xmm16 = internal global i128 0
@xmm17 = internal global i128 0
@xmm18 = internal global i128 0
@xmm19 = internal global i128 0
@xmm20 = internal global i128 0
@xmm21 = internal global i128 0
@xmm22 = internal global i128 0
@xmm23 = internal global i128 0
@xmm24 = internal global i128 0
@xmm25 = internal global i128 0
@xmm26 = internal global i128 0
@xmm27 = internal global i128 0
@xmm28 = internal global i128 0
@xmm29 = internal global i128 0
@xmm30 = internal global i128 0
@xmm31 = internal global i128 0
@ymm0 = internal global i256 0
@ymm1 = internal global i256 0
@ymm2 = internal global i256 0
@ymm3 = internal global i256 0
@ymm4 = internal global i256 0
@ymm5 = internal global i256 0
@ymm6 = internal global i256 0
@ymm7 = internal global i256 0
@ymm8 = internal global i256 0
@ymm9 = internal global i256 0
@ymm10 = internal global i256 0
@ymm11 = internal global i256 0
@ymm12 = internal global i256 0
@ymm13 = internal global i256 0
@ymm14 = internal global i256 0
@ymm15 = internal global i256 0
@ymm16 = internal global i256 0
@ymm17 = internal global i256 0
@ymm18 = internal global i256 0
@ymm19 = internal global i256 0
@ymm20 = internal global i256 0
@ymm21 = internal global i256 0
@ymm22 = internal global i256 0
@ymm23 = internal global i256 0
@ymm24 = internal global i256 0
@ymm25 = internal global i256 0
@ymm26 = internal global i256 0
@ymm27 = internal global i256 0
@ymm28 = internal global i256 0
@ymm29 = internal global i256 0
@ymm30 = internal global i256 0
@ymm31 = internal global i256 0
@zmm0 = internal global i512 0
@zmm1 = internal global i512 0
@zmm2 = internal global i512 0
@zmm3 = internal global i512 0
@zmm4 = internal global i512 0
@zmm5 = internal global i512 0
@zmm6 = internal global i512 0
@zmm7 = internal global i512 0
@zmm8 = internal global i512 0
@zmm9 = internal global i512 0
@zmm10 = internal global i512 0
@zmm11 = internal global i512 0
@zmm12 = internal global i512 0
@zmm13 = internal global i512 0
@zmm14 = internal global i512 0
@zmm15 = internal global i512 0
@zmm16 = internal global i512 0
@zmm17 = internal global i512 0
@zmm18 = internal global i512 0
@zmm19 = internal global i512 0
@zmm20 = internal global i512 0
@zmm21 = internal global i512 0
@zmm22 = internal global i512 0
@zmm23 = internal global i512 0
@zmm24 = internal global i512 0
@zmm25 = internal global i512 0
@zmm26 = internal global i512 0
@zmm27 = internal global i512 0
@zmm28 = internal global i512 0
@zmm29 = internal global i512 0
@zmm30 = internal global i512 0
@zmm31 = internal global i512 0
@bnd0 = internal global i128 0
@bnd1 = internal global i128 0
@bnd2 = internal global i128 0
@bnd3 = internal global i128 0
@dr0 = internal global i64 0
@dr1 = internal global i64 0
@dr2 = internal global i64 0
@dr3 = internal global i64 0
@dr4 = internal global i64 0
@dr5 = internal global i64 0
@dr6 = internal global i64 0
@dr7 = internal global i64 0
@dr8 = internal global i64 0
@dr9 = internal global i64 0
@dr10 = internal global i64 0
@dr11 = internal global i64 0
@dr12 = internal global i64 0
@dr13 = internal global i64 0
@dr14 = internal global i64 0
@dr15 = internal global i64 0
@cr0 = internal global i64 0
@cr1 = internal global i64 0
@cr2 = internal global i64 0
@cr3 = internal global i64 0
@cr4 = internal global i64 0
@cr5 = internal global i64 0
@cr6 = internal global i64 0
@cr7 = internal global i64 0
@cr8 = internal global i64 0
@cr9 = internal global i64 0
@cr10 = internal global i64 0
@cr11 = internal global i64 0
@cr12 = internal global i64 0
@cr13 = internal global i64 0
@cr14 = internal global i64 0
@cr15 = internal global i64 0
@fpsw = internal global i64 0
@rax = internal global i64 0
@rcx = internal global i64 0
@rdx = internal global i64 0
@rbx = internal global i64 0
@rsp = internal global i64 0
@rbp = internal global i64 0
@rsi = internal global i64 0
@rdi = internal global i64 0
@r8 = internal global i64 0
@r9 = internal global i64 0
@r10 = internal global i64 0
@r11 = internal global i64 0
@r12 = internal global i64 0
@r13 = internal global i64 0
@r14 = internal global i64 0
@r15 = internal global i64 0
@rip = internal global i64 0
@riz = internal global i64 0

define i64 @_init() {
dec_label_pc_401000:

; 0x401000
  store volatile i64 4198400, i64* @_asm_program_counter

; 0x401004
  store volatile i64 4198404, i64* @_asm_program_counter
  %0 = load i64, i64* @rsp
  %1 = sub i64 %0, 8
  %2 = and i64 %0, 15
  %3 = sub i64 %2, 8
  %4 = icmp ugt i64 %3, 15
  %5 = icmp ult i64 %0, 8
  %6 = xor i64 %0, 8
  %7 = xor i64 %0, %1
  %8 = and i64 %6, %7
  %9 = icmp slt i64 %8, 0
  store i1 %4, i1* @az
  store i1 %5, i1* @cf
  store i1 %9, i1* @of
  %10 = icmp eq i64 %1, 0
  store i1 %10, i1* @zf
  %11 = icmp slt i64 %1, 0
  store i1 %11, i1* @sf
  %12 = trunc i64 %1 to i8
  %13 = call i8 @llvm.ctpop.i8(i8 %12)
  %14 = and i8 %13, 1
  %15 = icmp eq i8 %14, 0
  store i1 %15, i1* @pf
  store i64 %1, i64* @rsp

; 0x401008
  store volatile i64 4198408, i64* @_asm_program_counter
  %16 = load i64, i64* inttoptr (i64 4210672 to i64*)
  store i64 %16, i64* @rax

; 0x40100f
  store volatile i64 4198415, i64* @_asm_program_counter
  %17 = load i64, i64* @rax
  store i1 false, i1* @az
  store i1 false, i1* @cf
  store i1 false, i1* @of
  %18 = icmp eq i64 %17, 0
  store i1 %18, i1* @zf
  %19 = icmp slt i64 %17, 0
  store i1 %19, i1* @sf
  %20 = trunc i64 %17 to i8
  %21 = call i8 @llvm.ctpop.i8(i8 %20)
  %22 = and i8 %21, 1
  %23 = icmp eq i8 %22, 0
  store i1 %23, i1* @pf

; 0x401012
  store volatile i64 4198418, i64* @_asm_program_counter
  %24 = load i1, i1* @zf
  br i1 %24, label %dec_label_pc_401016, label %dec_label_pc_401014

dec_label_pc_401014:                              ; preds = %dec_label_pc_401000

; 0x401014
  store volatile i64 4198420, i64* @_asm_program_counter
  %25 = call i64 @__gmon_start__()
  store i64 %25, i64* @rax
  br label %dec_label_pc_401016

dec_label_pc_401016:                              ; preds = %dec_label_pc_401014, %dec_label_pc_401000

; 0x401016
  store volatile i64 4198422, i64* @_asm_program_counter
  %26 = load i64, i64* @rsp
  %27 = add i64 %26, 8
  %28 = and i64 %26, 15
  %29 = add i64 %28, 8
  %30 = icmp ugt i64 %29, 15
  %31 = icmp ult i64 %27, %26
  %32 = xor i64 %26, %27
  %33 = xor i64 8, %27
  %34 = and i64 %32, %33
  %35 = icmp slt i64 %34, 0
  store i1 %30, i1* @az
  store i1 %31, i1* @cf
  store i1 %35, i1* @of
  %36 = icmp eq i64 %27, 0
  store i1 %36, i1* @zf
  %37 = icmp slt i64 %27, 0
  store i1 %37, i1* @sf
  %38 = trunc i64 %27 to i8
  %39 = call i8 @llvm.ctpop.i8(i8 %38)
  %40 = and i8 %39, 1
  %41 = icmp eq i8 %40, 0
  store i1 %41, i1* @pf
  store i64 %27, i64* @rsp

; 0x40101a
  store volatile i64 4198426, i64* @_asm_program_counter
  ret i64 undef
}

define i64 @function_401030() {
dec_label_pc_401030:

; 0x401030
  store volatile i64 4198448, i64* @_asm_program_counter
  %0 = call i64 @printf()
  store i64 %0, i64* @rax
  ret i64 undef
}

define i64 @_start() {
dec_label_pc_401040:

; 0x401040
  store volatile i64 4198464, i64* @_asm_program_counter

; 0x401044
  store volatile i64 4198468, i64* @_asm_program_counter
  %0 = load i64, i64* @rbp
  %1 = trunc i64 %0 to i32
  %2 = load i64, i64* @rbp
  %3 = trunc i64 %2 to i32
  %4 = xor i32 %1, %3
  store i1 false, i1* @az
  store i1 false, i1* @cf
  store i1 false, i1* @of
  %5 = icmp eq i32 %4, 0
  store i1 %5, i1* @zf
  %6 = icmp slt i32 %4, 0
  store i1 %6, i1* @sf
  %7 = trunc i32 %4 to i8
  %8 = call i8 @llvm.ctpop.i8(i8 %7)
  %9 = and i8 %8, 1
  %10 = icmp eq i8 %9, 0
  store i1 %10, i1* @pf
  %11 = zext i32 %4 to i64
  store i64 %11, i64* @rbp

; 0x401046
  store volatile i64 4198470, i64* @_asm_program_counter
  %12 = load i64, i64* @rdx
  store i64 %12, i64* @r9

; 0x401049
  store volatile i64 4198473, i64* @_asm_program_counter
  %13 = load i64, i64* @rsp
  %14 = inttoptr i64 %13 to i64*
  %15 = load i64, i64* %14
  store i64 %15, i64* @rsi
  %16 = add i64 %13, 8
  store i64 %16, i64* @rsp

; 0x40104a
  store volatile i64 4198474, i64* @_asm_program_counter
  %17 = load i64, i64* @rsp
  store i64 %17, i64* @rdx

; 0x40104d
  store volatile i64 4198477, i64* @_asm_program_counter
  %18 = load i64, i64* @rsp
  %19 = and i64 %18, -16
  store i1 false, i1* @az
  store i1 false, i1* @cf
  store i1 false, i1* @of
  %20 = icmp eq i64 %19, 0
  store i1 %20, i1* @zf
  %21 = icmp slt i64 %19, 0
  store i1 %21, i1* @sf
  %22 = trunc i64 %19 to i8
  %23 = call i8 @llvm.ctpop.i8(i8 %22)
  %24 = and i8 %23, 1
  %25 = icmp eq i8 %24, 0
  store i1 %25, i1* @pf
  store i64 %19, i64* @rsp

; 0x401051
  store volatile i64 4198481, i64* @_asm_program_counter
  %26 = load i64, i64* @rax
  %27 = load i64, i64* @rsp
  %28 = sub i64 %27, 8
  %29 = inttoptr i64 %28 to i64*
  store i64 %26, i64* %29
  store i64 %28, i64* @rsp

; 0x401052
  store volatile i64 4198482, i64* @_asm_program_counter
  %30 = load i64, i64* @rsp
  %31 = load i64, i64* @rsp
  %32 = sub i64 %31, 8
  %33 = inttoptr i64 %32 to i64*
  store i64 %30, i64* %33
  store i64 %32, i64* @rsp

; 0x401053
  store volatile i64 4198483, i64* @_asm_program_counter
  %34 = load i64, i64* @r8
  %35 = trunc i64 %34 to i32
  %36 = load i64, i64* @r8
  %37 = trunc i64 %36 to i32
  %38 = xor i32 %35, %37
  store i1 false, i1* @az
  store i1 false, i1* @cf
  store i1 false, i1* @of
  %39 = icmp eq i32 %38, 0
  store i1 %39, i1* @zf
  %40 = icmp slt i32 %38, 0
  store i1 %40, i1* @sf
  %41 = trunc i32 %38 to i8
  %42 = call i8 @llvm.ctpop.i8(i8 %41)
  %43 = and i8 %42, 1
  %44 = icmp eq i8 %43, 0
  store i1 %44, i1* @pf
  %45 = zext i32 %38 to i64
  store i64 %45, i64* @r8

; 0x401056
  store volatile i64 4198486, i64* @_asm_program_counter
  %46 = load i64, i64* @rcx
  %47 = trunc i64 %46 to i32
  %48 = load i64, i64* @rcx
  %49 = trunc i64 %48 to i32
  %50 = xor i32 %47, %49
  store i1 false, i1* @az
  store i1 false, i1* @cf
  store i1 false, i1* @of
  %51 = icmp eq i32 %50, 0
  store i1 %51, i1* @zf
  %52 = icmp slt i32 %50, 0
  store i1 %52, i1* @sf
  %53 = trunc i32 %50 to i8
  %54 = call i8 @llvm.ctpop.i8(i8 %53)
  %55 = and i8 %54, 1
  %56 = icmp eq i8 %55, 0
  store i1 %56, i1* @pf
  %57 = zext i32 %50 to i64
  store i64 %57, i64* @rcx

; 0x401058
  store volatile i64 4198488, i64* @_asm_program_counter
  store i64 4198721, i64* @rdi

; 0x40105f
  store volatile i64 4198495, i64* @_asm_program_counter
  %58 = call i64 @__libc_start_main()
  store i64 %58, i64* @rax

; 0x401065
  store volatile i64 4198501, i64* @_asm_program_counter
  call void @__asm_hlt()
  unreachable
}

define i64 @_dl_relocate_static_pie() {
dec_label_pc_401070:

; 0x401070
  store volatile i64 4198512, i64* @_asm_program_counter

; 0x401074
  store volatile i64 4198516, i64* @_asm_program_counter
  ret i64 undef
}

define i64 @deregister_tm_clones() {
dec_label_pc_401080:

; 0x401080
  store volatile i64 4198528, i64* @_asm_program_counter
  store i64 4210728, i64* @rdi

; 0x401087
  store volatile i64 4198535, i64* @_asm_program_counter
  store i64 4210728, i64* @rax

; 0x40108e
  store volatile i64 4198542, i64* @_asm_program_counter
  %0 = load i64, i64* @rax
  %1 = load i64, i64* @rdi
  %2 = sub i64 %0, %1
  %3 = and i64 %0, 15
  %4 = and i64 %1, 15
  %5 = sub i64 %3, %4
  %6 = icmp ugt i64 %5, 15
  %7 = icmp ult i64 %0, %1
  %8 = xor i64 %0, %1
  %9 = xor i64 %0, %2
  %10 = and i64 %8, %9
  %11 = icmp slt i64 %10, 0
  store i1 %6, i1* @az
  store i1 %7, i1* @cf
  store i1 %11, i1* @of
  %12 = icmp eq i64 %2, 0
  store i1 %12, i1* @zf
  %13 = icmp slt i64 %2, 0
  store i1 %13, i1* @sf
  %14 = trunc i64 %2 to i8
  %15 = call i8 @llvm.ctpop.i8(i8 %14)
  %16 = and i8 %15, 1
  %17 = icmp eq i8 %16, 0
  store i1 %17, i1* @pf

; 0x401091
  store volatile i64 4198545, i64* @_asm_program_counter
  %18 = load i1, i1* @zf
  br i1 %18, label %dec_label_pc_4010a8, label %dec_label_pc_401093

dec_label_pc_401093:                              ; preds = %dec_label_pc_401080

; 0x401093
  store volatile i64 4198547, i64* @_asm_program_counter
  %19 = load i64, i64* inttoptr (i64 4210664 to i64*)
  store i64 %19, i64* @rax

; 0x40109a
  store volatile i64 4198554, i64* @_asm_program_counter
  %20 = load i64, i64* @rax
  store i1 false, i1* @az
  store i1 false, i1* @cf
  store i1 false, i1* @of
  %21 = icmp eq i64 %20, 0
  store i1 %21, i1* @zf
  %22 = icmp slt i64 %20, 0
  store i1 %22, i1* @sf
  %23 = trunc i64 %20 to i8
  %24 = call i8 @llvm.ctpop.i8(i8 %23)
  %25 = and i8 %24, 1
  %26 = icmp eq i8 %25, 0
  store i1 %26, i1* @pf

; 0x40109d
  store volatile i64 4198557, i64* @_asm_program_counter
  %27 = load i1, i1* @zf
  br i1 %27, label %dec_label_pc_4010a8, label %dec_label_pc_40109f

dec_label_pc_40109f:                              ; preds = %dec_label_pc_401093

; 0x40109f
  store volatile i64 4198559, i64* @_asm_program_counter
  %28 = call i64 @_ITM_deregisterTMCloneTable()
  store i64 %28, i64* @rax
  ret i64 undef

dec_label_pc_4010a8:                              ; preds = %dec_label_pc_401093, %dec_label_pc_401080

; 0x4010a8
  store volatile i64 4198568, i64* @_asm_program_counter
  ret i64 undef
}

define i64 @register_tm_clones() {
dec_label_pc_4010b0:

; 0x4010b0
  store volatile i64 4198576, i64* @_asm_program_counter
  store i64 4210728, i64* @rdi

; 0x4010b7
  store volatile i64 4198583, i64* @_asm_program_counter
  store i64 4210728, i64* @rsi

; 0x4010be
  store volatile i64 4198590, i64* @_asm_program_counter
  %0 = load i64, i64* @rsi
  %1 = load i64, i64* @rdi
  %2 = sub i64 %0, %1
  %3 = and i64 %0, 15
  %4 = and i64 %1, 15
  %5 = sub i64 %3, %4
  %6 = icmp ugt i64 %5, 15
  %7 = icmp ult i64 %0, %1
  %8 = xor i64 %0, %1
  %9 = xor i64 %0, %2
  %10 = and i64 %8, %9
  %11 = icmp slt i64 %10, 0
  store i1 %6, i1* @az
  store i1 %7, i1* @cf
  store i1 %11, i1* @of
  %12 = icmp eq i64 %2, 0
  store i1 %12, i1* @zf
  %13 = icmp slt i64 %2, 0
  store i1 %13, i1* @sf
  %14 = trunc i64 %2 to i8
  %15 = call i8 @llvm.ctpop.i8(i8 %14)
  %16 = and i8 %15, 1
  %17 = icmp eq i8 %16, 0
  store i1 %17, i1* @pf
  store i64 %2, i64* @rsi

; 0x4010c1
  store volatile i64 4198593, i64* @_asm_program_counter
  %18 = load i64, i64* @rsi
  store i64 %18, i64* @rax

; 0x4010c4
  store volatile i64 4198596, i64* @_asm_program_counter
  %19 = load i64, i64* @rsi
  %20 = load i1, i1* @of
  %21 = lshr i64 %19, 63
  %22 = icmp eq i64 %21, 0
  store i1 %22, i1* @zf
  %23 = icmp slt i64 %21, 0
  store i1 %23, i1* @sf
  %24 = trunc i64 %21 to i8
  %25 = call i8 @llvm.ctpop.i8(i8 %24)
  %26 = and i8 %25, 1
  %27 = icmp eq i8 %26, 0
  store i1 %27, i1* @pf
  store i64 %21, i64* @rsi
  %28 = and i64 4611686018427387904, %19
  %29 = icmp ne i64 %28, 0
  store i1 %29, i1* @cf
  %30 = icmp slt i64 %19, 0
  %31 = select i1 false, i1 %30, i1 %20
  store i1 %31, i1* @of

; 0x4010c8
  store volatile i64 4198600, i64* @_asm_program_counter
  %32 = load i64, i64* @rax
  %33 = load i1, i1* @of
  %34 = ashr i64 %32, 3
  %35 = icmp eq i64 %34, 0
  store i1 %35, i1* @zf
  %36 = icmp slt i64 %34, 0
  store i1 %36, i1* @sf
  %37 = trunc i64 %34 to i8
  %38 = call i8 @llvm.ctpop.i8(i8 %37)
  %39 = and i8 %38, 1
  %40 = icmp eq i8 %39, 0
  store i1 %40, i1* @pf
  store i64 %34, i64* @rax
  %41 = and i64 4, %32
  %42 = icmp ne i64 %41, 0
  store i1 %42, i1* @cf
  %43 = select i1 false, i1 false, i1 %33
  store i1 %43, i1* @of

; 0x4010cc
  store volatile i64 4198604, i64* @_asm_program_counter
  %44 = load i64, i64* @rsi
  %45 = load i64, i64* @rax
  %46 = add i64 %44, %45
  %47 = and i64 %44, 15
  %48 = and i64 %45, 15
  %49 = add i64 %47, %48
  %50 = icmp ugt i64 %49, 15
  %51 = icmp ult i64 %46, %44
  %52 = xor i64 %44, %46
  %53 = xor i64 %45, %46
  %54 = and i64 %52, %53
  %55 = icmp slt i64 %54, 0
  store i1 %50, i1* @az
  store i1 %51, i1* @cf
  store i1 %55, i1* @of
  %56 = icmp eq i64 %46, 0
  store i1 %56, i1* @zf
  %57 = icmp slt i64 %46, 0
  store i1 %57, i1* @sf
  %58 = trunc i64 %46 to i8
  %59 = call i8 @llvm.ctpop.i8(i8 %58)
  %60 = and i8 %59, 1
  %61 = icmp eq i8 %60, 0
  store i1 %61, i1* @pf
  store i64 %46, i64* @rsi

; 0x4010cf
  store volatile i64 4198607, i64* @_asm_program_counter
  %62 = load i64, i64* @rsi
  %63 = load i1, i1* @of
  %64 = ashr i64 %62, 1
  %65 = icmp eq i64 %64, 0
  store i1 %65, i1* @zf
  %66 = icmp slt i64 %64, 0
  store i1 %66, i1* @sf
  %67 = trunc i64 %64 to i8
  %68 = call i8 @llvm.ctpop.i8(i8 %67)
  %69 = and i8 %68, 1
  %70 = icmp eq i8 %69, 0
  store i1 %70, i1* @pf
  store i64 %64, i64* @rsi
  %71 = and i64 1, %62
  %72 = icmp ne i64 %71, 0
  store i1 %72, i1* @cf
  %73 = select i1 true, i1 false, i1 %63
  store i1 %73, i1* @of

; 0x4010d2
  store volatile i64 4198610, i64* @_asm_program_counter
  %74 = load i1, i1* @zf
  br i1 %74, label %dec_label_pc_4010e8, label %dec_label_pc_4010d4

dec_label_pc_4010d4:                              ; preds = %dec_label_pc_4010b0

; 0x4010d4
  store volatile i64 4198612, i64* @_asm_program_counter
  %75 = load i64, i64* inttoptr (i64 4210680 to i64*)
  store i64 %75, i64* @rax

; 0x4010db
  store volatile i64 4198619, i64* @_asm_program_counter
  %76 = load i64, i64* @rax
  store i1 false, i1* @az
  store i1 false, i1* @cf
  store i1 false, i1* @of
  %77 = icmp eq i64 %76, 0
  store i1 %77, i1* @zf
  %78 = icmp slt i64 %76, 0
  store i1 %78, i1* @sf
  %79 = trunc i64 %76 to i8
  %80 = call i8 @llvm.ctpop.i8(i8 %79)
  %81 = and i8 %80, 1
  %82 = icmp eq i8 %81, 0
  store i1 %82, i1* @pf

; 0x4010de
  store volatile i64 4198622, i64* @_asm_program_counter
  %83 = load i1, i1* @zf
  br i1 %83, label %dec_label_pc_4010e8, label %dec_label_pc_4010e0

dec_label_pc_4010e0:                              ; preds = %dec_label_pc_4010d4

; 0x4010e0
  store volatile i64 4198624, i64* @_asm_program_counter
  %84 = call i64 @_ITM_registerTMCloneTable()
  store i64 %84, i64* @rax
  ret i64 undef

dec_label_pc_4010e8:                              ; preds = %dec_label_pc_4010d4, %dec_label_pc_4010b0

; 0x4010e8
  store volatile i64 4198632, i64* @_asm_program_counter
  ret i64 undef
}

define i64 @__do_global_dtors_aux() {
dec_label_pc_4010f0:

; 0x4010f0
  store volatile i64 4198640, i64* @_asm_program_counter

; 0x4010f4
  store volatile i64 4198644, i64* @_asm_program_counter
  %0 = load i8, i8* inttoptr (i64 4210724 to i8*)
  %1 = and i8 %0, 15
  %2 = icmp ugt i8 %1, 15
  %3 = icmp ult i8 %0, 0
  %4 = xor i8 %0, 0
  %5 = and i8 %4, 0
  %6 = icmp slt i8 %5, 0
  store i1 %2, i1* @az
  store i1 %3, i1* @cf
  store i1 %6, i1* @of
  %7 = icmp eq i8 %0, 0
  store i1 %7, i1* @zf
  %8 = icmp slt i8 %0, 0
  store i1 %8, i1* @sf
  %9 = call i8 @llvm.ctpop.i8(i8 %0)
  %10 = and i8 %9, 1
  %11 = icmp eq i8 %10, 0
  store i1 %11, i1* @pf

; 0x4010fb
  store volatile i64 4198651, i64* @_asm_program_counter
  %12 = load i1, i1* @zf
  %13 = icmp eq i1 %12, false
  br i1 %13, label %dec_label_pc_401110, label %dec_label_pc_4010fd

dec_label_pc_4010fd:                              ; preds = %dec_label_pc_4010f0

; 0x4010fd
  store volatile i64 4198653, i64* @_asm_program_counter
  %14 = load i64, i64* @rbp
  %15 = load i64, i64* @rsp
  %16 = sub i64 %15, 8
  %17 = inttoptr i64 %16 to i64*
  store i64 %14, i64* %17
  store i64 %16, i64* @rsp

; 0x4010fe
  store volatile i64 4198654, i64* @_asm_program_counter
  %18 = load i64, i64* @rsp
  store i64 %18, i64* @rbp

; 0x401101
  store volatile i64 4198657, i64* @_asm_program_counter
  %19 = call i64 @deregister_tm_clones()
  store i64 %19, i64* @rax

; 0x401106
  store volatile i64 4198662, i64* @_asm_program_counter
  store i8 1, i8* inttoptr (i64 4210724 to i8*)

; 0x40110d
  store volatile i64 4198669, i64* @_asm_program_counter
  %20 = load i64, i64* @rsp
  %21 = inttoptr i64 %20 to i64*
  %22 = load i64, i64* %21
  store i64 %22, i64* @rbp
  %23 = add i64 %20, 8
  store i64 %23, i64* @rsp

; 0x40110e
  store volatile i64 4198670, i64* @_asm_program_counter
  ret i64 undef

dec_label_pc_401110:                              ; preds = %dec_label_pc_4010f0

; 0x401110
  store volatile i64 4198672, i64* @_asm_program_counter
  ret i64 undef
}

define i64 @frame_dummy() {
dec_label_pc_401120:

; 0x401120
  store volatile i64 4198688, i64* @_asm_program_counter

; 0x401124
  store volatile i64 4198692, i64* @_asm_program_counter
  %0 = call i64 @register_tm_clones()
  store i64 %0, i64* @rax
  ret i64 undef
}

define i64 @add() {
dec_label_pc_401126:

; 0x401126
  store volatile i64 4198694, i64* @_asm_program_counter
  %0 = load i64, i64* @rbp
  %1 = load i64, i64* @rsp
  %2 = sub i64 %1, 8
  %3 = inttoptr i64 %2 to i64*
  store i64 %0, i64* %3
  store i64 %2, i64* @rsp

; 0x401127
  store volatile i64 4198695, i64* @_asm_program_counter
  %4 = load i64, i64* @rsp
  store i64 %4, i64* @rbp

; 0x40112a
  store volatile i64 4198698, i64* @_asm_program_counter
  %5 = load i64, i64* @rdi
  %6 = load i64, i64* @rbp
  %7 = add i64 %6, -8
  %8 = inttoptr i64 %7 to i64*
  store i64 %5, i64* %8

; 0x40112e
  store volatile i64 4198702, i64* @_asm_program_counter
  %9 = load i64, i64* @rsi
  %10 = trunc i64 %9 to i32
  %11 = zext i32 %10 to i64
  store i64 %11, i64* @rax

; 0x401130
  store volatile i64 4198704, i64* @_asm_program_counter
  %12 = load i64, i64* @rax
  %13 = trunc i64 %12 to i8
  %14 = load i64, i64* @rbp
  %15 = add i64 %14, -12
  %16 = inttoptr i64 %15 to i8*
  store i8 %13, i8* %16

; 0x401133
  store volatile i64 4198707, i64* @_asm_program_counter
  %17 = load i64, i64* @rbp
  %18 = add i64 %17, -8
  %19 = inttoptr i64 %18 to i64*
  %20 = load i64, i64* %19
  store i64 %20, i64* @rax

; 0x401137
  store volatile i64 4198711, i64* @_asm_program_counter
  %21 = load i64, i64* @rax
  %22 = inttoptr i64 %21 to i32*
  %23 = load i32, i32* %22
  %24 = zext i32 %23 to i64
  store i64 %24, i64* @rdx

; 0x401139
  store volatile i64 4198713, i64* @_asm_program_counter
  %25 = load i64, i64* @rbp
  %26 = add i64 %25, -12
  %27 = inttoptr i64 %26 to i8*
  %28 = load i8, i8* %27
  %29 = sext i8 %28 to i64
  store i64 %29, i64* @rax

; 0x40113d
  store volatile i64 4198717, i64* @_asm_program_counter
  %30 = load i64, i64* @rax
  %31 = trunc i64 %30 to i32
  %32 = load i64, i64* @rdx
  %33 = trunc i64 %32 to i32
  %34 = add i32 %31, %33
  %35 = and i32 %31, 15
  %36 = and i32 %33, 15
  %37 = add i32 %35, %36
  %38 = icmp ugt i32 %37, 15
  %39 = icmp ult i32 %34, %31
  %40 = xor i32 %31, %34
  %41 = xor i32 %33, %34
  %42 = and i32 %40, %41
  %43 = icmp slt i32 %42, 0
  store i1 %38, i1* @az
  store i1 %39, i1* @cf
  store i1 %43, i1* @of
  %44 = icmp eq i32 %34, 0
  store i1 %44, i1* @zf
  %45 = icmp slt i32 %34, 0
  store i1 %45, i1* @sf
  %46 = trunc i32 %34 to i8
  %47 = call i8 @llvm.ctpop.i8(i8 %46)
  %48 = and i8 %47, 1
  %49 = icmp eq i8 %48, 0
  store i1 %49, i1* @pf
  %50 = zext i32 %34 to i64
  store i64 %50, i64* @rax

; 0x40113f
  store volatile i64 4198719, i64* @_asm_program_counter
  %51 = load i64, i64* @rsp
  %52 = inttoptr i64 %51 to i64*
  %53 = load i64, i64* %52
  store i64 %53, i64* @rbp
  %54 = add i64 %51, 8
  store i64 %54, i64* @rsp

; 0x401140
  store volatile i64 4198720, i64* @_asm_program_counter
  ret i64 undef
}

define i64 @main() {
dec_label_pc_401141:

; 0x401141
  store volatile i64 4198721, i64* @_asm_program_counter
  %0 = load i64, i64* @rbp
  %1 = load i64, i64* @rsp
  %2 = sub i64 %1, 8
  %3 = inttoptr i64 %2 to i64*
  store i64 %0, i64* %3
  store i64 %2, i64* @rsp

; 0x401142
  store volatile i64 4198722, i64* @_asm_program_counter
  %4 = load i64, i64* @rsp
  store i64 %4, i64* @rbp

; 0x401145
  store volatile i64 4198725, i64* @_asm_program_counter
  %5 = load i64, i64* @rsp
  %6 = sub i64 %5, 32
  %7 = and i64 %5, 15
  %8 = icmp ugt i64 %7, 15
  %9 = icmp ult i64 %5, 32
  %10 = xor i64 %5, 32
  %11 = xor i64 %5, %6
  %12 = and i64 %10, %11
  %13 = icmp slt i64 %12, 0
  store i1 %8, i1* @az
  store i1 %9, i1* @cf
  store i1 %13, i1* @of
  %14 = icmp eq i64 %6, 0
  store i1 %14, i1* @zf
  %15 = icmp slt i64 %6, 0
  store i1 %15, i1* @sf
  %16 = trunc i64 %6 to i8
  %17 = call i8 @llvm.ctpop.i8(i8 %16)
  %18 = and i8 %17, 1
  %19 = icmp eq i8 %18, 0
  store i1 %19, i1* @pf
  store i64 %6, i64* @rsp

; 0x401149
  store volatile i64 4198729, i64* @_asm_program_counter
  %20 = load i64, i64* @rbp
  %21 = add i64 %20, -24
  %22 = inttoptr i64 %21 to i32*
  store i32 1, i32* %22

; 0x401150
  store volatile i64 4198736, i64* @_asm_program_counter
  %23 = load i64, i64* @rbp
  %24 = add i64 %23, -1
  %25 = inttoptr i64 %24 to i8*
  store i8 2, i8* %25

; 0x401154
  store volatile i64 4198740, i64* @_asm_program_counter
  %26 = load i64, i64* @rbp
  %27 = add i64 %26, -1
  %28 = inttoptr i64 %27 to i8*
  %29 = load i8, i8* %28
  %30 = sext i8 %29 to i64
  store i64 %30, i64* @rdx

; 0x401158
  store volatile i64 4198744, i64* @_asm_program_counter
  %31 = load i64, i64* @rbp
  %32 = add i64 %31, -24
  store i64 %32, i64* @rax

; 0x40115c
  store volatile i64 4198748, i64* @_asm_program_counter
  %33 = load i64, i64* @rdx
  %34 = trunc i64 %33 to i32
  %35 = zext i32 %34 to i64
  store i64 %35, i64* @rsi

; 0x40115e
  store volatile i64 4198750, i64* @_asm_program_counter
  %36 = load i64, i64* @rax
  store i64 %36, i64* @rdi

; 0x401161
  store volatile i64 4198753, i64* @_asm_program_counter
  %37 = call i64 @add()
  store i64 %37, i64* @rax

; 0x401166
  store volatile i64 4198758, i64* @_asm_program_counter
  %38 = load i64, i64* @rax
  %39 = trunc i64 %38 to i32
  %40 = load i64, i64* @rbp
  %41 = add i64 %40, -8
  %42 = inttoptr i64 %41 to i32*
  store i32 %39, i32* %42

; 0x401169
  store volatile i64 4198761, i64* @_asm_program_counter
  %43 = load i64, i64* @rbp
  %44 = add i64 %43, -24
  store i64 %44, i64* @rax

; 0x40116d
  store volatile i64 4198765, i64* @_asm_program_counter
  %45 = load i64, i64* @rax
  %46 = load i64, i64* @rbp
  %47 = add i64 %46, -16
  %48 = inttoptr i64 %47 to i64*
  store i64 %45, i64* %48

; 0x401171
  store volatile i64 4198769, i64* @_asm_program_counter
  %49 = load i64, i64* @rbp
  %50 = add i64 %49, -1
  %51 = inttoptr i64 %50 to i8*
  %52 = load i8, i8* %51
  %53 = sext i8 %52 to i64
  store i64 %53, i64* @rdx

; 0x401175
  store volatile i64 4198773, i64* @_asm_program_counter
  %54 = load i64, i64* @rbp
  %55 = add i64 %54, -16
  %56 = inttoptr i64 %55 to i64*
  %57 = load i64, i64* %56
  store i64 %57, i64* @rax

; 0x401179
  store volatile i64 4198777, i64* @_asm_program_counter
  %58 = load i64, i64* @rdx
  %59 = trunc i64 %58 to i32
  %60 = zext i32 %59 to i64
  store i64 %60, i64* @rsi

; 0x40117b
  store volatile i64 4198779, i64* @_asm_program_counter
  %61 = load i64, i64* @rax
  store i64 %61, i64* @rdi

; 0x40117e
  store volatile i64 4198782, i64* @_asm_program_counter
  %62 = call i64 @add()
  store i64 %62, i64* @rax

; 0x401183
  store volatile i64 4198787, i64* @_asm_program_counter
  %63 = load i64, i64* @rax
  %64 = trunc i64 %63 to i32
  %65 = load i64, i64* @rbp
  %66 = add i64 %65, -20
  %67 = inttoptr i64 %66 to i32*
  store i32 %64, i32* %67

; 0x401186
  store volatile i64 4198790, i64* @_asm_program_counter
  %68 = load i64, i64* @rbp
  %69 = add i64 %68, -8
  %70 = inttoptr i64 %69 to i32*
  %71 = load i32, i32* %70
  %72 = zext i32 %71 to i64
  store i64 %72, i64* @rax

; 0x401189
  store volatile i64 4198793, i64* @_asm_program_counter
  %73 = load i64, i64* @rax
  %74 = trunc i64 %73 to i32
  %75 = zext i32 %74 to i64
  store i64 %75, i64* @rsi

; 0x40118b
  store volatile i64 4198795, i64* @_asm_program_counter
  store i64 4202512, i64* @rdi

; 0x401190
  store volatile i64 4198800, i64* @_asm_program_counter
  store i64 0, i64* @rax

; 0x401195
  store volatile i64 4198805, i64* @_asm_program_counter
  %76 = call i64 @function_401030()
  store i64 %76, i64* @rax

; 0x40119a
  store volatile i64 4198810, i64* @_asm_program_counter
  store i64 0, i64* @rax

; 0x40119f
  store volatile i64 4198815, i64* @_asm_program_counter
  %77 = load i64, i64* @rbp
  %78 = inttoptr i64 %77 to i64*
  %79 = load i64, i64* %78
  %80 = add i64 %77, 8
  store i64 %79, i64* @rbp
  store i64 %80, i64* @rsp

; 0x4011a0
  store volatile i64 4198816, i64* @_asm_program_counter
  ret i64 undef
}

define i64 @_fini() {
dec_label_pc_4011a4:

; 0x4011a4
  store volatile i64 4198820, i64* @_asm_program_counter

; 0x4011a8
  store volatile i64 4198824, i64* @_asm_program_counter
  %0 = load i64, i64* @rsp
  %1 = sub i64 %0, 8
  %2 = and i64 %0, 15
  %3 = sub i64 %2, 8
  %4 = icmp ugt i64 %3, 15
  %5 = icmp ult i64 %0, 8
  %6 = xor i64 %0, 8
  %7 = xor i64 %0, %1
  %8 = and i64 %6, %7
  %9 = icmp slt i64 %8, 0
  store i1 %4, i1* @az
  store i1 %5, i1* @cf
  store i1 %9, i1* @of
  %10 = icmp eq i64 %1, 0
  store i1 %10, i1* @zf
  %11 = icmp slt i64 %1, 0
  store i1 %11, i1* @sf
  %12 = trunc i64 %1 to i8
  %13 = call i8 @llvm.ctpop.i8(i8 %12)
  %14 = and i8 %13, 1
  %15 = icmp eq i8 %14, 0
  store i1 %15, i1* @pf
  store i64 %1, i64* @rsp

; 0x4011ac
  store volatile i64 4198828, i64* @_asm_program_counter
  %16 = load i64, i64* @rsp
  %17 = add i64 %16, 8
  %18 = and i64 %16, 15
  %19 = add i64 %18, 8
  %20 = icmp ugt i64 %19, 15
  %21 = icmp ult i64 %17, %16
  %22 = xor i64 %16, %17
  %23 = xor i64 8, %17
  %24 = and i64 %22, %23
  %25 = icmp slt i64 %24, 0
  store i1 %20, i1* @az
  store i1 %21, i1* @cf
  store i1 %25, i1* @of
  %26 = icmp eq i64 %17, 0
  store i1 %26, i1* @zf
  %27 = icmp slt i64 %17, 0
  store i1 %27, i1* @sf
  %28 = trunc i64 %17 to i8
  %29 = call i8 @llvm.ctpop.i8(i8 %28)
  %30 = and i8 %29, 1
  %31 = icmp eq i8 %30, 0
  store i1 %31, i1* @pf
  store i64 %17, i64* @rsp

; 0x4011b0
  store volatile i64 4198832, i64* @_asm_program_counter
  ret i64 undef
}

declare i64 @__libc_start_main()

declare i64 @_ITM_deregisterTMCloneTable()

declare i64 @__gmon_start__()

declare i64 @_ITM_registerTMCloneTable()

declare i64 @printf()

declare void @__pseudo_call(i64)

declare void @__pseudo_return(i64)

declare void @__pseudo_branch(i64)

declare void @__pseudo_cond_branch(i1, i64)

declare void @__frontend_reg_store.fpr(i3, x86_fp80)

declare x86_fp80 @__frontend_reg_load.fpr(i3)

; Function Attrs: nounwind readnone speculatable
declare i8 @llvm.ctpop.i8(i8) #0

declare void @__asm_hlt()

attributes #0 = { nounwind readnone speculatable }
*** IR Dump After Conditional branch optimization ***
source_filename = "test"
target datalayout = "e-m:e-p:64:64-i64:64-f80:128-n8:16:32:64-S128"

@_asm_program_counter = internal global i64 0
@cf = internal global i1 false
@pf = internal global i1 false
@az = internal global i1 false
@zf = internal global i1 false
@sf = internal global i1 false
@tf = internal global i1 false
@if = internal global i1 false
@df = internal global i1 false
@of = internal global i1 false
@iopl = internal global i2 0
@nt = internal global i1 false
@rf = internal global i1 false
@vm = internal global i1 false
@ac = internal global i1 false
@vif = internal global i1 false
@vip = internal global i1 false
@id = internal global i1 false
@rflags = internal global i64 0
@ss = internal global i16 0
@cs = internal global i16 0
@ds = internal global i16 0
@es = internal global i16 0
@fs = internal global i16 0
@gs = internal global i16 0
@st0 = internal global x86_fp80 0xK00000000000000000000
@st1 = internal global x86_fp80 0xK00000000000000000000
@st2 = internal global x86_fp80 0xK00000000000000000000
@st3 = internal global x86_fp80 0xK00000000000000000000
@st4 = internal global x86_fp80 0xK00000000000000000000
@st5 = internal global x86_fp80 0xK00000000000000000000
@st6 = internal global x86_fp80 0xK00000000000000000000
@st7 = internal global x86_fp80 0xK00000000000000000000
@fpu_stat_IE = internal global i1 false
@fpu_stat_DE = internal global i1 false
@fpu_stat_ZE = internal global i1 false
@fpu_stat_OE = internal global i1 false
@fpu_stat_UE = internal global i1 false
@fpu_stat_PE = internal global i1 false
@fpu_stat_SF = internal global i1 false
@fpu_stat_ES = internal global i1 false
@fpu_stat_C0 = internal global i1 false
@fpu_stat_C1 = internal global i1 false
@fpu_stat_C2 = internal global i1 false
@fpu_stat_C3 = internal global i1 false
@fpu_stat_TOP = internal global i3 0
@fpu_stat_B = internal global i1 false
@fpu_control_IM = internal global i1 false
@fpu_control_DM = internal global i1 false
@fpu_control_ZM = internal global i1 false
@fpu_control_OM = internal global i1 false
@fpu_control_UM = internal global i1 false
@fpu_control_PM = internal global i1 false
@fpu_control_PC = internal global i2 0
@fpu_control_RC = internal global i2 0
@fpu_control_X = internal global i1 false
@fp0 = internal global double 0.000000e+00
@fp1 = internal global double 0.000000e+00
@fp2 = internal global double 0.000000e+00
@fp3 = internal global double 0.000000e+00
@fp4 = internal global double 0.000000e+00
@fp5 = internal global double 0.000000e+00
@fp6 = internal global double 0.000000e+00
@fp7 = internal global double 0.000000e+00
@k0 = internal global i64 0
@k1 = internal global i64 0
@k2 = internal global i64 0
@k3 = internal global i64 0
@k4 = internal global i64 0
@k5 = internal global i64 0
@k6 = internal global i64 0
@k7 = internal global i64 0
@mm0 = internal global i64 0
@mm1 = internal global i64 0
@mm2 = internal global i64 0
@mm3 = internal global i64 0
@mm4 = internal global i64 0
@mm5 = internal global i64 0
@mm6 = internal global i64 0
@mm7 = internal global i64 0
@xmm0 = internal global i128 0
@xmm1 = internal global i128 0
@xmm2 = internal global i128 0
@xmm3 = internal global i128 0
@xmm4 = internal global i128 0
@xmm5 = internal global i128 0
@xmm6 = internal global i128 0
@xmm7 = internal global i128 0
@xmm8 = internal global i128 0
@xmm9 = internal global i128 0
@xmm10 = internal global i128 0
@xmm11 = internal global i128 0
@xmm12 = internal global i128 0
@xmm13 = internal global i128 0
@xmm14 = internal global i128 0
@xmm15 = internal global i128 0
@xmm16 = internal global i128 0
@xmm17 = internal global i128 0
@xmm18 = internal global i128 0
@xmm19 = internal global i128 0
@xmm20 = internal global i128 0
@xmm21 = internal global i128 0
@xmm22 = internal global i128 0
@xmm23 = internal global i128 0
@xmm24 = internal global i128 0
@xmm25 = internal global i128 0
@xmm26 = internal global i128 0
@xmm27 = internal global i128 0
@xmm28 = internal global i128 0
@xmm29 = internal global i128 0
@xmm30 = internal global i128 0
@xmm31 = internal global i128 0
@ymm0 = internal global i256 0
@ymm1 = internal global i256 0
@ymm2 = internal global i256 0
@ymm3 = internal global i256 0
@ymm4 = internal global i256 0
@ymm5 = internal global i256 0
@ymm6 = internal global i256 0
@ymm7 = internal global i256 0
@ymm8 = internal global i256 0
@ymm9 = internal global i256 0
@ymm10 = internal global i256 0
@ymm11 = internal global i256 0
@ymm12 = internal global i256 0
@ymm13 = internal global i256 0
@ymm14 = internal global i256 0
@ymm15 = internal global i256 0
@ymm16 = internal global i256 0
@ymm17 = internal global i256 0
@ymm18 = internal global i256 0
@ymm19 = internal global i256 0
@ymm20 = internal global i256 0
@ymm21 = internal global i256 0
@ymm22 = internal global i256 0
@ymm23 = internal global i256 0
@ymm24 = internal global i256 0
@ymm25 = internal global i256 0
@ymm26 = internal global i256 0
@ymm27 = internal global i256 0
@ymm28 = internal global i256 0
@ymm29 = internal global i256 0
@ymm30 = internal global i256 0
@ymm31 = internal global i256 0
@zmm0 = internal global i512 0
@zmm1 = internal global i512 0
@zmm2 = internal global i512 0
@zmm3 = internal global i512 0
@zmm4 = internal global i512 0
@zmm5 = internal global i512 0
@zmm6 = internal global i512 0
@zmm7 = internal global i512 0
@zmm8 = internal global i512 0
@zmm9 = internal global i512 0
@zmm10 = internal global i512 0
@zmm11 = internal global i512 0
@zmm12 = internal global i512 0
@zmm13 = internal global i512 0
@zmm14 = internal global i512 0
@zmm15 = internal global i512 0
@zmm16 = internal global i512 0
@zmm17 = internal global i512 0
@zmm18 = internal global i512 0
@zmm19 = internal global i512 0
@zmm20 = internal global i512 0
@zmm21 = internal global i512 0
@zmm22 = internal global i512 0
@zmm23 = internal global i512 0
@zmm24 = internal global i512 0
@zmm25 = internal global i512 0
@zmm26 = internal global i512 0
@zmm27 = internal global i512 0
@zmm28 = internal global i512 0
@zmm29 = internal global i512 0
@zmm30 = internal global i512 0
@zmm31 = internal global i512 0
@bnd0 = internal global i128 0
@bnd1 = internal global i128 0
@bnd2 = internal global i128 0
@bnd3 = internal global i128 0
@dr0 = internal global i64 0
@dr1 = internal global i64 0
@dr2 = internal global i64 0
@dr3 = internal global i64 0
@dr4 = internal global i64 0
@dr5 = internal global i64 0
@dr6 = internal global i64 0
@dr7 = internal global i64 0
@dr8 = internal global i64 0
@dr9 = internal global i64 0
@dr10 = internal global i64 0
@dr11 = internal global i64 0
@dr12 = internal global i64 0
@dr13 = internal global i64 0
@dr14 = internal global i64 0
@dr15 = internal global i64 0
@cr0 = internal global i64 0
@cr1 = internal global i64 0
@cr2 = internal global i64 0
@cr3 = internal global i64 0
@cr4 = internal global i64 0
@cr5 = internal global i64 0
@cr6 = internal global i64 0
@cr7 = internal global i64 0
@cr8 = internal global i64 0
@cr9 = internal global i64 0
@cr10 = internal global i64 0
@cr11 = internal global i64 0
@cr12 = internal global i64 0
@cr13 = internal global i64 0
@cr14 = internal global i64 0
@cr15 = internal global i64 0
@fpsw = internal global i64 0
@rax = internal global i64 0
@rcx = internal global i64 0
@rdx = internal global i64 0
@rbx = internal global i64 0
@rsp = internal global i64 0
@rbp = internal global i64 0
@rsi = internal global i64 0
@rdi = internal global i64 0
@r8 = internal global i64 0
@r9 = internal global i64 0
@r10 = internal global i64 0
@r11 = internal global i64 0
@r12 = internal global i64 0
@r13 = internal global i64 0
@r14 = internal global i64 0
@r15 = internal global i64 0
@rip = internal global i64 0
@riz = internal global i64 0

define i64 @_init() {
dec_label_pc_401000:

; 0x401000
  store volatile i64 4198400, i64* @_asm_program_counter

; 0x401004
  store volatile i64 4198404, i64* @_asm_program_counter
  %0 = load i64, i64* @rsp
  %1 = sub i64 %0, 8
  %2 = and i64 %0, 15
  %3 = sub i64 %2, 8
  %4 = icmp ugt i64 %3, 15
  %5 = icmp ult i64 %0, 8
  %6 = xor i64 %0, 8
  %7 = xor i64 %0, %1
  %8 = and i64 %6, %7
  %9 = icmp slt i64 %8, 0
  store i1 %4, i1* @az
  store i1 %5, i1* @cf
  store i1 %9, i1* @of
  %10 = icmp eq i64 %1, 0
  store i1 %10, i1* @zf
  %11 = icmp slt i64 %1, 0
  store i1 %11, i1* @sf
  %12 = trunc i64 %1 to i8
  %13 = call i8 @llvm.ctpop.i8(i8 %12)
  %14 = and i8 %13, 1
  %15 = icmp eq i8 %14, 0
  store i1 %15, i1* @pf
  store i64 %1, i64* @rsp

; 0x401008
  store volatile i64 4198408, i64* @_asm_program_counter
  %16 = load i64, i64* inttoptr (i64 4210672 to i64*)
  store i64 %16, i64* @rax

; 0x40100f
  store volatile i64 4198415, i64* @_asm_program_counter
  %17 = load i64, i64* @rax
  store i1 false, i1* @az
  store i1 false, i1* @cf
  store i1 false, i1* @of
  %18 = icmp eq i64 %17, 0
  store i1 %18, i1* @zf
  %19 = icmp slt i64 %17, 0
  store i1 %19, i1* @sf
  %20 = trunc i64 %17 to i8
  %21 = call i8 @llvm.ctpop.i8(i8 %20)
  %22 = and i8 %21, 1
  %23 = icmp eq i8 %22, 0
  store i1 %23, i1* @pf

; 0x401012
  store volatile i64 4198418, i64* @_asm_program_counter
  %24 = load i1, i1* @zf
  br i1 %24, label %dec_label_pc_401016, label %dec_label_pc_401014

dec_label_pc_401014:                              ; preds = %dec_label_pc_401000

; 0x401014
  store volatile i64 4198420, i64* @_asm_program_counter
  %25 = call i64 @__gmon_start__()
  store i64 %25, i64* @rax
  br label %dec_label_pc_401016

dec_label_pc_401016:                              ; preds = %dec_label_pc_401014, %dec_label_pc_401000

; 0x401016
  store volatile i64 4198422, i64* @_asm_program_counter
  %26 = load i64, i64* @rsp
  %27 = add i64 %26, 8
  %28 = and i64 %26, 15
  %29 = add i64 %28, 8
  %30 = icmp ugt i64 %29, 15
  %31 = icmp ult i64 %27, %26
  %32 = xor i64 %26, %27
  %33 = xor i64 8, %27
  %34 = and i64 %32, %33
  %35 = icmp slt i64 %34, 0
  store i1 %30, i1* @az
  store i1 %31, i1* @cf
  store i1 %35, i1* @of
  %36 = icmp eq i64 %27, 0
  store i1 %36, i1* @zf
  %37 = icmp slt i64 %27, 0
  store i1 %37, i1* @sf
  %38 = trunc i64 %27 to i8
  %39 = call i8 @llvm.ctpop.i8(i8 %38)
  %40 = and i8 %39, 1
  %41 = icmp eq i8 %40, 0
  store i1 %41, i1* @pf
  store i64 %27, i64* @rsp

; 0x40101a
  store volatile i64 4198426, i64* @_asm_program_counter
  ret i64 undef
}

define i64 @function_401030() {
dec_label_pc_401030:

; 0x401030
  store volatile i64 4198448, i64* @_asm_program_counter
  %0 = call i64 @printf()
  store i64 %0, i64* @rax
  ret i64 undef
}

define i64 @_start() {
dec_label_pc_401040:

; 0x401040
  store volatile i64 4198464, i64* @_asm_program_counter

; 0x401044
  store volatile i64 4198468, i64* @_asm_program_counter
  %0 = load i64, i64* @rbp
  %1 = trunc i64 %0 to i32
  %2 = load i64, i64* @rbp
  %3 = trunc i64 %2 to i32
  %4 = xor i32 %1, %3
  store i1 false, i1* @az
  store i1 false, i1* @cf
  store i1 false, i1* @of
  %5 = icmp eq i32 %4, 0
  store i1 %5, i1* @zf
  %6 = icmp slt i32 %4, 0
  store i1 %6, i1* @sf
  %7 = trunc i32 %4 to i8
  %8 = call i8 @llvm.ctpop.i8(i8 %7)
  %9 = and i8 %8, 1
  %10 = icmp eq i8 %9, 0
  store i1 %10, i1* @pf
  %11 = zext i32 %4 to i64
  store i64 %11, i64* @rbp

; 0x401046
  store volatile i64 4198470, i64* @_asm_program_counter
  %12 = load i64, i64* @rdx
  store i64 %12, i64* @r9

; 0x401049
  store volatile i64 4198473, i64* @_asm_program_counter
  %13 = load i64, i64* @rsp
  %14 = inttoptr i64 %13 to i64*
  %15 = load i64, i64* %14
  store i64 %15, i64* @rsi
  %16 = add i64 %13, 8
  store i64 %16, i64* @rsp

; 0x40104a
  store volatile i64 4198474, i64* @_asm_program_counter
  %17 = load i64, i64* @rsp
  store i64 %17, i64* @rdx

; 0x40104d
  store volatile i64 4198477, i64* @_asm_program_counter
  %18 = load i64, i64* @rsp
  %19 = and i64 %18, -16
  store i1 false, i1* @az
  store i1 false, i1* @cf
  store i1 false, i1* @of
  %20 = icmp eq i64 %19, 0
  store i1 %20, i1* @zf
  %21 = icmp slt i64 %19, 0
  store i1 %21, i1* @sf
  %22 = trunc i64 %19 to i8
  %23 = call i8 @llvm.ctpop.i8(i8 %22)
  %24 = and i8 %23, 1
  %25 = icmp eq i8 %24, 0
  store i1 %25, i1* @pf
  store i64 %19, i64* @rsp

; 0x401051
  store volatile i64 4198481, i64* @_asm_program_counter
  %26 = load i64, i64* @rax
  %27 = load i64, i64* @rsp
  %28 = sub i64 %27, 8
  %29 = inttoptr i64 %28 to i64*
  store i64 %26, i64* %29
  store i64 %28, i64* @rsp

; 0x401052
  store volatile i64 4198482, i64* @_asm_program_counter
  %30 = load i64, i64* @rsp
  %31 = load i64, i64* @rsp
  %32 = sub i64 %31, 8
  %33 = inttoptr i64 %32 to i64*
  store i64 %30, i64* %33
  store i64 %32, i64* @rsp

; 0x401053
  store volatile i64 4198483, i64* @_asm_program_counter
  %34 = load i64, i64* @r8
  %35 = trunc i64 %34 to i32
  %36 = load i64, i64* @r8
  %37 = trunc i64 %36 to i32
  %38 = xor i32 %35, %37
  store i1 false, i1* @az
  store i1 false, i1* @cf
  store i1 false, i1* @of
  %39 = icmp eq i32 %38, 0
  store i1 %39, i1* @zf
  %40 = icmp slt i32 %38, 0
  store i1 %40, i1* @sf
  %41 = trunc i32 %38 to i8
  %42 = call i8 @llvm.ctpop.i8(i8 %41)
  %43 = and i8 %42, 1
  %44 = icmp eq i8 %43, 0
  store i1 %44, i1* @pf
  %45 = zext i32 %38 to i64
  store i64 %45, i64* @r8

; 0x401056
  store volatile i64 4198486, i64* @_asm_program_counter
  %46 = load i64, i64* @rcx
  %47 = trunc i64 %46 to i32
  %48 = load i64, i64* @rcx
  %49 = trunc i64 %48 to i32
  %50 = xor i32 %47, %49
  store i1 false, i1* @az
  store i1 false, i1* @cf
  store i1 false, i1* @of
  %51 = icmp eq i32 %50, 0
  store i1 %51, i1* @zf
  %52 = icmp slt i32 %50, 0
  store i1 %52, i1* @sf
  %53 = trunc i32 %50 to i8
  %54 = call i8 @llvm.ctpop.i8(i8 %53)
  %55 = and i8 %54, 1
  %56 = icmp eq i8 %55, 0
  store i1 %56, i1* @pf
  %57 = zext i32 %50 to i64
  store i64 %57, i64* @rcx

; 0x401058
  store volatile i64 4198488, i64* @_asm_program_counter
  store i64 4198721, i64* @rdi

; 0x40105f
  store volatile i64 4198495, i64* @_asm_program_counter
  %58 = call i64 @__libc_start_main()
  store i64 %58, i64* @rax

; 0x401065
  store volatile i64 4198501, i64* @_asm_program_counter
  call void @__asm_hlt()
  unreachable
}

define i64 @_dl_relocate_static_pie() {
dec_label_pc_401070:

; 0x401070
  store volatile i64 4198512, i64* @_asm_program_counter

; 0x401074
  store volatile i64 4198516, i64* @_asm_program_counter
  ret i64 undef
}

define i64 @deregister_tm_clones() {
dec_label_pc_401080:

; 0x401080
  store volatile i64 4198528, i64* @_asm_program_counter
  store i64 4210728, i64* @rdi

; 0x401087
  store volatile i64 4198535, i64* @_asm_program_counter
  store i64 4210728, i64* @rax

; 0x40108e
  store volatile i64 4198542, i64* @_asm_program_counter
  %0 = load i64, i64* @rax
  %1 = load i64, i64* @rdi
  %2 = sub i64 %0, %1
  %3 = and i64 %0, 15
  %4 = and i64 %1, 15
  %5 = sub i64 %3, %4
  %6 = icmp ugt i64 %5, 15
  %7 = icmp ult i64 %0, %1
  %8 = xor i64 %0, %1
  %9 = xor i64 %0, %2
  %10 = and i64 %8, %9
  %11 = icmp slt i64 %10, 0
  store i1 %6, i1* @az
  store i1 %7, i1* @cf
  store i1 %11, i1* @of
  %12 = icmp eq i64 %2, 0
  store i1 %12, i1* @zf
  %13 = icmp slt i64 %2, 0
  store i1 %13, i1* @sf
  %14 = trunc i64 %2 to i8
  %15 = call i8 @llvm.ctpop.i8(i8 %14)
  %16 = and i8 %15, 1
  %17 = icmp eq i8 %16, 0
  store i1 %17, i1* @pf

; 0x401091
  store volatile i64 4198545, i64* @_asm_program_counter
  %18 = load i1, i1* @zf
  br i1 %18, label %dec_label_pc_4010a8, label %dec_label_pc_401093

dec_label_pc_401093:                              ; preds = %dec_label_pc_401080

; 0x401093
  store volatile i64 4198547, i64* @_asm_program_counter
  %19 = load i64, i64* inttoptr (i64 4210664 to i64*)
  store i64 %19, i64* @rax

; 0x40109a
  store volatile i64 4198554, i64* @_asm_program_counter
  %20 = load i64, i64* @rax
  store i1 false, i1* @az
  store i1 false, i1* @cf
  store i1 false, i1* @of
  %21 = icmp eq i64 %20, 0
  store i1 %21, i1* @zf
  %22 = icmp slt i64 %20, 0
  store i1 %22, i1* @sf
  %23 = trunc i64 %20 to i8
  %24 = call i8 @llvm.ctpop.i8(i8 %23)
  %25 = and i8 %24, 1
  %26 = icmp eq i8 %25, 0
  store i1 %26, i1* @pf

; 0x40109d
  store volatile i64 4198557, i64* @_asm_program_counter
  %27 = load i1, i1* @zf
  br i1 %27, label %dec_label_pc_4010a8, label %dec_label_pc_40109f

dec_label_pc_40109f:                              ; preds = %dec_label_pc_401093

; 0x40109f
  store volatile i64 4198559, i64* @_asm_program_counter
  %28 = call i64 @_ITM_deregisterTMCloneTable()
  store i64 %28, i64* @rax
  ret i64 undef

dec_label_pc_4010a8:                              ; preds = %dec_label_pc_401093, %dec_label_pc_401080

; 0x4010a8
  store volatile i64 4198568, i64* @_asm_program_counter
  ret i64 undef
}

define i64 @register_tm_clones() {
dec_label_pc_4010b0:

; 0x4010b0
  store volatile i64 4198576, i64* @_asm_program_counter
  store i64 4210728, i64* @rdi

; 0x4010b7
  store volatile i64 4198583, i64* @_asm_program_counter
  store i64 4210728, i64* @rsi

; 0x4010be
  store volatile i64 4198590, i64* @_asm_program_counter
  %0 = load i64, i64* @rsi
  %1 = load i64, i64* @rdi
  %2 = sub i64 %0, %1
  %3 = and i64 %0, 15
  %4 = and i64 %1, 15
  %5 = sub i64 %3, %4
  %6 = icmp ugt i64 %5, 15
  %7 = icmp ult i64 %0, %1
  %8 = xor i64 %0, %1
  %9 = xor i64 %0, %2
  %10 = and i64 %8, %9
  %11 = icmp slt i64 %10, 0
  store i1 %6, i1* @az
  store i1 %7, i1* @cf
  store i1 %11, i1* @of
  %12 = icmp eq i64 %2, 0
  store i1 %12, i1* @zf
  %13 = icmp slt i64 %2, 0
  store i1 %13, i1* @sf
  %14 = trunc i64 %2 to i8
  %15 = call i8 @llvm.ctpop.i8(i8 %14)
  %16 = and i8 %15, 1
  %17 = icmp eq i8 %16, 0
  store i1 %17, i1* @pf
  store i64 %2, i64* @rsi

; 0x4010c1
  store volatile i64 4198593, i64* @_asm_program_counter
  %18 = load i64, i64* @rsi
  store i64 %18, i64* @rax

; 0x4010c4
  store volatile i64 4198596, i64* @_asm_program_counter
  %19 = load i64, i64* @rsi
  %20 = load i1, i1* @of
  %21 = lshr i64 %19, 63
  %22 = icmp eq i64 %21, 0
  store i1 %22, i1* @zf
  %23 = icmp slt i64 %21, 0
  store i1 %23, i1* @sf
  %24 = trunc i64 %21 to i8
  %25 = call i8 @llvm.ctpop.i8(i8 %24)
  %26 = and i8 %25, 1
  %27 = icmp eq i8 %26, 0
  store i1 %27, i1* @pf
  store i64 %21, i64* @rsi
  %28 = and i64 4611686018427387904, %19
  %29 = icmp ne i64 %28, 0
  store i1 %29, i1* @cf
  %30 = icmp slt i64 %19, 0
  %31 = select i1 false, i1 %30, i1 %20
  store i1 %31, i1* @of

; 0x4010c8
  store volatile i64 4198600, i64* @_asm_program_counter
  %32 = load i64, i64* @rax
  %33 = load i1, i1* @of
  %34 = ashr i64 %32, 3
  %35 = icmp eq i64 %34, 0
  store i1 %35, i1* @zf
  %36 = icmp slt i64 %34, 0
  store i1 %36, i1* @sf
  %37 = trunc i64 %34 to i8
  %38 = call i8 @llvm.ctpop.i8(i8 %37)
  %39 = and i8 %38, 1
  %40 = icmp eq i8 %39, 0
  store i1 %40, i1* @pf
  store i64 %34, i64* @rax
  %41 = and i64 4, %32
  %42 = icmp ne i64 %41, 0
  store i1 %42, i1* @cf
  %43 = select i1 false, i1 false, i1 %33
  store i1 %43, i1* @of

; 0x4010cc
  store volatile i64 4198604, i64* @_asm_program_counter
  %44 = load i64, i64* @rsi
  %45 = load i64, i64* @rax
  %46 = add i64 %44, %45
  %47 = and i64 %44, 15
  %48 = and i64 %45, 15
  %49 = add i64 %47, %48
  %50 = icmp ugt i64 %49, 15
  %51 = icmp ult i64 %46, %44
  %52 = xor i64 %44, %46
  %53 = xor i64 %45, %46
  %54 = and i64 %52, %53
  %55 = icmp slt i64 %54, 0
  store i1 %50, i1* @az
  store i1 %51, i1* @cf
  store i1 %55, i1* @of
  %56 = icmp eq i64 %46, 0
  store i1 %56, i1* @zf
  %57 = icmp slt i64 %46, 0
  store i1 %57, i1* @sf
  %58 = trunc i64 %46 to i8
  %59 = call i8 @llvm.ctpop.i8(i8 %58)
  %60 = and i8 %59, 1
  %61 = icmp eq i8 %60, 0
  store i1 %61, i1* @pf
  store i64 %46, i64* @rsi

; 0x4010cf
  store volatile i64 4198607, i64* @_asm_program_counter
  %62 = load i64, i64* @rsi
  %63 = load i1, i1* @of
  %64 = ashr i64 %62, 1
  %65 = icmp eq i64 %64, 0
  store i1 %65, i1* @zf
  %66 = icmp slt i64 %64, 0
  store i1 %66, i1* @sf
  %67 = trunc i64 %64 to i8
  %68 = call i8 @llvm.ctpop.i8(i8 %67)
  %69 = and i8 %68, 1
  %70 = icmp eq i8 %69, 0
  store i1 %70, i1* @pf
  store i64 %64, i64* @rsi
  %71 = and i64 1, %62
  %72 = icmp ne i64 %71, 0
  store i1 %72, i1* @cf
  %73 = select i1 true, i1 false, i1 %63
  store i1 %73, i1* @of

; 0x4010d2
  store volatile i64 4198610, i64* @_asm_program_counter
  %74 = load i1, i1* @zf
  br i1 %74, label %dec_label_pc_4010e8, label %dec_label_pc_4010d4

dec_label_pc_4010d4:                              ; preds = %dec_label_pc_4010b0

; 0x4010d4
  store volatile i64 4198612, i64* @_asm_program_counter
  %75 = load i64, i64* inttoptr (i64 4210680 to i64*)
  store i64 %75, i64* @rax

; 0x4010db
  store volatile i64 4198619, i64* @_asm_program_counter
  %76 = load i64, i64* @rax
  store i1 false, i1* @az
  store i1 false, i1* @cf
  store i1 false, i1* @of
  %77 = icmp eq i64 %76, 0
  store i1 %77, i1* @zf
  %78 = icmp slt i64 %76, 0
  store i1 %78, i1* @sf
  %79 = trunc i64 %76 to i8
  %80 = call i8 @llvm.ctpop.i8(i8 %79)
  %81 = and i8 %80, 1
  %82 = icmp eq i8 %81, 0
  store i1 %82, i1* @pf

; 0x4010de
  store volatile i64 4198622, i64* @_asm_program_counter
  %83 = load i1, i1* @zf
  br i1 %83, label %dec_label_pc_4010e8, label %dec_label_pc_4010e0

dec_label_pc_4010e0:                              ; preds = %dec_label_pc_4010d4

; 0x4010e0
  store volatile i64 4198624, i64* @_asm_program_counter
  %84 = call i64 @_ITM_registerTMCloneTable()
  store i64 %84, i64* @rax
  ret i64 undef

dec_label_pc_4010e8:                              ; preds = %dec_label_pc_4010d4, %dec_label_pc_4010b0

; 0x4010e8
  store volatile i64 4198632, i64* @_asm_program_counter
  ret i64 undef
}

define i64 @__do_global_dtors_aux() {
dec_label_pc_4010f0:

; 0x4010f0
  store volatile i64 4198640, i64* @_asm_program_counter

; 0x4010f4
  store volatile i64 4198644, i64* @_asm_program_counter
  %0 = load i8, i8* inttoptr (i64 4210724 to i8*)
  %1 = and i8 %0, 15
  %2 = icmp ugt i8 %1, 15
  %3 = icmp ult i8 %0, 0
  %4 = xor i8 %0, 0
  %5 = and i8 %4, 0
  %6 = icmp slt i8 %5, 0
  store i1 %2, i1* @az
  store i1 %3, i1* @cf
  store i1 %6, i1* @of
  %7 = icmp eq i8 %0, 0
  store i1 %7, i1* @zf
  %8 = icmp slt i8 %0, 0
  store i1 %8, i1* @sf
  %9 = call i8 @llvm.ctpop.i8(i8 %0)
  %10 = and i8 %9, 1
  %11 = icmp eq i8 %10, 0
  store i1 %11, i1* @pf

; 0x4010fb
  store volatile i64 4198651, i64* @_asm_program_counter
  %12 = load i1, i1* @zf
  %13 = icmp eq i1 %12, false
  br i1 %13, label %dec_label_pc_401110, label %dec_label_pc_4010fd

dec_label_pc_4010fd:                              ; preds = %dec_label_pc_4010f0

; 0x4010fd
  store volatile i64 4198653, i64* @_asm_program_counter
  %14 = load i64, i64* @rbp
  %15 = load i64, i64* @rsp
  %16 = sub i64 %15, 8
  %17 = inttoptr i64 %16 to i64*
  store i64 %14, i64* %17
  store i64 %16, i64* @rsp

; 0x4010fe
  store volatile i64 4198654, i64* @_asm_program_counter
  %18 = load i64, i64* @rsp
  store i64 %18, i64* @rbp

; 0x401101
  store volatile i64 4198657, i64* @_asm_program_counter
  %19 = call i64 @deregister_tm_clones()
  store i64 %19, i64* @rax

; 0x401106
  store volatile i64 4198662, i64* @_asm_program_counter
  store i8 1, i8* inttoptr (i64 4210724 to i8*)

; 0x40110d
  store volatile i64 4198669, i64* @_asm_program_counter
  %20 = load i64, i64* @rsp
  %21 = inttoptr i64 %20 to i64*
  %22 = load i64, i64* %21
  store i64 %22, i64* @rbp
  %23 = add i64 %20, 8
  store i64 %23, i64* @rsp

; 0x40110e
  store volatile i64 4198670, i64* @_asm_program_counter
  ret i64 undef

dec_label_pc_401110:                              ; preds = %dec_label_pc_4010f0

; 0x401110
  store volatile i64 4198672, i64* @_asm_program_counter
  ret i64 undef
}

define i64 @frame_dummy() {
dec_label_pc_401120:

; 0x401120
  store volatile i64 4198688, i64* @_asm_program_counter

; 0x401124
  store volatile i64 4198692, i64* @_asm_program_counter
  %0 = call i64 @register_tm_clones()
  store i64 %0, i64* @rax
  ret i64 undef
}

define i64 @add() {
dec_label_pc_401126:

; 0x401126
  store volatile i64 4198694, i64* @_asm_program_counter
  %0 = load i64, i64* @rbp
  %1 = load i64, i64* @rsp
  %2 = sub i64 %1, 8
  %3 = inttoptr i64 %2 to i64*
  store i64 %0, i64* %3
  store i64 %2, i64* @rsp

; 0x401127
  store volatile i64 4198695, i64* @_asm_program_counter
  %4 = load i64, i64* @rsp
  store i64 %4, i64* @rbp

; 0x40112a
  store volatile i64 4198698, i64* @_asm_program_counter
  %5 = load i64, i64* @rdi
  %6 = load i64, i64* @rbp
  %7 = add i64 %6, -8
  %8 = inttoptr i64 %7 to i64*
  store i64 %5, i64* %8

; 0x40112e
  store volatile i64 4198702, i64* @_asm_program_counter
  %9 = load i64, i64* @rsi
  %10 = trunc i64 %9 to i32
  %11 = zext i32 %10 to i64
  store i64 %11, i64* @rax

; 0x401130
  store volatile i64 4198704, i64* @_asm_program_counter
  %12 = load i64, i64* @rax
  %13 = trunc i64 %12 to i8
  %14 = load i64, i64* @rbp
  %15 = add i64 %14, -12
  %16 = inttoptr i64 %15 to i8*
  store i8 %13, i8* %16

; 0x401133
  store volatile i64 4198707, i64* @_asm_program_counter
  %17 = load i64, i64* @rbp
  %18 = add i64 %17, -8
  %19 = inttoptr i64 %18 to i64*
  %20 = load i64, i64* %19
  store i64 %20, i64* @rax

; 0x401137
  store volatile i64 4198711, i64* @_asm_program_counter
  %21 = load i64, i64* @rax
  %22 = inttoptr i64 %21 to i32*
  %23 = load i32, i32* %22
  %24 = zext i32 %23 to i64
  store i64 %24, i64* @rdx

; 0x401139
  store volatile i64 4198713, i64* @_asm_program_counter
  %25 = load i64, i64* @rbp
  %26 = add i64 %25, -12
  %27 = inttoptr i64 %26 to i8*
  %28 = load i8, i8* %27
  %29 = sext i8 %28 to i64
  store i64 %29, i64* @rax

; 0x40113d
  store volatile i64 4198717, i64* @_asm_program_counter
  %30 = load i64, i64* @rax
  %31 = trunc i64 %30 to i32
  %32 = load i64, i64* @rdx
  %33 = trunc i64 %32 to i32
  %34 = add i32 %31, %33
  %35 = and i32 %31, 15
  %36 = and i32 %33, 15
  %37 = add i32 %35, %36
  %38 = icmp ugt i32 %37, 15
  %39 = icmp ult i32 %34, %31
  %40 = xor i32 %31, %34
  %41 = xor i32 %33, %34
  %42 = and i32 %40, %41
  %43 = icmp slt i32 %42, 0
  store i1 %38, i1* @az
  store i1 %39, i1* @cf
  store i1 %43, i1* @of
  %44 = icmp eq i32 %34, 0
  store i1 %44, i1* @zf
  %45 = icmp slt i32 %34, 0
  store i1 %45, i1* @sf
  %46 = trunc i32 %34 to i8
  %47 = call i8 @llvm.ctpop.i8(i8 %46)
  %48 = and i8 %47, 1
  %49 = icmp eq i8 %48, 0
  store i1 %49, i1* @pf
  %50 = zext i32 %34 to i64
  store i64 %50, i64* @rax

; 0x40113f
  store volatile i64 4198719, i64* @_asm_program_counter
  %51 = load i64, i64* @rsp
  %52 = inttoptr i64 %51 to i64*
  %53 = load i64, i64* %52
  store i64 %53, i64* @rbp
  %54 = add i64 %51, 8
  store i64 %54, i64* @rsp

; 0x401140
  store volatile i64 4198720, i64* @_asm_program_counter
  ret i64 undef
}

define i64 @main() {
dec_label_pc_401141:

; 0x401141
  store volatile i64 4198721, i64* @_asm_program_counter
  %0 = load i64, i64* @rbp
  %1 = load i64, i64* @rsp
  %2 = sub i64 %1, 8
  %3 = inttoptr i64 %2 to i64*
  store i64 %0, i64* %3
  store i64 %2, i64* @rsp

; 0x401142
  store volatile i64 4198722, i64* @_asm_program_counter
  %4 = load i64, i64* @rsp
  store i64 %4, i64* @rbp

; 0x401145
  store volatile i64 4198725, i64* @_asm_program_counter
  %5 = load i64, i64* @rsp
  %6 = sub i64 %5, 32
  %7 = and i64 %5, 15
  %8 = icmp ugt i64 %7, 15
  %9 = icmp ult i64 %5, 32
  %10 = xor i64 %5, 32
  %11 = xor i64 %5, %6
  %12 = and i64 %10, %11
  %13 = icmp slt i64 %12, 0
  store i1 %8, i1* @az
  store i1 %9, i1* @cf
  store i1 %13, i1* @of
  %14 = icmp eq i64 %6, 0
  store i1 %14, i1* @zf
  %15 = icmp slt i64 %6, 0
  store i1 %15, i1* @sf
  %16 = trunc i64 %6 to i8
  %17 = call i8 @llvm.ctpop.i8(i8 %16)
  %18 = and i8 %17, 1
  %19 = icmp eq i8 %18, 0
  store i1 %19, i1* @pf
  store i64 %6, i64* @rsp

; 0x401149
  store volatile i64 4198729, i64* @_asm_program_counter
  %20 = load i64, i64* @rbp
  %21 = add i64 %20, -24
  %22 = inttoptr i64 %21 to i32*
  store i32 1, i32* %22

; 0x401150
  store volatile i64 4198736, i64* @_asm_program_counter
  %23 = load i64, i64* @rbp
  %24 = add i64 %23, -1
  %25 = inttoptr i64 %24 to i8*
  store i8 2, i8* %25

; 0x401154
  store volatile i64 4198740, i64* @_asm_program_counter
  %26 = load i64, i64* @rbp
  %27 = add i64 %26, -1
  %28 = inttoptr i64 %27 to i8*
  %29 = load i8, i8* %28
  %30 = sext i8 %29 to i64
  store i64 %30, i64* @rdx

; 0x401158
  store volatile i64 4198744, i64* @_asm_program_counter
  %31 = load i64, i64* @rbp
  %32 = add i64 %31, -24
  store i64 %32, i64* @rax

; 0x40115c
  store volatile i64 4198748, i64* @_asm_program_counter
  %33 = load i64, i64* @rdx
  %34 = trunc i64 %33 to i32
  %35 = zext i32 %34 to i64
  store i64 %35, i64* @rsi

; 0x40115e
  store volatile i64 4198750, i64* @_asm_program_counter
  %36 = load i64, i64* @rax
  store i64 %36, i64* @rdi

; 0x401161
  store volatile i64 4198753, i64* @_asm_program_counter
  %37 = call i64 @add()
  store i64 %37, i64* @rax

; 0x401166
  store volatile i64 4198758, i64* @_asm_program_counter
  %38 = load i64, i64* @rax
  %39 = trunc i64 %38 to i32
  %40 = load i64, i64* @rbp
  %41 = add i64 %40, -8
  %42 = inttoptr i64 %41 to i32*
  store i32 %39, i32* %42

; 0x401169
  store volatile i64 4198761, i64* @_asm_program_counter
  %43 = load i64, i64* @rbp
  %44 = add i64 %43, -24
  store i64 %44, i64* @rax

; 0x40116d
  store volatile i64 4198765, i64* @_asm_program_counter
  %45 = load i64, i64* @rax
  %46 = load i64, i64* @rbp
  %47 = add i64 %46, -16
  %48 = inttoptr i64 %47 to i64*
  store i64 %45, i64* %48

; 0x401171
  store volatile i64 4198769, i64* @_asm_program_counter
  %49 = load i64, i64* @rbp
  %50 = add i64 %49, -1
  %51 = inttoptr i64 %50 to i8*
  %52 = load i8, i8* %51
  %53 = sext i8 %52 to i64
  store i64 %53, i64* @rdx

; 0x401175
  store volatile i64 4198773, i64* @_asm_program_counter
  %54 = load i64, i64* @rbp
  %55 = add i64 %54, -16
  %56 = inttoptr i64 %55 to i64*
  %57 = load i64, i64* %56
  store i64 %57, i64* @rax

; 0x401179
  store volatile i64 4198777, i64* @_asm_program_counter
  %58 = load i64, i64* @rdx
  %59 = trunc i64 %58 to i32
  %60 = zext i32 %59 to i64
  store i64 %60, i64* @rsi

; 0x40117b
  store volatile i64 4198779, i64* @_asm_program_counter
  %61 = load i64, i64* @rax
  store i64 %61, i64* @rdi

; 0x40117e
  store volatile i64 4198782, i64* @_asm_program_counter
  %62 = call i64 @add()
  store i64 %62, i64* @rax

; 0x401183
  store volatile i64 4198787, i64* @_asm_program_counter
  %63 = load i64, i64* @rax
  %64 = trunc i64 %63 to i32
  %65 = load i64, i64* @rbp
  %66 = add i64 %65, -20
  %67 = inttoptr i64 %66 to i32*
  store i32 %64, i32* %67

; 0x401186
  store volatile i64 4198790, i64* @_asm_program_counter
  %68 = load i64, i64* @rbp
  %69 = add i64 %68, -8
  %70 = inttoptr i64 %69 to i32*
  %71 = load i32, i32* %70
  %72 = zext i32 %71 to i64
  store i64 %72, i64* @rax

; 0x401189
  store volatile i64 4198793, i64* @_asm_program_counter
  %73 = load i64, i64* @rax
  %74 = trunc i64 %73 to i32
  %75 = zext i32 %74 to i64
  store i64 %75, i64* @rsi

; 0x40118b
  store volatile i64 4198795, i64* @_asm_program_counter
  store i64 4202512, i64* @rdi

; 0x401190
  store volatile i64 4198800, i64* @_asm_program_counter
  store i64 0, i64* @rax

; 0x401195
  store volatile i64 4198805, i64* @_asm_program_counter
  %76 = call i64 @function_401030()
  store i64 %76, i64* @rax

; 0x40119a
  store volatile i64 4198810, i64* @_asm_program_counter
  store i64 0, i64* @rax

; 0x40119f
  store volatile i64 4198815, i64* @_asm_program_counter
  %77 = load i64, i64* @rbp
  %78 = inttoptr i64 %77 to i64*
  %79 = load i64, i64* %78
  %80 = add i64 %77, 8
  store i64 %79, i64* @rbp
  store i64 %80, i64* @rsp

; 0x4011a0
  store volatile i64 4198816, i64* @_asm_program_counter
  ret i64 undef
}

define i64 @_fini() {
dec_label_pc_4011a4:

; 0x4011a4
  store volatile i64 4198820, i64* @_asm_program_counter

; 0x4011a8
  store volatile i64 4198824, i64* @_asm_program_counter
  %0 = load i64, i64* @rsp
  %1 = sub i64 %0, 8
  %2 = and i64 %0, 15
  %3 = sub i64 %2, 8
  %4 = icmp ugt i64 %3, 15
  %5 = icmp ult i64 %0, 8
  %6 = xor i64 %0, 8
  %7 = xor i64 %0, %1
  %8 = and i64 %6, %7
  %9 = icmp slt i64 %8, 0
  store i1 %4, i1* @az
  store i1 %5, i1* @cf
  store i1 %9, i1* @of
  %10 = icmp eq i64 %1, 0
  store i1 %10, i1* @zf
  %11 = icmp slt i64 %1, 0
  store i1 %11, i1* @sf
  %12 = trunc i64 %1 to i8
  %13 = call i8 @llvm.ctpop.i8(i8 %12)
  %14 = and i8 %13, 1
  %15 = icmp eq i8 %14, 0
  store i1 %15, i1* @pf
  store i64 %1, i64* @rsp

; 0x4011ac
  store volatile i64 4198828, i64* @_asm_program_counter
  %16 = load i64, i64* @rsp
  %17 = add i64 %16, 8
  %18 = and i64 %16, 15
  %19 = add i64 %18, 8
  %20 = icmp ugt i64 %19, 15
  %21 = icmp ult i64 %17, %16
  %22 = xor i64 %16, %17
  %23 = xor i64 8, %17
  %24 = and i64 %22, %23
  %25 = icmp slt i64 %24, 0
  store i1 %20, i1* @az
  store i1 %21, i1* @cf
  store i1 %25, i1* @of
  %26 = icmp eq i64 %17, 0
  store i1 %26, i1* @zf
  %27 = icmp slt i64 %17, 0
  store i1 %27, i1* @sf
  %28 = trunc i64 %17 to i8
  %29 = call i8 @llvm.ctpop.i8(i8 %28)
  %30 = and i8 %29, 1
  %31 = icmp eq i8 %30, 0
  store i1 %31, i1* @pf
  store i64 %17, i64* @rsp

; 0x4011b0
  store volatile i64 4198832, i64* @_asm_program_counter
  ret i64 undef
}

declare i64 @__libc_start_main()

declare i64 @_ITM_deregisterTMCloneTable()

declare i64 @__gmon_start__()

declare i64 @_ITM_registerTMCloneTable()

declare i64 @printf()

declare void @__pseudo_call(i64)

declare void @__pseudo_return(i64)

declare void @__pseudo_branch(i64)

declare void @__pseudo_cond_branch(i1, i64)

declare void @__frontend_reg_store.fpr(i3, x86_fp80)

declare x86_fp80 @__frontend_reg_load.fpr(i3)

; Function Attrs: nounwind readnone speculatable
declare i8 @llvm.ctpop.i8(i8) #0

declare void @__asm_hlt()

attributes #0 = { nounwind readnone speculatable }
*** IR Dump After Syscalls optimization ***
source_filename = "test"
target datalayout = "e-m:e-p:64:64-i64:64-f80:128-n8:16:32:64-S128"

@_asm_program_counter = internal global i64 0
@cf = internal global i1 false
@pf = internal global i1 false
@az = internal global i1 false
@zf = internal global i1 false
@sf = internal global i1 false
@tf = internal global i1 false
@if = internal global i1 false
@df = internal global i1 false
@of = internal global i1 false
@iopl = internal global i2 0
@nt = internal global i1 false
@rf = internal global i1 false
@vm = internal global i1 false
@ac = internal global i1 false
@vif = internal global i1 false
@vip = internal global i1 false
@id = internal global i1 false
@rflags = internal global i64 0
@ss = internal global i16 0
@cs = internal global i16 0
@ds = internal global i16 0
@es = internal global i16 0
@fs = internal global i16 0
@gs = internal global i16 0
@st0 = internal global x86_fp80 0xK00000000000000000000
@st1 = internal global x86_fp80 0xK00000000000000000000
@st2 = internal global x86_fp80 0xK00000000000000000000
@st3 = internal global x86_fp80 0xK00000000000000000000
@st4 = internal global x86_fp80 0xK00000000000000000000
@st5 = internal global x86_fp80 0xK00000000000000000000
@st6 = internal global x86_fp80 0xK00000000000000000000
@st7 = internal global x86_fp80 0xK00000000000000000000
@fpu_stat_IE = internal global i1 false
@fpu_stat_DE = internal global i1 false
@fpu_stat_ZE = internal global i1 false
@fpu_stat_OE = internal global i1 false
@fpu_stat_UE = internal global i1 false
@fpu_stat_PE = internal global i1 false
@fpu_stat_SF = internal global i1 false
@fpu_stat_ES = internal global i1 false
@fpu_stat_C0 = internal global i1 false
@fpu_stat_C1 = internal global i1 false
@fpu_stat_C2 = internal global i1 false
@fpu_stat_C3 = internal global i1 false
@fpu_stat_TOP = internal global i3 0
@fpu_stat_B = internal global i1 false
@fpu_control_IM = internal global i1 false
@fpu_control_DM = internal global i1 false
@fpu_control_ZM = internal global i1 false
@fpu_control_OM = internal global i1 false
@fpu_control_UM = internal global i1 false
@fpu_control_PM = internal global i1 false
@fpu_control_PC = internal global i2 0
@fpu_control_RC = internal global i2 0
@fpu_control_X = internal global i1 false
@fp0 = internal global double 0.000000e+00
@fp1 = internal global double 0.000000e+00
@fp2 = internal global double 0.000000e+00
@fp3 = internal global double 0.000000e+00
@fp4 = internal global double 0.000000e+00
@fp5 = internal global double 0.000000e+00
@fp6 = internal global double 0.000000e+00
@fp7 = internal global double 0.000000e+00
@k0 = internal global i64 0
@k1 = internal global i64 0
@k2 = internal global i64 0
@k3 = internal global i64 0
@k4 = internal global i64 0
@k5 = internal global i64 0
@k6 = internal global i64 0
@k7 = internal global i64 0
@mm0 = internal global i64 0
@mm1 = internal global i64 0
@mm2 = internal global i64 0
@mm3 = internal global i64 0
@mm4 = internal global i64 0
@mm5 = internal global i64 0
@mm6 = internal global i64 0
@mm7 = internal global i64 0
@xmm0 = internal global i128 0
@xmm1 = internal global i128 0
@xmm2 = internal global i128 0
@xmm3 = internal global i128 0
@xmm4 = internal global i128 0
@xmm5 = internal global i128 0
@xmm6 = internal global i128 0
@xmm7 = internal global i128 0
@xmm8 = internal global i128 0
@xmm9 = internal global i128 0
@xmm10 = internal global i128 0
@xmm11 = internal global i128 0
@xmm12 = internal global i128 0
@xmm13 = internal global i128 0
@xmm14 = internal global i128 0
@xmm15 = internal global i128 0
@xmm16 = internal global i128 0
@xmm17 = internal global i128 0
@xmm18 = internal global i128 0
@xmm19 = internal global i128 0
@xmm20 = internal global i128 0
@xmm21 = internal global i128 0
@xmm22 = internal global i128 0
@xmm23 = internal global i128 0
@xmm24 = internal global i128 0
@xmm25 = internal global i128 0
@xmm26 = internal global i128 0
@xmm27 = internal global i128 0
@xmm28 = internal global i128 0
@xmm29 = internal global i128 0
@xmm30 = internal global i128 0
@xmm31 = internal global i128 0
@ymm0 = internal global i256 0
@ymm1 = internal global i256 0
@ymm2 = internal global i256 0
@ymm3 = internal global i256 0
@ymm4 = internal global i256 0
@ymm5 = internal global i256 0
@ymm6 = internal global i256 0
@ymm7 = internal global i256 0
@ymm8 = internal global i256 0
@ymm9 = internal global i256 0
@ymm10 = internal global i256 0
@ymm11 = internal global i256 0
@ymm12 = internal global i256 0
@ymm13 = internal global i256 0
@ymm14 = internal global i256 0
@ymm15 = internal global i256 0
@ymm16 = internal global i256 0
@ymm17 = internal global i256 0
@ymm18 = internal global i256 0
@ymm19 = internal global i256 0
@ymm20 = internal global i256 0
@ymm21 = internal global i256 0
@ymm22 = internal global i256 0
@ymm23 = internal global i256 0
@ymm24 = internal global i256 0
@ymm25 = internal global i256 0
@ymm26 = internal global i256 0
@ymm27 = internal global i256 0
@ymm28 = internal global i256 0
@ymm29 = internal global i256 0
@ymm30 = internal global i256 0
@ymm31 = internal global i256 0
@zmm0 = internal global i512 0
@zmm1 = internal global i512 0
@zmm2 = internal global i512 0
@zmm3 = internal global i512 0
@zmm4 = internal global i512 0
@zmm5 = internal global i512 0
@zmm6 = internal global i512 0
@zmm7 = internal global i512 0
@zmm8 = internal global i512 0
@zmm9 = internal global i512 0
@zmm10 = internal global i512 0
@zmm11 = internal global i512 0
@zmm12 = internal global i512 0
@zmm13 = internal global i512 0
@zmm14 = internal global i512 0
@zmm15 = internal global i512 0
@zmm16 = internal global i512 0
@zmm17 = internal global i512 0
@zmm18 = internal global i512 0
@zmm19 = internal global i512 0
@zmm20 = internal global i512 0
@zmm21 = internal global i512 0
@zmm22 = internal global i512 0
@zmm23 = internal global i512 0
@zmm24 = internal global i512 0
@zmm25 = internal global i512 0
@zmm26 = internal global i512 0
@zmm27 = internal global i512 0
@zmm28 = internal global i512 0
@zmm29 = internal global i512 0
@zmm30 = internal global i512 0
@zmm31 = internal global i512 0
@bnd0 = internal global i128 0
@bnd1 = internal global i128 0
@bnd2 = internal global i128 0
@bnd3 = internal global i128 0
@dr0 = internal global i64 0
@dr1 = internal global i64 0
@dr2 = internal global i64 0
@dr3 = internal global i64 0
@dr4 = internal global i64 0
@dr5 = internal global i64 0
@dr6 = internal global i64 0
@dr7 = internal global i64 0
@dr8 = internal global i64 0
@dr9 = internal global i64 0
@dr10 = internal global i64 0
@dr11 = internal global i64 0
@dr12 = internal global i64 0
@dr13 = internal global i64 0
@dr14 = internal global i64 0
@dr15 = internal global i64 0
@cr0 = internal global i64 0
@cr1 = internal global i64 0
@cr2 = internal global i64 0
@cr3 = internal global i64 0
@cr4 = internal global i64 0
@cr5 = internal global i64 0
@cr6 = internal global i64 0
@cr7 = internal global i64 0
@cr8 = internal global i64 0
@cr9 = internal global i64 0
@cr10 = internal global i64 0
@cr11 = internal global i64 0
@cr12 = internal global i64 0
@cr13 = internal global i64 0
@cr14 = internal global i64 0
@cr15 = internal global i64 0
@fpsw = internal global i64 0
@rax = internal global i64 0
@rcx = internal global i64 0
@rdx = internal global i64 0
@rbx = internal global i64 0
@rsp = internal global i64 0
@rbp = internal global i64 0
@rsi = internal global i64 0
@rdi = internal global i64 0
@r8 = internal global i64 0
@r9 = internal global i64 0
@r10 = internal global i64 0
@r11 = internal global i64 0
@r12 = internal global i64 0
@r13 = internal global i64 0
@r14 = internal global i64 0
@r15 = internal global i64 0
@rip = internal global i64 0
@riz = internal global i64 0

define i64 @_init() {
dec_label_pc_401000:

; 0x401000
  store volatile i64 4198400, i64* @_asm_program_counter

; 0x401004
  store volatile i64 4198404, i64* @_asm_program_counter
  %0 = load i64, i64* @rsp
  %1 = sub i64 %0, 8
  %2 = and i64 %0, 15
  %3 = sub i64 %2, 8
  %4 = icmp ugt i64 %3, 15
  %5 = icmp ult i64 %0, 8
  %6 = xor i64 %0, 8
  %7 = xor i64 %0, %1
  %8 = and i64 %6, %7
  %9 = icmp slt i64 %8, 0
  store i1 %4, i1* @az
  store i1 %5, i1* @cf
  store i1 %9, i1* @of
  %10 = icmp eq i64 %1, 0
  store i1 %10, i1* @zf
  %11 = icmp slt i64 %1, 0
  store i1 %11, i1* @sf
  %12 = trunc i64 %1 to i8
  %13 = call i8 @llvm.ctpop.i8(i8 %12)
  %14 = and i8 %13, 1
  %15 = icmp eq i8 %14, 0
  store i1 %15, i1* @pf
  store i64 %1, i64* @rsp

; 0x401008
  store volatile i64 4198408, i64* @_asm_program_counter
  %16 = load i64, i64* inttoptr (i64 4210672 to i64*)
  store i64 %16, i64* @rax

; 0x40100f
  store volatile i64 4198415, i64* @_asm_program_counter
  %17 = load i64, i64* @rax
  store i1 false, i1* @az
  store i1 false, i1* @cf
  store i1 false, i1* @of
  %18 = icmp eq i64 %17, 0
  store i1 %18, i1* @zf
  %19 = icmp slt i64 %17, 0
  store i1 %19, i1* @sf
  %20 = trunc i64 %17 to i8
  %21 = call i8 @llvm.ctpop.i8(i8 %20)
  %22 = and i8 %21, 1
  %23 = icmp eq i8 %22, 0
  store i1 %23, i1* @pf

; 0x401012
  store volatile i64 4198418, i64* @_asm_program_counter
  %24 = load i1, i1* @zf
  br i1 %24, label %dec_label_pc_401016, label %dec_label_pc_401014

dec_label_pc_401014:                              ; preds = %dec_label_pc_401000

; 0x401014
  store volatile i64 4198420, i64* @_asm_program_counter
  %25 = call i64 @__gmon_start__()
  store i64 %25, i64* @rax
  br label %dec_label_pc_401016

dec_label_pc_401016:                              ; preds = %dec_label_pc_401014, %dec_label_pc_401000

; 0x401016
  store volatile i64 4198422, i64* @_asm_program_counter
  %26 = load i64, i64* @rsp
  %27 = add i64 %26, 8
  %28 = and i64 %26, 15
  %29 = add i64 %28, 8
  %30 = icmp ugt i64 %29, 15
  %31 = icmp ult i64 %27, %26
  %32 = xor i64 %26, %27
  %33 = xor i64 8, %27
  %34 = and i64 %32, %33
  %35 = icmp slt i64 %34, 0
  store i1 %30, i1* @az
  store i1 %31, i1* @cf
  store i1 %35, i1* @of
  %36 = icmp eq i64 %27, 0
  store i1 %36, i1* @zf
  %37 = icmp slt i64 %27, 0
  store i1 %37, i1* @sf
  %38 = trunc i64 %27 to i8
  %39 = call i8 @llvm.ctpop.i8(i8 %38)
  %40 = and i8 %39, 1
  %41 = icmp eq i8 %40, 0
  store i1 %41, i1* @pf
  store i64 %27, i64* @rsp

; 0x40101a
  store volatile i64 4198426, i64* @_asm_program_counter
  ret i64 undef
}

define i64 @function_401030() {
dec_label_pc_401030:

; 0x401030
  store volatile i64 4198448, i64* @_asm_program_counter
  %0 = call i64 @printf()
  store i64 %0, i64* @rax
  ret i64 undef
}

define i64 @_start() {
dec_label_pc_401040:

; 0x401040
  store volatile i64 4198464, i64* @_asm_program_counter

; 0x401044
  store volatile i64 4198468, i64* @_asm_program_counter
  %0 = load i64, i64* @rbp
  %1 = trunc i64 %0 to i32
  %2 = load i64, i64* @rbp
  %3 = trunc i64 %2 to i32
  %4 = xor i32 %1, %3
  store i1 false, i1* @az
  store i1 false, i1* @cf
  store i1 false, i1* @of
  %5 = icmp eq i32 %4, 0
  store i1 %5, i1* @zf
  %6 = icmp slt i32 %4, 0
  store i1 %6, i1* @sf
  %7 = trunc i32 %4 to i8
  %8 = call i8 @llvm.ctpop.i8(i8 %7)
  %9 = and i8 %8, 1
  %10 = icmp eq i8 %9, 0
  store i1 %10, i1* @pf
  %11 = zext i32 %4 to i64
  store i64 %11, i64* @rbp

; 0x401046
  store volatile i64 4198470, i64* @_asm_program_counter
  %12 = load i64, i64* @rdx
  store i64 %12, i64* @r9

; 0x401049
  store volatile i64 4198473, i64* @_asm_program_counter
  %13 = load i64, i64* @rsp
  %14 = inttoptr i64 %13 to i64*
  %15 = load i64, i64* %14
  store i64 %15, i64* @rsi
  %16 = add i64 %13, 8
  store i64 %16, i64* @rsp

; 0x40104a
  store volatile i64 4198474, i64* @_asm_program_counter
  %17 = load i64, i64* @rsp
  store i64 %17, i64* @rdx

; 0x40104d
  store volatile i64 4198477, i64* @_asm_program_counter
  %18 = load i64, i64* @rsp
  %19 = and i64 %18, -16
  store i1 false, i1* @az
  store i1 false, i1* @cf
  store i1 false, i1* @of
  %20 = icmp eq i64 %19, 0
  store i1 %20, i1* @zf
  %21 = icmp slt i64 %19, 0
  store i1 %21, i1* @sf
  %22 = trunc i64 %19 to i8
  %23 = call i8 @llvm.ctpop.i8(i8 %22)
  %24 = and i8 %23, 1
  %25 = icmp eq i8 %24, 0
  store i1 %25, i1* @pf
  store i64 %19, i64* @rsp

; 0x401051
  store volatile i64 4198481, i64* @_asm_program_counter
  %26 = load i64, i64* @rax
  %27 = load i64, i64* @rsp
  %28 = sub i64 %27, 8
  %29 = inttoptr i64 %28 to i64*
  store i64 %26, i64* %29
  store i64 %28, i64* @rsp

; 0x401052
  store volatile i64 4198482, i64* @_asm_program_counter
  %30 = load i64, i64* @rsp
  %31 = load i64, i64* @rsp
  %32 = sub i64 %31, 8
  %33 = inttoptr i64 %32 to i64*
  store i64 %30, i64* %33
  store i64 %32, i64* @rsp

; 0x401053
  store volatile i64 4198483, i64* @_asm_program_counter
  %34 = load i64, i64* @r8
  %35 = trunc i64 %34 to i32
  %36 = load i64, i64* @r8
  %37 = trunc i64 %36 to i32
  %38 = xor i32 %35, %37
  store i1 false, i1* @az
  store i1 false, i1* @cf
  store i1 false, i1* @of
  %39 = icmp eq i32 %38, 0
  store i1 %39, i1* @zf
  %40 = icmp slt i32 %38, 0
  store i1 %40, i1* @sf
  %41 = trunc i32 %38 to i8
  %42 = call i8 @llvm.ctpop.i8(i8 %41)
  %43 = and i8 %42, 1
  %44 = icmp eq i8 %43, 0
  store i1 %44, i1* @pf
  %45 = zext i32 %38 to i64
  store i64 %45, i64* @r8

; 0x401056
  store volatile i64 4198486, i64* @_asm_program_counter
  %46 = load i64, i64* @rcx
  %47 = trunc i64 %46 to i32
  %48 = load i64, i64* @rcx
  %49 = trunc i64 %48 to i32
  %50 = xor i32 %47, %49
  store i1 false, i1* @az
  store i1 false, i1* @cf
  store i1 false, i1* @of
  %51 = icmp eq i32 %50, 0
  store i1 %51, i1* @zf
  %52 = icmp slt i32 %50, 0
  store i1 %52, i1* @sf
  %53 = trunc i32 %50 to i8
  %54 = call i8 @llvm.ctpop.i8(i8 %53)
  %55 = and i8 %54, 1
  %56 = icmp eq i8 %55, 0
  store i1 %56, i1* @pf
  %57 = zext i32 %50 to i64
  store i64 %57, i64* @rcx

; 0x401058
  store volatile i64 4198488, i64* @_asm_program_counter
  store i64 4198721, i64* @rdi

; 0x40105f
  store volatile i64 4198495, i64* @_asm_program_counter
  %58 = call i64 @__libc_start_main()
  store i64 %58, i64* @rax

; 0x401065
  store volatile i64 4198501, i64* @_asm_program_counter
  call void @__asm_hlt()
  unreachable
}

define i64 @_dl_relocate_static_pie() {
dec_label_pc_401070:

; 0x401070
  store volatile i64 4198512, i64* @_asm_program_counter

; 0x401074
  store volatile i64 4198516, i64* @_asm_program_counter
  ret i64 undef
}

define i64 @deregister_tm_clones() {
dec_label_pc_401080:

; 0x401080
  store volatile i64 4198528, i64* @_asm_program_counter
  store i64 4210728, i64* @rdi

; 0x401087
  store volatile i64 4198535, i64* @_asm_program_counter
  store i64 4210728, i64* @rax

; 0x40108e
  store volatile i64 4198542, i64* @_asm_program_counter
  %0 = load i64, i64* @rax
  %1 = load i64, i64* @rdi
  %2 = sub i64 %0, %1
  %3 = and i64 %0, 15
  %4 = and i64 %1, 15
  %5 = sub i64 %3, %4
  %6 = icmp ugt i64 %5, 15
  %7 = icmp ult i64 %0, %1
  %8 = xor i64 %0, %1
  %9 = xor i64 %0, %2
  %10 = and i64 %8, %9
  %11 = icmp slt i64 %10, 0
  store i1 %6, i1* @az
  store i1 %7, i1* @cf
  store i1 %11, i1* @of
  %12 = icmp eq i64 %2, 0
  store i1 %12, i1* @zf
  %13 = icmp slt i64 %2, 0
  store i1 %13, i1* @sf
  %14 = trunc i64 %2 to i8
  %15 = call i8 @llvm.ctpop.i8(i8 %14)
  %16 = and i8 %15, 1
  %17 = icmp eq i8 %16, 0
  store i1 %17, i1* @pf

; 0x401091
  store volatile i64 4198545, i64* @_asm_program_counter
  %18 = load i1, i1* @zf
  br i1 %18, label %dec_label_pc_4010a8, label %dec_label_pc_401093

dec_label_pc_401093:                              ; preds = %dec_label_pc_401080

; 0x401093
  store volatile i64 4198547, i64* @_asm_program_counter
  %19 = load i64, i64* inttoptr (i64 4210664 to i64*)
  store i64 %19, i64* @rax

; 0x40109a
  store volatile i64 4198554, i64* @_asm_program_counter
  %20 = load i64, i64* @rax
  store i1 false, i1* @az
  store i1 false, i1* @cf
  store i1 false, i1* @of
  %21 = icmp eq i64 %20, 0
  store i1 %21, i1* @zf
  %22 = icmp slt i64 %20, 0
  store i1 %22, i1* @sf
  %23 = trunc i64 %20 to i8
  %24 = call i8 @llvm.ctpop.i8(i8 %23)
  %25 = and i8 %24, 1
  %26 = icmp eq i8 %25, 0
  store i1 %26, i1* @pf

; 0x40109d
  store volatile i64 4198557, i64* @_asm_program_counter
  %27 = load i1, i1* @zf
  br i1 %27, label %dec_label_pc_4010a8, label %dec_label_pc_40109f

dec_label_pc_40109f:                              ; preds = %dec_label_pc_401093

; 0x40109f
  store volatile i64 4198559, i64* @_asm_program_counter
  %28 = call i64 @_ITM_deregisterTMCloneTable()
  store i64 %28, i64* @rax
  ret i64 undef

dec_label_pc_4010a8:                              ; preds = %dec_label_pc_401093, %dec_label_pc_401080

; 0x4010a8
  store volatile i64 4198568, i64* @_asm_program_counter
  ret i64 undef
}

define i64 @register_tm_clones() {
dec_label_pc_4010b0:

; 0x4010b0
  store volatile i64 4198576, i64* @_asm_program_counter
  store i64 4210728, i64* @rdi

; 0x4010b7
  store volatile i64 4198583, i64* @_asm_program_counter
  store i64 4210728, i64* @rsi

; 0x4010be
  store volatile i64 4198590, i64* @_asm_program_counter
  %0 = load i64, i64* @rsi
  %1 = load i64, i64* @rdi
  %2 = sub i64 %0, %1
  %3 = and i64 %0, 15
  %4 = and i64 %1, 15
  %5 = sub i64 %3, %4
  %6 = icmp ugt i64 %5, 15
  %7 = icmp ult i64 %0, %1
  %8 = xor i64 %0, %1
  %9 = xor i64 %0, %2
  %10 = and i64 %8, %9
  %11 = icmp slt i64 %10, 0
  store i1 %6, i1* @az
  store i1 %7, i1* @cf
  store i1 %11, i1* @of
  %12 = icmp eq i64 %2, 0
  store i1 %12, i1* @zf
  %13 = icmp slt i64 %2, 0
  store i1 %13, i1* @sf
  %14 = trunc i64 %2 to i8
  %15 = call i8 @llvm.ctpop.i8(i8 %14)
  %16 = and i8 %15, 1
  %17 = icmp eq i8 %16, 0
  store i1 %17, i1* @pf
  store i64 %2, i64* @rsi

; 0x4010c1
  store volatile i64 4198593, i64* @_asm_program_counter
  %18 = load i64, i64* @rsi
  store i64 %18, i64* @rax

; 0x4010c4
  store volatile i64 4198596, i64* @_asm_program_counter
  %19 = load i64, i64* @rsi
  %20 = load i1, i1* @of
  %21 = lshr i64 %19, 63
  %22 = icmp eq i64 %21, 0
  store i1 %22, i1* @zf
  %23 = icmp slt i64 %21, 0
  store i1 %23, i1* @sf
  %24 = trunc i64 %21 to i8
  %25 = call i8 @llvm.ctpop.i8(i8 %24)
  %26 = and i8 %25, 1
  %27 = icmp eq i8 %26, 0
  store i1 %27, i1* @pf
  store i64 %21, i64* @rsi
  %28 = and i64 4611686018427387904, %19
  %29 = icmp ne i64 %28, 0
  store i1 %29, i1* @cf
  %30 = icmp slt i64 %19, 0
  %31 = select i1 false, i1 %30, i1 %20
  store i1 %31, i1* @of

; 0x4010c8
  store volatile i64 4198600, i64* @_asm_program_counter
  %32 = load i64, i64* @rax
  %33 = load i1, i1* @of
  %34 = ashr i64 %32, 3
  %35 = icmp eq i64 %34, 0
  store i1 %35, i1* @zf
  %36 = icmp slt i64 %34, 0
  store i1 %36, i1* @sf
  %37 = trunc i64 %34 to i8
  %38 = call i8 @llvm.ctpop.i8(i8 %37)
  %39 = and i8 %38, 1
  %40 = icmp eq i8 %39, 0
  store i1 %40, i1* @pf
  store i64 %34, i64* @rax
  %41 = and i64 4, %32
  %42 = icmp ne i64 %41, 0
  store i1 %42, i1* @cf
  %43 = select i1 false, i1 false, i1 %33
  store i1 %43, i1* @of

; 0x4010cc
  store volatile i64 4198604, i64* @_asm_program_counter
  %44 = load i64, i64* @rsi
  %45 = load i64, i64* @rax
  %46 = add i64 %44, %45
  %47 = and i64 %44, 15
  %48 = and i64 %45, 15
  %49 = add i64 %47, %48
  %50 = icmp ugt i64 %49, 15
  %51 = icmp ult i64 %46, %44
  %52 = xor i64 %44, %46
  %53 = xor i64 %45, %46
  %54 = and i64 %52, %53
  %55 = icmp slt i64 %54, 0
  store i1 %50, i1* @az
  store i1 %51, i1* @cf
  store i1 %55, i1* @of
  %56 = icmp eq i64 %46, 0
  store i1 %56, i1* @zf
  %57 = icmp slt i64 %46, 0
  store i1 %57, i1* @sf
  %58 = trunc i64 %46 to i8
  %59 = call i8 @llvm.ctpop.i8(i8 %58)
  %60 = and i8 %59, 1
  %61 = icmp eq i8 %60, 0
  store i1 %61, i1* @pf
  store i64 %46, i64* @rsi

; 0x4010cf
  store volatile i64 4198607, i64* @_asm_program_counter
  %62 = load i64, i64* @rsi
  %63 = load i1, i1* @of
  %64 = ashr i64 %62, 1
  %65 = icmp eq i64 %64, 0
  store i1 %65, i1* @zf
  %66 = icmp slt i64 %64, 0
  store i1 %66, i1* @sf
  %67 = trunc i64 %64 to i8
  %68 = call i8 @llvm.ctpop.i8(i8 %67)
  %69 = and i8 %68, 1
  %70 = icmp eq i8 %69, 0
  store i1 %70, i1* @pf
  store i64 %64, i64* @rsi
  %71 = and i64 1, %62
  %72 = icmp ne i64 %71, 0
  store i1 %72, i1* @cf
  %73 = select i1 true, i1 false, i1 %63
  store i1 %73, i1* @of

; 0x4010d2
  store volatile i64 4198610, i64* @_asm_program_counter
  %74 = load i1, i1* @zf
  br i1 %74, label %dec_label_pc_4010e8, label %dec_label_pc_4010d4

dec_label_pc_4010d4:                              ; preds = %dec_label_pc_4010b0

; 0x4010d4
  store volatile i64 4198612, i64* @_asm_program_counter
  %75 = load i64, i64* inttoptr (i64 4210680 to i64*)
  store i64 %75, i64* @rax

; 0x4010db
  store volatile i64 4198619, i64* @_asm_program_counter
  %76 = load i64, i64* @rax
  store i1 false, i1* @az
  store i1 false, i1* @cf
  store i1 false, i1* @of
  %77 = icmp eq i64 %76, 0
  store i1 %77, i1* @zf
  %78 = icmp slt i64 %76, 0
  store i1 %78, i1* @sf
  %79 = trunc i64 %76 to i8
  %80 = call i8 @llvm.ctpop.i8(i8 %79)
  %81 = and i8 %80, 1
  %82 = icmp eq i8 %81, 0
  store i1 %82, i1* @pf

; 0x4010de
  store volatile i64 4198622, i64* @_asm_program_counter
  %83 = load i1, i1* @zf
  br i1 %83, label %dec_label_pc_4010e8, label %dec_label_pc_4010e0

dec_label_pc_4010e0:                              ; preds = %dec_label_pc_4010d4

; 0x4010e0
  store volatile i64 4198624, i64* @_asm_program_counter
  %84 = call i64 @_ITM_registerTMCloneTable()
  store i64 %84, i64* @rax
  ret i64 undef

dec_label_pc_4010e8:                              ; preds = %dec_label_pc_4010d4, %dec_label_pc_4010b0

; 0x4010e8
  store volatile i64 4198632, i64* @_asm_program_counter
  ret i64 undef
}

define i64 @__do_global_dtors_aux() {
dec_label_pc_4010f0:

; 0x4010f0
  store volatile i64 4198640, i64* @_asm_program_counter

; 0x4010f4
  store volatile i64 4198644, i64* @_asm_program_counter
  %0 = load i8, i8* inttoptr (i64 4210724 to i8*)
  %1 = and i8 %0, 15
  %2 = icmp ugt i8 %1, 15
  %3 = icmp ult i8 %0, 0
  %4 = xor i8 %0, 0
  %5 = and i8 %4, 0
  %6 = icmp slt i8 %5, 0
  store i1 %2, i1* @az
  store i1 %3, i1* @cf
  store i1 %6, i1* @of
  %7 = icmp eq i8 %0, 0
  store i1 %7, i1* @zf
  %8 = icmp slt i8 %0, 0
  store i1 %8, i1* @sf
  %9 = call i8 @llvm.ctpop.i8(i8 %0)
  %10 = and i8 %9, 1
  %11 = icmp eq i8 %10, 0
  store i1 %11, i1* @pf

; 0x4010fb
  store volatile i64 4198651, i64* @_asm_program_counter
  %12 = load i1, i1* @zf
  %13 = icmp eq i1 %12, false
  br i1 %13, label %dec_label_pc_401110, label %dec_label_pc_4010fd

dec_label_pc_4010fd:                              ; preds = %dec_label_pc_4010f0

; 0x4010fd
  store volatile i64 4198653, i64* @_asm_program_counter
  %14 = load i64, i64* @rbp
  %15 = load i64, i64* @rsp
  %16 = sub i64 %15, 8
  %17 = inttoptr i64 %16 to i64*
  store i64 %14, i64* %17
  store i64 %16, i64* @rsp

; 0x4010fe
  store volatile i64 4198654, i64* @_asm_program_counter
  %18 = load i64, i64* @rsp
  store i64 %18, i64* @rbp

; 0x401101
  store volatile i64 4198657, i64* @_asm_program_counter
  %19 = call i64 @deregister_tm_clones()
  store i64 %19, i64* @rax

; 0x401106
  store volatile i64 4198662, i64* @_asm_program_counter
  store i8 1, i8* inttoptr (i64 4210724 to i8*)

; 0x40110d
  store volatile i64 4198669, i64* @_asm_program_counter
  %20 = load i64, i64* @rsp
  %21 = inttoptr i64 %20 to i64*
  %22 = load i64, i64* %21
  store i64 %22, i64* @rbp
  %23 = add i64 %20, 8
  store i64 %23, i64* @rsp

; 0x40110e
  store volatile i64 4198670, i64* @_asm_program_counter
  ret i64 undef

dec_label_pc_401110:                              ; preds = %dec_label_pc_4010f0

; 0x401110
  store volatile i64 4198672, i64* @_asm_program_counter
  ret i64 undef
}

define i64 @frame_dummy() {
dec_label_pc_401120:

; 0x401120
  store volatile i64 4198688, i64* @_asm_program_counter

; 0x401124
  store volatile i64 4198692, i64* @_asm_program_counter
  %0 = call i64 @register_tm_clones()
  store i64 %0, i64* @rax
  ret i64 undef
}

define i64 @add() {
dec_label_pc_401126:

; 0x401126
  store volatile i64 4198694, i64* @_asm_program_counter
  %0 = load i64, i64* @rbp
  %1 = load i64, i64* @rsp
  %2 = sub i64 %1, 8
  %3 = inttoptr i64 %2 to i64*
  store i64 %0, i64* %3
  store i64 %2, i64* @rsp

; 0x401127
  store volatile i64 4198695, i64* @_asm_program_counter
  %4 = load i64, i64* @rsp
  store i64 %4, i64* @rbp

; 0x40112a
  store volatile i64 4198698, i64* @_asm_program_counter
  %5 = load i64, i64* @rdi
  %6 = load i64, i64* @rbp
  %7 = add i64 %6, -8
  %8 = inttoptr i64 %7 to i64*
  store i64 %5, i64* %8

; 0x40112e
  store volatile i64 4198702, i64* @_asm_program_counter
  %9 = load i64, i64* @rsi
  %10 = trunc i64 %9 to i32
  %11 = zext i32 %10 to i64
  store i64 %11, i64* @rax

; 0x401130
  store volatile i64 4198704, i64* @_asm_program_counter
  %12 = load i64, i64* @rax
  %13 = trunc i64 %12 to i8
  %14 = load i64, i64* @rbp
  %15 = add i64 %14, -12
  %16 = inttoptr i64 %15 to i8*
  store i8 %13, i8* %16

; 0x401133
  store volatile i64 4198707, i64* @_asm_program_counter
  %17 = load i64, i64* @rbp
  %18 = add i64 %17, -8
  %19 = inttoptr i64 %18 to i64*
  %20 = load i64, i64* %19
  store i64 %20, i64* @rax

; 0x401137
  store volatile i64 4198711, i64* @_asm_program_counter
  %21 = load i64, i64* @rax
  %22 = inttoptr i64 %21 to i32*
  %23 = load i32, i32* %22
  %24 = zext i32 %23 to i64
  store i64 %24, i64* @rdx

; 0x401139
  store volatile i64 4198713, i64* @_asm_program_counter
  %25 = load i64, i64* @rbp
  %26 = add i64 %25, -12
  %27 = inttoptr i64 %26 to i8*
  %28 = load i8, i8* %27
  %29 = sext i8 %28 to i64
  store i64 %29, i64* @rax

; 0x40113d
  store volatile i64 4198717, i64* @_asm_program_counter
  %30 = load i64, i64* @rax
  %31 = trunc i64 %30 to i32
  %32 = load i64, i64* @rdx
  %33 = trunc i64 %32 to i32
  %34 = add i32 %31, %33
  %35 = and i32 %31, 15
  %36 = and i32 %33, 15
  %37 = add i32 %35, %36
  %38 = icmp ugt i32 %37, 15
  %39 = icmp ult i32 %34, %31
  %40 = xor i32 %31, %34
  %41 = xor i32 %33, %34
  %42 = and i32 %40, %41
  %43 = icmp slt i32 %42, 0
  store i1 %38, i1* @az
  store i1 %39, i1* @cf
  store i1 %43, i1* @of
  %44 = icmp eq i32 %34, 0
  store i1 %44, i1* @zf
  %45 = icmp slt i32 %34, 0
  store i1 %45, i1* @sf
  %46 = trunc i32 %34 to i8
  %47 = call i8 @llvm.ctpop.i8(i8 %46)
  %48 = and i8 %47, 1
  %49 = icmp eq i8 %48, 0
  store i1 %49, i1* @pf
  %50 = zext i32 %34 to i64
  store i64 %50, i64* @rax

; 0x40113f
  store volatile i64 4198719, i64* @_asm_program_counter
  %51 = load i64, i64* @rsp
  %52 = inttoptr i64 %51 to i64*
  %53 = load i64, i64* %52
  store i64 %53, i64* @rbp
  %54 = add i64 %51, 8
  store i64 %54, i64* @rsp

; 0x401140
  store volatile i64 4198720, i64* @_asm_program_counter
  ret i64 undef
}

define i64 @main() {
dec_label_pc_401141:

; 0x401141
  store volatile i64 4198721, i64* @_asm_program_counter
  %0 = load i64, i64* @rbp
  %1 = load i64, i64* @rsp
  %2 = sub i64 %1, 8
  %3 = inttoptr i64 %2 to i64*
  store i64 %0, i64* %3
  store i64 %2, i64* @rsp

; 0x401142
  store volatile i64 4198722, i64* @_asm_program_counter
  %4 = load i64, i64* @rsp
  store i64 %4, i64* @rbp

; 0x401145
  store volatile i64 4198725, i64* @_asm_program_counter
  %5 = load i64, i64* @rsp
  %6 = sub i64 %5, 32
  %7 = and i64 %5, 15
  %8 = icmp ugt i64 %7, 15
  %9 = icmp ult i64 %5, 32
  %10 = xor i64 %5, 32
  %11 = xor i64 %5, %6
  %12 = and i64 %10, %11
  %13 = icmp slt i64 %12, 0
  store i1 %8, i1* @az
  store i1 %9, i1* @cf
  store i1 %13, i1* @of
  %14 = icmp eq i64 %6, 0
  store i1 %14, i1* @zf
  %15 = icmp slt i64 %6, 0
  store i1 %15, i1* @sf
  %16 = trunc i64 %6 to i8
  %17 = call i8 @llvm.ctpop.i8(i8 %16)
  %18 = and i8 %17, 1
  %19 = icmp eq i8 %18, 0
  store i1 %19, i1* @pf
  store i64 %6, i64* @rsp

; 0x401149
  store volatile i64 4198729, i64* @_asm_program_counter
  %20 = load i64, i64* @rbp
  %21 = add i64 %20, -24
  %22 = inttoptr i64 %21 to i32*
  store i32 1, i32* %22

; 0x401150
  store volatile i64 4198736, i64* @_asm_program_counter
  %23 = load i64, i64* @rbp
  %24 = add i64 %23, -1
  %25 = inttoptr i64 %24 to i8*
  store i8 2, i8* %25

; 0x401154
  store volatile i64 4198740, i64* @_asm_program_counter
  %26 = load i64, i64* @rbp
  %27 = add i64 %26, -1
  %28 = inttoptr i64 %27 to i8*
  %29 = load i8, i8* %28
  %30 = sext i8 %29 to i64
  store i64 %30, i64* @rdx

; 0x401158
  store volatile i64 4198744, i64* @_asm_program_counter
  %31 = load i64, i64* @rbp
  %32 = add i64 %31, -24
  store i64 %32, i64* @rax

; 0x40115c
  store volatile i64 4198748, i64* @_asm_program_counter
  %33 = load i64, i64* @rdx
  %34 = trunc i64 %33 to i32
  %35 = zext i32 %34 to i64
  store i64 %35, i64* @rsi

; 0x40115e
  store volatile i64 4198750, i64* @_asm_program_counter
  %36 = load i64, i64* @rax
  store i64 %36, i64* @rdi

; 0x401161
  store volatile i64 4198753, i64* @_asm_program_counter
  %37 = call i64 @add()
  store i64 %37, i64* @rax

; 0x401166
  store volatile i64 4198758, i64* @_asm_program_counter
  %38 = load i64, i64* @rax
  %39 = trunc i64 %38 to i32
  %40 = load i64, i64* @rbp
  %41 = add i64 %40, -8
  %42 = inttoptr i64 %41 to i32*
  store i32 %39, i32* %42

; 0x401169
  store volatile i64 4198761, i64* @_asm_program_counter
  %43 = load i64, i64* @rbp
  %44 = add i64 %43, -24
  store i64 %44, i64* @rax

; 0x40116d
  store volatile i64 4198765, i64* @_asm_program_counter
  %45 = load i64, i64* @rax
  %46 = load i64, i64* @rbp
  %47 = add i64 %46, -16
  %48 = inttoptr i64 %47 to i64*
  store i64 %45, i64* %48

; 0x401171
  store volatile i64 4198769, i64* @_asm_program_counter
  %49 = load i64, i64* @rbp
  %50 = add i64 %49, -1
  %51 = inttoptr i64 %50 to i8*
  %52 = load i8, i8* %51
  %53 = sext i8 %52 to i64
  store i64 %53, i64* @rdx

; 0x401175
  store volatile i64 4198773, i64* @_asm_program_counter
  %54 = load i64, i64* @rbp
  %55 = add i64 %54, -16
  %56 = inttoptr i64 %55 to i64*
  %57 = load i64, i64* %56
  store i64 %57, i64* @rax

; 0x401179
  store volatile i64 4198777, i64* @_asm_program_counter
  %58 = load i64, i64* @rdx
  %59 = trunc i64 %58 to i32
  %60 = zext i32 %59 to i64
  store i64 %60, i64* @rsi

; 0x40117b
  store volatile i64 4198779, i64* @_asm_program_counter
  %61 = load i64, i64* @rax
  store i64 %61, i64* @rdi

; 0x40117e
  store volatile i64 4198782, i64* @_asm_program_counter
  %62 = call i64 @add()
  store i64 %62, i64* @rax

; 0x401183
  store volatile i64 4198787, i64* @_asm_program_counter
  %63 = load i64, i64* @rax
  %64 = trunc i64 %63 to i32
  %65 = load i64, i64* @rbp
  %66 = add i64 %65, -20
  %67 = inttoptr i64 %66 to i32*
  store i32 %64, i32* %67

; 0x401186
  store volatile i64 4198790, i64* @_asm_program_counter
  %68 = load i64, i64* @rbp
  %69 = add i64 %68, -8
  %70 = inttoptr i64 %69 to i32*
  %71 = load i32, i32* %70
  %72 = zext i32 %71 to i64
  store i64 %72, i64* @rax

; 0x401189
  store volatile i64 4198793, i64* @_asm_program_counter
  %73 = load i64, i64* @rax
  %74 = trunc i64 %73 to i32
  %75 = zext i32 %74 to i64
  store i64 %75, i64* @rsi

; 0x40118b
  store volatile i64 4198795, i64* @_asm_program_counter
  store i64 4202512, i64* @rdi

; 0x401190
  store volatile i64 4198800, i64* @_asm_program_counter
  store i64 0, i64* @rax

; 0x401195
  store volatile i64 4198805, i64* @_asm_program_counter
  %76 = call i64 @function_401030()
  store i64 %76, i64* @rax

; 0x40119a
  store volatile i64 4198810, i64* @_asm_program_counter
  store i64 0, i64* @rax

; 0x40119f
  store volatile i64 4198815, i64* @_asm_program_counter
  %77 = load i64, i64* @rbp
  %78 = inttoptr i64 %77 to i64*
  %79 = load i64, i64* %78
  %80 = add i64 %77, 8
  store i64 %79, i64* @rbp
  store i64 %80, i64* @rsp

; 0x4011a0
  store volatile i64 4198816, i64* @_asm_program_counter
  ret i64 undef
}

define i64 @_fini() {
dec_label_pc_4011a4:

; 0x4011a4
  store volatile i64 4198820, i64* @_asm_program_counter

; 0x4011a8
  store volatile i64 4198824, i64* @_asm_program_counter
  %0 = load i64, i64* @rsp
  %1 = sub i64 %0, 8
  %2 = and i64 %0, 15
  %3 = sub i64 %2, 8
  %4 = icmp ugt i64 %3, 15
  %5 = icmp ult i64 %0, 8
  %6 = xor i64 %0, 8
  %7 = xor i64 %0, %1
  %8 = and i64 %6, %7
  %9 = icmp slt i64 %8, 0
  store i1 %4, i1* @az
  store i1 %5, i1* @cf
  store i1 %9, i1* @of
  %10 = icmp eq i64 %1, 0
  store i1 %10, i1* @zf
  %11 = icmp slt i64 %1, 0
  store i1 %11, i1* @sf
  %12 = trunc i64 %1 to i8
  %13 = call i8 @llvm.ctpop.i8(i8 %12)
  %14 = and i8 %13, 1
  %15 = icmp eq i8 %14, 0
  store i1 %15, i1* @pf
  store i64 %1, i64* @rsp

; 0x4011ac
  store volatile i64 4198828, i64* @_asm_program_counter
  %16 = load i64, i64* @rsp
  %17 = add i64 %16, 8
  %18 = and i64 %16, 15
  %19 = add i64 %18, 8
  %20 = icmp ugt i64 %19, 15
  %21 = icmp ult i64 %17, %16
  %22 = xor i64 %16, %17
  %23 = xor i64 8, %17
  %24 = and i64 %22, %23
  %25 = icmp slt i64 %24, 0
  store i1 %20, i1* @az
  store i1 %21, i1* @cf
  store i1 %25, i1* @of
  %26 = icmp eq i64 %17, 0
  store i1 %26, i1* @zf
  %27 = icmp slt i64 %17, 0
  store i1 %27, i1* @sf
  %28 = trunc i64 %17 to i8
  %29 = call i8 @llvm.ctpop.i8(i8 %28)
  %30 = and i8 %29, 1
  %31 = icmp eq i8 %30, 0
  store i1 %31, i1* @pf
  store i64 %17, i64* @rsp

; 0x4011b0
  store volatile i64 4198832, i64* @_asm_program_counter
  ret i64 undef
}

declare i64 @__libc_start_main()

declare i64 @_ITM_deregisterTMCloneTable()

declare i64 @__gmon_start__()

declare i64 @_ITM_registerTMCloneTable()

declare i64 @printf()

declare void @__pseudo_call(i64)

declare void @__pseudo_return(i64)

declare void @__pseudo_branch(i64)

declare void @__pseudo_cond_branch(i1, i64)

declare void @__frontend_reg_store.fpr(i3, x86_fp80)

declare x86_fp80 @__frontend_reg_load.fpr(i3)

; Function Attrs: nounwind readnone speculatable
declare i8 @llvm.ctpop.i8(i8) #0

declare void @__asm_hlt()

attributes #0 = { nounwind readnone speculatable }
*** IR Dump After Stack optimization ***
source_filename = "test"
target datalayout = "e-m:e-p:64:64-i64:64-f80:128-n8:16:32:64-S128"

@_asm_program_counter = internal global i64 0
@cf = internal global i1 false
@pf = internal global i1 false
@az = internal global i1 false
@zf = internal global i1 false
@sf = internal global i1 false
@tf = internal global i1 false
@if = internal global i1 false
@df = internal global i1 false
@of = internal global i1 false
@iopl = internal global i2 0
@nt = internal global i1 false
@rf = internal global i1 false
@vm = internal global i1 false
@ac = internal global i1 false
@vif = internal global i1 false
@vip = internal global i1 false
@id = internal global i1 false
@rflags = internal global i64 0
@ss = internal global i16 0
@cs = internal global i16 0
@ds = internal global i16 0
@es = internal global i16 0
@fs = internal global i16 0
@gs = internal global i16 0
@st0 = internal global x86_fp80 0xK00000000000000000000
@st1 = internal global x86_fp80 0xK00000000000000000000
@st2 = internal global x86_fp80 0xK00000000000000000000
@st3 = internal global x86_fp80 0xK00000000000000000000
@st4 = internal global x86_fp80 0xK00000000000000000000
@st5 = internal global x86_fp80 0xK00000000000000000000
@st6 = internal global x86_fp80 0xK00000000000000000000
@st7 = internal global x86_fp80 0xK00000000000000000000
@fpu_stat_IE = internal global i1 false
@fpu_stat_DE = internal global i1 false
@fpu_stat_ZE = internal global i1 false
@fpu_stat_OE = internal global i1 false
@fpu_stat_UE = internal global i1 false
@fpu_stat_PE = internal global i1 false
@fpu_stat_SF = internal global i1 false
@fpu_stat_ES = internal global i1 false
@fpu_stat_C0 = internal global i1 false
@fpu_stat_C1 = internal global i1 false
@fpu_stat_C2 = internal global i1 false
@fpu_stat_C3 = internal global i1 false
@fpu_stat_TOP = internal global i3 0
@fpu_stat_B = internal global i1 false
@fpu_control_IM = internal global i1 false
@fpu_control_DM = internal global i1 false
@fpu_control_ZM = internal global i1 false
@fpu_control_OM = internal global i1 false
@fpu_control_UM = internal global i1 false
@fpu_control_PM = internal global i1 false
@fpu_control_PC = internal global i2 0
@fpu_control_RC = internal global i2 0
@fpu_control_X = internal global i1 false
@fp0 = internal global double 0.000000e+00
@fp1 = internal global double 0.000000e+00
@fp2 = internal global double 0.000000e+00
@fp3 = internal global double 0.000000e+00
@fp4 = internal global double 0.000000e+00
@fp5 = internal global double 0.000000e+00
@fp6 = internal global double 0.000000e+00
@fp7 = internal global double 0.000000e+00
@k0 = internal global i64 0
@k1 = internal global i64 0
@k2 = internal global i64 0
@k3 = internal global i64 0
@k4 = internal global i64 0
@k5 = internal global i64 0
@k6 = internal global i64 0
@k7 = internal global i64 0
@mm0 = internal global i64 0
@mm1 = internal global i64 0
@mm2 = internal global i64 0
@mm3 = internal global i64 0
@mm4 = internal global i64 0
@mm5 = internal global i64 0
@mm6 = internal global i64 0
@mm7 = internal global i64 0
@xmm0 = internal global i128 0
@xmm1 = internal global i128 0
@xmm2 = internal global i128 0
@xmm3 = internal global i128 0
@xmm4 = internal global i128 0
@xmm5 = internal global i128 0
@xmm6 = internal global i128 0
@xmm7 = internal global i128 0
@xmm8 = internal global i128 0
@xmm9 = internal global i128 0
@xmm10 = internal global i128 0
@xmm11 = internal global i128 0
@xmm12 = internal global i128 0
@xmm13 = internal global i128 0
@xmm14 = internal global i128 0
@xmm15 = internal global i128 0
@xmm16 = internal global i128 0
@xmm17 = internal global i128 0
@xmm18 = internal global i128 0
@xmm19 = internal global i128 0
@xmm20 = internal global i128 0
@xmm21 = internal global i128 0
@xmm22 = internal global i128 0
@xmm23 = internal global i128 0
@xmm24 = internal global i128 0
@xmm25 = internal global i128 0
@xmm26 = internal global i128 0
@xmm27 = internal global i128 0
@xmm28 = internal global i128 0
@xmm29 = internal global i128 0
@xmm30 = internal global i128 0
@xmm31 = internal global i128 0
@ymm0 = internal global i256 0
@ymm1 = internal global i256 0
@ymm2 = internal global i256 0
@ymm3 = internal global i256 0
@ymm4 = internal global i256 0
@ymm5 = internal global i256 0
@ymm6 = internal global i256 0
@ymm7 = internal global i256 0
@ymm8 = internal global i256 0
@ymm9 = internal global i256 0
@ymm10 = internal global i256 0
@ymm11 = internal global i256 0
@ymm12 = internal global i256 0
@ymm13 = internal global i256 0
@ymm14 = internal global i256 0
@ymm15 = internal global i256 0
@ymm16 = internal global i256 0
@ymm17 = internal global i256 0
@ymm18 = internal global i256 0
@ymm19 = internal global i256 0
@ymm20 = internal global i256 0
@ymm21 = internal global i256 0
@ymm22 = internal global i256 0
@ymm23 = internal global i256 0
@ymm24 = internal global i256 0
@ymm25 = internal global i256 0
@ymm26 = internal global i256 0
@ymm27 = internal global i256 0
@ymm28 = internal global i256 0
@ymm29 = internal global i256 0
@ymm30 = internal global i256 0
@ymm31 = internal global i256 0
@zmm0 = internal global i512 0
@zmm1 = internal global i512 0
@zmm2 = internal global i512 0
@zmm3 = internal global i512 0
@zmm4 = internal global i512 0
@zmm5 = internal global i512 0
@zmm6 = internal global i512 0
@zmm7 = internal global i512 0
@zmm8 = internal global i512 0
@zmm9 = internal global i512 0
@zmm10 = internal global i512 0
@zmm11 = internal global i512 0
@zmm12 = internal global i512 0
@zmm13 = internal global i512 0
@zmm14 = internal global i512 0
@zmm15 = internal global i512 0
@zmm16 = internal global i512 0
@zmm17 = internal global i512 0
@zmm18 = internal global i512 0
@zmm19 = internal global i512 0
@zmm20 = internal global i512 0
@zmm21 = internal global i512 0
@zmm22 = internal global i512 0
@zmm23 = internal global i512 0
@zmm24 = internal global i512 0
@zmm25 = internal global i512 0
@zmm26 = internal global i512 0
@zmm27 = internal global i512 0
@zmm28 = internal global i512 0
@zmm29 = internal global i512 0
@zmm30 = internal global i512 0
@zmm31 = internal global i512 0
@bnd0 = internal global i128 0
@bnd1 = internal global i128 0
@bnd2 = internal global i128 0
@bnd3 = internal global i128 0
@dr0 = internal global i64 0
@dr1 = internal global i64 0
@dr2 = internal global i64 0
@dr3 = internal global i64 0
@dr4 = internal global i64 0
@dr5 = internal global i64 0
@dr6 = internal global i64 0
@dr7 = internal global i64 0
@dr8 = internal global i64 0
@dr9 = internal global i64 0
@dr10 = internal global i64 0
@dr11 = internal global i64 0
@dr12 = internal global i64 0
@dr13 = internal global i64 0
@dr14 = internal global i64 0
@dr15 = internal global i64 0
@cr0 = internal global i64 0
@cr1 = internal global i64 0
@cr2 = internal global i64 0
@cr3 = internal global i64 0
@cr4 = internal global i64 0
@cr5 = internal global i64 0
@cr6 = internal global i64 0
@cr7 = internal global i64 0
@cr8 = internal global i64 0
@cr9 = internal global i64 0
@cr10 = internal global i64 0
@cr11 = internal global i64 0
@cr12 = internal global i64 0
@cr13 = internal global i64 0
@cr14 = internal global i64 0
@cr15 = internal global i64 0
@fpsw = internal global i64 0
@rax = internal global i64 0
@rcx = internal global i64 0
@rdx = internal global i64 0
@rbx = internal global i64 0
@rsp = internal global i64 0
@rbp = internal global i64 0
@rsi = internal global i64 0
@rdi = internal global i64 0
@r8 = internal global i64 0
@r9 = internal global i64 0
@r10 = internal global i64 0
@r11 = internal global i64 0
@r12 = internal global i64 0
@r13 = internal global i64 0
@r14 = internal global i64 0
@r15 = internal global i64 0
@rip = internal global i64 0
@riz = internal global i64 0

define i64 @_init() {
dec_label_pc_401000:
  %stack_var_0 = alloca i64
  %stack_var_-8 = alloca i64

; 0x401000
  store volatile i64 4198400, i64* @_asm_program_counter

; 0x401004
  store volatile i64 4198404, i64* @_asm_program_counter
  %0 = load i64, i64* @rsp
  %1 = sub i64 %0, 8
  %2 = and i64 %0, 15
  %3 = sub i64 %2, 8
  %4 = icmp ugt i64 %3, 15
  %5 = icmp ult i64 %0, 8
  %6 = xor i64 %0, 8
  %7 = xor i64 %0, %1
  %8 = and i64 %6, %7
  %9 = icmp slt i64 %8, 0
  store i1 %4, i1* @az
  store i1 %5, i1* @cf
  store i1 %9, i1* @of
  %10 = icmp eq i64 %1, 0
  store i1 %10, i1* @zf
  %11 = icmp slt i64 %1, 0
  store i1 %11, i1* @sf
  %12 = trunc i64 %1 to i8
  %13 = call i8 @llvm.ctpop.i8(i8 %12)
  %14 = and i8 %13, 1
  %15 = icmp eq i8 %14, 0
  store i1 %15, i1* @pf
  %16 = ptrtoint i64* %stack_var_-8 to i64
  store i64 %16, i64* @rsp

; 0x401008
  store volatile i64 4198408, i64* @_asm_program_counter
  %17 = load i64, i64* inttoptr (i64 4210672 to i64*)
  store i64 %17, i64* @rax

; 0x40100f
  store volatile i64 4198415, i64* @_asm_program_counter
  %18 = load i64, i64* @rax
  store i1 false, i1* @az
  store i1 false, i1* @cf
  store i1 false, i1* @of
  %19 = icmp eq i64 %18, 0
  store i1 %19, i1* @zf
  %20 = icmp slt i64 %18, 0
  store i1 %20, i1* @sf
  %21 = trunc i64 %18 to i8
  %22 = call i8 @llvm.ctpop.i8(i8 %21)
  %23 = and i8 %22, 1
  %24 = icmp eq i8 %23, 0
  store i1 %24, i1* @pf

; 0x401012
  store volatile i64 4198418, i64* @_asm_program_counter
  %25 = load i1, i1* @zf
  br i1 %25, label %dec_label_pc_401016, label %dec_label_pc_401014

dec_label_pc_401014:                              ; preds = %dec_label_pc_401000

; 0x401014
  store volatile i64 4198420, i64* @_asm_program_counter
  %26 = call i64 @__gmon_start__()
  store i64 %26, i64* @rax
  br label %dec_label_pc_401016

dec_label_pc_401016:                              ; preds = %dec_label_pc_401014, %dec_label_pc_401000

; 0x401016
  store volatile i64 4198422, i64* @_asm_program_counter
  %27 = load i64, i64* @rsp
  %28 = add i64 %27, 8
  %29 = and i64 %27, 15
  %30 = add i64 %29, 8
  %31 = icmp ugt i64 %30, 15
  %32 = icmp ult i64 %28, %27
  %33 = xor i64 %27, %28
  %34 = xor i64 8, %28
  %35 = and i64 %33, %34
  %36 = icmp slt i64 %35, 0
  store i1 %31, i1* @az
  store i1 %32, i1* @cf
  store i1 %36, i1* @of
  %37 = icmp eq i64 %28, 0
  store i1 %37, i1* @zf
  %38 = icmp slt i64 %28, 0
  store i1 %38, i1* @sf
  %39 = trunc i64 %28 to i8
  %40 = call i8 @llvm.ctpop.i8(i8 %39)
  %41 = and i8 %40, 1
  %42 = icmp eq i8 %41, 0
  store i1 %42, i1* @pf
  %43 = ptrtoint i64* %stack_var_0 to i64
  store i64 %43, i64* @rsp

; 0x40101a
  store volatile i64 4198426, i64* @_asm_program_counter
  ret i64 undef
}

define i64 @function_401030() {
dec_label_pc_401030:

; 0x401030
  store volatile i64 4198448, i64* @_asm_program_counter
  %0 = call i64 @printf()
  store i64 %0, i64* @rax
  ret i64 undef
}

define i64 @_start() {
dec_label_pc_401040:
  %stack_var_-16 = alloca i64
  %stack_var_-8 = alloca i64
  %stack_var_8 = alloca i64
  %stack_var_0 = alloca i64

; 0x401040
  store volatile i64 4198464, i64* @_asm_program_counter

; 0x401044
  store volatile i64 4198468, i64* @_asm_program_counter
  %0 = load i64, i64* @rbp
  %1 = trunc i64 %0 to i32
  %2 = load i64, i64* @rbp
  %3 = trunc i64 %2 to i32
  %4 = xor i32 %1, %3
  store i1 false, i1* @az
  store i1 false, i1* @cf
  store i1 false, i1* @of
  %5 = icmp eq i32 %4, 0
  store i1 %5, i1* @zf
  %6 = icmp slt i32 %4, 0
  store i1 %6, i1* @sf
  %7 = trunc i32 %4 to i8
  %8 = call i8 @llvm.ctpop.i8(i8 %7)
  %9 = and i8 %8, 1
  %10 = icmp eq i8 %9, 0
  store i1 %10, i1* @pf
  %11 = zext i32 %4 to i64
  store i64 %11, i64* @rbp

; 0x401046
  store volatile i64 4198470, i64* @_asm_program_counter
  %12 = load i64, i64* @rdx
  store i64 %12, i64* @r9

; 0x401049
  store volatile i64 4198473, i64* @_asm_program_counter
  %13 = load i64, i64* %stack_var_0
  store i64 %13, i64* @rsi
  %14 = ptrtoint i64* %stack_var_8 to i64
  store i64 %14, i64* @rsp

; 0x40104a
  store volatile i64 4198474, i64* @_asm_program_counter
  %15 = ptrtoint i64* %stack_var_8 to i64
  store i64 %15, i64* @rdx

; 0x40104d
  store volatile i64 4198477, i64* @_asm_program_counter
  %16 = load i64, i64* @rsp
  %17 = and i64 %16, -16
  store i1 false, i1* @az
  store i1 false, i1* @cf
  store i1 false, i1* @of
  %18 = icmp eq i64 %17, 0
  store i1 %18, i1* @zf
  %19 = icmp slt i64 %17, 0
  store i1 %19, i1* @sf
  %20 = trunc i64 %17 to i8
  %21 = call i8 @llvm.ctpop.i8(i8 %20)
  %22 = and i8 %21, 1
  %23 = icmp eq i8 %22, 0
  store i1 %23, i1* @pf
  %24 = ptrtoint i64* %stack_var_0 to i64
  store i64 %24, i64* @rsp

; 0x401051
  store volatile i64 4198481, i64* @_asm_program_counter
  %25 = load i64, i64* @rax
  store i64 %25, i64* %stack_var_-8
  %26 = ptrtoint i64* %stack_var_-8 to i64
  store i64 %26, i64* @rsp

; 0x401052
  store volatile i64 4198482, i64* @_asm_program_counter
  %27 = ptrtoint i64* %stack_var_-8 to i64
  store i64 %27, i64* %stack_var_-16
  %28 = ptrtoint i64* %stack_var_-16 to i64
  store i64 %28, i64* @rsp

; 0x401053
  store volatile i64 4198483, i64* @_asm_program_counter
  %29 = load i64, i64* @r8
  %30 = trunc i64 %29 to i32
  %31 = load i64, i64* @r8
  %32 = trunc i64 %31 to i32
  %33 = xor i32 %30, %32
  store i1 false, i1* @az
  store i1 false, i1* @cf
  store i1 false, i1* @of
  %34 = icmp eq i32 %33, 0
  store i1 %34, i1* @zf
  %35 = icmp slt i32 %33, 0
  store i1 %35, i1* @sf
  %36 = trunc i32 %33 to i8
  %37 = call i8 @llvm.ctpop.i8(i8 %36)
  %38 = and i8 %37, 1
  %39 = icmp eq i8 %38, 0
  store i1 %39, i1* @pf
  %40 = zext i32 %33 to i64
  store i64 %40, i64* @r8

; 0x401056
  store volatile i64 4198486, i64* @_asm_program_counter
  %41 = load i64, i64* @rcx
  %42 = trunc i64 %41 to i32
  %43 = load i64, i64* @rcx
  %44 = trunc i64 %43 to i32
  %45 = xor i32 %42, %44
  store i1 false, i1* @az
  store i1 false, i1* @cf
  store i1 false, i1* @of
  %46 = icmp eq i32 %45, 0
  store i1 %46, i1* @zf
  %47 = icmp slt i32 %45, 0
  store i1 %47, i1* @sf
  %48 = trunc i32 %45 to i8
  %49 = call i8 @llvm.ctpop.i8(i8 %48)
  %50 = and i8 %49, 1
  %51 = icmp eq i8 %50, 0
  store i1 %51, i1* @pf
  %52 = zext i32 %45 to i64
  store i64 %52, i64* @rcx

; 0x401058
  store volatile i64 4198488, i64* @_asm_program_counter
  store i64 4198721, i64* @rdi

; 0x40105f
  store volatile i64 4198495, i64* @_asm_program_counter
  %53 = call i64 @__libc_start_main()
  store i64 %53, i64* @rax

; 0x401065
  store volatile i64 4198501, i64* @_asm_program_counter
  call void @__asm_hlt()
  unreachable
}

define i64 @_dl_relocate_static_pie() {
dec_label_pc_401070:

; 0x401070
  store volatile i64 4198512, i64* @_asm_program_counter

; 0x401074
  store volatile i64 4198516, i64* @_asm_program_counter
  ret i64 undef
}

define i64 @deregister_tm_clones() {
dec_label_pc_401080:

; 0x401080
  store volatile i64 4198528, i64* @_asm_program_counter
  store i64 4210728, i64* @rdi

; 0x401087
  store volatile i64 4198535, i64* @_asm_program_counter
  store i64 4210728, i64* @rax

; 0x40108e
  store volatile i64 4198542, i64* @_asm_program_counter
  %0 = load i64, i64* @rax
  %1 = load i64, i64* @rdi
  %2 = sub i64 %0, %1
  %3 = and i64 %0, 15
  %4 = and i64 %1, 15
  %5 = sub i64 %3, %4
  %6 = icmp ugt i64 %5, 15
  %7 = icmp ult i64 %0, %1
  %8 = xor i64 %0, %1
  %9 = xor i64 %0, %2
  %10 = and i64 %8, %9
  %11 = icmp slt i64 %10, 0
  store i1 %6, i1* @az
  store i1 %7, i1* @cf
  store i1 %11, i1* @of
  %12 = icmp eq i64 %2, 0
  store i1 %12, i1* @zf
  %13 = icmp slt i64 %2, 0
  store i1 %13, i1* @sf
  %14 = trunc i64 %2 to i8
  %15 = call i8 @llvm.ctpop.i8(i8 %14)
  %16 = and i8 %15, 1
  %17 = icmp eq i8 %16, 0
  store i1 %17, i1* @pf

; 0x401091
  store volatile i64 4198545, i64* @_asm_program_counter
  %18 = load i1, i1* @zf
  br i1 %18, label %dec_label_pc_4010a8, label %dec_label_pc_401093

dec_label_pc_401093:                              ; preds = %dec_label_pc_401080

; 0x401093
  store volatile i64 4198547, i64* @_asm_program_counter
  %19 = load i64, i64* inttoptr (i64 4210664 to i64*)
  store i64 %19, i64* @rax

; 0x40109a
  store volatile i64 4198554, i64* @_asm_program_counter
  %20 = load i64, i64* @rax
  store i1 false, i1* @az
  store i1 false, i1* @cf
  store i1 false, i1* @of
  %21 = icmp eq i64 %20, 0
  store i1 %21, i1* @zf
  %22 = icmp slt i64 %20, 0
  store i1 %22, i1* @sf
  %23 = trunc i64 %20 to i8
  %24 = call i8 @llvm.ctpop.i8(i8 %23)
  %25 = and i8 %24, 1
  %26 = icmp eq i8 %25, 0
  store i1 %26, i1* @pf

; 0x40109d
  store volatile i64 4198557, i64* @_asm_program_counter
  %27 = load i1, i1* @zf
  br i1 %27, label %dec_label_pc_4010a8, label %dec_label_pc_40109f

dec_label_pc_40109f:                              ; preds = %dec_label_pc_401093

; 0x40109f
  store volatile i64 4198559, i64* @_asm_program_counter
  %28 = call i64 @_ITM_deregisterTMCloneTable()
  store i64 %28, i64* @rax
  ret i64 undef

dec_label_pc_4010a8:                              ; preds = %dec_label_pc_401093, %dec_label_pc_401080

; 0x4010a8
  store volatile i64 4198568, i64* @_asm_program_counter
  ret i64 undef
}

define i64 @register_tm_clones() {
dec_label_pc_4010b0:

; 0x4010b0
  store volatile i64 4198576, i64* @_asm_program_counter
  store i64 4210728, i64* @rdi

; 0x4010b7
  store volatile i64 4198583, i64* @_asm_program_counter
  store i64 4210728, i64* @rsi

; 0x4010be
  store volatile i64 4198590, i64* @_asm_program_counter
  %0 = load i64, i64* @rsi
  %1 = load i64, i64* @rdi
  %2 = sub i64 %0, %1
  %3 = and i64 %0, 15
  %4 = and i64 %1, 15
  %5 = sub i64 %3, %4
  %6 = icmp ugt i64 %5, 15
  %7 = icmp ult i64 %0, %1
  %8 = xor i64 %0, %1
  %9 = xor i64 %0, %2
  %10 = and i64 %8, %9
  %11 = icmp slt i64 %10, 0
  store i1 %6, i1* @az
  store i1 %7, i1* @cf
  store i1 %11, i1* @of
  %12 = icmp eq i64 %2, 0
  store i1 %12, i1* @zf
  %13 = icmp slt i64 %2, 0
  store i1 %13, i1* @sf
  %14 = trunc i64 %2 to i8
  %15 = call i8 @llvm.ctpop.i8(i8 %14)
  %16 = and i8 %15, 1
  %17 = icmp eq i8 %16, 0
  store i1 %17, i1* @pf
  store i64 %2, i64* @rsi

; 0x4010c1
  store volatile i64 4198593, i64* @_asm_program_counter
  %18 = load i64, i64* @rsi
  store i64 %18, i64* @rax

; 0x4010c4
  store volatile i64 4198596, i64* @_asm_program_counter
  %19 = load i64, i64* @rsi
  %20 = load i1, i1* @of
  %21 = lshr i64 %19, 63
  %22 = icmp eq i64 %21, 0
  store i1 %22, i1* @zf
  %23 = icmp slt i64 %21, 0
  store i1 %23, i1* @sf
  %24 = trunc i64 %21 to i8
  %25 = call i8 @llvm.ctpop.i8(i8 %24)
  %26 = and i8 %25, 1
  %27 = icmp eq i8 %26, 0
  store i1 %27, i1* @pf
  store i64 %21, i64* @rsi
  %28 = and i64 4611686018427387904, %19
  %29 = icmp ne i64 %28, 0
  store i1 %29, i1* @cf
  %30 = icmp slt i64 %19, 0
  %31 = select i1 false, i1 %30, i1 %20
  store i1 %31, i1* @of

; 0x4010c8
  store volatile i64 4198600, i64* @_asm_program_counter
  %32 = load i64, i64* @rax
  %33 = load i1, i1* @of
  %34 = ashr i64 %32, 3
  %35 = icmp eq i64 %34, 0
  store i1 %35, i1* @zf
  %36 = icmp slt i64 %34, 0
  store i1 %36, i1* @sf
  %37 = trunc i64 %34 to i8
  %38 = call i8 @llvm.ctpop.i8(i8 %37)
  %39 = and i8 %38, 1
  %40 = icmp eq i8 %39, 0
  store i1 %40, i1* @pf
  store i64 %34, i64* @rax
  %41 = and i64 4, %32
  %42 = icmp ne i64 %41, 0
  store i1 %42, i1* @cf
  %43 = select i1 false, i1 false, i1 %33
  store i1 %43, i1* @of

; 0x4010cc
  store volatile i64 4198604, i64* @_asm_program_counter
  %44 = load i64, i64* @rsi
  %45 = load i64, i64* @rax
  %46 = add i64 %44, %45
  %47 = and i64 %44, 15
  %48 = and i64 %45, 15
  %49 = add i64 %47, %48
  %50 = icmp ugt i64 %49, 15
  %51 = icmp ult i64 %46, %44
  %52 = xor i64 %44, %46
  %53 = xor i64 %45, %46
  %54 = and i64 %52, %53
  %55 = icmp slt i64 %54, 0
  store i1 %50, i1* @az
  store i1 %51, i1* @cf
  store i1 %55, i1* @of
  %56 = icmp eq i64 %46, 0
  store i1 %56, i1* @zf
  %57 = icmp slt i64 %46, 0
  store i1 %57, i1* @sf
  %58 = trunc i64 %46 to i8
  %59 = call i8 @llvm.ctpop.i8(i8 %58)
  %60 = and i8 %59, 1
  %61 = icmp eq i8 %60, 0
  store i1 %61, i1* @pf
  store i64 %46, i64* @rsi

; 0x4010cf
  store volatile i64 4198607, i64* @_asm_program_counter
  %62 = load i64, i64* @rsi
  %63 = load i1, i1* @of
  %64 = ashr i64 %62, 1
  %65 = icmp eq i64 %64, 0
  store i1 %65, i1* @zf
  %66 = icmp slt i64 %64, 0
  store i1 %66, i1* @sf
  %67 = trunc i64 %64 to i8
  %68 = call i8 @llvm.ctpop.i8(i8 %67)
  %69 = and i8 %68, 1
  %70 = icmp eq i8 %69, 0
  store i1 %70, i1* @pf
  store i64 %64, i64* @rsi
  %71 = and i64 1, %62
  %72 = icmp ne i64 %71, 0
  store i1 %72, i1* @cf
  %73 = select i1 true, i1 false, i1 %63
  store i1 %73, i1* @of

; 0x4010d2
  store volatile i64 4198610, i64* @_asm_program_counter
  %74 = load i1, i1* @zf
  br i1 %74, label %dec_label_pc_4010e8, label %dec_label_pc_4010d4

dec_label_pc_4010d4:                              ; preds = %dec_label_pc_4010b0

; 0x4010d4
  store volatile i64 4198612, i64* @_asm_program_counter
  %75 = load i64, i64* inttoptr (i64 4210680 to i64*)
  store i64 %75, i64* @rax

; 0x4010db
  store volatile i64 4198619, i64* @_asm_program_counter
  %76 = load i64, i64* @rax
  store i1 false, i1* @az
  store i1 false, i1* @cf
  store i1 false, i1* @of
  %77 = icmp eq i64 %76, 0
  store i1 %77, i1* @zf
  %78 = icmp slt i64 %76, 0
  store i1 %78, i1* @sf
  %79 = trunc i64 %76 to i8
  %80 = call i8 @llvm.ctpop.i8(i8 %79)
  %81 = and i8 %80, 1
  %82 = icmp eq i8 %81, 0
  store i1 %82, i1* @pf

; 0x4010de
  store volatile i64 4198622, i64* @_asm_program_counter
  %83 = load i1, i1* @zf
  br i1 %83, label %dec_label_pc_4010e8, label %dec_label_pc_4010e0

dec_label_pc_4010e0:                              ; preds = %dec_label_pc_4010d4

; 0x4010e0
  store volatile i64 4198624, i64* @_asm_program_counter
  %84 = call i64 @_ITM_registerTMCloneTable()
  store i64 %84, i64* @rax
  ret i64 undef

dec_label_pc_4010e8:                              ; preds = %dec_label_pc_4010d4, %dec_label_pc_4010b0

; 0x4010e8
  store volatile i64 4198632, i64* @_asm_program_counter
  ret i64 undef
}

define i64 @__do_global_dtors_aux() {
dec_label_pc_4010f0:
  %stack_var_0 = alloca i64
  %stack_var_-8 = alloca i64

; 0x4010f0
  store volatile i64 4198640, i64* @_asm_program_counter

; 0x4010f4
  store volatile i64 4198644, i64* @_asm_program_counter
  %0 = load i8, i8* inttoptr (i64 4210724 to i8*)
  %1 = and i8 %0, 15
  %2 = icmp ugt i8 %1, 15
  %3 = icmp ult i8 %0, 0
  %4 = xor i8 %0, 0
  %5 = and i8 %4, 0
  %6 = icmp slt i8 %5, 0
  store i1 %2, i1* @az
  store i1 %3, i1* @cf
  store i1 %6, i1* @of
  %7 = icmp eq i8 %0, 0
  store i1 %7, i1* @zf
  %8 = icmp slt i8 %0, 0
  store i1 %8, i1* @sf
  %9 = call i8 @llvm.ctpop.i8(i8 %0)
  %10 = and i8 %9, 1
  %11 = icmp eq i8 %10, 0
  store i1 %11, i1* @pf

; 0x4010fb
  store volatile i64 4198651, i64* @_asm_program_counter
  %12 = load i1, i1* @zf
  %13 = icmp eq i1 %12, false
  br i1 %13, label %dec_label_pc_401110, label %dec_label_pc_4010fd

dec_label_pc_4010fd:                              ; preds = %dec_label_pc_4010f0

; 0x4010fd
  store volatile i64 4198653, i64* @_asm_program_counter
  %14 = load i64, i64* @rbp
  store i64 %14, i64* %stack_var_-8
  %15 = ptrtoint i64* %stack_var_-8 to i64
  store i64 %15, i64* @rsp

; 0x4010fe
  store volatile i64 4198654, i64* @_asm_program_counter
  %16 = ptrtoint i64* %stack_var_-8 to i64
  store i64 %16, i64* @rbp

; 0x401101
  store volatile i64 4198657, i64* @_asm_program_counter
  %17 = call i64 @deregister_tm_clones()
  store i64 %17, i64* @rax

; 0x401106
  store volatile i64 4198662, i64* @_asm_program_counter
  store i8 1, i8* inttoptr (i64 4210724 to i8*)

; 0x40110d
  store volatile i64 4198669, i64* @_asm_program_counter
  %18 = load i64, i64* %stack_var_-8
  store i64 %18, i64* @rbp
  %19 = ptrtoint i64* %stack_var_0 to i64
  store i64 %19, i64* @rsp

; 0x40110e
  store volatile i64 4198670, i64* @_asm_program_counter
  ret i64 undef

dec_label_pc_401110:                              ; preds = %dec_label_pc_4010f0

; 0x401110
  store volatile i64 4198672, i64* @_asm_program_counter
  ret i64 undef
}

define i64 @frame_dummy() {
dec_label_pc_401120:

; 0x401120
  store volatile i64 4198688, i64* @_asm_program_counter

; 0x401124
  store volatile i64 4198692, i64* @_asm_program_counter
  %0 = call i64 @register_tm_clones()
  store i64 %0, i64* @rax
  ret i64 undef
}

define i64 @add() {
dec_label_pc_401126:
  %stack_var_0 = alloca i64
  %stack_var_-20 = alloca i8
  %stack_var_-16 = alloca i64
  %stack_var_-8 = alloca i64

; 0x401126
  store volatile i64 4198694, i64* @_asm_program_counter
  %0 = load i64, i64* @rbp
  store i64 %0, i64* %stack_var_-8
  %1 = ptrtoint i64* %stack_var_-8 to i64
  store i64 %1, i64* @rsp

; 0x401127
  store volatile i64 4198695, i64* @_asm_program_counter
  %2 = ptrtoint i64* %stack_var_-8 to i64
  store i64 %2, i64* @rbp

; 0x40112a
  store volatile i64 4198698, i64* @_asm_program_counter
  %3 = load i64, i64* @rdi
  store i64 %3, i64* %stack_var_-16

; 0x40112e
  store volatile i64 4198702, i64* @_asm_program_counter
  %4 = load i64, i64* @rsi
  %5 = trunc i64 %4 to i32
  %6 = zext i32 %5 to i64
  store i64 %6, i64* @rax

; 0x401130
  store volatile i64 4198704, i64* @_asm_program_counter
  %7 = load i64, i64* @rax
  %8 = trunc i64 %7 to i8
  store i8 %8, i8* %stack_var_-20

; 0x401133
  store volatile i64 4198707, i64* @_asm_program_counter
  %9 = load i64, i64* %stack_var_-16
  store i64 %9, i64* @rax

; 0x401137
  store volatile i64 4198711, i64* @_asm_program_counter
  %10 = load i64, i64* @rax
  %11 = inttoptr i64 %10 to i32*
  %12 = load i32, i32* %11
  %13 = zext i32 %12 to i64
  store i64 %13, i64* @rdx

; 0x401139
  store volatile i64 4198713, i64* @_asm_program_counter
  %14 = load i8, i8* %stack_var_-20
  %15 = sext i8 %14 to i64
  store i64 %15, i64* @rax

; 0x40113d
  store volatile i64 4198717, i64* @_asm_program_counter
  %16 = load i64, i64* @rax
  %17 = trunc i64 %16 to i32
  %18 = load i64, i64* @rdx
  %19 = trunc i64 %18 to i32
  %20 = add i32 %17, %19
  %21 = and i32 %17, 15
  %22 = and i32 %19, 15
  %23 = add i32 %21, %22
  %24 = icmp ugt i32 %23, 15
  %25 = icmp ult i32 %20, %17
  %26 = xor i32 %17, %20
  %27 = xor i32 %19, %20
  %28 = and i32 %26, %27
  %29 = icmp slt i32 %28, 0
  store i1 %24, i1* @az
  store i1 %25, i1* @cf
  store i1 %29, i1* @of
  %30 = icmp eq i32 %20, 0
  store i1 %30, i1* @zf
  %31 = icmp slt i32 %20, 0
  store i1 %31, i1* @sf
  %32 = trunc i32 %20 to i8
  %33 = call i8 @llvm.ctpop.i8(i8 %32)
  %34 = and i8 %33, 1
  %35 = icmp eq i8 %34, 0
  store i1 %35, i1* @pf
  %36 = zext i32 %20 to i64
  store i64 %36, i64* @rax

; 0x40113f
  store volatile i64 4198719, i64* @_asm_program_counter
  %37 = load i64, i64* %stack_var_-8
  store i64 %37, i64* @rbp
  %38 = ptrtoint i64* %stack_var_0 to i64
  store i64 %38, i64* @rsp

; 0x401140
  store volatile i64 4198720, i64* @_asm_program_counter
  ret i64 undef
}

define i64 @main() {
dec_label_pc_401141:
  %stack_var_0 = alloca i64
  %stack_var_-28 = alloca i32
  %stack_var_-24 = alloca i64
  %stack_var_-16 = alloca i32
  %stack_var_-9 = alloca i8
  %stack_var_-32 = alloca i32
  %stack_var_-40 = alloca i64
  %stack_var_-8 = alloca i64

; 0x401141
  store volatile i64 4198721, i64* @_asm_program_counter
  %0 = load i64, i64* @rbp
  store i64 %0, i64* %stack_var_-8
  %1 = ptrtoint i64* %stack_var_-8 to i64
  store i64 %1, i64* @rsp

; 0x401142
  store volatile i64 4198722, i64* @_asm_program_counter
  %2 = ptrtoint i64* %stack_var_-8 to i64
  store i64 %2, i64* @rbp

; 0x401145
  store volatile i64 4198725, i64* @_asm_program_counter
  %3 = load i64, i64* @rsp
  %4 = sub i64 %3, 32
  %5 = and i64 %3, 15
  %6 = icmp ugt i64 %5, 15
  %7 = icmp ult i64 %3, 32
  %8 = xor i64 %3, 32
  %9 = xor i64 %3, %4
  %10 = and i64 %8, %9
  %11 = icmp slt i64 %10, 0
  store i1 %6, i1* @az
  store i1 %7, i1* @cf
  store i1 %11, i1* @of
  %12 = icmp eq i64 %4, 0
  store i1 %12, i1* @zf
  %13 = icmp slt i64 %4, 0
  store i1 %13, i1* @sf
  %14 = trunc i64 %4 to i8
  %15 = call i8 @llvm.ctpop.i8(i8 %14)
  %16 = and i8 %15, 1
  %17 = icmp eq i8 %16, 0
  store i1 %17, i1* @pf
  %18 = ptrtoint i64* %stack_var_-40 to i64
  store i64 %18, i64* @rsp

; 0x401149
  store volatile i64 4198729, i64* @_asm_program_counter
  store i32 1, i32* %stack_var_-32

; 0x401150
  store volatile i64 4198736, i64* @_asm_program_counter
  store i8 2, i8* %stack_var_-9

; 0x401154
  store volatile i64 4198740, i64* @_asm_program_counter
  %19 = load i8, i8* %stack_var_-9
  %20 = sext i8 %19 to i64
  store i64 %20, i64* @rdx

; 0x401158
  store volatile i64 4198744, i64* @_asm_program_counter
  %21 = ptrtoint i32* %stack_var_-32 to i64
  store i64 %21, i64* @rax

; 0x40115c
  store volatile i64 4198748, i64* @_asm_program_counter
  %22 = load i64, i64* @rdx
  %23 = trunc i64 %22 to i32
  %24 = zext i32 %23 to i64
  store i64 %24, i64* @rsi

; 0x40115e
  store volatile i64 4198750, i64* @_asm_program_counter
  %25 = ptrtoint i32* %stack_var_-32 to i64
  store i64 %25, i64* @rdi

; 0x401161
  store volatile i64 4198753, i64* @_asm_program_counter
  %26 = call i64 @add()
  store i64 %26, i64* @rax

; 0x401166
  store volatile i64 4198758, i64* @_asm_program_counter
  %27 = load i64, i64* @rax
  %28 = trunc i64 %27 to i32
  store i32 %28, i32* %stack_var_-16

; 0x401169
  store volatile i64 4198761, i64* @_asm_program_counter
  %29 = ptrtoint i32* %stack_var_-32 to i64
  store i64 %29, i64* @rax

; 0x40116d
  store volatile i64 4198765, i64* @_asm_program_counter
  %30 = ptrtoint i32* %stack_var_-32 to i64
  store i64 %30, i64* %stack_var_-24

; 0x401171
  store volatile i64 4198769, i64* @_asm_program_counter
  %31 = load i8, i8* %stack_var_-9
  %32 = sext i8 %31 to i64
  store i64 %32, i64* @rdx

; 0x401175
  store volatile i64 4198773, i64* @_asm_program_counter
  %33 = load i64, i64* %stack_var_-24
  store i64 %33, i64* @rax

; 0x401179
  store volatile i64 4198777, i64* @_asm_program_counter
  %34 = load i64, i64* @rdx
  %35 = trunc i64 %34 to i32
  %36 = zext i32 %35 to i64
  store i64 %36, i64* @rsi

; 0x40117b
  store volatile i64 4198779, i64* @_asm_program_counter
  %37 = load i64, i64* @rax
  store i64 %37, i64* @rdi

; 0x40117e
  store volatile i64 4198782, i64* @_asm_program_counter
  %38 = call i64 @add()
  store i64 %38, i64* @rax

; 0x401183
  store volatile i64 4198787, i64* @_asm_program_counter
  %39 = load i64, i64* @rax
  %40 = trunc i64 %39 to i32
  store i32 %40, i32* %stack_var_-28

; 0x401186
  store volatile i64 4198790, i64* @_asm_program_counter
  %41 = load i32, i32* %stack_var_-16
  %42 = zext i32 %41 to i64
  store i64 %42, i64* @rax

; 0x401189
  store volatile i64 4198793, i64* @_asm_program_counter
  %43 = load i64, i64* @rax
  %44 = trunc i64 %43 to i32
  %45 = zext i32 %44 to i64
  store i64 %45, i64* @rsi

; 0x40118b
  store volatile i64 4198795, i64* @_asm_program_counter
  store i64 4202512, i64* @rdi

; 0x401190
  store volatile i64 4198800, i64* @_asm_program_counter
  store i64 0, i64* @rax

; 0x401195
  store volatile i64 4198805, i64* @_asm_program_counter
  %46 = call i64 @function_401030()
  store i64 %46, i64* @rax

; 0x40119a
  store volatile i64 4198810, i64* @_asm_program_counter
  store i64 0, i64* @rax

; 0x40119f
  store volatile i64 4198815, i64* @_asm_program_counter
  %47 = load i64, i64* %stack_var_-8
  store i64 %47, i64* @rbp
  %48 = ptrtoint i64* %stack_var_0 to i64
  store i64 %48, i64* @rsp

; 0x4011a0
  store volatile i64 4198816, i64* @_asm_program_counter
  ret i64 undef
}

define i64 @_fini() {
dec_label_pc_4011a4:
  %stack_var_0 = alloca i64
  %stack_var_-8 = alloca i64

; 0x4011a4
  store volatile i64 4198820, i64* @_asm_program_counter

; 0x4011a8
  store volatile i64 4198824, i64* @_asm_program_counter
  %0 = load i64, i64* @rsp
  %1 = sub i64 %0, 8
  %2 = and i64 %0, 15
  %3 = sub i64 %2, 8
  %4 = icmp ugt i64 %3, 15
  %5 = icmp ult i64 %0, 8
  %6 = xor i64 %0, 8
  %7 = xor i64 %0, %1
  %8 = and i64 %6, %7
  %9 = icmp slt i64 %8, 0
  store i1 %4, i1* @az
  store i1 %5, i1* @cf
  store i1 %9, i1* @of
  %10 = icmp eq i64 %1, 0
  store i1 %10, i1* @zf
  %11 = icmp slt i64 %1, 0
  store i1 %11, i1* @sf
  %12 = trunc i64 %1 to i8
  %13 = call i8 @llvm.ctpop.i8(i8 %12)
  %14 = and i8 %13, 1
  %15 = icmp eq i8 %14, 0
  store i1 %15, i1* @pf
  %16 = ptrtoint i64* %stack_var_-8 to i64
  store i64 %16, i64* @rsp

; 0x4011ac
  store volatile i64 4198828, i64* @_asm_program_counter
  %17 = load i64, i64* @rsp
  %18 = add i64 %17, 8
  %19 = and i64 %17, 15
  %20 = add i64 %19, 8
  %21 = icmp ugt i64 %20, 15
  %22 = icmp ult i64 %18, %17
  %23 = xor i64 %17, %18
  %24 = xor i64 8, %18
  %25 = and i64 %23, %24
  %26 = icmp slt i64 %25, 0
  store i1 %21, i1* @az
  store i1 %22, i1* @cf
  store i1 %26, i1* @of
  %27 = icmp eq i64 %18, 0
  store i1 %27, i1* @zf
  %28 = icmp slt i64 %18, 0
  store i1 %28, i1* @sf
  %29 = trunc i64 %18 to i8
  %30 = call i8 @llvm.ctpop.i8(i8 %29)
  %31 = and i8 %30, 1
  %32 = icmp eq i8 %31, 0
  store i1 %32, i1* @pf
  %33 = ptrtoint i64* %stack_var_0 to i64
  store i64 %33, i64* @rsp

; 0x4011b0
  store volatile i64 4198832, i64* @_asm_program_counter
  ret i64 undef
}

declare i64 @__libc_start_main()

declare i64 @_ITM_deregisterTMCloneTable()

declare i64 @__gmon_start__()

declare i64 @_ITM_registerTMCloneTable()

declare i64 @printf()

declare void @__pseudo_call(i64)

declare void @__pseudo_return(i64)

declare void @__pseudo_branch(i64)

declare void @__pseudo_cond_branch(i1, i64)

declare void @__frontend_reg_store.fpr(i3, x86_fp80)

declare x86_fp80 @__frontend_reg_load.fpr(i3)

; Function Attrs: nounwind readnone speculatable
declare i8 @llvm.ctpop.i8(i8) #0

declare void @__asm_hlt()

attributes #0 = { nounwind readnone speculatable }
*** IR Dump After Constants optimization ***
source_filename = "test"
target datalayout = "e-m:e-p:64:64-i64:64-f80:128-n8:16:32:64-S128"

@_asm_program_counter = internal global i64 0
@cf = internal global i1 false
@pf = internal global i1 false
@az = internal global i1 false
@zf = internal global i1 false
@sf = internal global i1 false
@tf = internal global i1 false
@if = internal global i1 false
@df = internal global i1 false
@of = internal global i1 false
@iopl = internal global i2 0
@nt = internal global i1 false
@rf = internal global i1 false
@vm = internal global i1 false
@ac = internal global i1 false
@vif = internal global i1 false
@vip = internal global i1 false
@id = internal global i1 false
@rflags = internal global i64 0
@ss = internal global i16 0
@cs = internal global i16 0
@ds = internal global i16 0
@es = internal global i16 0
@fs = internal global i16 0
@gs = internal global i16 0
@st0 = internal global x86_fp80 0xK00000000000000000000
@st1 = internal global x86_fp80 0xK00000000000000000000
@st2 = internal global x86_fp80 0xK00000000000000000000
@st3 = internal global x86_fp80 0xK00000000000000000000
@st4 = internal global x86_fp80 0xK00000000000000000000
@st5 = internal global x86_fp80 0xK00000000000000000000
@st6 = internal global x86_fp80 0xK00000000000000000000
@st7 = internal global x86_fp80 0xK00000000000000000000
@fpu_stat_IE = internal global i1 false
@fpu_stat_DE = internal global i1 false
@fpu_stat_ZE = internal global i1 false
@fpu_stat_OE = internal global i1 false
@fpu_stat_UE = internal global i1 false
@fpu_stat_PE = internal global i1 false
@fpu_stat_SF = internal global i1 false
@fpu_stat_ES = internal global i1 false
@fpu_stat_C0 = internal global i1 false
@fpu_stat_C1 = internal global i1 false
@fpu_stat_C2 = internal global i1 false
@fpu_stat_C3 = internal global i1 false
@fpu_stat_TOP = internal global i3 0
@fpu_stat_B = internal global i1 false
@fpu_control_IM = internal global i1 false
@fpu_control_DM = internal global i1 false
@fpu_control_ZM = internal global i1 false
@fpu_control_OM = internal global i1 false
@fpu_control_UM = internal global i1 false
@fpu_control_PM = internal global i1 false
@fpu_control_PC = internal global i2 0
@fpu_control_RC = internal global i2 0
@fpu_control_X = internal global i1 false
@fp0 = internal global double 0.000000e+00
@fp1 = internal global double 0.000000e+00
@fp2 = internal global double 0.000000e+00
@fp3 = internal global double 0.000000e+00
@fp4 = internal global double 0.000000e+00
@fp5 = internal global double 0.000000e+00
@fp6 = internal global double 0.000000e+00
@fp7 = internal global double 0.000000e+00
@k0 = internal global i64 0
@k1 = internal global i64 0
@k2 = internal global i64 0
@k3 = internal global i64 0
@k4 = internal global i64 0
@k5 = internal global i64 0
@k6 = internal global i64 0
@k7 = internal global i64 0
@mm0 = internal global i64 0
@mm1 = internal global i64 0
@mm2 = internal global i64 0
@mm3 = internal global i64 0
@mm4 = internal global i64 0
@mm5 = internal global i64 0
@mm6 = internal global i64 0
@mm7 = internal global i64 0
@xmm0 = internal global i128 0
@xmm1 = internal global i128 0
@xmm2 = internal global i128 0
@xmm3 = internal global i128 0
@xmm4 = internal global i128 0
@xmm5 = internal global i128 0
@xmm6 = internal global i128 0
@xmm7 = internal global i128 0
@xmm8 = internal global i128 0
@xmm9 = internal global i128 0
@xmm10 = internal global i128 0
@xmm11 = internal global i128 0
@xmm12 = internal global i128 0
@xmm13 = internal global i128 0
@xmm14 = internal global i128 0
@xmm15 = internal global i128 0
@xmm16 = internal global i128 0
@xmm17 = internal global i128 0
@xmm18 = internal global i128 0
@xmm19 = internal global i128 0
@xmm20 = internal global i128 0
@xmm21 = internal global i128 0
@xmm22 = internal global i128 0
@xmm23 = internal global i128 0
@xmm24 = internal global i128 0
@xmm25 = internal global i128 0
@xmm26 = internal global i128 0
@xmm27 = internal global i128 0
@xmm28 = internal global i128 0
@xmm29 = internal global i128 0
@xmm30 = internal global i128 0
@xmm31 = internal global i128 0
@ymm0 = internal global i256 0
@ymm1 = internal global i256 0
@ymm2 = internal global i256 0
@ymm3 = internal global i256 0
@ymm4 = internal global i256 0
@ymm5 = internal global i256 0
@ymm6 = internal global i256 0
@ymm7 = internal global i256 0
@ymm8 = internal global i256 0
@ymm9 = internal global i256 0
@ymm10 = internal global i256 0
@ymm11 = internal global i256 0
@ymm12 = internal global i256 0
@ymm13 = internal global i256 0
@ymm14 = internal global i256 0
@ymm15 = internal global i256 0
@ymm16 = internal global i256 0
@ymm17 = internal global i256 0
@ymm18 = internal global i256 0
@ymm19 = internal global i256 0
@ymm20 = internal global i256 0
@ymm21 = internal global i256 0
@ymm22 = internal global i256 0
@ymm23 = internal global i256 0
@ymm24 = internal global i256 0
@ymm25 = internal global i256 0
@ymm26 = internal global i256 0
@ymm27 = internal global i256 0
@ymm28 = internal global i256 0
@ymm29 = internal global i256 0
@ymm30 = internal global i256 0
@ymm31 = internal global i256 0
@zmm0 = internal global i512 0
@zmm1 = internal global i512 0
@zmm2 = internal global i512 0
@zmm3 = internal global i512 0
@zmm4 = internal global i512 0
@zmm5 = internal global i512 0
@zmm6 = internal global i512 0
@zmm7 = internal global i512 0
@zmm8 = internal global i512 0
@zmm9 = internal global i512 0
@zmm10 = internal global i512 0
@zmm11 = internal global i512 0
@zmm12 = internal global i512 0
@zmm13 = internal global i512 0
@zmm14 = internal global i512 0
@zmm15 = internal global i512 0
@zmm16 = internal global i512 0
@zmm17 = internal global i512 0
@zmm18 = internal global i512 0
@zmm19 = internal global i512 0
@zmm20 = internal global i512 0
@zmm21 = internal global i512 0
@zmm22 = internal global i512 0
@zmm23 = internal global i512 0
@zmm24 = internal global i512 0
@zmm25 = internal global i512 0
@zmm26 = internal global i512 0
@zmm27 = internal global i512 0
@zmm28 = internal global i512 0
@zmm29 = internal global i512 0
@zmm30 = internal global i512 0
@zmm31 = internal global i512 0
@bnd0 = internal global i128 0
@bnd1 = internal global i128 0
@bnd2 = internal global i128 0
@bnd3 = internal global i128 0
@dr0 = internal global i64 0
@dr1 = internal global i64 0
@dr2 = internal global i64 0
@dr3 = internal global i64 0
@dr4 = internal global i64 0
@dr5 = internal global i64 0
@dr6 = internal global i64 0
@dr7 = internal global i64 0
@dr8 = internal global i64 0
@dr9 = internal global i64 0
@dr10 = internal global i64 0
@dr11 = internal global i64 0
@dr12 = internal global i64 0
@dr13 = internal global i64 0
@dr14 = internal global i64 0
@dr15 = internal global i64 0
@cr0 = internal global i64 0
@cr1 = internal global i64 0
@cr2 = internal global i64 0
@cr3 = internal global i64 0
@cr4 = internal global i64 0
@cr5 = internal global i64 0
@cr6 = internal global i64 0
@cr7 = internal global i64 0
@cr8 = internal global i64 0
@cr9 = internal global i64 0
@cr10 = internal global i64 0
@cr11 = internal global i64 0
@cr12 = internal global i64 0
@cr13 = internal global i64 0
@cr14 = internal global i64 0
@cr15 = internal global i64 0
@fpsw = internal global i64 0
@rax = internal global i64 0
@rcx = internal global i64 0
@rdx = internal global i64 0
@rbx = internal global i64 0
@rsp = internal global i64 0
@rbp = internal global i64 0
@rsi = internal global i64 0
@rdi = internal global i64 0
@r8 = internal global i64 0
@r9 = internal global i64 0
@r10 = internal global i64 0
@r11 = internal global i64 0
@r12 = internal global i64 0
@r13 = internal global i64 0
@r14 = internal global i64 0
@r15 = internal global i64 0
@rip = internal global i64 0
@riz = internal global i64 0
@global_var_403ff8 = global i64 0
@global_var_404024 = external global i64
@global_var_402010 = constant [4 x i8] c"%d\0A\00"

define i64 @_init() {
dec_label_pc_401000:
  %stack_var_0 = alloca i64
  %stack_var_-8 = alloca i64

; 0x401000
  store volatile i64 4198400, i64* @_asm_program_counter

; 0x401004
  store volatile i64 4198404, i64* @_asm_program_counter
  %0 = load i64, i64* @rsp
  %1 = sub i64 %0, 8
  %2 = and i64 %0, 15
  %3 = sub i64 %2, 8
  %4 = icmp ugt i64 %3, 15
  %5 = icmp ult i64 %0, 8
  %6 = xor i64 %0, 8
  %7 = xor i64 %0, %1
  %8 = and i64 %6, %7
  %9 = icmp slt i64 %8, 0
  store i1 %4, i1* @az
  store i1 %5, i1* @cf
  store i1 %9, i1* @of
  %10 = icmp eq i64 %1, 0
  store i1 %10, i1* @zf
  %11 = icmp slt i64 %1, 0
  store i1 %11, i1* @sf
  %12 = trunc i64 %1 to i8
  %13 = call i8 @llvm.ctpop.i8(i8 %12)
  %14 = and i8 %13, 1
  %15 = icmp eq i8 %14, 0
  store i1 %15, i1* @pf
  %16 = ptrtoint i64* %stack_var_-8 to i64
  store i64 %16, i64* @rsp

; 0x401008
  store volatile i64 4198408, i64* @_asm_program_counter
  %17 = load i64, i64* inttoptr (i64 4210672 to i64*)
  store i64 %17, i64* @rax

; 0x40100f
  store volatile i64 4198415, i64* @_asm_program_counter
  %18 = load i64, i64* @rax
  store i1 false, i1* @az
  store i1 false, i1* @cf
  store i1 false, i1* @of
  %19 = icmp eq i64 %18, 0
  store i1 %19, i1* @zf
  %20 = icmp slt i64 %18, 0
  store i1 %20, i1* @sf
  %21 = trunc i64 %18 to i8
  %22 = call i8 @llvm.ctpop.i8(i8 %21)
  %23 = and i8 %22, 1
  %24 = icmp eq i8 %23, 0
  store i1 %24, i1* @pf

; 0x401012
  store volatile i64 4198418, i64* @_asm_program_counter
  %25 = load i1, i1* @zf
  br i1 %25, label %dec_label_pc_401016, label %dec_label_pc_401014

dec_label_pc_401014:                              ; preds = %dec_label_pc_401000

; 0x401014
  store volatile i64 4198420, i64* @_asm_program_counter
  %26 = call i64 @__gmon_start__()
  store i64 %26, i64* @rax
  br label %dec_label_pc_401016

dec_label_pc_401016:                              ; preds = %dec_label_pc_401014, %dec_label_pc_401000

; 0x401016
  store volatile i64 4198422, i64* @_asm_program_counter
  %27 = load i64, i64* @rsp
  %28 = add i64 %27, 8
  %29 = and i64 %27, 15
  %30 = add i64 %29, 8
  %31 = icmp ugt i64 %30, 15
  %32 = icmp ult i64 %28, %27
  %33 = xor i64 %27, %28
  %34 = xor i64 8, %28
  %35 = and i64 %33, %34
  %36 = icmp slt i64 %35, 0
  store i1 %31, i1* @az
  store i1 %32, i1* @cf
  store i1 %36, i1* @of
  %37 = icmp eq i64 %28, 0
  store i1 %37, i1* @zf
  %38 = icmp slt i64 %28, 0
  store i1 %38, i1* @sf
  %39 = trunc i64 %28 to i8
  %40 = call i8 @llvm.ctpop.i8(i8 %39)
  %41 = and i8 %40, 1
  %42 = icmp eq i8 %41, 0
  store i1 %42, i1* @pf
  %43 = ptrtoint i64* %stack_var_0 to i64
  store i64 %43, i64* @rsp

; 0x40101a
  store volatile i64 4198426, i64* @_asm_program_counter
  ret i64 undef
}

define i64 @function_401030() {
dec_label_pc_401030:

; 0x401030
  store volatile i64 4198448, i64* @_asm_program_counter
  %0 = call i64 @printf()
  store i64 %0, i64* @rax
  ret i64 undef
}

define i64 @_start() {
dec_label_pc_401040:
  %stack_var_-16 = alloca i64
  %stack_var_-8 = alloca i64
  %stack_var_8 = alloca i64
  %stack_var_0 = alloca i64

; 0x401040
  store volatile i64 4198464, i64* @_asm_program_counter

; 0x401044
  store volatile i64 4198468, i64* @_asm_program_counter
  %0 = load i64, i64* @rbp
  %1 = trunc i64 %0 to i32
  %2 = load i64, i64* @rbp
  %3 = trunc i64 %2 to i32
  %4 = xor i32 %1, %3
  store i1 false, i1* @az
  store i1 false, i1* @cf
  store i1 false, i1* @of
  %5 = icmp eq i32 %4, 0
  store i1 %5, i1* @zf
  %6 = icmp slt i32 %4, 0
  store i1 %6, i1* @sf
  %7 = trunc i32 %4 to i8
  %8 = call i8 @llvm.ctpop.i8(i8 %7)
  %9 = and i8 %8, 1
  %10 = icmp eq i8 %9, 0
  store i1 %10, i1* @pf
  %11 = zext i32 %4 to i64
  store i64 %11, i64* @rbp

; 0x401046
  store volatile i64 4198470, i64* @_asm_program_counter
  %12 = load i64, i64* @rdx
  store i64 %12, i64* @r9

; 0x401049
  store volatile i64 4198473, i64* @_asm_program_counter
  %13 = load i64, i64* %stack_var_0
  store i64 %13, i64* @rsi
  %14 = ptrtoint i64* %stack_var_8 to i64
  store i64 %14, i64* @rsp

; 0x40104a
  store volatile i64 4198474, i64* @_asm_program_counter
  %15 = ptrtoint i64* %stack_var_8 to i64
  store i64 %15, i64* @rdx

; 0x40104d
  store volatile i64 4198477, i64* @_asm_program_counter
  %16 = load i64, i64* @rsp
  %17 = and i64 %16, -16
  store i1 false, i1* @az
  store i1 false, i1* @cf
  store i1 false, i1* @of
  %18 = icmp eq i64 %17, 0
  store i1 %18, i1* @zf
  %19 = icmp slt i64 %17, 0
  store i1 %19, i1* @sf
  %20 = trunc i64 %17 to i8
  %21 = call i8 @llvm.ctpop.i8(i8 %20)
  %22 = and i8 %21, 1
  %23 = icmp eq i8 %22, 0
  store i1 %23, i1* @pf
  %24 = ptrtoint i64* %stack_var_0 to i64
  store i64 %24, i64* @rsp

; 0x401051
  store volatile i64 4198481, i64* @_asm_program_counter
  %25 = load i64, i64* @rax
  store i64 %25, i64* %stack_var_-8
  %26 = ptrtoint i64* %stack_var_-8 to i64
  store i64 %26, i64* @rsp

; 0x401052
  store volatile i64 4198482, i64* @_asm_program_counter
  %27 = ptrtoint i64* %stack_var_-8 to i64
  store i64 %27, i64* %stack_var_-16
  %28 = ptrtoint i64* %stack_var_-16 to i64
  store i64 %28, i64* @rsp

; 0x401053
  store volatile i64 4198483, i64* @_asm_program_counter
  %29 = load i64, i64* @r8
  %30 = trunc i64 %29 to i32
  %31 = load i64, i64* @r8
  %32 = trunc i64 %31 to i32
  %33 = xor i32 %30, %32
  store i1 false, i1* @az
  store i1 false, i1* @cf
  store i1 false, i1* @of
  %34 = icmp eq i32 %33, 0
  store i1 %34, i1* @zf
  %35 = icmp slt i32 %33, 0
  store i1 %35, i1* @sf
  %36 = trunc i32 %33 to i8
  %37 = call i8 @llvm.ctpop.i8(i8 %36)
  %38 = and i8 %37, 1
  %39 = icmp eq i8 %38, 0
  store i1 %39, i1* @pf
  %40 = zext i32 %33 to i64
  store i64 %40, i64* @r8

; 0x401056
  store volatile i64 4198486, i64* @_asm_program_counter
  %41 = load i64, i64* @rcx
  %42 = trunc i64 %41 to i32
  %43 = load i64, i64* @rcx
  %44 = trunc i64 %43 to i32
  %45 = xor i32 %42, %44
  store i1 false, i1* @az
  store i1 false, i1* @cf
  store i1 false, i1* @of
  %46 = icmp eq i32 %45, 0
  store i1 %46, i1* @zf
  %47 = icmp slt i32 %45, 0
  store i1 %47, i1* @sf
  %48 = trunc i32 %45 to i8
  %49 = call i8 @llvm.ctpop.i8(i8 %48)
  %50 = and i8 %49, 1
  %51 = icmp eq i8 %50, 0
  store i1 %51, i1* @pf
  %52 = zext i32 %45 to i64
  store i64 %52, i64* @rcx

; 0x401058
  store volatile i64 4198488, i64* @_asm_program_counter
  store i64 4198721, i64* @rdi

; 0x40105f
  store volatile i64 4198495, i64* @_asm_program_counter
  %53 = call i64 @__libc_start_main()
  store i64 %53, i64* @rax

; 0x401065
  store volatile i64 4198501, i64* @_asm_program_counter
  call void @__asm_hlt()
  unreachable
}

define i64 @_dl_relocate_static_pie() {
dec_label_pc_401070:

; 0x401070
  store volatile i64 4198512, i64* @_asm_program_counter

; 0x401074
  store volatile i64 4198516, i64* @_asm_program_counter
  ret i64 undef
}

define i64 @deregister_tm_clones() {
dec_label_pc_401080:

; 0x401080
  store volatile i64 4198528, i64* @_asm_program_counter
  store i64 4210728, i64* @rdi

; 0x401087
  store volatile i64 4198535, i64* @_asm_program_counter
  store i64 4210728, i64* @rax

; 0x40108e
  store volatile i64 4198542, i64* @_asm_program_counter
  %0 = load i64, i64* @rax
  %1 = load i64, i64* @rdi
  %2 = sub i64 %0, %1
  %3 = and i64 %0, 15
  %4 = and i64 %1, 15
  %5 = sub i64 %3, %4
  %6 = icmp ugt i64 %5, 15
  %7 = icmp ult i64 %0, %1
  %8 = xor i64 %0, %1
  %9 = xor i64 %0, %2
  %10 = and i64 %8, %9
  %11 = icmp slt i64 %10, 0
  store i1 %6, i1* @az
  store i1 %7, i1* @cf
  store i1 %11, i1* @of
  %12 = icmp eq i64 %2, 0
  store i1 %12, i1* @zf
  %13 = icmp slt i64 %2, 0
  store i1 %13, i1* @sf
  %14 = trunc i64 %2 to i8
  %15 = call i8 @llvm.ctpop.i8(i8 %14)
  %16 = and i8 %15, 1
  %17 = icmp eq i8 %16, 0
  store i1 %17, i1* @pf

; 0x401091
  store volatile i64 4198545, i64* @_asm_program_counter
  %18 = load i1, i1* @zf
  br i1 %18, label %dec_label_pc_4010a8, label %dec_label_pc_401093

dec_label_pc_401093:                              ; preds = %dec_label_pc_401080

; 0x401093
  store volatile i64 4198547, i64* @_asm_program_counter
  %19 = load i64, i64* inttoptr (i64 4210664 to i64*)
  store i64 %19, i64* @rax

; 0x40109a
  store volatile i64 4198554, i64* @_asm_program_counter
  %20 = load i64, i64* @rax
  store i1 false, i1* @az
  store i1 false, i1* @cf
  store i1 false, i1* @of
  %21 = icmp eq i64 %20, 0
  store i1 %21, i1* @zf
  %22 = icmp slt i64 %20, 0
  store i1 %22, i1* @sf
  %23 = trunc i64 %20 to i8
  %24 = call i8 @llvm.ctpop.i8(i8 %23)
  %25 = and i8 %24, 1
  %26 = icmp eq i8 %25, 0
  store i1 %26, i1* @pf

; 0x40109d
  store volatile i64 4198557, i64* @_asm_program_counter
  %27 = load i1, i1* @zf
  br i1 %27, label %dec_label_pc_4010a8, label %dec_label_pc_40109f

dec_label_pc_40109f:                              ; preds = %dec_label_pc_401093

; 0x40109f
  store volatile i64 4198559, i64* @_asm_program_counter
  %28 = call i64 @_ITM_deregisterTMCloneTable()
  store i64 %28, i64* @rax
  ret i64 undef

dec_label_pc_4010a8:                              ; preds = %dec_label_pc_401093, %dec_label_pc_401080

; 0x4010a8
  store volatile i64 4198568, i64* @_asm_program_counter
  ret i64 undef
}

define i64 @register_tm_clones() {
dec_label_pc_4010b0:

; 0x4010b0
  store volatile i64 4198576, i64* @_asm_program_counter
  store i64 4210728, i64* @rdi

; 0x4010b7
  store volatile i64 4198583, i64* @_asm_program_counter
  store i64 4210728, i64* @rsi

; 0x4010be
  store volatile i64 4198590, i64* @_asm_program_counter
  %0 = load i64, i64* @rsi
  %1 = load i64, i64* @rdi
  %2 = sub i64 %0, %1
  %3 = and i64 %0, 15
  %4 = and i64 %1, 15
  %5 = sub i64 %3, %4
  %6 = icmp ugt i64 %5, 15
  %7 = icmp ult i64 %0, %1
  %8 = xor i64 %0, %1
  %9 = xor i64 %0, %2
  %10 = and i64 %8, %9
  %11 = icmp slt i64 %10, 0
  store i1 %6, i1* @az
  store i1 %7, i1* @cf
  store i1 %11, i1* @of
  %12 = icmp eq i64 %2, 0
  store i1 %12, i1* @zf
  %13 = icmp slt i64 %2, 0
  store i1 %13, i1* @sf
  %14 = trunc i64 %2 to i8
  %15 = call i8 @llvm.ctpop.i8(i8 %14)
  %16 = and i8 %15, 1
  %17 = icmp eq i8 %16, 0
  store i1 %17, i1* @pf
  store i64 %2, i64* @rsi

; 0x4010c1
  store volatile i64 4198593, i64* @_asm_program_counter
  %18 = load i64, i64* @rsi
  store i64 %18, i64* @rax

; 0x4010c4
  store volatile i64 4198596, i64* @_asm_program_counter
  %19 = load i64, i64* @rsi
  %20 = load i1, i1* @of
  %21 = lshr i64 %19, 63
  %22 = icmp eq i64 %21, 0
  store i1 %22, i1* @zf
  %23 = icmp slt i64 %21, 0
  store i1 %23, i1* @sf
  %24 = trunc i64 %21 to i8
  %25 = call i8 @llvm.ctpop.i8(i8 %24)
  %26 = and i8 %25, 1
  %27 = icmp eq i8 %26, 0
  store i1 %27, i1* @pf
  store i64 %21, i64* @rsi
  %28 = and i64 4611686018427387904, %19
  %29 = icmp ne i64 %28, 0
  store i1 %29, i1* @cf
  %30 = icmp slt i64 %19, 0
  %31 = select i1 false, i1 %30, i1 %20
  store i1 %31, i1* @of

; 0x4010c8
  store volatile i64 4198600, i64* @_asm_program_counter
  %32 = load i64, i64* @rax
  %33 = load i1, i1* @of
  %34 = ashr i64 %32, 3
  %35 = icmp eq i64 %34, 0
  store i1 %35, i1* @zf
  %36 = icmp slt i64 %34, 0
  store i1 %36, i1* @sf
  %37 = trunc i64 %34 to i8
  %38 = call i8 @llvm.ctpop.i8(i8 %37)
  %39 = and i8 %38, 1
  %40 = icmp eq i8 %39, 0
  store i1 %40, i1* @pf
  store i64 %34, i64* @rax
  %41 = and i64 4, %32
  %42 = icmp ne i64 %41, 0
  store i1 %42, i1* @cf
  %43 = select i1 false, i1 false, i1 %33
  store i1 %43, i1* @of

; 0x4010cc
  store volatile i64 4198604, i64* @_asm_program_counter
  %44 = load i64, i64* @rsi
  %45 = load i64, i64* @rax
  %46 = add i64 %44, %45
  %47 = and i64 %44, 15
  %48 = and i64 %45, 15
  %49 = add i64 %47, %48
  %50 = icmp ugt i64 %49, 15
  %51 = icmp ult i64 %46, %44
  %52 = xor i64 %44, %46
  %53 = xor i64 %45, %46
  %54 = and i64 %52, %53
  %55 = icmp slt i64 %54, 0
  store i1 %50, i1* @az
  store i1 %51, i1* @cf
  store i1 %55, i1* @of
  %56 = icmp eq i64 %46, 0
  store i1 %56, i1* @zf
  %57 = icmp slt i64 %46, 0
  store i1 %57, i1* @sf
  %58 = trunc i64 %46 to i8
  %59 = call i8 @llvm.ctpop.i8(i8 %58)
  %60 = and i8 %59, 1
  %61 = icmp eq i8 %60, 0
  store i1 %61, i1* @pf
  store i64 %46, i64* @rsi

; 0x4010cf
  store volatile i64 4198607, i64* @_asm_program_counter
  %62 = load i64, i64* @rsi
  %63 = load i1, i1* @of
  %64 = ashr i64 %62, 1
  %65 = icmp eq i64 %64, 0
  store i1 %65, i1* @zf
  %66 = icmp slt i64 %64, 0
  store i1 %66, i1* @sf
  %67 = trunc i64 %64 to i8
  %68 = call i8 @llvm.ctpop.i8(i8 %67)
  %69 = and i8 %68, 1
  %70 = icmp eq i8 %69, 0
  store i1 %70, i1* @pf
  store i64 %64, i64* @rsi
  %71 = and i64 1, %62
  %72 = icmp ne i64 %71, 0
  store i1 %72, i1* @cf
  %73 = select i1 true, i1 false, i1 %63
  store i1 %73, i1* @of

; 0x4010d2
  store volatile i64 4198610, i64* @_asm_program_counter
  %74 = load i1, i1* @zf
  br i1 %74, label %dec_label_pc_4010e8, label %dec_label_pc_4010d4

dec_label_pc_4010d4:                              ; preds = %dec_label_pc_4010b0

; 0x4010d4
  store volatile i64 4198612, i64* @_asm_program_counter
  %75 = load i64, i64* @global_var_403ff8
  store i64 %75, i64* @rax

; 0x4010db
  store volatile i64 4198619, i64* @_asm_program_counter
  %76 = load i64, i64* @rax
  store i1 false, i1* @az
  store i1 false, i1* @cf
  store i1 false, i1* @of
  %77 = icmp eq i64 %76, 0
  store i1 %77, i1* @zf
  %78 = icmp slt i64 %76, 0
  store i1 %78, i1* @sf
  %79 = trunc i64 %76 to i8
  %80 = call i8 @llvm.ctpop.i8(i8 %79)
  %81 = and i8 %80, 1
  %82 = icmp eq i8 %81, 0
  store i1 %82, i1* @pf

; 0x4010de
  store volatile i64 4198622, i64* @_asm_program_counter
  %83 = load i1, i1* @zf
  br i1 %83, label %dec_label_pc_4010e8, label %dec_label_pc_4010e0

dec_label_pc_4010e0:                              ; preds = %dec_label_pc_4010d4

; 0x4010e0
  store volatile i64 4198624, i64* @_asm_program_counter
  %84 = call i64 @_ITM_registerTMCloneTable()
  store i64 %84, i64* @rax
  ret i64 undef

dec_label_pc_4010e8:                              ; preds = %dec_label_pc_4010d4, %dec_label_pc_4010b0

; 0x4010e8
  store volatile i64 4198632, i64* @_asm_program_counter
  ret i64 undef
}

define i64 @__do_global_dtors_aux() {
dec_label_pc_4010f0:
  %stack_var_0 = alloca i64
  %stack_var_-8 = alloca i64

; 0x4010f0
  store volatile i64 4198640, i64* @_asm_program_counter

; 0x4010f4
  store volatile i64 4198644, i64* @_asm_program_counter
  %0 = load i8, i8* inttoptr (i64 4210724 to i8*)
  %1 = and i8 %0, 15
  %2 = icmp ugt i8 %1, 15
  %3 = icmp ult i8 %0, 0
  %4 = xor i8 %0, 0
  %5 = and i8 %4, 0
  %6 = icmp slt i8 %5, 0
  store i1 %2, i1* @az
  store i1 %3, i1* @cf
  store i1 %6, i1* @of
  %7 = icmp eq i8 %0, 0
  store i1 %7, i1* @zf
  %8 = icmp slt i8 %0, 0
  store i1 %8, i1* @sf
  %9 = call i8 @llvm.ctpop.i8(i8 %0)
  %10 = and i8 %9, 1
  %11 = icmp eq i8 %10, 0
  store i1 %11, i1* @pf

; 0x4010fb
  store volatile i64 4198651, i64* @_asm_program_counter
  %12 = load i1, i1* @zf
  %13 = icmp eq i1 %12, false
  br i1 %13, label %dec_label_pc_401110, label %dec_label_pc_4010fd

dec_label_pc_4010fd:                              ; preds = %dec_label_pc_4010f0

; 0x4010fd
  store volatile i64 4198653, i64* @_asm_program_counter
  %14 = load i64, i64* @rbp
  store i64 %14, i64* %stack_var_-8
  %15 = ptrtoint i64* %stack_var_-8 to i64
  store i64 %15, i64* @rsp

; 0x4010fe
  store volatile i64 4198654, i64* @_asm_program_counter
  %16 = ptrtoint i64* %stack_var_-8 to i64
  store i64 %16, i64* @rbp

; 0x401101
  store volatile i64 4198657, i64* @_asm_program_counter
  %17 = call i64 @deregister_tm_clones()
  store i64 %17, i64* @rax

; 0x401106
  store volatile i64 4198662, i64* @_asm_program_counter
  store i8 1, i8* bitcast (i64* @global_var_404024 to i8*)

; 0x40110d
  store volatile i64 4198669, i64* @_asm_program_counter
  %18 = load i64, i64* %stack_var_-8
  store i64 %18, i64* @rbp
  %19 = ptrtoint i64* %stack_var_0 to i64
  store i64 %19, i64* @rsp

; 0x40110e
  store volatile i64 4198670, i64* @_asm_program_counter
  ret i64 undef

dec_label_pc_401110:                              ; preds = %dec_label_pc_4010f0

; 0x401110
  store volatile i64 4198672, i64* @_asm_program_counter
  ret i64 undef
}

define i64 @frame_dummy() {
dec_label_pc_401120:

; 0x401120
  store volatile i64 4198688, i64* @_asm_program_counter

; 0x401124
  store volatile i64 4198692, i64* @_asm_program_counter
  %0 = call i64 @register_tm_clones()
  store i64 %0, i64* @rax
  ret i64 undef
}

define i64 @add() {
dec_label_pc_401126:
  %stack_var_0 = alloca i64
  %stack_var_-20 = alloca i8
  %stack_var_-16 = alloca i64
  %stack_var_-8 = alloca i64

; 0x401126
  store volatile i64 4198694, i64* @_asm_program_counter
  %0 = load i64, i64* @rbp
  store i64 %0, i64* %stack_var_-8
  %1 = ptrtoint i64* %stack_var_-8 to i64
  store i64 %1, i64* @rsp

; 0x401127
  store volatile i64 4198695, i64* @_asm_program_counter
  %2 = ptrtoint i64* %stack_var_-8 to i64
  store i64 %2, i64* @rbp

; 0x40112a
  store volatile i64 4198698, i64* @_asm_program_counter
  %3 = load i64, i64* @rdi
  store i64 %3, i64* %stack_var_-16

; 0x40112e
  store volatile i64 4198702, i64* @_asm_program_counter
  %4 = load i64, i64* @rsi
  %5 = trunc i64 %4 to i32
  %6 = zext i32 %5 to i64
  store i64 %6, i64* @rax

; 0x401130
  store volatile i64 4198704, i64* @_asm_program_counter
  %7 = load i64, i64* @rax
  %8 = trunc i64 %7 to i8
  store i8 %8, i8* %stack_var_-20

; 0x401133
  store volatile i64 4198707, i64* @_asm_program_counter
  %9 = load i64, i64* %stack_var_-16
  store i64 %9, i64* @rax

; 0x401137
  store volatile i64 4198711, i64* @_asm_program_counter
  %10 = load i32, i32* bitcast (i64* @rdi to i32*)
  %11 = zext i32 %10 to i64
  store i64 %11, i64* @rdx

; 0x401139
  store volatile i64 4198713, i64* @_asm_program_counter
  %12 = load i8, i8* %stack_var_-20
  %13 = sext i8 %12 to i64
  store i64 %13, i64* @rax

; 0x40113d
  store volatile i64 4198717, i64* @_asm_program_counter
  %14 = load i64, i64* @rax
  %15 = trunc i64 %14 to i32
  %16 = load i64, i64* @rdx
  %17 = trunc i64 %16 to i32
  %18 = add i32 %15, %17
  %19 = and i32 %15, 15
  %20 = and i32 %17, 15
  %21 = add i32 %19, %20
  %22 = icmp ugt i32 %21, 15
  %23 = icmp ult i32 %18, %15
  %24 = xor i32 %15, %18
  %25 = xor i32 %17, %18
  %26 = and i32 %24, %25
  %27 = icmp slt i32 %26, 0
  store i1 %22, i1* @az
  store i1 %23, i1* @cf
  store i1 %27, i1* @of
  %28 = icmp eq i32 %18, 0
  store i1 %28, i1* @zf
  %29 = icmp slt i32 %18, 0
  store i1 %29, i1* @sf
  %30 = trunc i32 %18 to i8
  %31 = call i8 @llvm.ctpop.i8(i8 %30)
  %32 = and i8 %31, 1
  %33 = icmp eq i8 %32, 0
  store i1 %33, i1* @pf
  %34 = zext i32 %18 to i64
  store i64 %34, i64* @rax

; 0x40113f
  store volatile i64 4198719, i64* @_asm_program_counter
  %35 = load i64, i64* %stack_var_-8
  store i64 %35, i64* @rbp
  %36 = ptrtoint i64* %stack_var_0 to i64
  store i64 %36, i64* @rsp

; 0x401140
  store volatile i64 4198720, i64* @_asm_program_counter
  ret i64 undef
}

define i64 @main() {
dec_label_pc_401141:
  %stack_var_0 = alloca i64
  %stack_var_-28 = alloca i32
  %stack_var_-24 = alloca i64
  %stack_var_-16 = alloca i32
  %stack_var_-9 = alloca i8
  %stack_var_-32 = alloca i32
  %stack_var_-40 = alloca i64
  %stack_var_-8 = alloca i64

; 0x401141
  store volatile i64 4198721, i64* @_asm_program_counter
  %0 = load i64, i64* @rbp
  store i64 %0, i64* %stack_var_-8
  %1 = ptrtoint i64* %stack_var_-8 to i64
  store i64 %1, i64* @rsp

; 0x401142
  store volatile i64 4198722, i64* @_asm_program_counter
  %2 = ptrtoint i64* %stack_var_-8 to i64
  store i64 %2, i64* @rbp

; 0x401145
  store volatile i64 4198725, i64* @_asm_program_counter
  %3 = load i64, i64* @rsp
  %4 = sub i64 %3, 32
  %5 = and i64 %3, 15
  %6 = icmp ugt i64 %5, 15
  %7 = icmp ult i64 %3, 32
  %8 = xor i64 %3, 32
  %9 = xor i64 %3, %4
  %10 = and i64 %8, %9
  %11 = icmp slt i64 %10, 0
  store i1 %6, i1* @az
  store i1 %7, i1* @cf
  store i1 %11, i1* @of
  %12 = icmp eq i64 %4, 0
  store i1 %12, i1* @zf
  %13 = icmp slt i64 %4, 0
  store i1 %13, i1* @sf
  %14 = trunc i64 %4 to i8
  %15 = call i8 @llvm.ctpop.i8(i8 %14)
  %16 = and i8 %15, 1
  %17 = icmp eq i8 %16, 0
  store i1 %17, i1* @pf
  %18 = ptrtoint i64* %stack_var_-40 to i64
  store i64 %18, i64* @rsp

; 0x401149
  store volatile i64 4198729, i64* @_asm_program_counter
  store i32 1, i32* %stack_var_-32

; 0x401150
  store volatile i64 4198736, i64* @_asm_program_counter
  store i8 2, i8* %stack_var_-9

; 0x401154
  store volatile i64 4198740, i64* @_asm_program_counter
  %19 = load i8, i8* %stack_var_-9
  %20 = sext i8 %19 to i64
  store i64 %20, i64* @rdx

; 0x401158
  store volatile i64 4198744, i64* @_asm_program_counter
  %21 = ptrtoint i32* %stack_var_-32 to i64
  store i64 %21, i64* @rax

; 0x40115c
  store volatile i64 4198748, i64* @_asm_program_counter
  %22 = load i64, i64* @rdx
  %23 = trunc i64 %22 to i32
  %24 = zext i32 %23 to i64
  store i64 %24, i64* @rsi

; 0x40115e
  store volatile i64 4198750, i64* @_asm_program_counter
  %25 = ptrtoint i32* %stack_var_-32 to i64
  store i64 %25, i64* @rdi

; 0x401161
  store volatile i64 4198753, i64* @_asm_program_counter
  %26 = call i64 @add()
  store i64 %26, i64* @rax

; 0x401166
  store volatile i64 4198758, i64* @_asm_program_counter
  %27 = load i64, i64* @rax
  %28 = trunc i64 %27 to i32
  store i32 %28, i32* %stack_var_-16

; 0x401169
  store volatile i64 4198761, i64* @_asm_program_counter
  %29 = ptrtoint i32* %stack_var_-32 to i64
  store i64 %29, i64* @rax

; 0x40116d
  store volatile i64 4198765, i64* @_asm_program_counter
  %30 = ptrtoint i32* %stack_var_-32 to i64
  store i64 %30, i64* %stack_var_-24

; 0x401171
  store volatile i64 4198769, i64* @_asm_program_counter
  %31 = load i8, i8* %stack_var_-9
  %32 = sext i8 %31 to i64
  store i64 %32, i64* @rdx

; 0x401175
  store volatile i64 4198773, i64* @_asm_program_counter
  %33 = load i64, i64* %stack_var_-24
  store i64 %33, i64* @rax

; 0x401179
  store volatile i64 4198777, i64* @_asm_program_counter
  %34 = load i64, i64* @rdx
  %35 = trunc i64 %34 to i32
  %36 = zext i32 %35 to i64
  store i64 %36, i64* @rsi

; 0x40117b
  store volatile i64 4198779, i64* @_asm_program_counter
  %37 = load i64, i64* @rax
  store i64 %37, i64* @rdi

; 0x40117e
  store volatile i64 4198782, i64* @_asm_program_counter
  %38 = call i64 @add()
  store i64 %38, i64* @rax

; 0x401183
  store volatile i64 4198787, i64* @_asm_program_counter
  %39 = load i64, i64* @rax
  %40 = trunc i64 %39 to i32
  store i32 %40, i32* %stack_var_-28

; 0x401186
  store volatile i64 4198790, i64* @_asm_program_counter
  %41 = load i32, i32* %stack_var_-16
  %42 = zext i32 %41 to i64
  store i64 %42, i64* @rax

; 0x401189
  store volatile i64 4198793, i64* @_asm_program_counter
  %43 = load i64, i64* @rax
  %44 = trunc i64 %43 to i32
  %45 = zext i32 %44 to i64
  store i64 %45, i64* @rsi

; 0x40118b
  store volatile i64 4198795, i64* @_asm_program_counter
  store i64 ptrtoint ([4 x i8]* @global_var_402010 to i64), i64* @rdi

; 0x401190
  store volatile i64 4198800, i64* @_asm_program_counter
  store i64 0, i64* @rax

; 0x401195
  store volatile i64 4198805, i64* @_asm_program_counter
  %46 = call i64 @function_401030()
  store i64 %46, i64* @rax

; 0x40119a
  store volatile i64 4198810, i64* @_asm_program_counter
  store i64 0, i64* @rax

; 0x40119f
  store volatile i64 4198815, i64* @_asm_program_counter
  %47 = load i64, i64* %stack_var_-8
  store i64 %47, i64* @rbp
  %48 = ptrtoint i64* %stack_var_0 to i64
  store i64 %48, i64* @rsp

; 0x4011a0
  store volatile i64 4198816, i64* @_asm_program_counter
  ret i64 undef
}

define i64 @_fini() {
dec_label_pc_4011a4:
  %stack_var_0 = alloca i64
  %stack_var_-8 = alloca i64

; 0x4011a4
  store volatile i64 4198820, i64* @_asm_program_counter

; 0x4011a8
  store volatile i64 4198824, i64* @_asm_program_counter
  %0 = load i64, i64* @rsp
  %1 = sub i64 %0, 8
  %2 = and i64 %0, 15
  %3 = sub i64 %2, 8
  %4 = icmp ugt i64 %3, 15
  %5 = icmp ult i64 %0, 8
  %6 = xor i64 %0, 8
  %7 = xor i64 %0, %1
  %8 = and i64 %6, %7
  %9 = icmp slt i64 %8, 0
  store i1 %4, i1* @az
  store i1 %5, i1* @cf
  store i1 %9, i1* @of
  %10 = icmp eq i64 %1, 0
  store i1 %10, i1* @zf
  %11 = icmp slt i64 %1, 0
  store i1 %11, i1* @sf
  %12 = trunc i64 %1 to i8
  %13 = call i8 @llvm.ctpop.i8(i8 %12)
  %14 = and i8 %13, 1
  %15 = icmp eq i8 %14, 0
  store i1 %15, i1* @pf
  %16 = ptrtoint i64* %stack_var_-8 to i64
  store i64 %16, i64* @rsp

; 0x4011ac
  store volatile i64 4198828, i64* @_asm_program_counter
  %17 = load i64, i64* @rsp
  %18 = add i64 %17, 8
  %19 = and i64 %17, 15
  %20 = add i64 %19, 8
  %21 = icmp ugt i64 %20, 15
  %22 = icmp ult i64 %18, %17
  %23 = xor i64 %17, %18
  %24 = xor i64 8, %18
  %25 = and i64 %23, %24
  %26 = icmp slt i64 %25, 0
  store i1 %21, i1* @az
  store i1 %22, i1* @cf
  store i1 %26, i1* @of
  %27 = icmp eq i64 %18, 0
  store i1 %27, i1* @zf
  %28 = icmp slt i64 %18, 0
  store i1 %28, i1* @sf
  %29 = trunc i64 %18 to i8
  %30 = call i8 @llvm.ctpop.i8(i8 %29)
  %31 = and i8 %30, 1
  %32 = icmp eq i8 %31, 0
  store i1 %32, i1* @pf
  %33 = ptrtoint i64* %stack_var_0 to i64
  store i64 %33, i64* @rsp

; 0x4011b0
  store volatile i64 4198832, i64* @_asm_program_counter
  ret i64 undef
}

declare i64 @__libc_start_main()

declare i64 @_ITM_deregisterTMCloneTable()

declare i64 @__gmon_start__()

declare i64 @_ITM_registerTMCloneTable()

declare i64 @printf()

declare void @__pseudo_call(i64)

declare void @__pseudo_return(i64)

declare void @__pseudo_branch(i64)

declare void @__pseudo_cond_branch(i1, i64)

declare void @__frontend_reg_store.fpr(i3, x86_fp80)

declare x86_fp80 @__frontend_reg_load.fpr(i3)

; Function Attrs: nounwind readnone speculatable
declare i8 @llvm.ctpop.i8(i8) #0

declare void @__asm_hlt()

attributes #0 = { nounwind readnone speculatable }
*** IR Dump After Function parameters and returns optimization ***
source_filename = "test"
target datalayout = "e-m:e-p:64:64-i64:64-f80:128-n8:16:32:64-S128"

@_asm_program_counter = internal global i64 0
@cf = internal global i1 false
@pf = internal global i1 false
@az = internal global i1 false
@zf = internal global i1 false
@sf = internal global i1 false
@tf = internal global i1 false
@if = internal global i1 false
@df = internal global i1 false
@of = internal global i1 false
@iopl = internal global i2 0
@nt = internal global i1 false
@rf = internal global i1 false
@vm = internal global i1 false
@ac = internal global i1 false
@vif = internal global i1 false
@vip = internal global i1 false
@id = internal global i1 false
@rflags = internal global i64 0
@ss = internal global i16 0
@cs = internal global i16 0
@ds = internal global i16 0
@es = internal global i16 0
@fs = internal global i16 0
@gs = internal global i16 0
@st0 = internal global x86_fp80 0xK00000000000000000000
@st1 = internal global x86_fp80 0xK00000000000000000000
@st2 = internal global x86_fp80 0xK00000000000000000000
@st3 = internal global x86_fp80 0xK00000000000000000000
@st4 = internal global x86_fp80 0xK00000000000000000000
@st5 = internal global x86_fp80 0xK00000000000000000000
@st6 = internal global x86_fp80 0xK00000000000000000000
@st7 = internal global x86_fp80 0xK00000000000000000000
@fpu_stat_IE = internal global i1 false
@fpu_stat_DE = internal global i1 false
@fpu_stat_ZE = internal global i1 false
@fpu_stat_OE = internal global i1 false
@fpu_stat_UE = internal global i1 false
@fpu_stat_PE = internal global i1 false
@fpu_stat_SF = internal global i1 false
@fpu_stat_ES = internal global i1 false
@fpu_stat_C0 = internal global i1 false
@fpu_stat_C1 = internal global i1 false
@fpu_stat_C2 = internal global i1 false
@fpu_stat_C3 = internal global i1 false
@fpu_stat_TOP = internal global i3 0
@fpu_stat_B = internal global i1 false
@fpu_control_IM = internal global i1 false
@fpu_control_DM = internal global i1 false
@fpu_control_ZM = internal global i1 false
@fpu_control_OM = internal global i1 false
@fpu_control_UM = internal global i1 false
@fpu_control_PM = internal global i1 false
@fpu_control_PC = internal global i2 0
@fpu_control_RC = internal global i2 0
@fpu_control_X = internal global i1 false
@fp0 = internal global double 0.000000e+00
@fp1 = internal global double 0.000000e+00
@fp2 = internal global double 0.000000e+00
@fp3 = internal global double 0.000000e+00
@fp4 = internal global double 0.000000e+00
@fp5 = internal global double 0.000000e+00
@fp6 = internal global double 0.000000e+00
@fp7 = internal global double 0.000000e+00
@k0 = internal global i64 0
@k1 = internal global i64 0
@k2 = internal global i64 0
@k3 = internal global i64 0
@k4 = internal global i64 0
@k5 = internal global i64 0
@k6 = internal global i64 0
@k7 = internal global i64 0
@mm0 = internal global i64 0
@mm1 = internal global i64 0
@mm2 = internal global i64 0
@mm3 = internal global i64 0
@mm4 = internal global i64 0
@mm5 = internal global i64 0
@mm6 = internal global i64 0
@mm7 = internal global i64 0
@xmm0 = internal global i128 0
@xmm1 = internal global i128 0
@xmm2 = internal global i128 0
@xmm3 = internal global i128 0
@xmm4 = internal global i128 0
@xmm5 = internal global i128 0
@xmm6 = internal global i128 0
@xmm7 = internal global i128 0
@xmm8 = internal global i128 0
@xmm9 = internal global i128 0
@xmm10 = internal global i128 0
@xmm11 = internal global i128 0
@xmm12 = internal global i128 0
@xmm13 = internal global i128 0
@xmm14 = internal global i128 0
@xmm15 = internal global i128 0
@xmm16 = internal global i128 0
@xmm17 = internal global i128 0
@xmm18 = internal global i128 0
@xmm19 = internal global i128 0
@xmm20 = internal global i128 0
@xmm21 = internal global i128 0
@xmm22 = internal global i128 0
@xmm23 = internal global i128 0
@xmm24 = internal global i128 0
@xmm25 = internal global i128 0
@xmm26 = internal global i128 0
@xmm27 = internal global i128 0
@xmm28 = internal global i128 0
@xmm29 = internal global i128 0
@xmm30 = internal global i128 0
@xmm31 = internal global i128 0
@ymm0 = internal global i256 0
@ymm1 = internal global i256 0
@ymm2 = internal global i256 0
@ymm3 = internal global i256 0
@ymm4 = internal global i256 0
@ymm5 = internal global i256 0
@ymm6 = internal global i256 0
@ymm7 = internal global i256 0
@ymm8 = internal global i256 0
@ymm9 = internal global i256 0
@ymm10 = internal global i256 0
@ymm11 = internal global i256 0
@ymm12 = internal global i256 0
@ymm13 = internal global i256 0
@ymm14 = internal global i256 0
@ymm15 = internal global i256 0
@ymm16 = internal global i256 0
@ymm17 = internal global i256 0
@ymm18 = internal global i256 0
@ymm19 = internal global i256 0
@ymm20 = internal global i256 0
@ymm21 = internal global i256 0
@ymm22 = internal global i256 0
@ymm23 = internal global i256 0
@ymm24 = internal global i256 0
@ymm25 = internal global i256 0
@ymm26 = internal global i256 0
@ymm27 = internal global i256 0
@ymm28 = internal global i256 0
@ymm29 = internal global i256 0
@ymm30 = internal global i256 0
@ymm31 = internal global i256 0
@zmm0 = internal global i512 0
@zmm1 = internal global i512 0
@zmm2 = internal global i512 0
@zmm3 = internal global i512 0
@zmm4 = internal global i512 0
@zmm5 = internal global i512 0
@zmm6 = internal global i512 0
@zmm7 = internal global i512 0
@zmm8 = internal global i512 0
@zmm9 = internal global i512 0
@zmm10 = internal global i512 0
@zmm11 = internal global i512 0
@zmm12 = internal global i512 0
@zmm13 = internal global i512 0
@zmm14 = internal global i512 0
@zmm15 = internal global i512 0
@zmm16 = internal global i512 0
@zmm17 = internal global i512 0
@zmm18 = internal global i512 0
@zmm19 = internal global i512 0
@zmm20 = internal global i512 0
@zmm21 = internal global i512 0
@zmm22 = internal global i512 0
@zmm23 = internal global i512 0
@zmm24 = internal global i512 0
@zmm25 = internal global i512 0
@zmm26 = internal global i512 0
@zmm27 = internal global i512 0
@zmm28 = internal global i512 0
@zmm29 = internal global i512 0
@zmm30 = internal global i512 0
@zmm31 = internal global i512 0
@bnd0 = internal global i128 0
@bnd1 = internal global i128 0
@bnd2 = internal global i128 0
@bnd3 = internal global i128 0
@dr0 = internal global i64 0
@dr1 = internal global i64 0
@dr2 = internal global i64 0
@dr3 = internal global i64 0
@dr4 = internal global i64 0
@dr5 = internal global i64 0
@dr6 = internal global i64 0
@dr7 = internal global i64 0
@dr8 = internal global i64 0
@dr9 = internal global i64 0
@dr10 = internal global i64 0
@dr11 = internal global i64 0
@dr12 = internal global i64 0
@dr13 = internal global i64 0
@dr14 = internal global i64 0
@dr15 = internal global i64 0
@cr0 = internal global i64 0
@cr1 = internal global i64 0
@cr2 = internal global i64 0
@cr3 = internal global i64 0
@cr4 = internal global i64 0
@cr5 = internal global i64 0
@cr6 = internal global i64 0
@cr7 = internal global i64 0
@cr8 = internal global i64 0
@cr9 = internal global i64 0
@cr10 = internal global i64 0
@cr11 = internal global i64 0
@cr12 = internal global i64 0
@cr13 = internal global i64 0
@cr14 = internal global i64 0
@cr15 = internal global i64 0
@fpsw = internal global i64 0
@rax = internal global i64 0
@rcx = internal global i64 0
@rdx = internal global i64 0
@rbx = internal global i64 0
@rsp = internal global i64 0
@rbp = internal global i64 0
@rsi = internal global i64 0
@rdi = internal global i64 0
@r8 = internal global i64 0
@r9 = internal global i64 0
@r10 = internal global i64 0
@r11 = internal global i64 0
@r12 = internal global i64 0
@r13 = internal global i64 0
@r14 = internal global i64 0
@r15 = internal global i64 0
@rip = internal global i64 0
@riz = internal global i64 0
@global_var_403ff8 = global i64 0
@global_var_404024 = external global i64
@global_var_402010 = constant [4 x i8] c"%d\0A\00"
@0 = external global i32

define i64 @_init() {
dec_label_pc_401000:
  %stack_var_0 = alloca i64
  %stack_var_-8 = alloca i64

; 0x401000
  store volatile i64 4198400, i64* @_asm_program_counter

; 0x401004
  store volatile i64 4198404, i64* @_asm_program_counter
  %0 = load i64, i64* @rsp
  %1 = sub i64 %0, 8
  %2 = and i64 %0, 15
  %3 = sub i64 %2, 8
  %4 = icmp ugt i64 %3, 15
  %5 = icmp ult i64 %0, 8
  %6 = xor i64 %0, 8
  %7 = xor i64 %0, %1
  %8 = and i64 %6, %7
  %9 = icmp slt i64 %8, 0
  store i1 %4, i1* @az
  store i1 %5, i1* @cf
  store i1 %9, i1* @of
  %10 = icmp eq i64 %1, 0
  store i1 %10, i1* @zf
  %11 = icmp slt i64 %1, 0
  store i1 %11, i1* @sf
  %12 = trunc i64 %1 to i8
  %13 = call i8 @llvm.ctpop.i8(i8 %12)
  %14 = and i8 %13, 1
  %15 = icmp eq i8 %14, 0
  store i1 %15, i1* @pf
  %16 = ptrtoint i64* %stack_var_-8 to i64
  store i64 %16, i64* @rsp

; 0x401008
  store volatile i64 4198408, i64* @_asm_program_counter
  %17 = load i64, i64* inttoptr (i64 4210672 to i64*)
  store i64 %17, i64* @rax

; 0x40100f
  store volatile i64 4198415, i64* @_asm_program_counter
  %18 = load i64, i64* @rax
  store i1 false, i1* @az
  store i1 false, i1* @cf
  store i1 false, i1* @of
  %19 = icmp eq i64 %18, 0
  store i1 %19, i1* @zf
  %20 = icmp slt i64 %18, 0
  store i1 %20, i1* @sf
  %21 = trunc i64 %18 to i8
  %22 = call i8 @llvm.ctpop.i8(i8 %21)
  %23 = and i8 %22, 1
  %24 = icmp eq i8 %23, 0
  store i1 %24, i1* @pf

; 0x401012
  store volatile i64 4198418, i64* @_asm_program_counter
  %25 = load i1, i1* @zf
  br i1 %25, label %dec_label_pc_401016, label %dec_label_pc_401014

dec_label_pc_401014:                              ; preds = %dec_label_pc_401000

; 0x401014
  store volatile i64 4198420, i64* @_asm_program_counter
  call void @__gmon_start__()
  %26 = ptrtoint i32* @0 to i64
  store i64 %26, i64* @rax
  br label %dec_label_pc_401016

dec_label_pc_401016:                              ; preds = %dec_label_pc_401014, %dec_label_pc_401000

; 0x401016
  store volatile i64 4198422, i64* @_asm_program_counter
  %27 = load i64, i64* @rsp
  %28 = add i64 %27, 8
  %29 = and i64 %27, 15
  %30 = add i64 %29, 8
  %31 = icmp ugt i64 %30, 15
  %32 = icmp ult i64 %28, %27
  %33 = xor i64 %27, %28
  %34 = xor i64 8, %28
  %35 = and i64 %33, %34
  %36 = icmp slt i64 %35, 0
  store i1 %31, i1* @az
  store i1 %32, i1* @cf
  store i1 %36, i1* @of
  %37 = icmp eq i64 %28, 0
  store i1 %37, i1* @zf
  %38 = icmp slt i64 %28, 0
  store i1 %38, i1* @sf
  %39 = trunc i64 %28 to i8
  %40 = call i8 @llvm.ctpop.i8(i8 %39)
  %41 = and i8 %40, 1
  %42 = icmp eq i8 %41, 0
  store i1 %42, i1* @pf
  %43 = ptrtoint i64* %stack_var_0 to i64
  store i64 %43, i64* @rsp

; 0x40101a
  store volatile i64 4198426, i64* @_asm_program_counter
  %44 = load i64, i64* @rax
  ret i64 %44
}

define i32 @function_401030(i8* %format, ...) {
dec_label_pc_401030:
  %0 = ptrtoint i8* %format to i64
  store i64 %0, i64* @rdi

; 0x401030
  store volatile i64 4198448, i64* @_asm_program_counter
  %1 = load i64, i64* @rdi
  %2 = inttoptr i64 %1 to i8*
  %3 = call i32 (i8*, ...) @printf(i8* %format)
  %4 = sext i32 %3 to i64
  store i64 %4, i64* @rax
  %5 = sext i32 %3 to i64
  store i64 %5, i64* @rax
  %6 = load i64, i64* @rax
  %7 = trunc i64 %6 to i32
  ret i32 %7
}

declare i64 @1()

define i64 @_start(i64 %arg1, i64 %arg2, i64 %arg3, i64 %arg4, i64 %arg5, i64 %arg6) {
dec_label_pc_401040:
  store i64 %arg5, i64* @r8
  store i64 %arg4, i64* @rcx
  store i64 %arg3, i64* @rdx
  store i64 %arg2, i64* @rsi
  store i64 %arg1, i64* @rdi
  %stack_var_-16 = alloca i64
  %stack_var_-8 = alloca i64
  %stack_var_8 = alloca i64
  %stack_var_0 = alloca i64
  store i64 %arg6, i64* %stack_var_0

; 0x401040
  store volatile i64 4198464, i64* @_asm_program_counter

; 0x401044
  store volatile i64 4198468, i64* @_asm_program_counter
  %0 = load i64, i64* @rbp
  %1 = trunc i64 %0 to i32
  %2 = load i64, i64* @rbp
  %3 = trunc i64 %2 to i32
  %4 = xor i32 %1, %3
  store i1 false, i1* @az
  store i1 false, i1* @cf
  store i1 false, i1* @of
  %5 = icmp eq i32 %4, 0
  store i1 %5, i1* @zf
  %6 = icmp slt i32 %4, 0
  store i1 %6, i1* @sf
  %7 = trunc i32 %4 to i8
  %8 = call i8 @llvm.ctpop.i8(i8 %7)
  %9 = and i8 %8, 1
  %10 = icmp eq i8 %9, 0
  store i1 %10, i1* @pf
  %11 = zext i32 %4 to i64
  store i64 %11, i64* @rbp

; 0x401046
  store volatile i64 4198470, i64* @_asm_program_counter
  %12 = load i64, i64* @rdx
  store i64 %12, i64* @r9

; 0x401049
  store volatile i64 4198473, i64* @_asm_program_counter
  %13 = load i64, i64* %stack_var_0
  store i64 %13, i64* @rsi
  %14 = ptrtoint i64* %stack_var_8 to i64
  store i64 %14, i64* @rsp

; 0x40104a
  store volatile i64 4198474, i64* @_asm_program_counter
  %15 = ptrtoint i64* %stack_var_8 to i64
  store i64 %15, i64* @rdx

; 0x40104d
  store volatile i64 4198477, i64* @_asm_program_counter
  %16 = load i64, i64* @rsp
  %17 = and i64 %16, -16
  store i1 false, i1* @az
  store i1 false, i1* @cf
  store i1 false, i1* @of
  %18 = icmp eq i64 %17, 0
  store i1 %18, i1* @zf
  %19 = icmp slt i64 %17, 0
  store i1 %19, i1* @sf
  %20 = trunc i64 %17 to i8
  %21 = call i8 @llvm.ctpop.i8(i8 %20)
  %22 = and i8 %21, 1
  %23 = icmp eq i8 %22, 0
  store i1 %23, i1* @pf
  %24 = ptrtoint i64* %stack_var_0 to i64
  store i64 %24, i64* @rsp

; 0x401051
  store volatile i64 4198481, i64* @_asm_program_counter
  %25 = load i64, i64* @rax
  store i64 %25, i64* %stack_var_-8
  %26 = ptrtoint i64* %stack_var_-8 to i64
  store i64 %26, i64* @rsp

; 0x401052
  store volatile i64 4198482, i64* @_asm_program_counter
  %27 = ptrtoint i64* %stack_var_-8 to i64
  store i64 %27, i64* %stack_var_-16
  %28 = ptrtoint i64* %stack_var_-16 to i64
  store i64 %28, i64* @rsp

; 0x401053
  store volatile i64 4198483, i64* @_asm_program_counter
  %29 = load i64, i64* @r8
  %30 = trunc i64 %29 to i32
  %31 = load i64, i64* @r8
  %32 = trunc i64 %31 to i32
  %33 = xor i32 %30, %32
  store i1 false, i1* @az
  store i1 false, i1* @cf
  store i1 false, i1* @of
  %34 = icmp eq i32 %33, 0
  store i1 %34, i1* @zf
  %35 = icmp slt i32 %33, 0
  store i1 %35, i1* @sf
  %36 = trunc i32 %33 to i8
  %37 = call i8 @llvm.ctpop.i8(i8 %36)
  %38 = and i8 %37, 1
  %39 = icmp eq i8 %38, 0
  store i1 %39, i1* @pf
  %40 = zext i32 %33 to i64
  store i64 %40, i64* @r8

; 0x401056
  store volatile i64 4198486, i64* @_asm_program_counter
  %41 = load i64, i64* @rcx
  %42 = trunc i64 %41 to i32
  %43 = load i64, i64* @rcx
  %44 = trunc i64 %43 to i32
  %45 = xor i32 %42, %44
  store i1 false, i1* @az
  store i1 false, i1* @cf
  store i1 false, i1* @of
  %46 = icmp eq i32 %45, 0
  store i1 %46, i1* @zf
  %47 = icmp slt i32 %45, 0
  store i1 %47, i1* @sf
  %48 = trunc i32 %45 to i8
  %49 = call i8 @llvm.ctpop.i8(i8 %48)
  %50 = and i8 %49, 1
  %51 = icmp eq i8 %50, 0
  store i1 %51, i1* @pf
  %52 = zext i32 %45 to i64
  store i64 %52, i64* @rcx

; 0x401058
  store volatile i64 4198488, i64* @_asm_program_counter
  store i64 4198721, i64* @rdi

; 0x40105f
  store volatile i64 4198495, i64* @_asm_program_counter
  %53 = load i64, i64* @rdi
  %54 = load i64, i64* @rsi
  %55 = trunc i64 %54 to i32
  %56 = load i64, i64* @rdx
  %57 = inttoptr i64 %56 to i8**
  %58 = load i64, i64* @rcx
  %59 = inttoptr i64 %58 to void ()*
  %60 = load i64, i64* @r8
  %61 = inttoptr i64 %60 to void ()*
  %62 = load i64, i64* @r9
  %63 = inttoptr i64 %62 to void ()*
  %64 = call i32 @__libc_start_main(i64 %53, i32 %55, i8** %57, void ()* %59, void ()* %61, void ()* %63)
  %65 = sext i32 %64 to i64
  store i64 %65, i64* @rax
  %66 = sext i32 %64 to i64
  store i64 %66, i64* @rax

; 0x401065
  store volatile i64 4198501, i64* @_asm_program_counter
  %67 = call i64 @__asm_hlt()
  store i64 %67, i64* @rax
  unreachable
}

declare i64 @2()

define i64 @_dl_relocate_static_pie() {
dec_label_pc_401070:

; 0x401070
  store volatile i64 4198512, i64* @_asm_program_counter

; 0x401074
  store volatile i64 4198516, i64* @_asm_program_counter
  %0 = load i64, i64* @rax
  ret i64 %0
}

define i64 @deregister_tm_clones() {
dec_label_pc_401080:

; 0x401080
  store volatile i64 4198528, i64* @_asm_program_counter
  store i64 4210728, i64* @rdi

; 0x401087
  store volatile i64 4198535, i64* @_asm_program_counter
  store i64 4210728, i64* @rax

; 0x40108e
  store volatile i64 4198542, i64* @_asm_program_counter
  %0 = load i64, i64* @rax
  %1 = load i64, i64* @rdi
  %2 = sub i64 %0, %1
  %3 = and i64 %0, 15
  %4 = and i64 %1, 15
  %5 = sub i64 %3, %4
  %6 = icmp ugt i64 %5, 15
  %7 = icmp ult i64 %0, %1
  %8 = xor i64 %0, %1
  %9 = xor i64 %0, %2
  %10 = and i64 %8, %9
  %11 = icmp slt i64 %10, 0
  store i1 %6, i1* @az
  store i1 %7, i1* @cf
  store i1 %11, i1* @of
  %12 = icmp eq i64 %2, 0
  store i1 %12, i1* @zf
  %13 = icmp slt i64 %2, 0
  store i1 %13, i1* @sf
  %14 = trunc i64 %2 to i8
  %15 = call i8 @llvm.ctpop.i8(i8 %14)
  %16 = and i8 %15, 1
  %17 = icmp eq i8 %16, 0
  store i1 %17, i1* @pf

; 0x401091
  store volatile i64 4198545, i64* @_asm_program_counter
  %18 = load i1, i1* @zf
  br i1 %18, label %dec_label_pc_4010a8, label %dec_label_pc_401093

dec_label_pc_401093:                              ; preds = %dec_label_pc_401080

; 0x401093
  store volatile i64 4198547, i64* @_asm_program_counter
  %19 = load i64, i64* inttoptr (i64 4210664 to i64*)
  store i64 %19, i64* @rax

; 0x40109a
  store volatile i64 4198554, i64* @_asm_program_counter
  %20 = load i64, i64* @rax
  store i1 false, i1* @az
  store i1 false, i1* @cf
  store i1 false, i1* @of
  %21 = icmp eq i64 %20, 0
  store i1 %21, i1* @zf
  %22 = icmp slt i64 %20, 0
  store i1 %22, i1* @sf
  %23 = trunc i64 %20 to i8
  %24 = call i8 @llvm.ctpop.i8(i8 %23)
  %25 = and i8 %24, 1
  %26 = icmp eq i8 %25, 0
  store i1 %26, i1* @pf

; 0x40109d
  store volatile i64 4198557, i64* @_asm_program_counter
  %27 = load i1, i1* @zf
  br i1 %27, label %dec_label_pc_4010a8, label %dec_label_pc_40109f

dec_label_pc_40109f:                              ; preds = %dec_label_pc_401093

; 0x40109f
  store volatile i64 4198559, i64* @_asm_program_counter
  %28 = load i64, i64* @rdi
  %29 = call i64 @_ITM_deregisterTMCloneTable(i64 %28)
  store i64 %29, i64* @rax
  store i64 %29, i64* @rax
  %30 = load i64, i64* @rax
  ret i64 %30

dec_label_pc_4010a8:                              ; preds = %dec_label_pc_401093, %dec_label_pc_401080

; 0x4010a8
  store volatile i64 4198568, i64* @_asm_program_counter
  %31 = load i64, i64* @rax
  ret i64 %31
}

define i64 @register_tm_clones() {
dec_label_pc_4010b0:

; 0x4010b0
  store volatile i64 4198576, i64* @_asm_program_counter
  store i64 4210728, i64* @rdi

; 0x4010b7
  store volatile i64 4198583, i64* @_asm_program_counter
  store i64 4210728, i64* @rsi

; 0x4010be
  store volatile i64 4198590, i64* @_asm_program_counter
  %0 = load i64, i64* @rsi
  %1 = load i64, i64* @rdi
  %2 = sub i64 %0, %1
  %3 = and i64 %0, 15
  %4 = and i64 %1, 15
  %5 = sub i64 %3, %4
  %6 = icmp ugt i64 %5, 15
  %7 = icmp ult i64 %0, %1
  %8 = xor i64 %0, %1
  %9 = xor i64 %0, %2
  %10 = and i64 %8, %9
  %11 = icmp slt i64 %10, 0
  store i1 %6, i1* @az
  store i1 %7, i1* @cf
  store i1 %11, i1* @of
  %12 = icmp eq i64 %2, 0
  store i1 %12, i1* @zf
  %13 = icmp slt i64 %2, 0
  store i1 %13, i1* @sf
  %14 = trunc i64 %2 to i8
  %15 = call i8 @llvm.ctpop.i8(i8 %14)
  %16 = and i8 %15, 1
  %17 = icmp eq i8 %16, 0
  store i1 %17, i1* @pf
  store i64 %2, i64* @rsi

; 0x4010c1
  store volatile i64 4198593, i64* @_asm_program_counter
  %18 = load i64, i64* @rsi
  store i64 %18, i64* @rax

; 0x4010c4
  store volatile i64 4198596, i64* @_asm_program_counter
  %19 = load i64, i64* @rsi
  %20 = load i1, i1* @of
  %21 = lshr i64 %19, 63
  %22 = icmp eq i64 %21, 0
  store i1 %22, i1* @zf
  %23 = icmp slt i64 %21, 0
  store i1 %23, i1* @sf
  %24 = trunc i64 %21 to i8
  %25 = call i8 @llvm.ctpop.i8(i8 %24)
  %26 = and i8 %25, 1
  %27 = icmp eq i8 %26, 0
  store i1 %27, i1* @pf
  store i64 %21, i64* @rsi
  %28 = and i64 4611686018427387904, %19
  %29 = icmp ne i64 %28, 0
  store i1 %29, i1* @cf
  %30 = icmp slt i64 %19, 0
  %31 = select i1 false, i1 %30, i1 %20
  store i1 %31, i1* @of

; 0x4010c8
  store volatile i64 4198600, i64* @_asm_program_counter
  %32 = load i64, i64* @rax
  %33 = load i1, i1* @of
  %34 = ashr i64 %32, 3
  %35 = icmp eq i64 %34, 0
  store i1 %35, i1* @zf
  %36 = icmp slt i64 %34, 0
  store i1 %36, i1* @sf
  %37 = trunc i64 %34 to i8
  %38 = call i8 @llvm.ctpop.i8(i8 %37)
  %39 = and i8 %38, 1
  %40 = icmp eq i8 %39, 0
  store i1 %40, i1* @pf
  store i64 %34, i64* @rax
  %41 = and i64 4, %32
  %42 = icmp ne i64 %41, 0
  store i1 %42, i1* @cf
  %43 = select i1 false, i1 false, i1 %33
  store i1 %43, i1* @of

; 0x4010cc
  store volatile i64 4198604, i64* @_asm_program_counter
  %44 = load i64, i64* @rsi
  %45 = load i64, i64* @rax
  %46 = add i64 %44, %45
  %47 = and i64 %44, 15
  %48 = and i64 %45, 15
  %49 = add i64 %47, %48
  %50 = icmp ugt i64 %49, 15
  %51 = icmp ult i64 %46, %44
  %52 = xor i64 %44, %46
  %53 = xor i64 %45, %46
  %54 = and i64 %52, %53
  %55 = icmp slt i64 %54, 0
  store i1 %50, i1* @az
  store i1 %51, i1* @cf
  store i1 %55, i1* @of
  %56 = icmp eq i64 %46, 0
  store i1 %56, i1* @zf
  %57 = icmp slt i64 %46, 0
  store i1 %57, i1* @sf
  %58 = trunc i64 %46 to i8
  %59 = call i8 @llvm.ctpop.i8(i8 %58)
  %60 = and i8 %59, 1
  %61 = icmp eq i8 %60, 0
  store i1 %61, i1* @pf
  store i64 %46, i64* @rsi

; 0x4010cf
  store volatile i64 4198607, i64* @_asm_program_counter
  %62 = load i64, i64* @rsi
  %63 = load i1, i1* @of
  %64 = ashr i64 %62, 1
  %65 = icmp eq i64 %64, 0
  store i1 %65, i1* @zf
  %66 = icmp slt i64 %64, 0
  store i1 %66, i1* @sf
  %67 = trunc i64 %64 to i8
  %68 = call i8 @llvm.ctpop.i8(i8 %67)
  %69 = and i8 %68, 1
  %70 = icmp eq i8 %69, 0
  store i1 %70, i1* @pf
  store i64 %64, i64* @rsi
  %71 = and i64 1, %62
  %72 = icmp ne i64 %71, 0
  store i1 %72, i1* @cf
  %73 = select i1 true, i1 false, i1 %63
  store i1 %73, i1* @of

; 0x4010d2
  store volatile i64 4198610, i64* @_asm_program_counter
  %74 = load i1, i1* @zf
  br i1 %74, label %dec_label_pc_4010e8, label %dec_label_pc_4010d4

dec_label_pc_4010d4:                              ; preds = %dec_label_pc_4010b0

; 0x4010d4
  store volatile i64 4198612, i64* @_asm_program_counter
  %75 = load i64, i64* @global_var_403ff8
  store i64 %75, i64* @rax

; 0x4010db
  store volatile i64 4198619, i64* @_asm_program_counter
  %76 = load i64, i64* @rax
  store i1 false, i1* @az
  store i1 false, i1* @cf
  store i1 false, i1* @of
  %77 = icmp eq i64 %76, 0
  store i1 %77, i1* @zf
  %78 = icmp slt i64 %76, 0
  store i1 %78, i1* @sf
  %79 = trunc i64 %76 to i8
  %80 = call i8 @llvm.ctpop.i8(i8 %79)
  %81 = and i8 %80, 1
  %82 = icmp eq i8 %81, 0
  store i1 %82, i1* @pf

; 0x4010de
  store volatile i64 4198622, i64* @_asm_program_counter
  %83 = load i1, i1* @zf
  br i1 %83, label %dec_label_pc_4010e8, label %dec_label_pc_4010e0

dec_label_pc_4010e0:                              ; preds = %dec_label_pc_4010d4

; 0x4010e0
  store volatile i64 4198624, i64* @_asm_program_counter
  %84 = load i64, i64* @rdi
  %85 = load i64, i64* @rsi
  %86 = call i64 @_ITM_registerTMCloneTable(i64 %84, i64 %85)
  store i64 %86, i64* @rax
  store i64 %86, i64* @rax
  %87 = load i64, i64* @rax
  ret i64 %87

dec_label_pc_4010e8:                              ; preds = %dec_label_pc_4010d4, %dec_label_pc_4010b0

; 0x4010e8
  store volatile i64 4198632, i64* @_asm_program_counter
  %88 = load i64, i64* @rax
  ret i64 %88
}

define i64 @__do_global_dtors_aux() {
dec_label_pc_4010f0:
  %stack_var_0 = alloca i64
  %stack_var_-8 = alloca i64

; 0x4010f0
  store volatile i64 4198640, i64* @_asm_program_counter

; 0x4010f4
  store volatile i64 4198644, i64* @_asm_program_counter
  %0 = load i8, i8* inttoptr (i64 4210724 to i8*)
  %1 = and i8 %0, 15
  %2 = icmp ugt i8 %1, 15
  %3 = icmp ult i8 %0, 0
  %4 = xor i8 %0, 0
  %5 = and i8 %4, 0
  %6 = icmp slt i8 %5, 0
  store i1 %2, i1* @az
  store i1 %3, i1* @cf
  store i1 %6, i1* @of
  %7 = icmp eq i8 %0, 0
  store i1 %7, i1* @zf
  %8 = icmp slt i8 %0, 0
  store i1 %8, i1* @sf
  %9 = call i8 @llvm.ctpop.i8(i8 %0)
  %10 = and i8 %9, 1
  %11 = icmp eq i8 %10, 0
  store i1 %11, i1* @pf

; 0x4010fb
  store volatile i64 4198651, i64* @_asm_program_counter
  %12 = load i1, i1* @zf
  %13 = icmp eq i1 %12, false
  br i1 %13, label %dec_label_pc_401110, label %dec_label_pc_4010fd

dec_label_pc_4010fd:                              ; preds = %dec_label_pc_4010f0

; 0x4010fd
  store volatile i64 4198653, i64* @_asm_program_counter
  %14 = load i64, i64* @rbp
  store i64 %14, i64* %stack_var_-8
  %15 = ptrtoint i64* %stack_var_-8 to i64
  store i64 %15, i64* @rsp

; 0x4010fe
  store volatile i64 4198654, i64* @_asm_program_counter
  %16 = ptrtoint i64* %stack_var_-8 to i64
  store i64 %16, i64* @rbp

; 0x401101
  store volatile i64 4198657, i64* @_asm_program_counter
  %17 = call i64 @deregister_tm_clones()
  store i64 %17, i64* @rax
  store i64 %17, i64* @rax

; 0x401106
  store volatile i64 4198662, i64* @_asm_program_counter
  store i8 1, i8* bitcast (i64* @global_var_404024 to i8*)

; 0x40110d
  store volatile i64 4198669, i64* @_asm_program_counter
  %18 = load i64, i64* %stack_var_-8
  store i64 %18, i64* @rbp
  %19 = ptrtoint i64* %stack_var_0 to i64
  store i64 %19, i64* @rsp

; 0x40110e
  store volatile i64 4198670, i64* @_asm_program_counter
  %20 = load i64, i64* @rax
  ret i64 %20

dec_label_pc_401110:                              ; preds = %dec_label_pc_4010f0

; 0x401110
  store volatile i64 4198672, i64* @_asm_program_counter
  %21 = load i64, i64* @rax
  ret i64 %21
}

define i64 @frame_dummy() {
dec_label_pc_401120:

; 0x401120
  store volatile i64 4198688, i64* @_asm_program_counter

; 0x401124
  store volatile i64 4198692, i64* @_asm_program_counter
  %0 = call i64 @register_tm_clones()
  store i64 %0, i64* @rax
  store i64 %0, i64* @rax
  %1 = load i64, i64* @rax
  ret i64 %1
}

define i64 @add(i32* %arg1, i64 %arg2) {
dec_label_pc_401126:
  store i64 %arg2, i64* @rsi
  %0 = ptrtoint i32* %arg1 to i64
  store i64 %0, i64* @rdi
  %stack_var_0 = alloca i64
  %stack_var_-20 = alloca i8
  %stack_var_-16 = alloca i64
  %stack_var_-8 = alloca i64

; 0x401126
  store volatile i64 4198694, i64* @_asm_program_counter
  %1 = load i64, i64* @rbp
  store i64 %1, i64* %stack_var_-8
  %2 = ptrtoint i64* %stack_var_-8 to i64
  store i64 %2, i64* @rsp

; 0x401127
  store volatile i64 4198695, i64* @_asm_program_counter
  %3 = ptrtoint i64* %stack_var_-8 to i64
  store i64 %3, i64* @rbp

; 0x40112a
  store volatile i64 4198698, i64* @_asm_program_counter
  %4 = load i64, i64* @rdi
  store i64 %4, i64* %stack_var_-16

; 0x40112e
  store volatile i64 4198702, i64* @_asm_program_counter
  %5 = load i64, i64* @rsi
  %6 = trunc i64 %5 to i32
  %7 = zext i32 %6 to i64
  store i64 %7, i64* @rax

; 0x401130
  store volatile i64 4198704, i64* @_asm_program_counter
  %8 = load i64, i64* @rax
  %9 = trunc i64 %8 to i8
  store i8 %9, i8* %stack_var_-20

; 0x401133
  store volatile i64 4198707, i64* @_asm_program_counter
  %10 = load i64, i64* %stack_var_-16
  store i64 %10, i64* @rax

; 0x401137
  store volatile i64 4198711, i64* @_asm_program_counter
  %11 = load i32, i32* bitcast (i64* @rdi to i32*)
  %12 = zext i32 %11 to i64
  store i64 %12, i64* @rdx

; 0x401139
  store volatile i64 4198713, i64* @_asm_program_counter
  %13 = load i8, i8* %stack_var_-20
  %14 = sext i8 %13 to i64
  store i64 %14, i64* @rax

; 0x40113d
  store volatile i64 4198717, i64* @_asm_program_counter
  %15 = load i64, i64* @rax
  %16 = trunc i64 %15 to i32
  %17 = load i64, i64* @rdx
  %18 = trunc i64 %17 to i32
  %19 = add i32 %16, %18
  %20 = and i32 %16, 15
  %21 = and i32 %18, 15
  %22 = add i32 %20, %21
  %23 = icmp ugt i32 %22, 15
  %24 = icmp ult i32 %19, %16
  %25 = xor i32 %16, %19
  %26 = xor i32 %18, %19
  %27 = and i32 %25, %26
  %28 = icmp slt i32 %27, 0
  store i1 %23, i1* @az
  store i1 %24, i1* @cf
  store i1 %28, i1* @of
  %29 = icmp eq i32 %19, 0
  store i1 %29, i1* @zf
  %30 = icmp slt i32 %19, 0
  store i1 %30, i1* @sf
  %31 = trunc i32 %19 to i8
  %32 = call i8 @llvm.ctpop.i8(i8 %31)
  %33 = and i8 %32, 1
  %34 = icmp eq i8 %33, 0
  store i1 %34, i1* @pf
  %35 = zext i32 %19 to i64
  store i64 %35, i64* @rax

; 0x40113f
  store volatile i64 4198719, i64* @_asm_program_counter
  %36 = load i64, i64* %stack_var_-8
  store i64 %36, i64* @rbp
  %37 = ptrtoint i64* %stack_var_0 to i64
  store i64 %37, i64* @rsp

; 0x401140
  store volatile i64 4198720, i64* @_asm_program_counter
  %38 = load i64, i64* @rax
  ret i64 %38
}

declare i64 @3()

define i64 @main(i64 %argc, i8** %argv) {
dec_label_pc_401141:
  %0 = ptrtoint i8** %argv to i64
  store i64 %0, i64* @rsi
  store i64 %argc, i64* @rdi
  %stack_var_0 = alloca i64
  %stack_var_-28 = alloca i32
  %stack_var_-24 = alloca i64
  %stack_var_-16 = alloca i32
  %stack_var_-9 = alloca i8
  %stack_var_-32 = alloca i32
  %stack_var_-40 = alloca i64
  %stack_var_-8 = alloca i64

; 0x401141
  store volatile i64 4198721, i64* @_asm_program_counter
  %1 = load i64, i64* @rbp
  store i64 %1, i64* %stack_var_-8
  %2 = ptrtoint i64* %stack_var_-8 to i64
  store i64 %2, i64* @rsp

; 0x401142
  store volatile i64 4198722, i64* @_asm_program_counter
  %3 = ptrtoint i64* %stack_var_-8 to i64
  store i64 %3, i64* @rbp

; 0x401145
  store volatile i64 4198725, i64* @_asm_program_counter
  %4 = load i64, i64* @rsp
  %5 = sub i64 %4, 32
  %6 = and i64 %4, 15
  %7 = icmp ugt i64 %6, 15
  %8 = icmp ult i64 %4, 32
  %9 = xor i64 %4, 32
  %10 = xor i64 %4, %5
  %11 = and i64 %9, %10
  %12 = icmp slt i64 %11, 0
  store i1 %7, i1* @az
  store i1 %8, i1* @cf
  store i1 %12, i1* @of
  %13 = icmp eq i64 %5, 0
  store i1 %13, i1* @zf
  %14 = icmp slt i64 %5, 0
  store i1 %14, i1* @sf
  %15 = trunc i64 %5 to i8
  %16 = call i8 @llvm.ctpop.i8(i8 %15)
  %17 = and i8 %16, 1
  %18 = icmp eq i8 %17, 0
  store i1 %18, i1* @pf
  %19 = ptrtoint i64* %stack_var_-40 to i64
  store i64 %19, i64* @rsp

; 0x401149
  store volatile i64 4198729, i64* @_asm_program_counter
  store i32 1, i32* %stack_var_-32

; 0x401150
  store volatile i64 4198736, i64* @_asm_program_counter
  store i8 2, i8* %stack_var_-9

; 0x401154
  store volatile i64 4198740, i64* @_asm_program_counter
  %20 = load i8, i8* %stack_var_-9
  %21 = sext i8 %20 to i64
  store i64 %21, i64* @rdx

; 0x401158
  store volatile i64 4198744, i64* @_asm_program_counter
  %22 = ptrtoint i32* %stack_var_-32 to i64
  store i64 %22, i64* @rax

; 0x40115c
  store volatile i64 4198748, i64* @_asm_program_counter
  %23 = load i64, i64* @rdx
  %24 = trunc i64 %23 to i32
  %25 = zext i32 %24 to i64
  store i64 %25, i64* @rsi

; 0x40115e
  store volatile i64 4198750, i64* @_asm_program_counter
  %26 = ptrtoint i32* %stack_var_-32 to i64
  store i64 %26, i64* @rdi

; 0x401161
  store volatile i64 4198753, i64* @_asm_program_counter
  %27 = load i64, i64* @rdi
  %28 = inttoptr i64 %27 to i32*
  %29 = load i64, i64* @rsi
  %30 = call i64 @add(i32* %28, i64 %29)
  store i64 %30, i64* @rax
  store i64 %30, i64* @rax

; 0x401166
  store volatile i64 4198758, i64* @_asm_program_counter
  %31 = load i64, i64* @rax
  %32 = trunc i64 %31 to i32
  store i32 %32, i32* %stack_var_-16

; 0x401169
  store volatile i64 4198761, i64* @_asm_program_counter
  %33 = ptrtoint i32* %stack_var_-32 to i64
  store i64 %33, i64* @rax

; 0x40116d
  store volatile i64 4198765, i64* @_asm_program_counter
  %34 = ptrtoint i32* %stack_var_-32 to i64
  store i64 %34, i64* %stack_var_-24

; 0x401171
  store volatile i64 4198769, i64* @_asm_program_counter
  %35 = load i8, i8* %stack_var_-9
  %36 = sext i8 %35 to i64
  store i64 %36, i64* @rdx

; 0x401175
  store volatile i64 4198773, i64* @_asm_program_counter
  %37 = load i64, i64* %stack_var_-24
  store i64 %37, i64* @rax

; 0x401179
  store volatile i64 4198777, i64* @_asm_program_counter
  %38 = load i64, i64* @rdx
  %39 = trunc i64 %38 to i32
  %40 = zext i32 %39 to i64
  store i64 %40, i64* @rsi

; 0x40117b
  store volatile i64 4198779, i64* @_asm_program_counter
  %41 = load i64, i64* @rax
  store i64 %41, i64* @rdi

; 0x40117e
  store volatile i64 4198782, i64* @_asm_program_counter
  %42 = load i64, i64* @rdi
  %43 = inttoptr i64 %42 to i32*
  %44 = load i64, i64* @rsi
  %45 = call i64 @add(i32* %43, i64 %44)
  store i64 %45, i64* @rax
  store i64 %45, i64* @rax

; 0x401183
  store volatile i64 4198787, i64* @_asm_program_counter
  %46 = load i64, i64* @rax
  %47 = trunc i64 %46 to i32
  store i32 %47, i32* %stack_var_-28

; 0x401186
  store volatile i64 4198790, i64* @_asm_program_counter
  %48 = load i32, i32* %stack_var_-16
  %49 = zext i32 %48 to i64
  store i64 %49, i64* @rax

; 0x401189
  store volatile i64 4198793, i64* @_asm_program_counter
  %50 = load i64, i64* @rax
  %51 = trunc i64 %50 to i32
  %52 = zext i32 %51 to i64
  store i64 %52, i64* @rsi

; 0x40118b
  store volatile i64 4198795, i64* @_asm_program_counter
  store i64 ptrtoint ([4 x i8]* @global_var_402010 to i64), i64* @rdi

; 0x401190
  store volatile i64 4198800, i64* @_asm_program_counter
  store i64 0, i64* @rax

; 0x401195
  store volatile i64 4198805, i64* @_asm_program_counter
  %53 = load i64, i64* @rdi
  %54 = inttoptr i64 %53 to i8*
  %55 = load i64, i64* @rsi
  %56 = call i32 (i8*, ...) @printf(i8* %54, i64 %55)
  %57 = sext i32 %56 to i64
  store i64 %57, i64* @rax
  %58 = sext i32 %56 to i64
  store i64 %58, i64* @rax

; 0x40119a
  store volatile i64 4198810, i64* @_asm_program_counter
  store i64 0, i64* @rax

; 0x40119f
  store volatile i64 4198815, i64* @_asm_program_counter
  %59 = load i64, i64* %stack_var_-8
  store i64 %59, i64* @rbp
  %60 = ptrtoint i64* %stack_var_0 to i64
  store i64 %60, i64* @rsp

; 0x4011a0
  store volatile i64 4198816, i64* @_asm_program_counter
  %61 = load i64, i64* @rax
  ret i64 %61
}

declare i64 @4()

define i64 @_fini() {
dec_label_pc_4011a4:
  %stack_var_0 = alloca i64
  %stack_var_-8 = alloca i64

; 0x4011a4
  store volatile i64 4198820, i64* @_asm_program_counter

; 0x4011a8
  store volatile i64 4198824, i64* @_asm_program_counter
  %0 = load i64, i64* @rsp
  %1 = sub i64 %0, 8
  %2 = and i64 %0, 15
  %3 = sub i64 %2, 8
  %4 = icmp ugt i64 %3, 15
  %5 = icmp ult i64 %0, 8
  %6 = xor i64 %0, 8
  %7 = xor i64 %0, %1
  %8 = and i64 %6, %7
  %9 = icmp slt i64 %8, 0
  store i1 %4, i1* @az
  store i1 %5, i1* @cf
  store i1 %9, i1* @of
  %10 = icmp eq i64 %1, 0
  store i1 %10, i1* @zf
  %11 = icmp slt i64 %1, 0
  store i1 %11, i1* @sf
  %12 = trunc i64 %1 to i8
  %13 = call i8 @llvm.ctpop.i8(i8 %12)
  %14 = and i8 %13, 1
  %15 = icmp eq i8 %14, 0
  store i1 %15, i1* @pf
  %16 = ptrtoint i64* %stack_var_-8 to i64
  store i64 %16, i64* @rsp

; 0x4011ac
  store volatile i64 4198828, i64* @_asm_program_counter
  %17 = load i64, i64* @rsp
  %18 = add i64 %17, 8
  %19 = and i64 %17, 15
  %20 = add i64 %19, 8
  %21 = icmp ugt i64 %20, 15
  %22 = icmp ult i64 %18, %17
  %23 = xor i64 %17, %18
  %24 = xor i64 8, %18
  %25 = and i64 %23, %24
  %26 = icmp slt i64 %25, 0
  store i1 %21, i1* @az
  store i1 %22, i1* @cf
  store i1 %26, i1* @of
  %27 = icmp eq i64 %18, 0
  store i1 %27, i1* @zf
  %28 = icmp slt i64 %18, 0
  store i1 %28, i1* @sf
  %29 = trunc i64 %18 to i8
  %30 = call i8 @llvm.ctpop.i8(i8 %29)
  %31 = and i8 %30, 1
  %32 = icmp eq i8 %31, 0
  store i1 %32, i1* @pf
  %33 = ptrtoint i64* %stack_var_0 to i64
  store i64 %33, i64* @rsp

; 0x4011b0
  store volatile i64 4198832, i64* @_asm_program_counter
  %34 = load i64, i64* @rax
  ret i64 %34
}

declare i32 @__libc_start_main(i64, i32, i8**, void ()*, void ()*, void ()*)

declare i64 @5()

declare i64 @_ITM_deregisterTMCloneTable(i64)

declare i64 @6()

declare void @__gmon_start__()

declare i64 @7()

declare i64 @_ITM_registerTMCloneTable(i64, i64)

declare i64 @8()

declare i32 @printf(i8*, ...)

declare i64 @9()

declare void @__pseudo_call(i64)

declare void @__pseudo_return(i64)

declare void @__pseudo_branch(i64)

declare void @__pseudo_cond_branch(i1, i64)

declare void @__frontend_reg_store.fpr(i3, x86_fp80)

declare x86_fp80 @__frontend_reg_load.fpr(i3)

; Function Attrs: nounwind readnone speculatable
declare i8 @llvm.ctpop.i8(i8) #0

declare i64 @__asm_hlt()

declare void @10()

attributes #0 = { nounwind readnone speculatable }
*** IR Dump After LLVM instruction optimization using RDA ***
source_filename = "test"
target datalayout = "e-m:e-p:64:64-i64:64-f80:128-n8:16:32:64-S128"

@_asm_program_counter = internal global i64 0
@cf = internal global i1 false
@pf = internal global i1 false
@az = internal global i1 false
@zf = internal global i1 false
@sf = internal global i1 false
@tf = internal global i1 false
@if = internal global i1 false
@df = internal global i1 false
@of = internal global i1 false
@iopl = internal global i2 0
@nt = internal global i1 false
@rf = internal global i1 false
@vm = internal global i1 false
@ac = internal global i1 false
@vif = internal global i1 false
@vip = internal global i1 false
@id = internal global i1 false
@rflags = internal global i64 0
@ss = internal global i16 0
@cs = internal global i16 0
@ds = internal global i16 0
@es = internal global i16 0
@fs = internal global i16 0
@gs = internal global i16 0
@st0 = internal global x86_fp80 0xK00000000000000000000
@st1 = internal global x86_fp80 0xK00000000000000000000
@st2 = internal global x86_fp80 0xK00000000000000000000
@st3 = internal global x86_fp80 0xK00000000000000000000
@st4 = internal global x86_fp80 0xK00000000000000000000
@st5 = internal global x86_fp80 0xK00000000000000000000
@st6 = internal global x86_fp80 0xK00000000000000000000
@st7 = internal global x86_fp80 0xK00000000000000000000
@fpu_stat_IE = internal global i1 false
@fpu_stat_DE = internal global i1 false
@fpu_stat_ZE = internal global i1 false
@fpu_stat_OE = internal global i1 false
@fpu_stat_UE = internal global i1 false
@fpu_stat_PE = internal global i1 false
@fpu_stat_SF = internal global i1 false
@fpu_stat_ES = internal global i1 false
@fpu_stat_C0 = internal global i1 false
@fpu_stat_C1 = internal global i1 false
@fpu_stat_C2 = internal global i1 false
@fpu_stat_C3 = internal global i1 false
@fpu_stat_TOP = internal global i3 0
@fpu_stat_B = internal global i1 false
@fpu_control_IM = internal global i1 false
@fpu_control_DM = internal global i1 false
@fpu_control_ZM = internal global i1 false
@fpu_control_OM = internal global i1 false
@fpu_control_UM = internal global i1 false
@fpu_control_PM = internal global i1 false
@fpu_control_PC = internal global i2 0
@fpu_control_RC = internal global i2 0
@fpu_control_X = internal global i1 false
@fp0 = internal global double 0.000000e+00
@fp1 = internal global double 0.000000e+00
@fp2 = internal global double 0.000000e+00
@fp3 = internal global double 0.000000e+00
@fp4 = internal global double 0.000000e+00
@fp5 = internal global double 0.000000e+00
@fp6 = internal global double 0.000000e+00
@fp7 = internal global double 0.000000e+00
@k0 = internal global i64 0
@k1 = internal global i64 0
@k2 = internal global i64 0
@k3 = internal global i64 0
@k4 = internal global i64 0
@k5 = internal global i64 0
@k6 = internal global i64 0
@k7 = internal global i64 0
@mm0 = internal global i64 0
@mm1 = internal global i64 0
@mm2 = internal global i64 0
@mm3 = internal global i64 0
@mm4 = internal global i64 0
@mm5 = internal global i64 0
@mm6 = internal global i64 0
@mm7 = internal global i64 0
@xmm0 = internal global i128 0
@xmm1 = internal global i128 0
@xmm2 = internal global i128 0
@xmm3 = internal global i128 0
@xmm4 = internal global i128 0
@xmm5 = internal global i128 0
@xmm6 = internal global i128 0
@xmm7 = internal global i128 0
@xmm8 = internal global i128 0
@xmm9 = internal global i128 0
@xmm10 = internal global i128 0
@xmm11 = internal global i128 0
@xmm12 = internal global i128 0
@xmm13 = internal global i128 0
@xmm14 = internal global i128 0
@xmm15 = internal global i128 0
@xmm16 = internal global i128 0
@xmm17 = internal global i128 0
@xmm18 = internal global i128 0
@xmm19 = internal global i128 0
@xmm20 = internal global i128 0
@xmm21 = internal global i128 0
@xmm22 = internal global i128 0
@xmm23 = internal global i128 0
@xmm24 = internal global i128 0
@xmm25 = internal global i128 0
@xmm26 = internal global i128 0
@xmm27 = internal global i128 0
@xmm28 = internal global i128 0
@xmm29 = internal global i128 0
@xmm30 = internal global i128 0
@xmm31 = internal global i128 0
@ymm0 = internal global i256 0
@ymm1 = internal global i256 0
@ymm2 = internal global i256 0
@ymm3 = internal global i256 0
@ymm4 = internal global i256 0
@ymm5 = internal global i256 0
@ymm6 = internal global i256 0
@ymm7 = internal global i256 0
@ymm8 = internal global i256 0
@ymm9 = internal global i256 0
@ymm10 = internal global i256 0
@ymm11 = internal global i256 0
@ymm12 = internal global i256 0
@ymm13 = internal global i256 0
@ymm14 = internal global i256 0
@ymm15 = internal global i256 0
@ymm16 = internal global i256 0
@ymm17 = internal global i256 0
@ymm18 = internal global i256 0
@ymm19 = internal global i256 0
@ymm20 = internal global i256 0
@ymm21 = internal global i256 0
@ymm22 = internal global i256 0
@ymm23 = internal global i256 0
@ymm24 = internal global i256 0
@ymm25 = internal global i256 0
@ymm26 = internal global i256 0
@ymm27 = internal global i256 0
@ymm28 = internal global i256 0
@ymm29 = internal global i256 0
@ymm30 = internal global i256 0
@ymm31 = internal global i256 0
@zmm0 = internal global i512 0
@zmm1 = internal global i512 0
@zmm2 = internal global i512 0
@zmm3 = internal global i512 0
@zmm4 = internal global i512 0
@zmm5 = internal global i512 0
@zmm6 = internal global i512 0
@zmm7 = internal global i512 0
@zmm8 = internal global i512 0
@zmm9 = internal global i512 0
@zmm10 = internal global i512 0
@zmm11 = internal global i512 0
@zmm12 = internal global i512 0
@zmm13 = internal global i512 0
@zmm14 = internal global i512 0
@zmm15 = internal global i512 0
@zmm16 = internal global i512 0
@zmm17 = internal global i512 0
@zmm18 = internal global i512 0
@zmm19 = internal global i512 0
@zmm20 = internal global i512 0
@zmm21 = internal global i512 0
@zmm22 = internal global i512 0
@zmm23 = internal global i512 0
@zmm24 = internal global i512 0
@zmm25 = internal global i512 0
@zmm26 = internal global i512 0
@zmm27 = internal global i512 0
@zmm28 = internal global i512 0
@zmm29 = internal global i512 0
@zmm30 = internal global i512 0
@zmm31 = internal global i512 0
@bnd0 = internal global i128 0
@bnd1 = internal global i128 0
@bnd2 = internal global i128 0
@bnd3 = internal global i128 0
@dr0 = internal global i64 0
@dr1 = internal global i64 0
@dr2 = internal global i64 0
@dr3 = internal global i64 0
@dr4 = internal global i64 0
@dr5 = internal global i64 0
@dr6 = internal global i64 0
@dr7 = internal global i64 0
@dr8 = internal global i64 0
@dr9 = internal global i64 0
@dr10 = internal global i64 0
@dr11 = internal global i64 0
@dr12 = internal global i64 0
@dr13 = internal global i64 0
@dr14 = internal global i64 0
@dr15 = internal global i64 0
@cr0 = internal global i64 0
@cr1 = internal global i64 0
@cr2 = internal global i64 0
@cr3 = internal global i64 0
@cr4 = internal global i64 0
@cr5 = internal global i64 0
@cr6 = internal global i64 0
@cr7 = internal global i64 0
@cr8 = internal global i64 0
@cr9 = internal global i64 0
@cr10 = internal global i64 0
@cr11 = internal global i64 0
@cr12 = internal global i64 0
@cr13 = internal global i64 0
@cr14 = internal global i64 0
@cr15 = internal global i64 0
@fpsw = internal global i64 0
@rax = internal global i64 0
@rcx = internal global i64 0
@rdx = internal global i64 0
@rbx = internal global i64 0
@rsp = internal global i64 0
@rbp = internal global i64 0
@rsi = internal global i64 0
@rdi = internal global i64 0
@r8 = internal global i64 0
@r9 = internal global i64 0
@r10 = internal global i64 0
@r11 = internal global i64 0
@r12 = internal global i64 0
@r13 = internal global i64 0
@r14 = internal global i64 0
@r15 = internal global i64 0
@rip = internal global i64 0
@riz = internal global i64 0
@global_var_403ff8 = global i64 0
@global_var_404024 = external global i64
@global_var_402010 = constant [4 x i8] c"%d\0A\00"
@0 = external global i32

define i64 @_init() {
dec_label_pc_401000:
  %stack_var_-8 = alloca i64

; 0x401000
  store volatile i64 4198400, i64* @_asm_program_counter

; 0x401004
  store volatile i64 4198404, i64* @_asm_program_counter
  %0 = ptrtoint i64* %stack_var_-8 to i64
  store i64 %0, i64* @rsp

; 0x401008
  store volatile i64 4198408, i64* @_asm_program_counter
  %1 = load i64, i64* inttoptr (i64 4210672 to i64*)
  store i64 %1, i64* @rax

; 0x40100f
  store volatile i64 4198415, i64* @_asm_program_counter
  %2 = icmp eq i64 %1, 0

; 0x401012
  store volatile i64 4198418, i64* @_asm_program_counter
  br i1 %2, label %dec_label_pc_401016, label %dec_label_pc_401014

dec_label_pc_401014:                              ; preds = %dec_label_pc_401000

; 0x401014
  store volatile i64 4198420, i64* @_asm_program_counter
  call void @__gmon_start__()
  %3 = ptrtoint i32* @0 to i64
  store i64 %3, i64* @rax
  br label %dec_label_pc_401016

dec_label_pc_401016:                              ; preds = %dec_label_pc_401014, %dec_label_pc_401000

; 0x401016
  store volatile i64 4198422, i64* @_asm_program_counter

; 0x40101a
  store volatile i64 4198426, i64* @_asm_program_counter
  %4 = load i64, i64* @rax
  ret i64 %4
}

define i32 @function_401030(i8* %format, ...) {
dec_label_pc_401030:
  %0 = ptrtoint i8* %format to i64

; 0x401030
  store volatile i64 4198448, i64* @_asm_program_counter
  %1 = inttoptr i64 %0 to i8*
  %2 = call i32 (i8*, ...) @printf(i8* %format)
  %3 = sext i32 %2 to i64
  %4 = trunc i64 %3 to i32
  ret i32 %4
}

declare i64 @1()

define i64 @_start(i64 %arg1, i64 %arg2, i64 %arg3, i64 %arg4, i64 %arg5, i64 %arg6) {
dec_label_pc_401040:
  %stack_var_-16 = alloca i64
  %stack_var_-8 = alloca i64
  %stack_var_8 = alloca i64
  %stack_var_0 = alloca i64
  store i64 %arg6, i64* %stack_var_0

; 0x401040
  store volatile i64 4198464, i64* @_asm_program_counter

; 0x401044
  store volatile i64 4198468, i64* @_asm_program_counter

; 0x401046
  store volatile i64 4198470, i64* @_asm_program_counter

; 0x401049
  store volatile i64 4198473, i64* @_asm_program_counter
  %0 = load i64, i64* %stack_var_0

; 0x40104a
  store volatile i64 4198474, i64* @_asm_program_counter
  %1 = ptrtoint i64* %stack_var_8 to i64

; 0x40104d
  store volatile i64 4198477, i64* @_asm_program_counter

; 0x401051
  store volatile i64 4198481, i64* @_asm_program_counter
  %2 = load i64, i64* @rax
  store i64 %2, i64* %stack_var_-8

; 0x401052
  store volatile i64 4198482, i64* @_asm_program_counter
  %3 = ptrtoint i64* %stack_var_-8 to i64
  store i64 %3, i64* %stack_var_-16

; 0x401053
  store volatile i64 4198483, i64* @_asm_program_counter
  %4 = trunc i64 %arg5 to i32
  %5 = trunc i64 %arg5 to i32
  %6 = xor i32 %4, %5
  %7 = zext i32 %6 to i64

; 0x401056
  store volatile i64 4198486, i64* @_asm_program_counter
  %8 = trunc i64 %arg4 to i32
  %9 = trunc i64 %arg4 to i32
  %10 = xor i32 %8, %9
  %11 = zext i32 %10 to i64

; 0x401058
  store volatile i64 4198488, i64* @_asm_program_counter

; 0x40105f
  store volatile i64 4198495, i64* @_asm_program_counter
  %12 = trunc i64 %0 to i32
  %13 = inttoptr i64 %1 to i8**
  %14 = inttoptr i64 %11 to void ()*
  %15 = inttoptr i64 %7 to void ()*
  %16 = inttoptr i64 %arg3 to void ()*
  %17 = call i32 @__libc_start_main(i64 4198721, i32 %12, i8** %13, void ()* %14, void ()* %15, void ()* %16)

; 0x401065
  store volatile i64 4198501, i64* @_asm_program_counter
  %18 = call i64 @__asm_hlt()
  unreachable
}

declare i64 @2()

define i64 @_dl_relocate_static_pie() {
dec_label_pc_401070:

; 0x401070
  store volatile i64 4198512, i64* @_asm_program_counter

; 0x401074
  store volatile i64 4198516, i64* @_asm_program_counter
  %0 = load i64, i64* @rax
  ret i64 %0
}

define i64 @deregister_tm_clones() {
dec_label_pc_401080:

; 0x401080
  store volatile i64 4198528, i64* @_asm_program_counter
  store i64 4210728, i64* @rdi

; 0x401087
  store volatile i64 4198535, i64* @_asm_program_counter
  store i64 4210728, i64* @rax

; 0x40108e
  store volatile i64 4198542, i64* @_asm_program_counter
  %0 = sub i64 4210728, 4210728
  %1 = icmp eq i64 %0, 0

; 0x401091
  store volatile i64 4198545, i64* @_asm_program_counter
  br i1 %1, label %dec_label_pc_4010a8, label %dec_label_pc_401093

dec_label_pc_401093:                              ; preds = %dec_label_pc_401080

; 0x401093
  store volatile i64 4198547, i64* @_asm_program_counter
  %2 = load i64, i64* inttoptr (i64 4210664 to i64*)
  store i64 %2, i64* @rax

; 0x40109a
  store volatile i64 4198554, i64* @_asm_program_counter
  %3 = icmp eq i64 %2, 0

; 0x40109d
  store volatile i64 4198557, i64* @_asm_program_counter
  br i1 %3, label %dec_label_pc_4010a8, label %dec_label_pc_40109f

dec_label_pc_40109f:                              ; preds = %dec_label_pc_401093

; 0x40109f
  store volatile i64 4198559, i64* @_asm_program_counter
  %4 = load i64, i64* @rdi
  %5 = call i64 @_ITM_deregisterTMCloneTable(i64 %4)
  ret i64 %5

dec_label_pc_4010a8:                              ; preds = %dec_label_pc_401093, %dec_label_pc_401080

; 0x4010a8
  store volatile i64 4198568, i64* @_asm_program_counter
  %6 = load i64, i64* @rax
  ret i64 %6
}

define i64 @register_tm_clones() {
dec_label_pc_4010b0:

; 0x4010b0
  store volatile i64 4198576, i64* @_asm_program_counter
  store i64 4210728, i64* @rdi

; 0x4010b7
  store volatile i64 4198583, i64* @_asm_program_counter

; 0x4010be
  store volatile i64 4198590, i64* @_asm_program_counter
  %0 = sub i64 4210728, 4210728

; 0x4010c1
  store volatile i64 4198593, i64* @_asm_program_counter

; 0x4010c4
  store volatile i64 4198596, i64* @_asm_program_counter
  %1 = lshr i64 %0, 63

; 0x4010c8
  store volatile i64 4198600, i64* @_asm_program_counter
  %2 = ashr i64 %0, 3
  store i64 %2, i64* @rax

; 0x4010cc
  store volatile i64 4198604, i64* @_asm_program_counter
  %3 = add i64 %1, %2

; 0x4010cf
  store volatile i64 4198607, i64* @_asm_program_counter
  %4 = ashr i64 %3, 1
  %5 = icmp eq i64 %4, 0
  store i64 %4, i64* @rsi

; 0x4010d2
  store volatile i64 4198610, i64* @_asm_program_counter
  br i1 %5, label %dec_label_pc_4010e8, label %dec_label_pc_4010d4

dec_label_pc_4010d4:                              ; preds = %dec_label_pc_4010b0

; 0x4010d4
  store volatile i64 4198612, i64* @_asm_program_counter
  %6 = load i64, i64* @global_var_403ff8
  store i64 %6, i64* @rax

; 0x4010db
  store volatile i64 4198619, i64* @_asm_program_counter
  %7 = icmp eq i64 %6, 0

; 0x4010de
  store volatile i64 4198622, i64* @_asm_program_counter
  br i1 %7, label %dec_label_pc_4010e8, label %dec_label_pc_4010e0

dec_label_pc_4010e0:                              ; preds = %dec_label_pc_4010d4

; 0x4010e0
  store volatile i64 4198624, i64* @_asm_program_counter
  %8 = load i64, i64* @rdi
  %9 = load i64, i64* @rsi
  %10 = call i64 @_ITM_registerTMCloneTable(i64 %8, i64 %9)
  ret i64 %10

dec_label_pc_4010e8:                              ; preds = %dec_label_pc_4010d4, %dec_label_pc_4010b0

; 0x4010e8
  store volatile i64 4198632, i64* @_asm_program_counter
  %11 = load i64, i64* @rax
  ret i64 %11
}

define i64 @__do_global_dtors_aux() {
dec_label_pc_4010f0:
  %stack_var_-8 = alloca i64

; 0x4010f0
  store volatile i64 4198640, i64* @_asm_program_counter

; 0x4010f4
  store volatile i64 4198644, i64* @_asm_program_counter
  %0 = load i8, i8* inttoptr (i64 4210724 to i8*)
  %1 = icmp eq i8 %0, 0

; 0x4010fb
  store volatile i64 4198651, i64* @_asm_program_counter
  %2 = icmp eq i1 %1, false
  br i1 %2, label %dec_label_pc_401110, label %dec_label_pc_4010fd

dec_label_pc_4010fd:                              ; preds = %dec_label_pc_4010f0

; 0x4010fd
  store volatile i64 4198653, i64* @_asm_program_counter
  %3 = load i64, i64* @rbp
  store i64 %3, i64* %stack_var_-8

; 0x4010fe
  store volatile i64 4198654, i64* @_asm_program_counter

; 0x401101
  store volatile i64 4198657, i64* @_asm_program_counter
  %4 = call i64 @deregister_tm_clones()

; 0x401106
  store volatile i64 4198662, i64* @_asm_program_counter
  store i8 1, i8* bitcast (i64* @global_var_404024 to i8*)

; 0x40110d
  store volatile i64 4198669, i64* @_asm_program_counter

; 0x40110e
  store volatile i64 4198670, i64* @_asm_program_counter
  ret i64 %4

dec_label_pc_401110:                              ; preds = %dec_label_pc_4010f0

; 0x401110
  store volatile i64 4198672, i64* @_asm_program_counter
  %5 = load i64, i64* @rax
  ret i64 %5
}

define i64 @frame_dummy() {
dec_label_pc_401120:

; 0x401120
  store volatile i64 4198688, i64* @_asm_program_counter

; 0x401124
  store volatile i64 4198692, i64* @_asm_program_counter
  %0 = call i64 @register_tm_clones()
  ret i64 %0
}

define i64 @add(i32* %arg1, i64 %arg2) {
dec_label_pc_401126:
  %stack_var_-8 = alloca i64

; 0x401126
  store volatile i64 4198694, i64* @_asm_program_counter
  %0 = load i64, i64* @rbp
  store i64 %0, i64* %stack_var_-8

; 0x401127
  store volatile i64 4198695, i64* @_asm_program_counter

; 0x40112a
  store volatile i64 4198698, i64* @_asm_program_counter

; 0x40112e
  store volatile i64 4198702, i64* @_asm_program_counter
  %1 = trunc i64 %arg2 to i32
  %2 = zext i32 %1 to i64

; 0x401130
  store volatile i64 4198704, i64* @_asm_program_counter
  %3 = trunc i64 %2 to i8

; 0x401133
  store volatile i64 4198707, i64* @_asm_program_counter

; 0x401137
  store volatile i64 4198711, i64* @_asm_program_counter
  %4 = load i32, i32* bitcast (i64* @rdi to i32*)
  %5 = zext i32 %4 to i64

; 0x401139
  store volatile i64 4198713, i64* @_asm_program_counter
  %6 = sext i8 %3 to i64

; 0x40113d
  store volatile i64 4198717, i64* @_asm_program_counter
  %7 = trunc i64 %6 to i32
  %8 = trunc i64 %5 to i32
  %9 = add i32 %7, %8
  %10 = zext i32 %9 to i64

; 0x40113f
  store volatile i64 4198719, i64* @_asm_program_counter

; 0x401140
  store volatile i64 4198720, i64* @_asm_program_counter
  ret i64 %10
}

declare i64 @3()

define i64 @main(i64 %argc, i8** %argv) {
dec_label_pc_401141:
  %stack_var_-32 = alloca i32
  %stack_var_-8 = alloca i64

; 0x401141
  store volatile i64 4198721, i64* @_asm_program_counter
  %0 = load i64, i64* @rbp
  store i64 %0, i64* %stack_var_-8

; 0x401142
  store volatile i64 4198722, i64* @_asm_program_counter

; 0x401145
  store volatile i64 4198725, i64* @_asm_program_counter

; 0x401149
  store volatile i64 4198729, i64* @_asm_program_counter
  store i32 1, i32* %stack_var_-32

; 0x401150
  store volatile i64 4198736, i64* @_asm_program_counter

; 0x401154
  store volatile i64 4198740, i64* @_asm_program_counter
  %1 = sext i8 2 to i64

; 0x401158
  store volatile i64 4198744, i64* @_asm_program_counter

; 0x40115c
  store volatile i64 4198748, i64* @_asm_program_counter
  %2 = trunc i64 %1 to i32
  %3 = zext i32 %2 to i64

; 0x40115e
  store volatile i64 4198750, i64* @_asm_program_counter
  %4 = ptrtoint i32* %stack_var_-32 to i64

; 0x401161
  store volatile i64 4198753, i64* @_asm_program_counter
  %5 = inttoptr i64 %4 to i32*
  %6 = call i64 @add(i32* %5, i64 %3)

; 0x401166
  store volatile i64 4198758, i64* @_asm_program_counter
  %7 = trunc i64 %6 to i32

; 0x401169
  store volatile i64 4198761, i64* @_asm_program_counter

; 0x40116d
  store volatile i64 4198765, i64* @_asm_program_counter
  %8 = ptrtoint i32* %stack_var_-32 to i64

; 0x401171
  store volatile i64 4198769, i64* @_asm_program_counter
  %9 = sext i8 2 to i64

; 0x401175
  store volatile i64 4198773, i64* @_asm_program_counter

; 0x401179
  store volatile i64 4198777, i64* @_asm_program_counter
  %10 = trunc i64 %9 to i32
  %11 = zext i32 %10 to i64

; 0x40117b
  store volatile i64 4198779, i64* @_asm_program_counter

; 0x40117e
  store volatile i64 4198782, i64* @_asm_program_counter
  %12 = inttoptr i64 %8 to i32*
  %13 = call i64 @add(i32* %12, i64 %11)

; 0x401183
  store volatile i64 4198787, i64* @_asm_program_counter

; 0x401186
  store volatile i64 4198790, i64* @_asm_program_counter
  %14 = zext i32 %7 to i64

; 0x401189
  store volatile i64 4198793, i64* @_asm_program_counter
  %15 = trunc i64 %14 to i32
  %16 = zext i32 %15 to i64

; 0x40118b
  store volatile i64 4198795, i64* @_asm_program_counter

; 0x401190
  store volatile i64 4198800, i64* @_asm_program_counter

; 0x401195
  store volatile i64 4198805, i64* @_asm_program_counter
  %17 = inttoptr i64 ptrtoint ([4 x i8]* @global_var_402010 to i64) to i8*
  %18 = call i32 (i8*, ...) @printf(i8* %17, i64 %16)

; 0x40119a
  store volatile i64 4198810, i64* @_asm_program_counter

; 0x40119f
  store volatile i64 4198815, i64* @_asm_program_counter

; 0x4011a0
  store volatile i64 4198816, i64* @_asm_program_counter
  ret i64 0
}

declare i64 @4()

define i64 @_fini() {
dec_label_pc_4011a4:

; 0x4011a4
  store volatile i64 4198820, i64* @_asm_program_counter

; 0x4011a8
  store volatile i64 4198824, i64* @_asm_program_counter

; 0x4011ac
  store volatile i64 4198828, i64* @_asm_program_counter

; 0x4011b0
  store volatile i64 4198832, i64* @_asm_program_counter
  %0 = load i64, i64* @rax
  ret i64 %0
}

declare i32 @__libc_start_main(i64, i32, i8**, void ()*, void ()*, void ()*)

declare i64 @5()

declare i64 @_ITM_deregisterTMCloneTable(i64)

declare i64 @6()

declare void @__gmon_start__()

declare i64 @7()

declare i64 @_ITM_registerTMCloneTable(i64, i64)

declare i64 @8()

declare i32 @printf(i8*, ...)

declare i64 @9()

declare void @__pseudo_call(i64)

declare void @__pseudo_return(i64)

declare void @__pseudo_branch(i64)

declare void @__pseudo_cond_branch(i1, i64)

declare void @__frontend_reg_store.fpr(i3, x86_fp80)

declare x86_fp80 @__frontend_reg_load.fpr(i3)

; Function Attrs: nounwind readnone speculatable
declare i8 @llvm.ctpop.i8(i8) #0

declare i64 @__asm_hlt()

declare void @10()

attributes #0 = { nounwind readnone speculatable }
*** IR Dump After LLVM instruction optimization ***
source_filename = "test"
target datalayout = "e-m:e-p:64:64-i64:64-f80:128-n8:16:32:64-S128"

@_asm_program_counter = internal global i64 0
@cf = internal global i1 false
@pf = internal global i1 false
@az = internal global i1 false
@zf = internal global i1 false
@sf = internal global i1 false
@tf = internal global i1 false
@if = internal global i1 false
@df = internal global i1 false
@of = internal global i1 false
@iopl = internal global i2 0
@nt = internal global i1 false
@rf = internal global i1 false
@vm = internal global i1 false
@ac = internal global i1 false
@vif = internal global i1 false
@vip = internal global i1 false
@id = internal global i1 false
@rflags = internal global i64 0
@ss = internal global i16 0
@cs = internal global i16 0
@ds = internal global i16 0
@es = internal global i16 0
@fs = internal global i16 0
@gs = internal global i16 0
@st0 = internal global x86_fp80 0xK00000000000000000000
@st1 = internal global x86_fp80 0xK00000000000000000000
@st2 = internal global x86_fp80 0xK00000000000000000000
@st3 = internal global x86_fp80 0xK00000000000000000000
@st4 = internal global x86_fp80 0xK00000000000000000000
@st5 = internal global x86_fp80 0xK00000000000000000000
@st6 = internal global x86_fp80 0xK00000000000000000000
@st7 = internal global x86_fp80 0xK00000000000000000000
@fpu_stat_IE = internal global i1 false
@fpu_stat_DE = internal global i1 false
@fpu_stat_ZE = internal global i1 false
@fpu_stat_OE = internal global i1 false
@fpu_stat_UE = internal global i1 false
@fpu_stat_PE = internal global i1 false
@fpu_stat_SF = internal global i1 false
@fpu_stat_ES = internal global i1 false
@fpu_stat_C0 = internal global i1 false
@fpu_stat_C1 = internal global i1 false
@fpu_stat_C2 = internal global i1 false
@fpu_stat_C3 = internal global i1 false
@fpu_stat_TOP = internal global i3 0
@fpu_stat_B = internal global i1 false
@fpu_control_IM = internal global i1 false
@fpu_control_DM = internal global i1 false
@fpu_control_ZM = internal global i1 false
@fpu_control_OM = internal global i1 false
@fpu_control_UM = internal global i1 false
@fpu_control_PM = internal global i1 false
@fpu_control_PC = internal global i2 0
@fpu_control_RC = internal global i2 0
@fpu_control_X = internal global i1 false
@fp0 = internal global double 0.000000e+00
@fp1 = internal global double 0.000000e+00
@fp2 = internal global double 0.000000e+00
@fp3 = internal global double 0.000000e+00
@fp4 = internal global double 0.000000e+00
@fp5 = internal global double 0.000000e+00
@fp6 = internal global double 0.000000e+00
@fp7 = internal global double 0.000000e+00
@k0 = internal global i64 0
@k1 = internal global i64 0
@k2 = internal global i64 0
@k3 = internal global i64 0
@k4 = internal global i64 0
@k5 = internal global i64 0
@k6 = internal global i64 0
@k7 = internal global i64 0
@mm0 = internal global i64 0
@mm1 = internal global i64 0
@mm2 = internal global i64 0
@mm3 = internal global i64 0
@mm4 = internal global i64 0
@mm5 = internal global i64 0
@mm6 = internal global i64 0
@mm7 = internal global i64 0
@xmm0 = internal global i128 0
@xmm1 = internal global i128 0
@xmm2 = internal global i128 0
@xmm3 = internal global i128 0
@xmm4 = internal global i128 0
@xmm5 = internal global i128 0
@xmm6 = internal global i128 0
@xmm7 = internal global i128 0
@xmm8 = internal global i128 0
@xmm9 = internal global i128 0
@xmm10 = internal global i128 0
@xmm11 = internal global i128 0
@xmm12 = internal global i128 0
@xmm13 = internal global i128 0
@xmm14 = internal global i128 0
@xmm15 = internal global i128 0
@xmm16 = internal global i128 0
@xmm17 = internal global i128 0
@xmm18 = internal global i128 0
@xmm19 = internal global i128 0
@xmm20 = internal global i128 0
@xmm21 = internal global i128 0
@xmm22 = internal global i128 0
@xmm23 = internal global i128 0
@xmm24 = internal global i128 0
@xmm25 = internal global i128 0
@xmm26 = internal global i128 0
@xmm27 = internal global i128 0
@xmm28 = internal global i128 0
@xmm29 = internal global i128 0
@xmm30 = internal global i128 0
@xmm31 = internal global i128 0
@ymm0 = internal global i256 0
@ymm1 = internal global i256 0
@ymm2 = internal global i256 0
@ymm3 = internal global i256 0
@ymm4 = internal global i256 0
@ymm5 = internal global i256 0
@ymm6 = internal global i256 0
@ymm7 = internal global i256 0
@ymm8 = internal global i256 0
@ymm9 = internal global i256 0
@ymm10 = internal global i256 0
@ymm11 = internal global i256 0
@ymm12 = internal global i256 0
@ymm13 = internal global i256 0
@ymm14 = internal global i256 0
@ymm15 = internal global i256 0
@ymm16 = internal global i256 0
@ymm17 = internal global i256 0
@ymm18 = internal global i256 0
@ymm19 = internal global i256 0
@ymm20 = internal global i256 0
@ymm21 = internal global i256 0
@ymm22 = internal global i256 0
@ymm23 = internal global i256 0
@ymm24 = internal global i256 0
@ymm25 = internal global i256 0
@ymm26 = internal global i256 0
@ymm27 = internal global i256 0
@ymm28 = internal global i256 0
@ymm29 = internal global i256 0
@ymm30 = internal global i256 0
@ymm31 = internal global i256 0
@zmm0 = internal global i512 0
@zmm1 = internal global i512 0
@zmm2 = internal global i512 0
@zmm3 = internal global i512 0
@zmm4 = internal global i512 0
@zmm5 = internal global i512 0
@zmm6 = internal global i512 0
@zmm7 = internal global i512 0
@zmm8 = internal global i512 0
@zmm9 = internal global i512 0
@zmm10 = internal global i512 0
@zmm11 = internal global i512 0
@zmm12 = internal global i512 0
@zmm13 = internal global i512 0
@zmm14 = internal global i512 0
@zmm15 = internal global i512 0
@zmm16 = internal global i512 0
@zmm17 = internal global i512 0
@zmm18 = internal global i512 0
@zmm19 = internal global i512 0
@zmm20 = internal global i512 0
@zmm21 = internal global i512 0
@zmm22 = internal global i512 0
@zmm23 = internal global i512 0
@zmm24 = internal global i512 0
@zmm25 = internal global i512 0
@zmm26 = internal global i512 0
@zmm27 = internal global i512 0
@zmm28 = internal global i512 0
@zmm29 = internal global i512 0
@zmm30 = internal global i512 0
@zmm31 = internal global i512 0
@bnd0 = internal global i128 0
@bnd1 = internal global i128 0
@bnd2 = internal global i128 0
@bnd3 = internal global i128 0
@dr0 = internal global i64 0
@dr1 = internal global i64 0
@dr2 = internal global i64 0
@dr3 = internal global i64 0
@dr4 = internal global i64 0
@dr5 = internal global i64 0
@dr6 = internal global i64 0
@dr7 = internal global i64 0
@dr8 = internal global i64 0
@dr9 = internal global i64 0
@dr10 = internal global i64 0
@dr11 = internal global i64 0
@dr12 = internal global i64 0
@dr13 = internal global i64 0
@dr14 = internal global i64 0
@dr15 = internal global i64 0
@cr0 = internal global i64 0
@cr1 = internal global i64 0
@cr2 = internal global i64 0
@cr3 = internal global i64 0
@cr4 = internal global i64 0
@cr5 = internal global i64 0
@cr6 = internal global i64 0
@cr7 = internal global i64 0
@cr8 = internal global i64 0
@cr9 = internal global i64 0
@cr10 = internal global i64 0
@cr11 = internal global i64 0
@cr12 = internal global i64 0
@cr13 = internal global i64 0
@cr14 = internal global i64 0
@cr15 = internal global i64 0
@fpsw = internal global i64 0
@rax = internal global i64 0
@rcx = internal global i64 0
@rdx = internal global i64 0
@rbx = internal global i64 0
@rsp = internal global i64 0
@rbp = internal global i64 0
@rsi = internal global i64 0
@rdi = internal global i64 0
@r8 = internal global i64 0
@r9 = internal global i64 0
@r10 = internal global i64 0
@r11 = internal global i64 0
@r12 = internal global i64 0
@r13 = internal global i64 0
@r14 = internal global i64 0
@r15 = internal global i64 0
@rip = internal global i64 0
@riz = internal global i64 0
@global_var_403ff8 = global i64 0
@global_var_404024 = external global i64
@global_var_402010 = constant [4 x i8] c"%d\0A\00"
@0 = external global i32

define i64 @_init() {
dec_label_pc_401000:
  %stack_var_-8 = alloca i64

; 0x401000
  store volatile i64 4198400, i64* @_asm_program_counter

; 0x401004
  store volatile i64 4198404, i64* @_asm_program_counter
  %0 = ptrtoint i64* %stack_var_-8 to i64
  store i64 %0, i64* @rsp

; 0x401008
  store volatile i64 4198408, i64* @_asm_program_counter
  %1 = load i64, i64* inttoptr (i64 4210672 to i64*)
  store i64 %1, i64* @rax

; 0x40100f
  store volatile i64 4198415, i64* @_asm_program_counter
  %2 = icmp eq i64 %1, 0

; 0x401012
  store volatile i64 4198418, i64* @_asm_program_counter
  br i1 %2, label %dec_label_pc_401016, label %dec_label_pc_401014

dec_label_pc_401014:                              ; preds = %dec_label_pc_401000

; 0x401014
  store volatile i64 4198420, i64* @_asm_program_counter
  call void @__gmon_start__()
  %3 = ptrtoint i32* @0 to i64
  store i64 %3, i64* @rax
  br label %dec_label_pc_401016

dec_label_pc_401016:                              ; preds = %dec_label_pc_401014, %dec_label_pc_401000

; 0x401016
  store volatile i64 4198422, i64* @_asm_program_counter

; 0x40101a
  store volatile i64 4198426, i64* @_asm_program_counter
  %4 = load i64, i64* @rax
  ret i64 %4
}

define i32 @function_401030(i8* %format, ...) {
dec_label_pc_401030:

; 0x401030
  store volatile i64 4198448, i64* @_asm_program_counter
  %0 = call i32 (i8*, ...) @printf(i8* %format)
  %1 = sext i32 %0 to i64
  %2 = trunc i64 %1 to i32
  ret i32 %2
}

declare i64 @1()

define i64 @_start(i64 %arg1, i64 %arg2, i64 %arg3, i64 %arg4, i64 %arg5, i64 %arg6) {
dec_label_pc_401040:
  %stack_var_-16 = alloca i64
  %stack_var_-8 = alloca i64
  %stack_var_8 = alloca i64
  %stack_var_0 = alloca i64
  store i64 %arg6, i64* %stack_var_0

; 0x401040
  store volatile i64 4198464, i64* @_asm_program_counter

; 0x401044
  store volatile i64 4198468, i64* @_asm_program_counter

; 0x401046
  store volatile i64 4198470, i64* @_asm_program_counter

; 0x401049
  store volatile i64 4198473, i64* @_asm_program_counter
  %0 = load i64, i64* %stack_var_0

; 0x40104a
  store volatile i64 4198474, i64* @_asm_program_counter

; 0x40104d
  store volatile i64 4198477, i64* @_asm_program_counter

; 0x401051
  store volatile i64 4198481, i64* @_asm_program_counter
  %1 = load i64, i64* @rax
  store i64 %1, i64* %stack_var_-8

; 0x401052
  store volatile i64 4198482, i64* @_asm_program_counter
  %2 = ptrtoint i64* %stack_var_-8 to i64
  store i64 %2, i64* %stack_var_-16

; 0x401053
  store volatile i64 4198483, i64* @_asm_program_counter
  %3 = trunc i64 %arg5 to i32
  %4 = trunc i64 %arg5 to i32
  %5 = xor i32 %3, %4
  %6 = zext i32 %5 to i64

; 0x401056
  store volatile i64 4198486, i64* @_asm_program_counter
  %7 = trunc i64 %arg4 to i32
  %8 = trunc i64 %arg4 to i32
  %9 = xor i32 %7, %8
  %10 = zext i32 %9 to i64

; 0x401058
  store volatile i64 4198488, i64* @_asm_program_counter

; 0x40105f
  store volatile i64 4198495, i64* @_asm_program_counter
  %11 = trunc i64 %0 to i32
  %12 = bitcast i64* %stack_var_8 to i8**
  %13 = inttoptr i64 %10 to void ()*
  %14 = inttoptr i64 %6 to void ()*
  %15 = inttoptr i64 %arg3 to void ()*
  %16 = call i32 @__libc_start_main(i64 4198721, i32 %11, i8** %12, void ()* %13, void ()* %14, void ()* %15)

; 0x401065
  store volatile i64 4198501, i64* @_asm_program_counter
  %17 = call i64 @__asm_hlt()
  unreachable
}

declare i64 @2()

define i64 @_dl_relocate_static_pie() {
dec_label_pc_401070:

; 0x401070
  store volatile i64 4198512, i64* @_asm_program_counter

; 0x401074
  store volatile i64 4198516, i64* @_asm_program_counter
  %0 = load i64, i64* @rax
  ret i64 %0
}

define i64 @deregister_tm_clones() {
dec_label_pc_401080:

; 0x401080
  store volatile i64 4198528, i64* @_asm_program_counter
  store i64 4210728, i64* @rdi

; 0x401087
  store volatile i64 4198535, i64* @_asm_program_counter
  store i64 4210728, i64* @rax

; 0x40108e
  store volatile i64 4198542, i64* @_asm_program_counter
  %0 = sub i64 4210728, 4210728
  %1 = icmp eq i64 %0, 0

; 0x401091
  store volatile i64 4198545, i64* @_asm_program_counter
  br i1 %1, label %dec_label_pc_4010a8, label %dec_label_pc_401093

dec_label_pc_401093:                              ; preds = %dec_label_pc_401080

; 0x401093
  store volatile i64 4198547, i64* @_asm_program_counter
  %2 = load i64, i64* inttoptr (i64 4210664 to i64*)
  store i64 %2, i64* @rax

; 0x40109a
  store volatile i64 4198554, i64* @_asm_program_counter
  %3 = icmp eq i64 %2, 0

; 0x40109d
  store volatile i64 4198557, i64* @_asm_program_counter
  br i1 %3, label %dec_label_pc_4010a8, label %dec_label_pc_40109f

dec_label_pc_40109f:                              ; preds = %dec_label_pc_401093

; 0x40109f
  store volatile i64 4198559, i64* @_asm_program_counter
  %4 = load i64, i64* @rdi
  %5 = call i64 @_ITM_deregisterTMCloneTable(i64 %4)
  ret i64 %5

dec_label_pc_4010a8:                              ; preds = %dec_label_pc_401093, %dec_label_pc_401080

; 0x4010a8
  store volatile i64 4198568, i64* @_asm_program_counter
  %6 = load i64, i64* @rax
  ret i64 %6
}

define i64 @register_tm_clones() {
dec_label_pc_4010b0:

; 0x4010b0
  store volatile i64 4198576, i64* @_asm_program_counter
  store i64 4210728, i64* @rdi

; 0x4010b7
  store volatile i64 4198583, i64* @_asm_program_counter

; 0x4010be
  store volatile i64 4198590, i64* @_asm_program_counter
  %0 = sub i64 4210728, 4210728

; 0x4010c1
  store volatile i64 4198593, i64* @_asm_program_counter

; 0x4010c4
  store volatile i64 4198596, i64* @_asm_program_counter
  %1 = lshr i64 %0, 63

; 0x4010c8
  store volatile i64 4198600, i64* @_asm_program_counter
  %2 = ashr i64 %0, 3
  store i64 %2, i64* @rax

; 0x4010cc
  store volatile i64 4198604, i64* @_asm_program_counter
  %3 = add i64 %1, %2

; 0x4010cf
  store volatile i64 4198607, i64* @_asm_program_counter
  %4 = ashr i64 %3, 1
  %5 = icmp eq i64 %4, 0
  store i64 %4, i64* @rsi

; 0x4010d2
  store volatile i64 4198610, i64* @_asm_program_counter
  br i1 %5, label %dec_label_pc_4010e8, label %dec_label_pc_4010d4

dec_label_pc_4010d4:                              ; preds = %dec_label_pc_4010b0

; 0x4010d4
  store volatile i64 4198612, i64* @_asm_program_counter
  %6 = load i64, i64* @global_var_403ff8
  store i64 %6, i64* @rax

; 0x4010db
  store volatile i64 4198619, i64* @_asm_program_counter
  %7 = icmp eq i64 %6, 0

; 0x4010de
  store volatile i64 4198622, i64* @_asm_program_counter
  br i1 %7, label %dec_label_pc_4010e8, label %dec_label_pc_4010e0

dec_label_pc_4010e0:                              ; preds = %dec_label_pc_4010d4

; 0x4010e0
  store volatile i64 4198624, i64* @_asm_program_counter
  %8 = load i64, i64* @rdi
  %9 = load i64, i64* @rsi
  %10 = call i64 @_ITM_registerTMCloneTable(i64 %8, i64 %9)
  ret i64 %10

dec_label_pc_4010e8:                              ; preds = %dec_label_pc_4010d4, %dec_label_pc_4010b0

; 0x4010e8
  store volatile i64 4198632, i64* @_asm_program_counter
  %11 = load i64, i64* @rax
  ret i64 %11
}

define i64 @__do_global_dtors_aux() {
dec_label_pc_4010f0:
  %stack_var_-8 = alloca i64

; 0x4010f0
  store volatile i64 4198640, i64* @_asm_program_counter

; 0x4010f4
  store volatile i64 4198644, i64* @_asm_program_counter
  %0 = load i8, i8* inttoptr (i64 4210724 to i8*)
  %1 = icmp eq i8 %0, 0

; 0x4010fb
  store volatile i64 4198651, i64* @_asm_program_counter
  %2 = icmp eq i1 %1, false
  br i1 %2, label %dec_label_pc_401110, label %dec_label_pc_4010fd

dec_label_pc_4010fd:                              ; preds = %dec_label_pc_4010f0

; 0x4010fd
  store volatile i64 4198653, i64* @_asm_program_counter
  %3 = load i64, i64* @rbp
  store i64 %3, i64* %stack_var_-8

; 0x4010fe
  store volatile i64 4198654, i64* @_asm_program_counter

; 0x401101
  store volatile i64 4198657, i64* @_asm_program_counter
  %4 = call i64 @deregister_tm_clones()

; 0x401106
  store volatile i64 4198662, i64* @_asm_program_counter
  store i8 1, i8* bitcast (i64* @global_var_404024 to i8*)

; 0x40110d
  store volatile i64 4198669, i64* @_asm_program_counter

; 0x40110e
  store volatile i64 4198670, i64* @_asm_program_counter
  ret i64 %4

dec_label_pc_401110:                              ; preds = %dec_label_pc_4010f0

; 0x401110
  store volatile i64 4198672, i64* @_asm_program_counter
  %5 = load i64, i64* @rax
  ret i64 %5
}

define i64 @frame_dummy() {
dec_label_pc_401120:

; 0x401120
  store volatile i64 4198688, i64* @_asm_program_counter

; 0x401124
  store volatile i64 4198692, i64* @_asm_program_counter
  %0 = call i64 @register_tm_clones()
  ret i64 %0
}

define i64 @add(i32* %arg1, i64 %arg2) {
dec_label_pc_401126:
  %stack_var_-8 = alloca i64

; 0x401126
  store volatile i64 4198694, i64* @_asm_program_counter
  %0 = load i64, i64* @rbp
  store i64 %0, i64* %stack_var_-8

; 0x401127
  store volatile i64 4198695, i64* @_asm_program_counter

; 0x40112a
  store volatile i64 4198698, i64* @_asm_program_counter

; 0x40112e
  store volatile i64 4198702, i64* @_asm_program_counter
  %1 = trunc i64 %arg2 to i32
  %2 = zext i32 %1 to i64

; 0x401130
  store volatile i64 4198704, i64* @_asm_program_counter
  %3 = trunc i64 %2 to i8

; 0x401133
  store volatile i64 4198707, i64* @_asm_program_counter

; 0x401137
  store volatile i64 4198711, i64* @_asm_program_counter
  %4 = load i32, i32* bitcast (i64* @rdi to i32*)
  %5 = zext i32 %4 to i64

; 0x401139
  store volatile i64 4198713, i64* @_asm_program_counter
  %6 = sext i8 %3 to i64

; 0x40113d
  store volatile i64 4198717, i64* @_asm_program_counter
  %7 = trunc i64 %6 to i32
  %8 = trunc i64 %5 to i32
  %9 = add i32 %7, %8
  %10 = zext i32 %9 to i64

; 0x40113f
  store volatile i64 4198719, i64* @_asm_program_counter

; 0x401140
  store volatile i64 4198720, i64* @_asm_program_counter
  ret i64 %10
}

declare i64 @3()

define i64 @main(i64 %argc, i8** %argv) {
dec_label_pc_401141:
  %stack_var_-32 = alloca i32
  %stack_var_-8 = alloca i64

; 0x401141
  store volatile i64 4198721, i64* @_asm_program_counter
  %0 = load i64, i64* @rbp
  store i64 %0, i64* %stack_var_-8

; 0x401142
  store volatile i64 4198722, i64* @_asm_program_counter

; 0x401145
  store volatile i64 4198725, i64* @_asm_program_counter

; 0x401149
  store volatile i64 4198729, i64* @_asm_program_counter
  store i32 1, i32* %stack_var_-32

; 0x401150
  store volatile i64 4198736, i64* @_asm_program_counter

; 0x401154
  store volatile i64 4198740, i64* @_asm_program_counter
  %1 = sext i8 2 to i64

; 0x401158
  store volatile i64 4198744, i64* @_asm_program_counter

; 0x40115c
  store volatile i64 4198748, i64* @_asm_program_counter
  %2 = trunc i64 %1 to i32
  %3 = zext i32 %2 to i64

; 0x40115e
  store volatile i64 4198750, i64* @_asm_program_counter

; 0x401161
  store volatile i64 4198753, i64* @_asm_program_counter
  %4 = call i64 @add(i32* %stack_var_-32, i64 %3)

; 0x401166
  store volatile i64 4198758, i64* @_asm_program_counter
  %5 = trunc i64 %4 to i32

; 0x401169
  store volatile i64 4198761, i64* @_asm_program_counter

; 0x40116d
  store volatile i64 4198765, i64* @_asm_program_counter

; 0x401171
  store volatile i64 4198769, i64* @_asm_program_counter
  %6 = sext i8 2 to i64

; 0x401175
  store volatile i64 4198773, i64* @_asm_program_counter

; 0x401179
  store volatile i64 4198777, i64* @_asm_program_counter
  %7 = trunc i64 %6 to i32
  %8 = zext i32 %7 to i64

; 0x40117b
  store volatile i64 4198779, i64* @_asm_program_counter

; 0x40117e
  store volatile i64 4198782, i64* @_asm_program_counter
  %9 = call i64 @add(i32* %stack_var_-32, i64 %8)

; 0x401183
  store volatile i64 4198787, i64* @_asm_program_counter

; 0x401186
  store volatile i64 4198790, i64* @_asm_program_counter
  %10 = zext i32 %5 to i64

; 0x401189
  store volatile i64 4198793, i64* @_asm_program_counter
  %11 = trunc i64 %10 to i32
  %12 = zext i32 %11 to i64

; 0x40118b
  store volatile i64 4198795, i64* @_asm_program_counter

; 0x401190
  store volatile i64 4198800, i64* @_asm_program_counter

; 0x401195
  store volatile i64 4198805, i64* @_asm_program_counter
  %13 = inttoptr i64 ptrtoint ([4 x i8]* @global_var_402010 to i64) to i8*
  %14 = call i32 (i8*, ...) @printf(i8* %13, i64 %12)

; 0x40119a
  store volatile i64 4198810, i64* @_asm_program_counter

; 0x40119f
  store volatile i64 4198815, i64* @_asm_program_counter

; 0x4011a0
  store volatile i64 4198816, i64* @_asm_program_counter
  ret i64 0
}

declare i64 @4()

define i64 @_fini() {
dec_label_pc_4011a4:

; 0x4011a4
  store volatile i64 4198820, i64* @_asm_program_counter

; 0x4011a8
  store volatile i64 4198824, i64* @_asm_program_counter

; 0x4011ac
  store volatile i64 4198828, i64* @_asm_program_counter

; 0x4011b0
  store volatile i64 4198832, i64* @_asm_program_counter
  %0 = load i64, i64* @rax
  ret i64 %0
}

declare i32 @__libc_start_main(i64, i32, i8**, void ()*, void ()*, void ()*)

declare i64 @5()

declare i64 @_ITM_deregisterTMCloneTable(i64)

declare i64 @6()

declare void @__gmon_start__()

declare i64 @7()

declare i64 @_ITM_registerTMCloneTable(i64, i64)

declare i64 @8()

declare i32 @printf(i8*, ...)

declare i64 @9()

declare void @__pseudo_call(i64)

declare void @__pseudo_return(i64)

declare void @__pseudo_branch(i64)

declare void @__pseudo_cond_branch(i1, i64)

declare void @__frontend_reg_store.fpr(i3, x86_fp80)

declare x86_fp80 @__frontend_reg_load.fpr(i3)

; Function Attrs: nounwind readnone speculatable
declare i8 @llvm.ctpop.i8(i8) #0

declare i64 @__asm_hlt()

declare void @10()

attributes #0 = { nounwind readnone speculatable }
*** IR Dump After Simple types recovery optimization ***
source_filename = "test"
target datalayout = "e-m:e-p:64:64-i64:64-f80:128-n8:16:32:64-S128"

@_asm_program_counter = internal global i64 0
@cf = internal global i1 false
@pf = internal global i1 false
@az = internal global i1 false
@zf = internal global i1 false
@sf = internal global i1 false
@tf = internal global i1 false
@if = internal global i1 false
@df = internal global i1 false
@of = internal global i1 false
@iopl = internal global i2 0
@nt = internal global i1 false
@rf = internal global i1 false
@vm = internal global i1 false
@ac = internal global i1 false
@vif = internal global i1 false
@vip = internal global i1 false
@id = internal global i1 false
@rflags = internal global i64 0
@ss = internal global i16 0
@cs = internal global i16 0
@ds = internal global i16 0
@es = internal global i16 0
@fs = internal global i16 0
@gs = internal global i16 0
@st0 = internal global x86_fp80 0xK00000000000000000000
@st1 = internal global x86_fp80 0xK00000000000000000000
@st2 = internal global x86_fp80 0xK00000000000000000000
@st3 = internal global x86_fp80 0xK00000000000000000000
@st4 = internal global x86_fp80 0xK00000000000000000000
@st5 = internal global x86_fp80 0xK00000000000000000000
@st6 = internal global x86_fp80 0xK00000000000000000000
@st7 = internal global x86_fp80 0xK00000000000000000000
@fpu_stat_IE = internal global i1 false
@fpu_stat_DE = internal global i1 false
@fpu_stat_ZE = internal global i1 false
@fpu_stat_OE = internal global i1 false
@fpu_stat_UE = internal global i1 false
@fpu_stat_PE = internal global i1 false
@fpu_stat_SF = internal global i1 false
@fpu_stat_ES = internal global i1 false
@fpu_stat_C0 = internal global i1 false
@fpu_stat_C1 = internal global i1 false
@fpu_stat_C2 = internal global i1 false
@fpu_stat_C3 = internal global i1 false
@fpu_stat_TOP = internal global i3 0
@fpu_stat_B = internal global i1 false
@fpu_control_IM = internal global i1 false
@fpu_control_DM = internal global i1 false
@fpu_control_ZM = internal global i1 false
@fpu_control_OM = internal global i1 false
@fpu_control_UM = internal global i1 false
@fpu_control_PM = internal global i1 false
@fpu_control_PC = internal global i2 0
@fpu_control_RC = internal global i2 0
@fpu_control_X = internal global i1 false
@fp0 = internal global double 0.000000e+00
@fp1 = internal global double 0.000000e+00
@fp2 = internal global double 0.000000e+00
@fp3 = internal global double 0.000000e+00
@fp4 = internal global double 0.000000e+00
@fp5 = internal global double 0.000000e+00
@fp6 = internal global double 0.000000e+00
@fp7 = internal global double 0.000000e+00
@k0 = internal global i64 0
@k1 = internal global i64 0
@k2 = internal global i64 0
@k3 = internal global i64 0
@k4 = internal global i64 0
@k5 = internal global i64 0
@k6 = internal global i64 0
@k7 = internal global i64 0
@mm0 = internal global i64 0
@mm1 = internal global i64 0
@mm2 = internal global i64 0
@mm3 = internal global i64 0
@mm4 = internal global i64 0
@mm5 = internal global i64 0
@mm6 = internal global i64 0
@mm7 = internal global i64 0
@xmm0 = internal global i128 0
@xmm1 = internal global i128 0
@xmm2 = internal global i128 0
@xmm3 = internal global i128 0
@xmm4 = internal global i128 0
@xmm5 = internal global i128 0
@xmm6 = internal global i128 0
@xmm7 = internal global i128 0
@xmm8 = internal global i128 0
@xmm9 = internal global i128 0
@xmm10 = internal global i128 0
@xmm11 = internal global i128 0
@xmm12 = internal global i128 0
@xmm13 = internal global i128 0
@xmm14 = internal global i128 0
@xmm15 = internal global i128 0
@xmm16 = internal global i128 0
@xmm17 = internal global i128 0
@xmm18 = internal global i128 0
@xmm19 = internal global i128 0
@xmm20 = internal global i128 0
@xmm21 = internal global i128 0
@xmm22 = internal global i128 0
@xmm23 = internal global i128 0
@xmm24 = internal global i128 0
@xmm25 = internal global i128 0
@xmm26 = internal global i128 0
@xmm27 = internal global i128 0
@xmm28 = internal global i128 0
@xmm29 = internal global i128 0
@xmm30 = internal global i128 0
@xmm31 = internal global i128 0
@ymm0 = internal global i256 0
@ymm1 = internal global i256 0
@ymm2 = internal global i256 0
@ymm3 = internal global i256 0
@ymm4 = internal global i256 0
@ymm5 = internal global i256 0
@ymm6 = internal global i256 0
@ymm7 = internal global i256 0
@ymm8 = internal global i256 0
@ymm9 = internal global i256 0
@ymm10 = internal global i256 0
@ymm11 = internal global i256 0
@ymm12 = internal global i256 0
@ymm13 = internal global i256 0
@ymm14 = internal global i256 0
@ymm15 = internal global i256 0
@ymm16 = internal global i256 0
@ymm17 = internal global i256 0
@ymm18 = internal global i256 0
@ymm19 = internal global i256 0
@ymm20 = internal global i256 0
@ymm21 = internal global i256 0
@ymm22 = internal global i256 0
@ymm23 = internal global i256 0
@ymm24 = internal global i256 0
@ymm25 = internal global i256 0
@ymm26 = internal global i256 0
@ymm27 = internal global i256 0
@ymm28 = internal global i256 0
@ymm29 = internal global i256 0
@ymm30 = internal global i256 0
@ymm31 = internal global i256 0
@zmm0 = internal global i512 0
@zmm1 = internal global i512 0
@zmm2 = internal global i512 0
@zmm3 = internal global i512 0
@zmm4 = internal global i512 0
@zmm5 = internal global i512 0
@zmm6 = internal global i512 0
@zmm7 = internal global i512 0
@zmm8 = internal global i512 0
@zmm9 = internal global i512 0
@zmm10 = internal global i512 0
@zmm11 = internal global i512 0
@zmm12 = internal global i512 0
@zmm13 = internal global i512 0
@zmm14 = internal global i512 0
@zmm15 = internal global i512 0
@zmm16 = internal global i512 0
@zmm17 = internal global i512 0
@zmm18 = internal global i512 0
@zmm19 = internal global i512 0
@zmm20 = internal global i512 0
@zmm21 = internal global i512 0
@zmm22 = internal global i512 0
@zmm23 = internal global i512 0
@zmm24 = internal global i512 0
@zmm25 = internal global i512 0
@zmm26 = internal global i512 0
@zmm27 = internal global i512 0
@zmm28 = internal global i512 0
@zmm29 = internal global i512 0
@zmm30 = internal global i512 0
@zmm31 = internal global i512 0
@bnd0 = internal global i128 0
@bnd1 = internal global i128 0
@bnd2 = internal global i128 0
@bnd3 = internal global i128 0
@dr0 = internal global i64 0
@dr1 = internal global i64 0
@dr2 = internal global i64 0
@dr3 = internal global i64 0
@dr4 = internal global i64 0
@dr5 = internal global i64 0
@dr6 = internal global i64 0
@dr7 = internal global i64 0
@dr8 = internal global i64 0
@dr9 = internal global i64 0
@dr10 = internal global i64 0
@dr11 = internal global i64 0
@dr12 = internal global i64 0
@dr13 = internal global i64 0
@dr14 = internal global i64 0
@dr15 = internal global i64 0
@cr0 = internal global i64 0
@cr1 = internal global i64 0
@cr2 = internal global i64 0
@cr3 = internal global i64 0
@cr4 = internal global i64 0
@cr5 = internal global i64 0
@cr6 = internal global i64 0
@cr7 = internal global i64 0
@cr8 = internal global i64 0
@cr9 = internal global i64 0
@cr10 = internal global i64 0
@cr11 = internal global i64 0
@cr12 = internal global i64 0
@cr13 = internal global i64 0
@cr14 = internal global i64 0
@cr15 = internal global i64 0
@fpsw = internal global i64 0
@rax = internal global i64 0
@rcx = internal global i64 0
@rdx = internal global i64 0
@rbx = internal global i64 0
@rsp = internal global i64 0
@rbp = internal global i64 0
@rsi = internal global i64 0
@rdi = internal global i64 0
@r8 = internal global i64 0
@r9 = internal global i64 0
@r10 = internal global i64 0
@r11 = internal global i64 0
@r12 = internal global i64 0
@r13 = internal global i64 0
@r14 = internal global i64 0
@r15 = internal global i64 0
@rip = internal global i64 0
@riz = internal global i64 0
@global_var_403ff8 = global i64 0
@global_var_404024 = external global i64
@global_var_402010 = constant [4 x i8] c"%d\0A\00"
@0 = external global i32

define i64 @_init() {
dec_label_pc_401000:
  %stack_var_-8 = alloca i64

; 0x401000
  store volatile i64 4198400, i64* @_asm_program_counter

; 0x401004
  store volatile i64 4198404, i64* @_asm_program_counter
  %0 = ptrtoint i64* %stack_var_-8 to i64
  store i64 %0, i64* @rsp

; 0x401008
  store volatile i64 4198408, i64* @_asm_program_counter
  %1 = load i64, i64* inttoptr (i64 4210672 to i64*)
  store i64 %1, i64* @rax

; 0x40100f
  store volatile i64 4198415, i64* @_asm_program_counter
  %2 = icmp eq i64 %1, 0

; 0x401012
  store volatile i64 4198418, i64* @_asm_program_counter
  br i1 %2, label %dec_label_pc_401016, label %dec_label_pc_401014

dec_label_pc_401014:                              ; preds = %dec_label_pc_401000

; 0x401014
  store volatile i64 4198420, i64* @_asm_program_counter
  call void @__gmon_start__()
  %3 = ptrtoint i32* @0 to i64
  store i64 %3, i64* @rax
  br label %dec_label_pc_401016

dec_label_pc_401016:                              ; preds = %dec_label_pc_401014, %dec_label_pc_401000

; 0x401016
  store volatile i64 4198422, i64* @_asm_program_counter

; 0x40101a
  store volatile i64 4198426, i64* @_asm_program_counter
  %4 = load i64, i64* @rax
  ret i64 %4
}

define i32 @function_401030(i8* %format, ...) {
dec_label_pc_401030:

; 0x401030
  store volatile i64 4198448, i64* @_asm_program_counter
  %0 = call i32 (i8*, ...) @printf(i8* %format)
  %1 = sext i32 %0 to i64
  %2 = trunc i64 %1 to i32
  ret i32 %2
}

declare i64 @1()

define i64 @_start(i64 %arg1, i64 %arg2, i64 %arg3, i64 %arg4, i64 %arg5, i64 %arg6) {
dec_label_pc_401040:
  %stack_var_-16 = alloca i64
  %stack_var_-8 = alloca i64
  %stack_var_8 = alloca i64
  %stack_var_0 = alloca i64
  store i64 %arg6, i64* %stack_var_0

; 0x401040
  store volatile i64 4198464, i64* @_asm_program_counter

; 0x401044
  store volatile i64 4198468, i64* @_asm_program_counter

; 0x401046
  store volatile i64 4198470, i64* @_asm_program_counter

; 0x401049
  store volatile i64 4198473, i64* @_asm_program_counter
  %0 = load i64, i64* %stack_var_0

; 0x40104a
  store volatile i64 4198474, i64* @_asm_program_counter

; 0x40104d
  store volatile i64 4198477, i64* @_asm_program_counter

; 0x401051
  store volatile i64 4198481, i64* @_asm_program_counter
  %1 = load i64, i64* @rax
  store i64 %1, i64* %stack_var_-8

; 0x401052
  store volatile i64 4198482, i64* @_asm_program_counter
  %2 = ptrtoint i64* %stack_var_-8 to i64
  store i64 %2, i64* %stack_var_-16

; 0x401053
  store volatile i64 4198483, i64* @_asm_program_counter
  %3 = trunc i64 %arg5 to i32
  %4 = trunc i64 %arg5 to i32
  %5 = xor i32 %3, %4
  %6 = zext i32 %5 to i64

; 0x401056
  store volatile i64 4198486, i64* @_asm_program_counter
  %7 = trunc i64 %arg4 to i32
  %8 = trunc i64 %arg4 to i32
  %9 = xor i32 %7, %8
  %10 = zext i32 %9 to i64

; 0x401058
  store volatile i64 4198488, i64* @_asm_program_counter

; 0x40105f
  store volatile i64 4198495, i64* @_asm_program_counter
  %11 = trunc i64 %0 to i32
  %12 = bitcast i64* %stack_var_8 to i8**
  %13 = inttoptr i64 %10 to void ()*
  %14 = inttoptr i64 %6 to void ()*
  %15 = inttoptr i64 %arg3 to void ()*
  %16 = call i32 @__libc_start_main(i64 4198721, i32 %11, i8** %12, void ()* %13, void ()* %14, void ()* %15)

; 0x401065
  store volatile i64 4198501, i64* @_asm_program_counter
  %17 = call i64 @__asm_hlt()
  unreachable
}

declare i64 @2()

define i64 @_dl_relocate_static_pie() {
dec_label_pc_401070:

; 0x401070
  store volatile i64 4198512, i64* @_asm_program_counter

; 0x401074
  store volatile i64 4198516, i64* @_asm_program_counter
  %0 = load i64, i64* @rax
  ret i64 %0
}

define i64 @deregister_tm_clones() {
dec_label_pc_401080:

; 0x401080
  store volatile i64 4198528, i64* @_asm_program_counter
  store i64 4210728, i64* @rdi

; 0x401087
  store volatile i64 4198535, i64* @_asm_program_counter
  store i64 4210728, i64* @rax

; 0x40108e
  store volatile i64 4198542, i64* @_asm_program_counter
  %0 = sub i64 4210728, 4210728
  %1 = icmp eq i64 %0, 0

; 0x401091
  store volatile i64 4198545, i64* @_asm_program_counter
  br i1 %1, label %dec_label_pc_4010a8, label %dec_label_pc_401093

dec_label_pc_401093:                              ; preds = %dec_label_pc_401080

; 0x401093
  store volatile i64 4198547, i64* @_asm_program_counter
  %2 = load i64, i64* inttoptr (i64 4210664 to i64*)
  store i64 %2, i64* @rax

; 0x40109a
  store volatile i64 4198554, i64* @_asm_program_counter
  %3 = icmp eq i64 %2, 0

; 0x40109d
  store volatile i64 4198557, i64* @_asm_program_counter
  br i1 %3, label %dec_label_pc_4010a8, label %dec_label_pc_40109f

dec_label_pc_40109f:                              ; preds = %dec_label_pc_401093

; 0x40109f
  store volatile i64 4198559, i64* @_asm_program_counter
  %4 = load i64, i64* @rdi
  %5 = call i64 @_ITM_deregisterTMCloneTable(i64 %4)
  ret i64 %5

dec_label_pc_4010a8:                              ; preds = %dec_label_pc_401093, %dec_label_pc_401080

; 0x4010a8
  store volatile i64 4198568, i64* @_asm_program_counter
  %6 = load i64, i64* @rax
  ret i64 %6
}

define i64 @register_tm_clones() {
dec_label_pc_4010b0:

; 0x4010b0
  store volatile i64 4198576, i64* @_asm_program_counter
  store i64 4210728, i64* @rdi

; 0x4010b7
  store volatile i64 4198583, i64* @_asm_program_counter

; 0x4010be
  store volatile i64 4198590, i64* @_asm_program_counter
  %0 = sub i64 4210728, 4210728

; 0x4010c1
  store volatile i64 4198593, i64* @_asm_program_counter

; 0x4010c4
  store volatile i64 4198596, i64* @_asm_program_counter
  %1 = lshr i64 %0, 63

; 0x4010c8
  store volatile i64 4198600, i64* @_asm_program_counter
  %2 = ashr i64 %0, 3
  store i64 %2, i64* @rax

; 0x4010cc
  store volatile i64 4198604, i64* @_asm_program_counter
  %3 = add i64 %1, %2

; 0x4010cf
  store volatile i64 4198607, i64* @_asm_program_counter
  %4 = ashr i64 %3, 1
  %5 = icmp eq i64 %4, 0
  store i64 %4, i64* @rsi

; 0x4010d2
  store volatile i64 4198610, i64* @_asm_program_counter
  br i1 %5, label %dec_label_pc_4010e8, label %dec_label_pc_4010d4

dec_label_pc_4010d4:                              ; preds = %dec_label_pc_4010b0

; 0x4010d4
  store volatile i64 4198612, i64* @_asm_program_counter
  %6 = load i64, i64* @global_var_403ff8
  store i64 %6, i64* @rax

; 0x4010db
  store volatile i64 4198619, i64* @_asm_program_counter
  %7 = icmp eq i64 %6, 0

; 0x4010de
  store volatile i64 4198622, i64* @_asm_program_counter
  br i1 %7, label %dec_label_pc_4010e8, label %dec_label_pc_4010e0

dec_label_pc_4010e0:                              ; preds = %dec_label_pc_4010d4

; 0x4010e0
  store volatile i64 4198624, i64* @_asm_program_counter
  %8 = load i64, i64* @rdi
  %9 = load i64, i64* @rsi
  %10 = call i64 @_ITM_registerTMCloneTable(i64 %8, i64 %9)
  ret i64 %10

dec_label_pc_4010e8:                              ; preds = %dec_label_pc_4010d4, %dec_label_pc_4010b0

; 0x4010e8
  store volatile i64 4198632, i64* @_asm_program_counter
  %11 = load i64, i64* @rax
  ret i64 %11
}

define i64 @__do_global_dtors_aux() {
dec_label_pc_4010f0:
  %stack_var_-8 = alloca i64

; 0x4010f0
  store volatile i64 4198640, i64* @_asm_program_counter

; 0x4010f4
  store volatile i64 4198644, i64* @_asm_program_counter
  %0 = load i8, i8* inttoptr (i64 4210724 to i8*)
  %1 = icmp eq i8 %0, 0

; 0x4010fb
  store volatile i64 4198651, i64* @_asm_program_counter
  %2 = icmp eq i1 %1, false
  br i1 %2, label %dec_label_pc_401110, label %dec_label_pc_4010fd

dec_label_pc_4010fd:                              ; preds = %dec_label_pc_4010f0

; 0x4010fd
  store volatile i64 4198653, i64* @_asm_program_counter
  %3 = load i64, i64* @rbp
  store i64 %3, i64* %stack_var_-8

; 0x4010fe
  store volatile i64 4198654, i64* @_asm_program_counter

; 0x401101
  store volatile i64 4198657, i64* @_asm_program_counter
  %4 = call i64 @deregister_tm_clones()

; 0x401106
  store volatile i64 4198662, i64* @_asm_program_counter
  store i8 1, i8* bitcast (i64* @global_var_404024 to i8*)

; 0x40110d
  store volatile i64 4198669, i64* @_asm_program_counter

; 0x40110e
  store volatile i64 4198670, i64* @_asm_program_counter
  ret i64 %4

dec_label_pc_401110:                              ; preds = %dec_label_pc_4010f0

; 0x401110
  store volatile i64 4198672, i64* @_asm_program_counter
  %5 = load i64, i64* @rax
  ret i64 %5
}

define i64 @frame_dummy() {
dec_label_pc_401120:

; 0x401120
  store volatile i64 4198688, i64* @_asm_program_counter

; 0x401124
  store volatile i64 4198692, i64* @_asm_program_counter
  %0 = call i64 @register_tm_clones()
  ret i64 %0
}

define i64 @add(i32* %arg1, i64 %arg2) {
dec_label_pc_401126:
  %stack_var_-8 = alloca i64

; 0x401126
  store volatile i64 4198694, i64* @_asm_program_counter
  %0 = load i64, i64* @rbp
  store i64 %0, i64* %stack_var_-8

; 0x401127
  store volatile i64 4198695, i64* @_asm_program_counter

; 0x40112a
  store volatile i64 4198698, i64* @_asm_program_counter

; 0x40112e
  store volatile i64 4198702, i64* @_asm_program_counter
  %1 = trunc i64 %arg2 to i32
  %2 = zext i32 %1 to i64

; 0x401130
  store volatile i64 4198704, i64* @_asm_program_counter
  %3 = trunc i64 %2 to i8

; 0x401133
  store volatile i64 4198707, i64* @_asm_program_counter

; 0x401137
  store volatile i64 4198711, i64* @_asm_program_counter
  %4 = load i32, i32* bitcast (i64* @rdi to i32*)
  %5 = zext i32 %4 to i64

; 0x401139
  store volatile i64 4198713, i64* @_asm_program_counter
  %6 = sext i8 %3 to i64

; 0x40113d
  store volatile i64 4198717, i64* @_asm_program_counter
  %7 = trunc i64 %6 to i32
  %8 = trunc i64 %5 to i32
  %9 = add i32 %7, %8
  %10 = zext i32 %9 to i64

; 0x40113f
  store volatile i64 4198719, i64* @_asm_program_counter

; 0x401140
  store volatile i64 4198720, i64* @_asm_program_counter
  ret i64 %10
}

declare i64 @3()

define i64 @main(i64 %argc, i8** %argv) {
dec_label_pc_401141:
  %stack_var_-32 = alloca i32
  %stack_var_-8 = alloca i64

; 0x401141
  store volatile i64 4198721, i64* @_asm_program_counter
  %0 = load i64, i64* @rbp
  store i64 %0, i64* %stack_var_-8

; 0x401142
  store volatile i64 4198722, i64* @_asm_program_counter

; 0x401145
  store volatile i64 4198725, i64* @_asm_program_counter

; 0x401149
  store volatile i64 4198729, i64* @_asm_program_counter
  store i32 1, i32* %stack_var_-32

; 0x401150
  store volatile i64 4198736, i64* @_asm_program_counter

; 0x401154
  store volatile i64 4198740, i64* @_asm_program_counter
  %1 = sext i8 2 to i64

; 0x401158
  store volatile i64 4198744, i64* @_asm_program_counter

; 0x40115c
  store volatile i64 4198748, i64* @_asm_program_counter
  %2 = trunc i64 %1 to i32
  %3 = zext i32 %2 to i64

; 0x40115e
  store volatile i64 4198750, i64* @_asm_program_counter

; 0x401161
  store volatile i64 4198753, i64* @_asm_program_counter
  %4 = call i64 @add(i32* %stack_var_-32, i64 %3)

; 0x401166
  store volatile i64 4198758, i64* @_asm_program_counter
  %5 = trunc i64 %4 to i32

; 0x401169
  store volatile i64 4198761, i64* @_asm_program_counter

; 0x40116d
  store volatile i64 4198765, i64* @_asm_program_counter

; 0x401171
  store volatile i64 4198769, i64* @_asm_program_counter
  %6 = sext i8 2 to i64

; 0x401175
  store volatile i64 4198773, i64* @_asm_program_counter

; 0x401179
  store volatile i64 4198777, i64* @_asm_program_counter
  %7 = trunc i64 %6 to i32
  %8 = zext i32 %7 to i64

; 0x40117b
  store volatile i64 4198779, i64* @_asm_program_counter

; 0x40117e
  store volatile i64 4198782, i64* @_asm_program_counter
  %9 = call i64 @add(i32* %stack_var_-32, i64 %8)

; 0x401183
  store volatile i64 4198787, i64* @_asm_program_counter

; 0x401186
  store volatile i64 4198790, i64* @_asm_program_counter
  %10 = zext i32 %5 to i64

; 0x401189
  store volatile i64 4198793, i64* @_asm_program_counter
  %11 = trunc i64 %10 to i32
  %12 = zext i32 %11 to i64

; 0x40118b
  store volatile i64 4198795, i64* @_asm_program_counter

; 0x401190
  store volatile i64 4198800, i64* @_asm_program_counter

; 0x401195
  store volatile i64 4198805, i64* @_asm_program_counter
  %13 = inttoptr i64 ptrtoint ([4 x i8]* @global_var_402010 to i64) to i8*
  %14 = call i32 (i8*, ...) @printf(i8* %13, i64 %12)

; 0x40119a
  store volatile i64 4198810, i64* @_asm_program_counter

; 0x40119f
  store volatile i64 4198815, i64* @_asm_program_counter

; 0x4011a0
  store volatile i64 4198816, i64* @_asm_program_counter
  ret i64 0
}

declare i64 @4()

define i64 @_fini() {
dec_label_pc_4011a4:

; 0x4011a4
  store volatile i64 4198820, i64* @_asm_program_counter

; 0x4011a8
  store volatile i64 4198824, i64* @_asm_program_counter

; 0x4011ac
  store volatile i64 4198828, i64* @_asm_program_counter

; 0x4011b0
  store volatile i64 4198832, i64* @_asm_program_counter
  %0 = load i64, i64* @rax
  ret i64 %0
}

declare i32 @__libc_start_main(i64, i32, i8**, void ()*, void ()*, void ()*)

declare i64 @5()

declare i64 @_ITM_deregisterTMCloneTable(i64)

declare i64 @6()

declare void @__gmon_start__()

declare i64 @7()

declare i64 @_ITM_registerTMCloneTable(i64, i64)

declare i64 @8()

declare i32 @printf(i8*, ...)

declare i64 @9()

declare void @__pseudo_call(i64)

declare void @__pseudo_return(i64)

declare void @__pseudo_branch(i64)

declare void @__pseudo_cond_branch(i1, i64)

declare void @__frontend_reg_store.fpr(i3, x86_fp80)

declare x86_fp80 @__frontend_reg_load.fpr(i3)

; Function Attrs: nounwind readnone speculatable
declare i8 @llvm.ctpop.i8(i8) #0

declare i64 @__asm_hlt()

declare void @10()

attributes #0 = { nounwind readnone speculatable }
*** IR Dump After Disassembly generation ***
source_filename = "test"
target datalayout = "e-m:e-p:64:64-i64:64-f80:128-n8:16:32:64-S128"

@_asm_program_counter = internal global i64 0
@cf = internal global i1 false
@pf = internal global i1 false
@az = internal global i1 false
@zf = internal global i1 false
@sf = internal global i1 false
@tf = internal global i1 false
@if = internal global i1 false
@df = internal global i1 false
@of = internal global i1 false
@iopl = internal global i2 0
@nt = internal global i1 false
@rf = internal global i1 false
@vm = internal global i1 false
@ac = internal global i1 false
@vif = internal global i1 false
@vip = internal global i1 false
@id = internal global i1 false
@rflags = internal global i64 0
@ss = internal global i16 0
@cs = internal global i16 0
@ds = internal global i16 0
@es = internal global i16 0
@fs = internal global i16 0
@gs = internal global i16 0
@st0 = internal global x86_fp80 0xK00000000000000000000
@st1 = internal global x86_fp80 0xK00000000000000000000
@st2 = internal global x86_fp80 0xK00000000000000000000
@st3 = internal global x86_fp80 0xK00000000000000000000
@st4 = internal global x86_fp80 0xK00000000000000000000
@st5 = internal global x86_fp80 0xK00000000000000000000
@st6 = internal global x86_fp80 0xK00000000000000000000
@st7 = internal global x86_fp80 0xK00000000000000000000
@fpu_stat_IE = internal global i1 false
@fpu_stat_DE = internal global i1 false
@fpu_stat_ZE = internal global i1 false
@fpu_stat_OE = internal global i1 false
@fpu_stat_UE = internal global i1 false
@fpu_stat_PE = internal global i1 false
@fpu_stat_SF = internal global i1 false
@fpu_stat_ES = internal global i1 false
@fpu_stat_C0 = internal global i1 false
@fpu_stat_C1 = internal global i1 false
@fpu_stat_C2 = internal global i1 false
@fpu_stat_C3 = internal global i1 false
@fpu_stat_TOP = internal global i3 0
@fpu_stat_B = internal global i1 false
@fpu_control_IM = internal global i1 false
@fpu_control_DM = internal global i1 false
@fpu_control_ZM = internal global i1 false
@fpu_control_OM = internal global i1 false
@fpu_control_UM = internal global i1 false
@fpu_control_PM = internal global i1 false
@fpu_control_PC = internal global i2 0
@fpu_control_RC = internal global i2 0
@fpu_control_X = internal global i1 false
@fp0 = internal global double 0.000000e+00
@fp1 = internal global double 0.000000e+00
@fp2 = internal global double 0.000000e+00
@fp3 = internal global double 0.000000e+00
@fp4 = internal global double 0.000000e+00
@fp5 = internal global double 0.000000e+00
@fp6 = internal global double 0.000000e+00
@fp7 = internal global double 0.000000e+00
@k0 = internal global i64 0
@k1 = internal global i64 0
@k2 = internal global i64 0
@k3 = internal global i64 0
@k4 = internal global i64 0
@k5 = internal global i64 0
@k6 = internal global i64 0
@k7 = internal global i64 0
@mm0 = internal global i64 0
@mm1 = internal global i64 0
@mm2 = internal global i64 0
@mm3 = internal global i64 0
@mm4 = internal global i64 0
@mm5 = internal global i64 0
@mm6 = internal global i64 0
@mm7 = internal global i64 0
@xmm0 = internal global i128 0
@xmm1 = internal global i128 0
@xmm2 = internal global i128 0
@xmm3 = internal global i128 0
@xmm4 = internal global i128 0
@xmm5 = internal global i128 0
@xmm6 = internal global i128 0
@xmm7 = internal global i128 0
@xmm8 = internal global i128 0
@xmm9 = internal global i128 0
@xmm10 = internal global i128 0
@xmm11 = internal global i128 0
@xmm12 = internal global i128 0
@xmm13 = internal global i128 0
@xmm14 = internal global i128 0
@xmm15 = internal global i128 0
@xmm16 = internal global i128 0
@xmm17 = internal global i128 0
@xmm18 = internal global i128 0
@xmm19 = internal global i128 0
@xmm20 = internal global i128 0
@xmm21 = internal global i128 0
@xmm22 = internal global i128 0
@xmm23 = internal global i128 0
@xmm24 = internal global i128 0
@xmm25 = internal global i128 0
@xmm26 = internal global i128 0
@xmm27 = internal global i128 0
@xmm28 = internal global i128 0
@xmm29 = internal global i128 0
@xmm30 = internal global i128 0
@xmm31 = internal global i128 0
@ymm0 = internal global i256 0
@ymm1 = internal global i256 0
@ymm2 = internal global i256 0
@ymm3 = internal global i256 0
@ymm4 = internal global i256 0
@ymm5 = internal global i256 0
@ymm6 = internal global i256 0
@ymm7 = internal global i256 0
@ymm8 = internal global i256 0
@ymm9 = internal global i256 0
@ymm10 = internal global i256 0
@ymm11 = internal global i256 0
@ymm12 = internal global i256 0
@ymm13 = internal global i256 0
@ymm14 = internal global i256 0
@ymm15 = internal global i256 0
@ymm16 = internal global i256 0
@ymm17 = internal global i256 0
@ymm18 = internal global i256 0
@ymm19 = internal global i256 0
@ymm20 = internal global i256 0
@ymm21 = internal global i256 0
@ymm22 = internal global i256 0
@ymm23 = internal global i256 0
@ymm24 = internal global i256 0
@ymm25 = internal global i256 0
@ymm26 = internal global i256 0
@ymm27 = internal global i256 0
@ymm28 = internal global i256 0
@ymm29 = internal global i256 0
@ymm30 = internal global i256 0
@ymm31 = internal global i256 0
@zmm0 = internal global i512 0
@zmm1 = internal global i512 0
@zmm2 = internal global i512 0
@zmm3 = internal global i512 0
@zmm4 = internal global i512 0
@zmm5 = internal global i512 0
@zmm6 = internal global i512 0
@zmm7 = internal global i512 0
@zmm8 = internal global i512 0
@zmm9 = internal global i512 0
@zmm10 = internal global i512 0
@zmm11 = internal global i512 0
@zmm12 = internal global i512 0
@zmm13 = internal global i512 0
@zmm14 = internal global i512 0
@zmm15 = internal global i512 0
@zmm16 = internal global i512 0
@zmm17 = internal global i512 0
@zmm18 = internal global i512 0
@zmm19 = internal global i512 0
@zmm20 = internal global i512 0
@zmm21 = internal global i512 0
@zmm22 = internal global i512 0
@zmm23 = internal global i512 0
@zmm24 = internal global i512 0
@zmm25 = internal global i512 0
@zmm26 = internal global i512 0
@zmm27 = internal global i512 0
@zmm28 = internal global i512 0
@zmm29 = internal global i512 0
@zmm30 = internal global i512 0
@zmm31 = internal global i512 0
@bnd0 = internal global i128 0
@bnd1 = internal global i128 0
@bnd2 = internal global i128 0
@bnd3 = internal global i128 0
@dr0 = internal global i64 0
@dr1 = internal global i64 0
@dr2 = internal global i64 0
@dr3 = internal global i64 0
@dr4 = internal global i64 0
@dr5 = internal global i64 0
@dr6 = internal global i64 0
@dr7 = internal global i64 0
@dr8 = internal global i64 0
@dr9 = internal global i64 0
@dr10 = internal global i64 0
@dr11 = internal global i64 0
@dr12 = internal global i64 0
@dr13 = internal global i64 0
@dr14 = internal global i64 0
@dr15 = internal global i64 0
@cr0 = internal global i64 0
@cr1 = internal global i64 0
@cr2 = internal global i64 0
@cr3 = internal global i64 0
@cr4 = internal global i64 0
@cr5 = internal global i64 0
@cr6 = internal global i64 0
@cr7 = internal global i64 0
@cr8 = internal global i64 0
@cr9 = internal global i64 0
@cr10 = internal global i64 0
@cr11 = internal global i64 0
@cr12 = internal global i64 0
@cr13 = internal global i64 0
@cr14 = internal global i64 0
@cr15 = internal global i64 0
@fpsw = internal global i64 0
@rax = internal global i64 0
@rcx = internal global i64 0
@rdx = internal global i64 0
@rbx = internal global i64 0
@rsp = internal global i64 0
@rbp = internal global i64 0
@rsi = internal global i64 0
@rdi = internal global i64 0
@r8 = internal global i64 0
@r9 = internal global i64 0
@r10 = internal global i64 0
@r11 = internal global i64 0
@r12 = internal global i64 0
@r13 = internal global i64 0
@r14 = internal global i64 0
@r15 = internal global i64 0
@rip = internal global i64 0
@riz = internal global i64 0
@global_var_403ff8 = global i64 0
@global_var_404024 = external global i64
@global_var_402010 = constant [4 x i8] c"%d\0A\00"
@0 = external global i32

define i64 @_init() {
dec_label_pc_401000:
  %stack_var_-8 = alloca i64

; 0x401000
  store volatile i64 4198400, i64* @_asm_program_counter

; 0x401004
  store volatile i64 4198404, i64* @_asm_program_counter
  %0 = ptrtoint i64* %stack_var_-8 to i64
  store i64 %0, i64* @rsp

; 0x401008
  store volatile i64 4198408, i64* @_asm_program_counter
  %1 = load i64, i64* inttoptr (i64 4210672 to i64*)
  store i64 %1, i64* @rax

; 0x40100f
  store volatile i64 4198415, i64* @_asm_program_counter
  %2 = icmp eq i64 %1, 0

; 0x401012
  store volatile i64 4198418, i64* @_asm_program_counter
  br i1 %2, label %dec_label_pc_401016, label %dec_label_pc_401014

dec_label_pc_401014:                              ; preds = %dec_label_pc_401000

; 0x401014
  store volatile i64 4198420, i64* @_asm_program_counter
  call void @__gmon_start__()
  %3 = ptrtoint i32* @0 to i64
  store i64 %3, i64* @rax
  br label %dec_label_pc_401016

dec_label_pc_401016:                              ; preds = %dec_label_pc_401014, %dec_label_pc_401000

; 0x401016
  store volatile i64 4198422, i64* @_asm_program_counter

; 0x40101a
  store volatile i64 4198426, i64* @_asm_program_counter
  %4 = load i64, i64* @rax
  ret i64 %4
}

define i32 @function_401030(i8* %format, ...) {
dec_label_pc_401030:

; 0x401030
  store volatile i64 4198448, i64* @_asm_program_counter
  %0 = call i32 (i8*, ...) @printf(i8* %format)
  %1 = sext i32 %0 to i64
  %2 = trunc i64 %1 to i32
  ret i32 %2
}

declare i64 @1()

define i64 @_start(i64 %arg1, i64 %arg2, i64 %arg3, i64 %arg4, i64 %arg5, i64 %arg6) {
dec_label_pc_401040:
  %stack_var_-16 = alloca i64
  %stack_var_-8 = alloca i64
  %stack_var_8 = alloca i64
  %stack_var_0 = alloca i64
  store i64 %arg6, i64* %stack_var_0

; 0x401040
  store volatile i64 4198464, i64* @_asm_program_counter

; 0x401044
  store volatile i64 4198468, i64* @_asm_program_counter

; 0x401046
  store volatile i64 4198470, i64* @_asm_program_counter

; 0x401049
  store volatile i64 4198473, i64* @_asm_program_counter
  %0 = load i64, i64* %stack_var_0

; 0x40104a
  store volatile i64 4198474, i64* @_asm_program_counter

; 0x40104d
  store volatile i64 4198477, i64* @_asm_program_counter

; 0x401051
  store volatile i64 4198481, i64* @_asm_program_counter
  %1 = load i64, i64* @rax
  store i64 %1, i64* %stack_var_-8

; 0x401052
  store volatile i64 4198482, i64* @_asm_program_counter
  %2 = ptrtoint i64* %stack_var_-8 to i64
  store i64 %2, i64* %stack_var_-16

; 0x401053
  store volatile i64 4198483, i64* @_asm_program_counter
  %3 = trunc i64 %arg5 to i32
  %4 = trunc i64 %arg5 to i32
  %5 = xor i32 %3, %4
  %6 = zext i32 %5 to i64

; 0x401056
  store volatile i64 4198486, i64* @_asm_program_counter
  %7 = trunc i64 %arg4 to i32
  %8 = trunc i64 %arg4 to i32
  %9 = xor i32 %7, %8
  %10 = zext i32 %9 to i64

; 0x401058
  store volatile i64 4198488, i64* @_asm_program_counter

; 0x40105f
  store volatile i64 4198495, i64* @_asm_program_counter
  %11 = trunc i64 %0 to i32
  %12 = bitcast i64* %stack_var_8 to i8**
  %13 = inttoptr i64 %10 to void ()*
  %14 = inttoptr i64 %6 to void ()*
  %15 = inttoptr i64 %arg3 to void ()*
  %16 = call i32 @__libc_start_main(i64 4198721, i32 %11, i8** %12, void ()* %13, void ()* %14, void ()* %15)

; 0x401065
  store volatile i64 4198501, i64* @_asm_program_counter
  %17 = call i64 @__asm_hlt()
  unreachable
}

declare i64 @2()

define i64 @_dl_relocate_static_pie() {
dec_label_pc_401070:

; 0x401070
  store volatile i64 4198512, i64* @_asm_program_counter

; 0x401074
  store volatile i64 4198516, i64* @_asm_program_counter
  %0 = load i64, i64* @rax
  ret i64 %0
}

define i64 @deregister_tm_clones() {
dec_label_pc_401080:

; 0x401080
  store volatile i64 4198528, i64* @_asm_program_counter
  store i64 4210728, i64* @rdi

; 0x401087
  store volatile i64 4198535, i64* @_asm_program_counter
  store i64 4210728, i64* @rax

; 0x40108e
  store volatile i64 4198542, i64* @_asm_program_counter
  %0 = sub i64 4210728, 4210728
  %1 = icmp eq i64 %0, 0

; 0x401091
  store volatile i64 4198545, i64* @_asm_program_counter
  br i1 %1, label %dec_label_pc_4010a8, label %dec_label_pc_401093

dec_label_pc_401093:                              ; preds = %dec_label_pc_401080

; 0x401093
  store volatile i64 4198547, i64* @_asm_program_counter
  %2 = load i64, i64* inttoptr (i64 4210664 to i64*)
  store i64 %2, i64* @rax

; 0x40109a
  store volatile i64 4198554, i64* @_asm_program_counter
  %3 = icmp eq i64 %2, 0

; 0x40109d
  store volatile i64 4198557, i64* @_asm_program_counter
  br i1 %3, label %dec_label_pc_4010a8, label %dec_label_pc_40109f

dec_label_pc_40109f:                              ; preds = %dec_label_pc_401093

; 0x40109f
  store volatile i64 4198559, i64* @_asm_program_counter
  %4 = load i64, i64* @rdi
  %5 = call i64 @_ITM_deregisterTMCloneTable(i64 %4)
  ret i64 %5

dec_label_pc_4010a8:                              ; preds = %dec_label_pc_401093, %dec_label_pc_401080

; 0x4010a8
  store volatile i64 4198568, i64* @_asm_program_counter
  %6 = load i64, i64* @rax
  ret i64 %6
}

define i64 @register_tm_clones() {
dec_label_pc_4010b0:

; 0x4010b0
  store volatile i64 4198576, i64* @_asm_program_counter
  store i64 4210728, i64* @rdi

; 0x4010b7
  store volatile i64 4198583, i64* @_asm_program_counter

; 0x4010be
  store volatile i64 4198590, i64* @_asm_program_counter
  %0 = sub i64 4210728, 4210728

; 0x4010c1
  store volatile i64 4198593, i64* @_asm_program_counter

; 0x4010c4
  store volatile i64 4198596, i64* @_asm_program_counter
  %1 = lshr i64 %0, 63

; 0x4010c8
  store volatile i64 4198600, i64* @_asm_program_counter
  %2 = ashr i64 %0, 3
  store i64 %2, i64* @rax

; 0x4010cc
  store volatile i64 4198604, i64* @_asm_program_counter
  %3 = add i64 %1, %2

; 0x4010cf
  store volatile i64 4198607, i64* @_asm_program_counter
  %4 = ashr i64 %3, 1
  %5 = icmp eq i64 %4, 0
  store i64 %4, i64* @rsi

; 0x4010d2
  store volatile i64 4198610, i64* @_asm_program_counter
  br i1 %5, label %dec_label_pc_4010e8, label %dec_label_pc_4010d4

dec_label_pc_4010d4:                              ; preds = %dec_label_pc_4010b0

; 0x4010d4
  store volatile i64 4198612, i64* @_asm_program_counter
  %6 = load i64, i64* @global_var_403ff8
  store i64 %6, i64* @rax

; 0x4010db
  store volatile i64 4198619, i64* @_asm_program_counter
  %7 = icmp eq i64 %6, 0

; 0x4010de
  store volatile i64 4198622, i64* @_asm_program_counter
  br i1 %7, label %dec_label_pc_4010e8, label %dec_label_pc_4010e0

dec_label_pc_4010e0:                              ; preds = %dec_label_pc_4010d4

; 0x4010e0
  store volatile i64 4198624, i64* @_asm_program_counter
  %8 = load i64, i64* @rdi
  %9 = load i64, i64* @rsi
  %10 = call i64 @_ITM_registerTMCloneTable(i64 %8, i64 %9)
  ret i64 %10

dec_label_pc_4010e8:                              ; preds = %dec_label_pc_4010d4, %dec_label_pc_4010b0

; 0x4010e8
  store volatile i64 4198632, i64* @_asm_program_counter
  %11 = load i64, i64* @rax
  ret i64 %11
}

define i64 @__do_global_dtors_aux() {
dec_label_pc_4010f0:
  %stack_var_-8 = alloca i64

; 0x4010f0
  store volatile i64 4198640, i64* @_asm_program_counter

; 0x4010f4
  store volatile i64 4198644, i64* @_asm_program_counter
  %0 = load i8, i8* inttoptr (i64 4210724 to i8*)
  %1 = icmp eq i8 %0, 0

; 0x4010fb
  store volatile i64 4198651, i64* @_asm_program_counter
  %2 = icmp eq i1 %1, false
  br i1 %2, label %dec_label_pc_401110, label %dec_label_pc_4010fd

dec_label_pc_4010fd:                              ; preds = %dec_label_pc_4010f0

; 0x4010fd
  store volatile i64 4198653, i64* @_asm_program_counter
  %3 = load i64, i64* @rbp
  store i64 %3, i64* %stack_var_-8

; 0x4010fe
  store volatile i64 4198654, i64* @_asm_program_counter

; 0x401101
  store volatile i64 4198657, i64* @_asm_program_counter
  %4 = call i64 @deregister_tm_clones()

; 0x401106
  store volatile i64 4198662, i64* @_asm_program_counter
  store i8 1, i8* bitcast (i64* @global_var_404024 to i8*)

; 0x40110d
  store volatile i64 4198669, i64* @_asm_program_counter

; 0x40110e
  store volatile i64 4198670, i64* @_asm_program_counter
  ret i64 %4

dec_label_pc_401110:                              ; preds = %dec_label_pc_4010f0

; 0x401110
  store volatile i64 4198672, i64* @_asm_program_counter
  %5 = load i64, i64* @rax
  ret i64 %5
}

define i64 @frame_dummy() {
dec_label_pc_401120:

; 0x401120
  store volatile i64 4198688, i64* @_asm_program_counter

; 0x401124
  store volatile i64 4198692, i64* @_asm_program_counter
  %0 = call i64 @register_tm_clones()
  ret i64 %0
}

define i64 @add(i32* %arg1, i64 %arg2) {
dec_label_pc_401126:
  %stack_var_-8 = alloca i64

; 0x401126
  store volatile i64 4198694, i64* @_asm_program_counter
  %0 = load i64, i64* @rbp
  store i64 %0, i64* %stack_var_-8

; 0x401127
  store volatile i64 4198695, i64* @_asm_program_counter

; 0x40112a
  store volatile i64 4198698, i64* @_asm_program_counter

; 0x40112e
  store volatile i64 4198702, i64* @_asm_program_counter
  %1 = trunc i64 %arg2 to i32
  %2 = zext i32 %1 to i64

; 0x401130
  store volatile i64 4198704, i64* @_asm_program_counter
  %3 = trunc i64 %2 to i8

; 0x401133
  store volatile i64 4198707, i64* @_asm_program_counter

; 0x401137
  store volatile i64 4198711, i64* @_asm_program_counter
  %4 = load i32, i32* bitcast (i64* @rdi to i32*)
  %5 = zext i32 %4 to i64

; 0x401139
  store volatile i64 4198713, i64* @_asm_program_counter
  %6 = sext i8 %3 to i64

; 0x40113d
  store volatile i64 4198717, i64* @_asm_program_counter
  %7 = trunc i64 %6 to i32
  %8 = trunc i64 %5 to i32
  %9 = add i32 %7, %8
  %10 = zext i32 %9 to i64

; 0x40113f
  store volatile i64 4198719, i64* @_asm_program_counter

; 0x401140
  store volatile i64 4198720, i64* @_asm_program_counter
  ret i64 %10
}

declare i64 @3()

define i64 @main(i64 %argc, i8** %argv) {
dec_label_pc_401141:
  %stack_var_-32 = alloca i32
  %stack_var_-8 = alloca i64

; 0x401141
  store volatile i64 4198721, i64* @_asm_program_counter
  %0 = load i64, i64* @rbp
  store i64 %0, i64* %stack_var_-8

; 0x401142
  store volatile i64 4198722, i64* @_asm_program_counter

; 0x401145
  store volatile i64 4198725, i64* @_asm_program_counter

; 0x401149
  store volatile i64 4198729, i64* @_asm_program_counter
  store i32 1, i32* %stack_var_-32

; 0x401150
  store volatile i64 4198736, i64* @_asm_program_counter

; 0x401154
  store volatile i64 4198740, i64* @_asm_program_counter
  %1 = sext i8 2 to i64

; 0x401158
  store volatile i64 4198744, i64* @_asm_program_counter

; 0x40115c
  store volatile i64 4198748, i64* @_asm_program_counter
  %2 = trunc i64 %1 to i32
  %3 = zext i32 %2 to i64

; 0x40115e
  store volatile i64 4198750, i64* @_asm_program_counter

; 0x401161
  store volatile i64 4198753, i64* @_asm_program_counter
  %4 = call i64 @add(i32* %stack_var_-32, i64 %3)

; 0x401166
  store volatile i64 4198758, i64* @_asm_program_counter
  %5 = trunc i64 %4 to i32

; 0x401169
  store volatile i64 4198761, i64* @_asm_program_counter

; 0x40116d
  store volatile i64 4198765, i64* @_asm_program_counter

; 0x401171
  store volatile i64 4198769, i64* @_asm_program_counter
  %6 = sext i8 2 to i64

; 0x401175
  store volatile i64 4198773, i64* @_asm_program_counter

; 0x401179
  store volatile i64 4198777, i64* @_asm_program_counter
  %7 = trunc i64 %6 to i32
  %8 = zext i32 %7 to i64

; 0x40117b
  store volatile i64 4198779, i64* @_asm_program_counter

; 0x40117e
  store volatile i64 4198782, i64* @_asm_program_counter
  %9 = call i64 @add(i32* %stack_var_-32, i64 %8)

; 0x401183
  store volatile i64 4198787, i64* @_asm_program_counter

; 0x401186
  store volatile i64 4198790, i64* @_asm_program_counter
  %10 = zext i32 %5 to i64

; 0x401189
  store volatile i64 4198793, i64* @_asm_program_counter
  %11 = trunc i64 %10 to i32
  %12 = zext i32 %11 to i64

; 0x40118b
  store volatile i64 4198795, i64* @_asm_program_counter

; 0x401190
  store volatile i64 4198800, i64* @_asm_program_counter

; 0x401195
  store volatile i64 4198805, i64* @_asm_program_counter
  %13 = inttoptr i64 ptrtoint ([4 x i8]* @global_var_402010 to i64) to i8*
  %14 = call i32 (i8*, ...) @printf(i8* %13, i64 %12)

; 0x40119a
  store volatile i64 4198810, i64* @_asm_program_counter

; 0x40119f
  store volatile i64 4198815, i64* @_asm_program_counter

; 0x4011a0
  store volatile i64 4198816, i64* @_asm_program_counter
  ret i64 0
}

declare i64 @4()

define i64 @_fini() {
dec_label_pc_4011a4:

; 0x4011a4
  store volatile i64 4198820, i64* @_asm_program_counter

; 0x4011a8
  store volatile i64 4198824, i64* @_asm_program_counter

; 0x4011ac
  store volatile i64 4198828, i64* @_asm_program_counter

; 0x4011b0
  store volatile i64 4198832, i64* @_asm_program_counter
  %0 = load i64, i64* @rax
  ret i64 %0
}

declare i32 @__libc_start_main(i64, i32, i8**, void ()*, void ()*, void ()*)

declare i64 @5()

declare i64 @_ITM_deregisterTMCloneTable(i64)

declare i64 @6()

declare void @__gmon_start__()

declare i64 @7()

declare i64 @_ITM_registerTMCloneTable(i64, i64)

declare i64 @8()

declare i32 @printf(i8*, ...)

declare i64 @9()

declare void @__pseudo_call(i64)

declare void @__pseudo_return(i64)

declare void @__pseudo_branch(i64)

declare void @__pseudo_cond_branch(i1, i64)

declare void @__frontend_reg_store.fpr(i3, x86_fp80)

declare x86_fp80 @__frontend_reg_load.fpr(i3)

; Function Attrs: nounwind readnone speculatable
declare i8 @llvm.ctpop.i8(i8) #0

declare i64 @__asm_hlt()

declare void @10()

attributes #0 = { nounwind readnone speculatable }
*** IR Dump After Assembly mapping instruction removal ***
source_filename = "test"
target datalayout = "e-m:e-p:64:64-i64:64-f80:128-n8:16:32:64-S128"

@cf = internal global i1 false
@pf = internal global i1 false
@az = internal global i1 false
@zf = internal global i1 false
@sf = internal global i1 false
@tf = internal global i1 false
@if = internal global i1 false
@df = internal global i1 false
@of = internal global i1 false
@iopl = internal global i2 0
@nt = internal global i1 false
@rf = internal global i1 false
@vm = internal global i1 false
@ac = internal global i1 false
@vif = internal global i1 false
@vip = internal global i1 false
@id = internal global i1 false
@rflags = internal global i64 0
@ss = internal global i16 0
@cs = internal global i16 0
@ds = internal global i16 0
@es = internal global i16 0
@fs = internal global i16 0
@gs = internal global i16 0
@st0 = internal global x86_fp80 0xK00000000000000000000
@st1 = internal global x86_fp80 0xK00000000000000000000
@st2 = internal global x86_fp80 0xK00000000000000000000
@st3 = internal global x86_fp80 0xK00000000000000000000
@st4 = internal global x86_fp80 0xK00000000000000000000
@st5 = internal global x86_fp80 0xK00000000000000000000
@st6 = internal global x86_fp80 0xK00000000000000000000
@st7 = internal global x86_fp80 0xK00000000000000000000
@fpu_stat_IE = internal global i1 false
@fpu_stat_DE = internal global i1 false
@fpu_stat_ZE = internal global i1 false
@fpu_stat_OE = internal global i1 false
@fpu_stat_UE = internal global i1 false
@fpu_stat_PE = internal global i1 false
@fpu_stat_SF = internal global i1 false
@fpu_stat_ES = internal global i1 false
@fpu_stat_C0 = internal global i1 false
@fpu_stat_C1 = internal global i1 false
@fpu_stat_C2 = internal global i1 false
@fpu_stat_C3 = internal global i1 false
@fpu_stat_TOP = internal global i3 0
@fpu_stat_B = internal global i1 false
@fpu_control_IM = internal global i1 false
@fpu_control_DM = internal global i1 false
@fpu_control_ZM = internal global i1 false
@fpu_control_OM = internal global i1 false
@fpu_control_UM = internal global i1 false
@fpu_control_PM = internal global i1 false
@fpu_control_PC = internal global i2 0
@fpu_control_RC = internal global i2 0
@fpu_control_X = internal global i1 false
@fp0 = internal global double 0.000000e+00
@fp1 = internal global double 0.000000e+00
@fp2 = internal global double 0.000000e+00
@fp3 = internal global double 0.000000e+00
@fp4 = internal global double 0.000000e+00
@fp5 = internal global double 0.000000e+00
@fp6 = internal global double 0.000000e+00
@fp7 = internal global double 0.000000e+00
@k0 = internal global i64 0
@k1 = internal global i64 0
@k2 = internal global i64 0
@k3 = internal global i64 0
@k4 = internal global i64 0
@k5 = internal global i64 0
@k6 = internal global i64 0
@k7 = internal global i64 0
@mm0 = internal global i64 0
@mm1 = internal global i64 0
@mm2 = internal global i64 0
@mm3 = internal global i64 0
@mm4 = internal global i64 0
@mm5 = internal global i64 0
@mm6 = internal global i64 0
@mm7 = internal global i64 0
@xmm0 = internal global i128 0
@xmm1 = internal global i128 0
@xmm2 = internal global i128 0
@xmm3 = internal global i128 0
@xmm4 = internal global i128 0
@xmm5 = internal global i128 0
@xmm6 = internal global i128 0
@xmm7 = internal global i128 0
@xmm8 = internal global i128 0
@xmm9 = internal global i128 0
@xmm10 = internal global i128 0
@xmm11 = internal global i128 0
@xmm12 = internal global i128 0
@xmm13 = internal global i128 0
@xmm14 = internal global i128 0
@xmm15 = internal global i128 0
@xmm16 = internal global i128 0
@xmm17 = internal global i128 0
@xmm18 = internal global i128 0
@xmm19 = internal global i128 0
@xmm20 = internal global i128 0
@xmm21 = internal global i128 0
@xmm22 = internal global i128 0
@xmm23 = internal global i128 0
@xmm24 = internal global i128 0
@xmm25 = internal global i128 0
@xmm26 = internal global i128 0
@xmm27 = internal global i128 0
@xmm28 = internal global i128 0
@xmm29 = internal global i128 0
@xmm30 = internal global i128 0
@xmm31 = internal global i128 0
@ymm0 = internal global i256 0
@ymm1 = internal global i256 0
@ymm2 = internal global i256 0
@ymm3 = internal global i256 0
@ymm4 = internal global i256 0
@ymm5 = internal global i256 0
@ymm6 = internal global i256 0
@ymm7 = internal global i256 0
@ymm8 = internal global i256 0
@ymm9 = internal global i256 0
@ymm10 = internal global i256 0
@ymm11 = internal global i256 0
@ymm12 = internal global i256 0
@ymm13 = internal global i256 0
@ymm14 = internal global i256 0
@ymm15 = internal global i256 0
@ymm16 = internal global i256 0
@ymm17 = internal global i256 0
@ymm18 = internal global i256 0
@ymm19 = internal global i256 0
@ymm20 = internal global i256 0
@ymm21 = internal global i256 0
@ymm22 = internal global i256 0
@ymm23 = internal global i256 0
@ymm24 = internal global i256 0
@ymm25 = internal global i256 0
@ymm26 = internal global i256 0
@ymm27 = internal global i256 0
@ymm28 = internal global i256 0
@ymm29 = internal global i256 0
@ymm30 = internal global i256 0
@ymm31 = internal global i256 0
@zmm0 = internal global i512 0
@zmm1 = internal global i512 0
@zmm2 = internal global i512 0
@zmm3 = internal global i512 0
@zmm4 = internal global i512 0
@zmm5 = internal global i512 0
@zmm6 = internal global i512 0
@zmm7 = internal global i512 0
@zmm8 = internal global i512 0
@zmm9 = internal global i512 0
@zmm10 = internal global i512 0
@zmm11 = internal global i512 0
@zmm12 = internal global i512 0
@zmm13 = internal global i512 0
@zmm14 = internal global i512 0
@zmm15 = internal global i512 0
@zmm16 = internal global i512 0
@zmm17 = internal global i512 0
@zmm18 = internal global i512 0
@zmm19 = internal global i512 0
@zmm20 = internal global i512 0
@zmm21 = internal global i512 0
@zmm22 = internal global i512 0
@zmm23 = internal global i512 0
@zmm24 = internal global i512 0
@zmm25 = internal global i512 0
@zmm26 = internal global i512 0
@zmm27 = internal global i512 0
@zmm28 = internal global i512 0
@zmm29 = internal global i512 0
@zmm30 = internal global i512 0
@zmm31 = internal global i512 0
@bnd0 = internal global i128 0
@bnd1 = internal global i128 0
@bnd2 = internal global i128 0
@bnd3 = internal global i128 0
@dr0 = internal global i64 0
@dr1 = internal global i64 0
@dr2 = internal global i64 0
@dr3 = internal global i64 0
@dr4 = internal global i64 0
@dr5 = internal global i64 0
@dr6 = internal global i64 0
@dr7 = internal global i64 0
@dr8 = internal global i64 0
@dr9 = internal global i64 0
@dr10 = internal global i64 0
@dr11 = internal global i64 0
@dr12 = internal global i64 0
@dr13 = internal global i64 0
@dr14 = internal global i64 0
@dr15 = internal global i64 0
@cr0 = internal global i64 0
@cr1 = internal global i64 0
@cr2 = internal global i64 0
@cr3 = internal global i64 0
@cr4 = internal global i64 0
@cr5 = internal global i64 0
@cr6 = internal global i64 0
@cr7 = internal global i64 0
@cr8 = internal global i64 0
@cr9 = internal global i64 0
@cr10 = internal global i64 0
@cr11 = internal global i64 0
@cr12 = internal global i64 0
@cr13 = internal global i64 0
@cr14 = internal global i64 0
@cr15 = internal global i64 0
@fpsw = internal global i64 0
@rax = internal global i64 0
@rcx = internal global i64 0
@rdx = internal global i64 0
@rbx = internal global i64 0
@rsp = internal global i64 0
@rbp = internal global i64 0
@rsi = internal global i64 0
@rdi = internal global i64 0
@r8 = internal global i64 0
@r9 = internal global i64 0
@r10 = internal global i64 0
@r11 = internal global i64 0
@r12 = internal global i64 0
@r13 = internal global i64 0
@r14 = internal global i64 0
@r15 = internal global i64 0
@rip = internal global i64 0
@riz = internal global i64 0
@global_var_403ff8 = global i64 0
@global_var_404024 = external global i64
@global_var_402010 = constant [4 x i8] c"%d\0A\00"
@0 = external global i32

define i64 @_init() {
dec_label_pc_401000:
  %stack_var_-8 = alloca i64
  %0 = ptrtoint i64* %stack_var_-8 to i64, !insn.addr !0
  store i64 %0, i64* @rsp, !insn.addr !0
  %1 = load i64, i64* inttoptr (i64 4210672 to i64*), !insn.addr !1
  store i64 %1, i64* @rax, !insn.addr !1
  %2 = icmp eq i64 %1, 0, !insn.addr !2
  br i1 %2, label %dec_label_pc_401016, label %dec_label_pc_401014, !insn.addr !3

dec_label_pc_401014:                              ; preds = %dec_label_pc_401000
  call void @__gmon_start__(), !insn.addr !4
  %3 = ptrtoint i32* @0 to i64, !insn.addr !4
  store i64 %3, i64* @rax, !insn.addr !4
  br label %dec_label_pc_401016, !insn.addr !4

dec_label_pc_401016:                              ; preds = %dec_label_pc_401014, %dec_label_pc_401000
  %4 = load i64, i64* @rax, !insn.addr !5
  ret i64 %4, !insn.addr !5
}

define i32 @function_401030(i8* %format, ...) {
dec_label_pc_401030:
  %0 = call i32 (i8*, ...) @printf(i8* %format), !insn.addr !6
  %1 = sext i32 %0 to i64, !insn.addr !6
  %2 = trunc i64 %1 to i32, !insn.addr !6
  ret i32 %2, !insn.addr !6
}

declare i64 @1()

define i64 @_start(i64 %arg1, i64 %arg2, i64 %arg3, i64 %arg4, i64 %arg5, i64 %arg6) {
dec_label_pc_401040:
  %stack_var_-16 = alloca i64
  %stack_var_-8 = alloca i64
  %stack_var_8 = alloca i64
  %stack_var_0 = alloca i64
  store i64 %arg6, i64* %stack_var_0
  %0 = load i64, i64* %stack_var_0, !insn.addr !7
  %1 = load i64, i64* @rax, !insn.addr !8
  store i64 %1, i64* %stack_var_-8, !insn.addr !8
  %2 = ptrtoint i64* %stack_var_-8 to i64, !insn.addr !9
  store i64 %2, i64* %stack_var_-16, !insn.addr !9
  %3 = trunc i64 %arg5 to i32, !insn.addr !10
  %4 = trunc i64 %arg5 to i32, !insn.addr !10
  %5 = xor i32 %3, %4, !insn.addr !10
  %6 = zext i32 %5 to i64, !insn.addr !10
  %7 = trunc i64 %arg4 to i32, !insn.addr !11
  %8 = trunc i64 %arg4 to i32, !insn.addr !11
  %9 = xor i32 %7, %8, !insn.addr !11
  %10 = zext i32 %9 to i64, !insn.addr !11
  %11 = trunc i64 %0 to i32, !insn.addr !12
  %12 = bitcast i64* %stack_var_8 to i8**, !insn.addr !12
  %13 = inttoptr i64 %10 to void ()*, !insn.addr !12
  %14 = inttoptr i64 %6 to void ()*, !insn.addr !12
  %15 = inttoptr i64 %arg3 to void ()*, !insn.addr !12
  %16 = call i32 @__libc_start_main(i64 4198721, i32 %11, i8** %12, void ()* %13, void ()* %14, void ()* %15), !insn.addr !12
  %17 = call i64 @__asm_hlt(), !insn.addr !13
  unreachable, !insn.addr !13
}

declare i64 @2()

define i64 @_dl_relocate_static_pie() {
dec_label_pc_401070:
  %0 = load i64, i64* @rax, !insn.addr !14
  ret i64 %0, !insn.addr !14
}

define i64 @deregister_tm_clones() {
dec_label_pc_401080:
  store i64 4210728, i64* @rdi, !insn.addr !15
  store i64 4210728, i64* @rax, !insn.addr !16
  %0 = sub i64 4210728, 4210728, !insn.addr !17
  %1 = icmp eq i64 %0, 0, !insn.addr !17
  br i1 %1, label %dec_label_pc_4010a8, label %dec_label_pc_401093, !insn.addr !18

dec_label_pc_401093:                              ; preds = %dec_label_pc_401080
  %2 = load i64, i64* inttoptr (i64 4210664 to i64*), !insn.addr !19
  store i64 %2, i64* @rax, !insn.addr !19
  %3 = icmp eq i64 %2, 0, !insn.addr !20
  br i1 %3, label %dec_label_pc_4010a8, label %dec_label_pc_40109f, !insn.addr !21

dec_label_pc_40109f:                              ; preds = %dec_label_pc_401093
  %4 = load i64, i64* @rdi, !insn.addr !22
  %5 = call i64 @_ITM_deregisterTMCloneTable(i64 %4), !insn.addr !22
  ret i64 %5, !insn.addr !22

dec_label_pc_4010a8:                              ; preds = %dec_label_pc_401093, %dec_label_pc_401080
  %6 = load i64, i64* @rax, !insn.addr !23
  ret i64 %6, !insn.addr !23
}

define i64 @register_tm_clones() {
dec_label_pc_4010b0:
  store i64 4210728, i64* @rdi, !insn.addr !24
  %0 = sub i64 4210728, 4210728, !insn.addr !25
  %1 = lshr i64 %0, 63, !insn.addr !26
  %2 = ashr i64 %0, 3, !insn.addr !27
  store i64 %2, i64* @rax, !insn.addr !27
  %3 = add i64 %1, %2, !insn.addr !28
  %4 = ashr i64 %3, 1, !insn.addr !29
  %5 = icmp eq i64 %4, 0, !insn.addr !29
  store i64 %4, i64* @rsi, !insn.addr !29
  br i1 %5, label %dec_label_pc_4010e8, label %dec_label_pc_4010d4, !insn.addr !30

dec_label_pc_4010d4:                              ; preds = %dec_label_pc_4010b0
  %6 = load i64, i64* @global_var_403ff8, !insn.addr !31
  store i64 %6, i64* @rax, !insn.addr !31
  %7 = icmp eq i64 %6, 0, !insn.addr !32
  br i1 %7, label %dec_label_pc_4010e8, label %dec_label_pc_4010e0, !insn.addr !33

dec_label_pc_4010e0:                              ; preds = %dec_label_pc_4010d4
  %8 = load i64, i64* @rdi, !insn.addr !34
  %9 = load i64, i64* @rsi, !insn.addr !34
  %10 = call i64 @_ITM_registerTMCloneTable(i64 %8, i64 %9), !insn.addr !34
  ret i64 %10, !insn.addr !34

dec_label_pc_4010e8:                              ; preds = %dec_label_pc_4010d4, %dec_label_pc_4010b0
  %11 = load i64, i64* @rax, !insn.addr !35
  ret i64 %11, !insn.addr !35
}

define i64 @__do_global_dtors_aux() {
dec_label_pc_4010f0:
  %stack_var_-8 = alloca i64
  %0 = load i8, i8* inttoptr (i64 4210724 to i8*), !insn.addr !36
  %1 = icmp eq i8 %0, 0, !insn.addr !36
  %2 = icmp eq i1 %1, false, !insn.addr !37
  br i1 %2, label %dec_label_pc_401110, label %dec_label_pc_4010fd, !insn.addr !37

dec_label_pc_4010fd:                              ; preds = %dec_label_pc_4010f0
  %3 = load i64, i64* @rbp, !insn.addr !38
  store i64 %3, i64* %stack_var_-8, !insn.addr !38
  %4 = call i64 @deregister_tm_clones(), !insn.addr !39
  store i8 1, i8* bitcast (i64* @global_var_404024 to i8*), !insn.addr !40
  ret i64 %4, !insn.addr !41

dec_label_pc_401110:                              ; preds = %dec_label_pc_4010f0
  %5 = load i64, i64* @rax, !insn.addr !42
  ret i64 %5, !insn.addr !42
}

define i64 @frame_dummy() {
dec_label_pc_401120:
  %0 = call i64 @register_tm_clones(), !insn.addr !43
  ret i64 %0, !insn.addr !43
}

define i64 @add(i32* %arg1, i64 %arg2) {
dec_label_pc_401126:
  %stack_var_-8 = alloca i64
  %0 = load i64, i64* @rbp, !insn.addr !44
  store i64 %0, i64* %stack_var_-8, !insn.addr !44
  %1 = trunc i64 %arg2 to i32, !insn.addr !45
  %2 = zext i32 %1 to i64, !insn.addr !45
  %3 = trunc i64 %2 to i8, !insn.addr !46
  %4 = load i32, i32* bitcast (i64* @rdi to i32*), !insn.addr !47
  %5 = zext i32 %4 to i64, !insn.addr !47
  %6 = sext i8 %3 to i64, !insn.addr !48
  %7 = trunc i64 %6 to i32, !insn.addr !49
  %8 = trunc i64 %5 to i32, !insn.addr !49
  %9 = add i32 %7, %8, !insn.addr !49
  %10 = zext i32 %9 to i64, !insn.addr !49
  ret i64 %10, !insn.addr !50
}

declare i64 @3()

define i64 @main(i64 %argc, i8** %argv) {
dec_label_pc_401141:
  %stack_var_-32 = alloca i32
  %stack_var_-8 = alloca i64
  %0 = load i64, i64* @rbp, !insn.addr !51
  store i64 %0, i64* %stack_var_-8, !insn.addr !51
  store i32 1, i32* %stack_var_-32, !insn.addr !52
  %1 = sext i8 2 to i64, !insn.addr !53
  %2 = trunc i64 %1 to i32, !insn.addr !54
  %3 = zext i32 %2 to i64, !insn.addr !54
  %4 = call i64 @add(i32* %stack_var_-32, i64 %3), !insn.addr !55
  %5 = trunc i64 %4 to i32, !insn.addr !56
  %6 = sext i8 2 to i64, !insn.addr !57
  %7 = trunc i64 %6 to i32, !insn.addr !58
  %8 = zext i32 %7 to i64, !insn.addr !58
  %9 = call i64 @add(i32* %stack_var_-32, i64 %8), !insn.addr !59
  %10 = zext i32 %5 to i64, !insn.addr !60
  %11 = trunc i64 %10 to i32, !insn.addr !61
  %12 = zext i32 %11 to i64, !insn.addr !61
  %13 = inttoptr i64 ptrtoint ([4 x i8]* @global_var_402010 to i64) to i8*, !insn.addr !62
  %14 = call i32 (i8*, ...) @printf(i8* %13, i64 %12), !insn.addr !62
  ret i64 0, !insn.addr !63
}

declare i64 @4()

define i64 @_fini() {
dec_label_pc_4011a4:
  %0 = load i64, i64* @rax, !insn.addr !64
  ret i64 %0, !insn.addr !64
}

declare i32 @__libc_start_main(i64, i32, i8**, void ()*, void ()*, void ()*)

declare i64 @5()

declare i64 @_ITM_deregisterTMCloneTable(i64)

declare i64 @6()

declare void @__gmon_start__()

declare i64 @7()

declare i64 @_ITM_registerTMCloneTable(i64, i64)

declare i64 @8()

declare i32 @printf(i8*, ...)

declare i64 @9()

declare void @__pseudo_call(i64)

declare void @__pseudo_return(i64)

declare void @__pseudo_branch(i64)

declare void @__pseudo_cond_branch(i1, i64)

declare void @__frontend_reg_store.fpr(i3, x86_fp80)

declare x86_fp80 @__frontend_reg_load.fpr(i3)

; Function Attrs: nounwind readnone speculatable
declare i8 @llvm.ctpop.i8(i8) #0

declare i64 @__asm_hlt()

declare void @10()

attributes #0 = { nounwind readnone speculatable }

!0 = !{i64 4198404}
!1 = !{i64 4198408}
!2 = !{i64 4198415}
!3 = !{i64 4198418}
!4 = !{i64 4198420}
!5 = !{i64 4198426}
!6 = !{i64 4198448}
!7 = !{i64 4198473}
!8 = !{i64 4198481}
!9 = !{i64 4198482}
!10 = !{i64 4198483}
!11 = !{i64 4198486}
!12 = !{i64 4198495}
!13 = !{i64 4198501}
!14 = !{i64 4198516}
!15 = !{i64 4198528}
!16 = !{i64 4198535}
!17 = !{i64 4198542}
!18 = !{i64 4198545}
!19 = !{i64 4198547}
!20 = !{i64 4198554}
!21 = !{i64 4198557}
!22 = !{i64 4198559}
!23 = !{i64 4198568}
!24 = !{i64 4198576}
!25 = !{i64 4198590}
!26 = !{i64 4198596}
!27 = !{i64 4198600}
!28 = !{i64 4198604}
!29 = !{i64 4198607}
!30 = !{i64 4198610}
!31 = !{i64 4198612}
!32 = !{i64 4198619}
!33 = !{i64 4198622}
!34 = !{i64 4198624}
!35 = !{i64 4198632}
!36 = !{i64 4198644}
!37 = !{i64 4198651}
!38 = !{i64 4198653}
!39 = !{i64 4198657}
!40 = !{i64 4198662}
!41 = !{i64 4198670}
!42 = !{i64 4198672}
!43 = !{i64 4198692}
!44 = !{i64 4198694}
!45 = !{i64 4198702}
!46 = !{i64 4198704}
!47 = !{i64 4198711}
!48 = !{i64 4198713}
!49 = !{i64 4198717}
!50 = !{i64 4198720}
!51 = !{i64 4198721}
!52 = !{i64 4198729}
!53 = !{i64 4198740}
!54 = !{i64 4198748}
!55 = !{i64 4198753}
!56 = !{i64 4198758}
!57 = !{i64 4198769}
!58 = !{i64 4198777}
!59 = !{i64 4198782}
!60 = !{i64 4198790}
!61 = !{i64 4198793}
!62 = !{i64 4198805}
!63 = !{i64 4198816}
!64 = !{i64 4198832}
*** IR Dump After C++ class hierarchy optimization ***
source_filename = "test"
target datalayout = "e-m:e-p:64:64-i64:64-f80:128-n8:16:32:64-S128"

@cf = internal global i1 false
@pf = internal global i1 false
@az = internal global i1 false
@zf = internal global i1 false
@sf = internal global i1 false
@tf = internal global i1 false
@if = internal global i1 false
@df = internal global i1 false
@of = internal global i1 false
@iopl = internal global i2 0
@nt = internal global i1 false
@rf = internal global i1 false
@vm = internal global i1 false
@ac = internal global i1 false
@vif = internal global i1 false
@vip = internal global i1 false
@id = internal global i1 false
@rflags = internal global i64 0
@ss = internal global i16 0
@cs = internal global i16 0
@ds = internal global i16 0
@es = internal global i16 0
@fs = internal global i16 0
@gs = internal global i16 0
@st0 = internal global x86_fp80 0xK00000000000000000000
@st1 = internal global x86_fp80 0xK00000000000000000000
@st2 = internal global x86_fp80 0xK00000000000000000000
@st3 = internal global x86_fp80 0xK00000000000000000000
@st4 = internal global x86_fp80 0xK00000000000000000000
@st5 = internal global x86_fp80 0xK00000000000000000000
@st6 = internal global x86_fp80 0xK00000000000000000000
@st7 = internal global x86_fp80 0xK00000000000000000000
@fpu_stat_IE = internal global i1 false
@fpu_stat_DE = internal global i1 false
@fpu_stat_ZE = internal global i1 false
@fpu_stat_OE = internal global i1 false
@fpu_stat_UE = internal global i1 false
@fpu_stat_PE = internal global i1 false
@fpu_stat_SF = internal global i1 false
@fpu_stat_ES = internal global i1 false
@fpu_stat_C0 = internal global i1 false
@fpu_stat_C1 = internal global i1 false
@fpu_stat_C2 = internal global i1 false
@fpu_stat_C3 = internal global i1 false
@fpu_stat_TOP = internal global i3 0
@fpu_stat_B = internal global i1 false
@fpu_control_IM = internal global i1 false
@fpu_control_DM = internal global i1 false
@fpu_control_ZM = internal global i1 false
@fpu_control_OM = internal global i1 false
@fpu_control_UM = internal global i1 false
@fpu_control_PM = internal global i1 false
@fpu_control_PC = internal global i2 0
@fpu_control_RC = internal global i2 0
@fpu_control_X = internal global i1 false
@fp0 = internal global double 0.000000e+00
@fp1 = internal global double 0.000000e+00
@fp2 = internal global double 0.000000e+00
@fp3 = internal global double 0.000000e+00
@fp4 = internal global double 0.000000e+00
@fp5 = internal global double 0.000000e+00
@fp6 = internal global double 0.000000e+00
@fp7 = internal global double 0.000000e+00
@k0 = internal global i64 0
@k1 = internal global i64 0
@k2 = internal global i64 0
@k3 = internal global i64 0
@k4 = internal global i64 0
@k5 = internal global i64 0
@k6 = internal global i64 0
@k7 = internal global i64 0
@mm0 = internal global i64 0
@mm1 = internal global i64 0
@mm2 = internal global i64 0
@mm3 = internal global i64 0
@mm4 = internal global i64 0
@mm5 = internal global i64 0
@mm6 = internal global i64 0
@mm7 = internal global i64 0
@xmm0 = internal global i128 0
@xmm1 = internal global i128 0
@xmm2 = internal global i128 0
@xmm3 = internal global i128 0
@xmm4 = internal global i128 0
@xmm5 = internal global i128 0
@xmm6 = internal global i128 0
@xmm7 = internal global i128 0
@xmm8 = internal global i128 0
@xmm9 = internal global i128 0
@xmm10 = internal global i128 0
@xmm11 = internal global i128 0
@xmm12 = internal global i128 0
@xmm13 = internal global i128 0
@xmm14 = internal global i128 0
@xmm15 = internal global i128 0
@xmm16 = internal global i128 0
@xmm17 = internal global i128 0
@xmm18 = internal global i128 0
@xmm19 = internal global i128 0
@xmm20 = internal global i128 0
@xmm21 = internal global i128 0
@xmm22 = internal global i128 0
@xmm23 = internal global i128 0
@xmm24 = internal global i128 0
@xmm25 = internal global i128 0
@xmm26 = internal global i128 0
@xmm27 = internal global i128 0
@xmm28 = internal global i128 0
@xmm29 = internal global i128 0
@xmm30 = internal global i128 0
@xmm31 = internal global i128 0
@ymm0 = internal global i256 0
@ymm1 = internal global i256 0
@ymm2 = internal global i256 0
@ymm3 = internal global i256 0
@ymm4 = internal global i256 0
@ymm5 = internal global i256 0
@ymm6 = internal global i256 0
@ymm7 = internal global i256 0
@ymm8 = internal global i256 0
@ymm9 = internal global i256 0
@ymm10 = internal global i256 0
@ymm11 = internal global i256 0
@ymm12 = internal global i256 0
@ymm13 = internal global i256 0
@ymm14 = internal global i256 0
@ymm15 = internal global i256 0
@ymm16 = internal global i256 0
@ymm17 = internal global i256 0
@ymm18 = internal global i256 0
@ymm19 = internal global i256 0
@ymm20 = internal global i256 0
@ymm21 = internal global i256 0
@ymm22 = internal global i256 0
@ymm23 = internal global i256 0
@ymm24 = internal global i256 0
@ymm25 = internal global i256 0
@ymm26 = internal global i256 0
@ymm27 = internal global i256 0
@ymm28 = internal global i256 0
@ymm29 = internal global i256 0
@ymm30 = internal global i256 0
@ymm31 = internal global i256 0
@zmm0 = internal global i512 0
@zmm1 = internal global i512 0
@zmm2 = internal global i512 0
@zmm3 = internal global i512 0
@zmm4 = internal global i512 0
@zmm5 = internal global i512 0
@zmm6 = internal global i512 0
@zmm7 = internal global i512 0
@zmm8 = internal global i512 0
@zmm9 = internal global i512 0
@zmm10 = internal global i512 0
@zmm11 = internal global i512 0
@zmm12 = internal global i512 0
@zmm13 = internal global i512 0
@zmm14 = internal global i512 0
@zmm15 = internal global i512 0
@zmm16 = internal global i512 0
@zmm17 = internal global i512 0
@zmm18 = internal global i512 0
@zmm19 = internal global i512 0
@zmm20 = internal global i512 0
@zmm21 = internal global i512 0
@zmm22 = internal global i512 0
@zmm23 = internal global i512 0
@zmm24 = internal global i512 0
@zmm25 = internal global i512 0
@zmm26 = internal global i512 0
@zmm27 = internal global i512 0
@zmm28 = internal global i512 0
@zmm29 = internal global i512 0
@zmm30 = internal global i512 0
@zmm31 = internal global i512 0
@bnd0 = internal global i128 0
@bnd1 = internal global i128 0
@bnd2 = internal global i128 0
@bnd3 = internal global i128 0
@dr0 = internal global i64 0
@dr1 = internal global i64 0
@dr2 = internal global i64 0
@dr3 = internal global i64 0
@dr4 = internal global i64 0
@dr5 = internal global i64 0
@dr6 = internal global i64 0
@dr7 = internal global i64 0
@dr8 = internal global i64 0
@dr9 = internal global i64 0
@dr10 = internal global i64 0
@dr11 = internal global i64 0
@dr12 = internal global i64 0
@dr13 = internal global i64 0
@dr14 = internal global i64 0
@dr15 = internal global i64 0
@cr0 = internal global i64 0
@cr1 = internal global i64 0
@cr2 = internal global i64 0
@cr3 = internal global i64 0
@cr4 = internal global i64 0
@cr5 = internal global i64 0
@cr6 = internal global i64 0
@cr7 = internal global i64 0
@cr8 = internal global i64 0
@cr9 = internal global i64 0
@cr10 = internal global i64 0
@cr11 = internal global i64 0
@cr12 = internal global i64 0
@cr13 = internal global i64 0
@cr14 = internal global i64 0
@cr15 = internal global i64 0
@fpsw = internal global i64 0
@rax = internal global i64 0
@rcx = internal global i64 0
@rdx = internal global i64 0
@rbx = internal global i64 0
@rsp = internal global i64 0
@rbp = internal global i64 0
@rsi = internal global i64 0
@rdi = internal global i64 0
@r8 = internal global i64 0
@r9 = internal global i64 0
@r10 = internal global i64 0
@r11 = internal global i64 0
@r12 = internal global i64 0
@r13 = internal global i64 0
@r14 = internal global i64 0
@r15 = internal global i64 0
@rip = internal global i64 0
@riz = internal global i64 0
@global_var_403ff8 = global i64 0
@global_var_404024 = external global i64
@global_var_402010 = constant [4 x i8] c"%d\0A\00"
@0 = external global i32

define i64 @_init() {
dec_label_pc_401000:
  %stack_var_-8 = alloca i64
  %0 = ptrtoint i64* %stack_var_-8 to i64, !insn.addr !0
  store i64 %0, i64* @rsp, !insn.addr !0
  %1 = load i64, i64* inttoptr (i64 4210672 to i64*), !insn.addr !1
  store i64 %1, i64* @rax, !insn.addr !1
  %2 = icmp eq i64 %1, 0, !insn.addr !2
  br i1 %2, label %dec_label_pc_401016, label %dec_label_pc_401014, !insn.addr !3

dec_label_pc_401014:                              ; preds = %dec_label_pc_401000
  call void @__gmon_start__(), !insn.addr !4
  %3 = ptrtoint i32* @0 to i64, !insn.addr !4
  store i64 %3, i64* @rax, !insn.addr !4
  br label %dec_label_pc_401016, !insn.addr !4

dec_label_pc_401016:                              ; preds = %dec_label_pc_401014, %dec_label_pc_401000
  %4 = load i64, i64* @rax, !insn.addr !5
  ret i64 %4, !insn.addr !5
}

define i32 @function_401030(i8* %format, ...) {
dec_label_pc_401030:
  %0 = call i32 (i8*, ...) @printf(i8* %format), !insn.addr !6
  %1 = sext i32 %0 to i64, !insn.addr !6
  %2 = trunc i64 %1 to i32, !insn.addr !6
  ret i32 %2, !insn.addr !6
}

declare i64 @1()

define i64 @_start(i64 %arg1, i64 %arg2, i64 %arg3, i64 %arg4, i64 %arg5, i64 %arg6) {
dec_label_pc_401040:
  %stack_var_-16 = alloca i64
  %stack_var_-8 = alloca i64
  %stack_var_8 = alloca i64
  %stack_var_0 = alloca i64
  store i64 %arg6, i64* %stack_var_0
  %0 = load i64, i64* %stack_var_0, !insn.addr !7
  %1 = load i64, i64* @rax, !insn.addr !8
  store i64 %1, i64* %stack_var_-8, !insn.addr !8
  %2 = ptrtoint i64* %stack_var_-8 to i64, !insn.addr !9
  store i64 %2, i64* %stack_var_-16, !insn.addr !9
  %3 = trunc i64 %arg5 to i32, !insn.addr !10
  %4 = trunc i64 %arg5 to i32, !insn.addr !10
  %5 = xor i32 %3, %4, !insn.addr !10
  %6 = zext i32 %5 to i64, !insn.addr !10
  %7 = trunc i64 %arg4 to i32, !insn.addr !11
  %8 = trunc i64 %arg4 to i32, !insn.addr !11
  %9 = xor i32 %7, %8, !insn.addr !11
  %10 = zext i32 %9 to i64, !insn.addr !11
  %11 = trunc i64 %0 to i32, !insn.addr !12
  %12 = bitcast i64* %stack_var_8 to i8**, !insn.addr !12
  %13 = inttoptr i64 %10 to void ()*, !insn.addr !12
  %14 = inttoptr i64 %6 to void ()*, !insn.addr !12
  %15 = inttoptr i64 %arg3 to void ()*, !insn.addr !12
  %16 = call i32 @__libc_start_main(i64 4198721, i32 %11, i8** %12, void ()* %13, void ()* %14, void ()* %15), !insn.addr !12
  %17 = call i64 @__asm_hlt(), !insn.addr !13
  unreachable, !insn.addr !13
}

declare i64 @2()

define i64 @_dl_relocate_static_pie() {
dec_label_pc_401070:
  %0 = load i64, i64* @rax, !insn.addr !14
  ret i64 %0, !insn.addr !14
}

define i64 @deregister_tm_clones() {
dec_label_pc_401080:
  store i64 4210728, i64* @rdi, !insn.addr !15
  store i64 4210728, i64* @rax, !insn.addr !16
  %0 = sub i64 4210728, 4210728, !insn.addr !17
  %1 = icmp eq i64 %0, 0, !insn.addr !17
  br i1 %1, label %dec_label_pc_4010a8, label %dec_label_pc_401093, !insn.addr !18

dec_label_pc_401093:                              ; preds = %dec_label_pc_401080
  %2 = load i64, i64* inttoptr (i64 4210664 to i64*), !insn.addr !19
  store i64 %2, i64* @rax, !insn.addr !19
  %3 = icmp eq i64 %2, 0, !insn.addr !20
  br i1 %3, label %dec_label_pc_4010a8, label %dec_label_pc_40109f, !insn.addr !21

dec_label_pc_40109f:                              ; preds = %dec_label_pc_401093
  %4 = load i64, i64* @rdi, !insn.addr !22
  %5 = call i64 @_ITM_deregisterTMCloneTable(i64 %4), !insn.addr !22
  ret i64 %5, !insn.addr !22

dec_label_pc_4010a8:                              ; preds = %dec_label_pc_401093, %dec_label_pc_401080
  %6 = load i64, i64* @rax, !insn.addr !23
  ret i64 %6, !insn.addr !23
}

define i64 @register_tm_clones() {
dec_label_pc_4010b0:
  store i64 4210728, i64* @rdi, !insn.addr !24
  %0 = sub i64 4210728, 4210728, !insn.addr !25
  %1 = lshr i64 %0, 63, !insn.addr !26
  %2 = ashr i64 %0, 3, !insn.addr !27
  store i64 %2, i64* @rax, !insn.addr !27
  %3 = add i64 %1, %2, !insn.addr !28
  %4 = ashr i64 %3, 1, !insn.addr !29
  %5 = icmp eq i64 %4, 0, !insn.addr !29
  store i64 %4, i64* @rsi, !insn.addr !29
  br i1 %5, label %dec_label_pc_4010e8, label %dec_label_pc_4010d4, !insn.addr !30

dec_label_pc_4010d4:                              ; preds = %dec_label_pc_4010b0
  %6 = load i64, i64* @global_var_403ff8, !insn.addr !31
  store i64 %6, i64* @rax, !insn.addr !31
  %7 = icmp eq i64 %6, 0, !insn.addr !32
  br i1 %7, label %dec_label_pc_4010e8, label %dec_label_pc_4010e0, !insn.addr !33

dec_label_pc_4010e0:                              ; preds = %dec_label_pc_4010d4
  %8 = load i64, i64* @rdi, !insn.addr !34
  %9 = load i64, i64* @rsi, !insn.addr !34
  %10 = call i64 @_ITM_registerTMCloneTable(i64 %8, i64 %9), !insn.addr !34
  ret i64 %10, !insn.addr !34

dec_label_pc_4010e8:                              ; preds = %dec_label_pc_4010d4, %dec_label_pc_4010b0
  %11 = load i64, i64* @rax, !insn.addr !35
  ret i64 %11, !insn.addr !35
}

define i64 @__do_global_dtors_aux() {
dec_label_pc_4010f0:
  %stack_var_-8 = alloca i64
  %0 = load i8, i8* inttoptr (i64 4210724 to i8*), !insn.addr !36
  %1 = icmp eq i8 %0, 0, !insn.addr !36
  %2 = icmp eq i1 %1, false, !insn.addr !37
  br i1 %2, label %dec_label_pc_401110, label %dec_label_pc_4010fd, !insn.addr !37

dec_label_pc_4010fd:                              ; preds = %dec_label_pc_4010f0
  %3 = load i64, i64* @rbp, !insn.addr !38
  store i64 %3, i64* %stack_var_-8, !insn.addr !38
  %4 = call i64 @deregister_tm_clones(), !insn.addr !39
  store i8 1, i8* bitcast (i64* @global_var_404024 to i8*), !insn.addr !40
  ret i64 %4, !insn.addr !41

dec_label_pc_401110:                              ; preds = %dec_label_pc_4010f0
  %5 = load i64, i64* @rax, !insn.addr !42
  ret i64 %5, !insn.addr !42
}

define i64 @frame_dummy() {
dec_label_pc_401120:
  %0 = call i64 @register_tm_clones(), !insn.addr !43
  ret i64 %0, !insn.addr !43
}

define i64 @add(i32* %arg1, i64 %arg2) {
dec_label_pc_401126:
  %stack_var_-8 = alloca i64
  %0 = load i64, i64* @rbp, !insn.addr !44
  store i64 %0, i64* %stack_var_-8, !insn.addr !44
  %1 = trunc i64 %arg2 to i32, !insn.addr !45
  %2 = zext i32 %1 to i64, !insn.addr !45
  %3 = trunc i64 %2 to i8, !insn.addr !46
  %4 = load i32, i32* bitcast (i64* @rdi to i32*), !insn.addr !47
  %5 = zext i32 %4 to i64, !insn.addr !47
  %6 = sext i8 %3 to i64, !insn.addr !48
  %7 = trunc i64 %6 to i32, !insn.addr !49
  %8 = trunc i64 %5 to i32, !insn.addr !49
  %9 = add i32 %7, %8, !insn.addr !49
  %10 = zext i32 %9 to i64, !insn.addr !49
  ret i64 %10, !insn.addr !50
}

declare i64 @3()

define i64 @main(i64 %argc, i8** %argv) {
dec_label_pc_401141:
  %stack_var_-32 = alloca i32
  %stack_var_-8 = alloca i64
  %0 = load i64, i64* @rbp, !insn.addr !51
  store i64 %0, i64* %stack_var_-8, !insn.addr !51
  store i32 1, i32* %stack_var_-32, !insn.addr !52
  %1 = sext i8 2 to i64, !insn.addr !53
  %2 = trunc i64 %1 to i32, !insn.addr !54
  %3 = zext i32 %2 to i64, !insn.addr !54
  %4 = call i64 @add(i32* %stack_var_-32, i64 %3), !insn.addr !55
  %5 = trunc i64 %4 to i32, !insn.addr !56
  %6 = sext i8 2 to i64, !insn.addr !57
  %7 = trunc i64 %6 to i32, !insn.addr !58
  %8 = zext i32 %7 to i64, !insn.addr !58
  %9 = call i64 @add(i32* %stack_var_-32, i64 %8), !insn.addr !59
  %10 = zext i32 %5 to i64, !insn.addr !60
  %11 = trunc i64 %10 to i32, !insn.addr !61
  %12 = zext i32 %11 to i64, !insn.addr !61
  %13 = inttoptr i64 ptrtoint ([4 x i8]* @global_var_402010 to i64) to i8*, !insn.addr !62
  %14 = call i32 (i8*, ...) @printf(i8* %13, i64 %12), !insn.addr !62
  ret i64 0, !insn.addr !63
}

declare i64 @4()

define i64 @_fini() {
dec_label_pc_4011a4:
  %0 = load i64, i64* @rax, !insn.addr !64
  ret i64 %0, !insn.addr !64
}

declare i32 @__libc_start_main(i64, i32, i8**, void ()*, void ()*, void ()*)

declare i64 @5()

declare i64 @_ITM_deregisterTMCloneTable(i64)

declare i64 @6()

declare void @__gmon_start__()

declare i64 @7()

declare i64 @_ITM_registerTMCloneTable(i64, i64)

declare i64 @8()

declare i32 @printf(i8*, ...)

declare i64 @9()

declare void @__pseudo_call(i64)

declare void @__pseudo_return(i64)

declare void @__pseudo_branch(i64)

declare void @__pseudo_cond_branch(i1, i64)

declare void @__frontend_reg_store.fpr(i3, x86_fp80)

declare x86_fp80 @__frontend_reg_load.fpr(i3)

; Function Attrs: nounwind readnone speculatable
declare i8 @llvm.ctpop.i8(i8) #0

declare i64 @__asm_hlt()

declare void @10()

attributes #0 = { nounwind readnone speculatable }

!0 = !{i64 4198404}
!1 = !{i64 4198408}
!2 = !{i64 4198415}
!3 = !{i64 4198418}
!4 = !{i64 4198420}
!5 = !{i64 4198426}
!6 = !{i64 4198448}
!7 = !{i64 4198473}
!8 = !{i64 4198481}
!9 = !{i64 4198482}
!10 = !{i64 4198483}
!11 = !{i64 4198486}
!12 = !{i64 4198495}
!13 = !{i64 4198501}
!14 = !{i64 4198516}
!15 = !{i64 4198528}
!16 = !{i64 4198535}
!17 = !{i64 4198542}
!18 = !{i64 4198545}
!19 = !{i64 4198547}
!20 = !{i64 4198554}
!21 = !{i64 4198557}
!22 = !{i64 4198559}
!23 = !{i64 4198568}
!24 = !{i64 4198576}
!25 = !{i64 4198590}
!26 = !{i64 4198596}
!27 = !{i64 4198600}
!28 = !{i64 4198604}
!29 = !{i64 4198607}
!30 = !{i64 4198610}
!31 = !{i64 4198612}
!32 = !{i64 4198619}
!33 = !{i64 4198622}
!34 = !{i64 4198624}
!35 = !{i64 4198632}
!36 = !{i64 4198644}
!37 = !{i64 4198651}
!38 = !{i64 4198653}
!39 = !{i64 4198657}
!40 = !{i64 4198662}
!41 = !{i64 4198670}
!42 = !{i64 4198672}
!43 = !{i64 4198692}
!44 = !{i64 4198694}
!45 = !{i64 4198702}
!46 = !{i64 4198704}
!47 = !{i64 4198711}
!48 = !{i64 4198713}
!49 = !{i64 4198717}
!50 = !{i64 4198720}
!51 = !{i64 4198721}
!52 = !{i64 4198729}
!53 = !{i64 4198740}
!54 = !{i64 4198748}
!55 = !{i64 4198753}
!56 = !{i64 4198758}
!57 = !{i64 4198769}
!58 = !{i64 4198777}
!59 = !{i64 4198782}
!60 = !{i64 4198790}
!61 = !{i64 4198793}
!62 = !{i64 4198805}
!63 = !{i64 4198816}
!64 = !{i64 4198832}
*** IR Dump After Selected functions optimization ***
source_filename = "test"
target datalayout = "e-m:e-p:64:64-i64:64-f80:128-n8:16:32:64-S128"

@cf = internal global i1 false
@pf = internal global i1 false
@az = internal global i1 false
@zf = internal global i1 false
@sf = internal global i1 false
@tf = internal global i1 false
@if = internal global i1 false
@df = internal global i1 false
@of = internal global i1 false
@iopl = internal global i2 0
@nt = internal global i1 false
@rf = internal global i1 false
@vm = internal global i1 false
@ac = internal global i1 false
@vif = internal global i1 false
@vip = internal global i1 false
@id = internal global i1 false
@rflags = internal global i64 0
@ss = internal global i16 0
@cs = internal global i16 0
@ds = internal global i16 0
@es = internal global i16 0
@fs = internal global i16 0
@gs = internal global i16 0
@st0 = internal global x86_fp80 0xK00000000000000000000
@st1 = internal global x86_fp80 0xK00000000000000000000
@st2 = internal global x86_fp80 0xK00000000000000000000
@st3 = internal global x86_fp80 0xK00000000000000000000
@st4 = internal global x86_fp80 0xK00000000000000000000
@st5 = internal global x86_fp80 0xK00000000000000000000
@st6 = internal global x86_fp80 0xK00000000000000000000
@st7 = internal global x86_fp80 0xK00000000000000000000
@fpu_stat_IE = internal global i1 false
@fpu_stat_DE = internal global i1 false
@fpu_stat_ZE = internal global i1 false
@fpu_stat_OE = internal global i1 false
@fpu_stat_UE = internal global i1 false
@fpu_stat_PE = internal global i1 false
@fpu_stat_SF = internal global i1 false
@fpu_stat_ES = internal global i1 false
@fpu_stat_C0 = internal global i1 false
@fpu_stat_C1 = internal global i1 false
@fpu_stat_C2 = internal global i1 false
@fpu_stat_C3 = internal global i1 false
@fpu_stat_TOP = internal global i3 0
@fpu_stat_B = internal global i1 false
@fpu_control_IM = internal global i1 false
@fpu_control_DM = internal global i1 false
@fpu_control_ZM = internal global i1 false
@fpu_control_OM = internal global i1 false
@fpu_control_UM = internal global i1 false
@fpu_control_PM = internal global i1 false
@fpu_control_PC = internal global i2 0
@fpu_control_RC = internal global i2 0
@fpu_control_X = internal global i1 false
@fp0 = internal global double 0.000000e+00
@fp1 = internal global double 0.000000e+00
@fp2 = internal global double 0.000000e+00
@fp3 = internal global double 0.000000e+00
@fp4 = internal global double 0.000000e+00
@fp5 = internal global double 0.000000e+00
@fp6 = internal global double 0.000000e+00
@fp7 = internal global double 0.000000e+00
@k0 = internal global i64 0
@k1 = internal global i64 0
@k2 = internal global i64 0
@k3 = internal global i64 0
@k4 = internal global i64 0
@k5 = internal global i64 0
@k6 = internal global i64 0
@k7 = internal global i64 0
@mm0 = internal global i64 0
@mm1 = internal global i64 0
@mm2 = internal global i64 0
@mm3 = internal global i64 0
@mm4 = internal global i64 0
@mm5 = internal global i64 0
@mm6 = internal global i64 0
@mm7 = internal global i64 0
@xmm0 = internal global i128 0
@xmm1 = internal global i128 0
@xmm2 = internal global i128 0
@xmm3 = internal global i128 0
@xmm4 = internal global i128 0
@xmm5 = internal global i128 0
@xmm6 = internal global i128 0
@xmm7 = internal global i128 0
@xmm8 = internal global i128 0
@xmm9 = internal global i128 0
@xmm10 = internal global i128 0
@xmm11 = internal global i128 0
@xmm12 = internal global i128 0
@xmm13 = internal global i128 0
@xmm14 = internal global i128 0
@xmm15 = internal global i128 0
@xmm16 = internal global i128 0
@xmm17 = internal global i128 0
@xmm18 = internal global i128 0
@xmm19 = internal global i128 0
@xmm20 = internal global i128 0
@xmm21 = internal global i128 0
@xmm22 = internal global i128 0
@xmm23 = internal global i128 0
@xmm24 = internal global i128 0
@xmm25 = internal global i128 0
@xmm26 = internal global i128 0
@xmm27 = internal global i128 0
@xmm28 = internal global i128 0
@xmm29 = internal global i128 0
@xmm30 = internal global i128 0
@xmm31 = internal global i128 0
@ymm0 = internal global i256 0
@ymm1 = internal global i256 0
@ymm2 = internal global i256 0
@ymm3 = internal global i256 0
@ymm4 = internal global i256 0
@ymm5 = internal global i256 0
@ymm6 = internal global i256 0
@ymm7 = internal global i256 0
@ymm8 = internal global i256 0
@ymm9 = internal global i256 0
@ymm10 = internal global i256 0
@ymm11 = internal global i256 0
@ymm12 = internal global i256 0
@ymm13 = internal global i256 0
@ymm14 = internal global i256 0
@ymm15 = internal global i256 0
@ymm16 = internal global i256 0
@ymm17 = internal global i256 0
@ymm18 = internal global i256 0
@ymm19 = internal global i256 0
@ymm20 = internal global i256 0
@ymm21 = internal global i256 0
@ymm22 = internal global i256 0
@ymm23 = internal global i256 0
@ymm24 = internal global i256 0
@ymm25 = internal global i256 0
@ymm26 = internal global i256 0
@ymm27 = internal global i256 0
@ymm28 = internal global i256 0
@ymm29 = internal global i256 0
@ymm30 = internal global i256 0
@ymm31 = internal global i256 0
@zmm0 = internal global i512 0
@zmm1 = internal global i512 0
@zmm2 = internal global i512 0
@zmm3 = internal global i512 0
@zmm4 = internal global i512 0
@zmm5 = internal global i512 0
@zmm6 = internal global i512 0
@zmm7 = internal global i512 0
@zmm8 = internal global i512 0
@zmm9 = internal global i512 0
@zmm10 = internal global i512 0
@zmm11 = internal global i512 0
@zmm12 = internal global i512 0
@zmm13 = internal global i512 0
@zmm14 = internal global i512 0
@zmm15 = internal global i512 0
@zmm16 = internal global i512 0
@zmm17 = internal global i512 0
@zmm18 = internal global i512 0
@zmm19 = internal global i512 0
@zmm20 = internal global i512 0
@zmm21 = internal global i512 0
@zmm22 = internal global i512 0
@zmm23 = internal global i512 0
@zmm24 = internal global i512 0
@zmm25 = internal global i512 0
@zmm26 = internal global i512 0
@zmm27 = internal global i512 0
@zmm28 = internal global i512 0
@zmm29 = internal global i512 0
@zmm30 = internal global i512 0
@zmm31 = internal global i512 0
@bnd0 = internal global i128 0
@bnd1 = internal global i128 0
@bnd2 = internal global i128 0
@bnd3 = internal global i128 0
@dr0 = internal global i64 0
@dr1 = internal global i64 0
@dr2 = internal global i64 0
@dr3 = internal global i64 0
@dr4 = internal global i64 0
@dr5 = internal global i64 0
@dr6 = internal global i64 0
@dr7 = internal global i64 0
@dr8 = internal global i64 0
@dr9 = internal global i64 0
@dr10 = internal global i64 0
@dr11 = internal global i64 0
@dr12 = internal global i64 0
@dr13 = internal global i64 0
@dr14 = internal global i64 0
@dr15 = internal global i64 0
@cr0 = internal global i64 0
@cr1 = internal global i64 0
@cr2 = internal global i64 0
@cr3 = internal global i64 0
@cr4 = internal global i64 0
@cr5 = internal global i64 0
@cr6 = internal global i64 0
@cr7 = internal global i64 0
@cr8 = internal global i64 0
@cr9 = internal global i64 0
@cr10 = internal global i64 0
@cr11 = internal global i64 0
@cr12 = internal global i64 0
@cr13 = internal global i64 0
@cr14 = internal global i64 0
@cr15 = internal global i64 0
@fpsw = internal global i64 0
@rax = internal global i64 0
@rcx = internal global i64 0
@rdx = internal global i64 0
@rbx = internal global i64 0
@rsp = internal global i64 0
@rbp = internal global i64 0
@rsi = internal global i64 0
@rdi = internal global i64 0
@r8 = internal global i64 0
@r9 = internal global i64 0
@r10 = internal global i64 0
@r11 = internal global i64 0
@r12 = internal global i64 0
@r13 = internal global i64 0
@r14 = internal global i64 0
@r15 = internal global i64 0
@rip = internal global i64 0
@riz = internal global i64 0
@global_var_403ff8 = global i64 0
@global_var_404024 = external global i64
@global_var_402010 = constant [4 x i8] c"%d\0A\00"
@0 = external global i32

define i64 @_init() {
dec_label_pc_401000:
  %stack_var_-8 = alloca i64
  %0 = ptrtoint i64* %stack_var_-8 to i64, !insn.addr !0
  store i64 %0, i64* @rsp, !insn.addr !0
  %1 = load i64, i64* inttoptr (i64 4210672 to i64*), !insn.addr !1
  store i64 %1, i64* @rax, !insn.addr !1
  %2 = icmp eq i64 %1, 0, !insn.addr !2
  br i1 %2, label %dec_label_pc_401016, label %dec_label_pc_401014, !insn.addr !3

dec_label_pc_401014:                              ; preds = %dec_label_pc_401000
  call void @__gmon_start__(), !insn.addr !4
  %3 = ptrtoint i32* @0 to i64, !insn.addr !4
  store i64 %3, i64* @rax, !insn.addr !4
  br label %dec_label_pc_401016, !insn.addr !4

dec_label_pc_401016:                              ; preds = %dec_label_pc_401014, %dec_label_pc_401000
  %4 = load i64, i64* @rax, !insn.addr !5
  ret i64 %4, !insn.addr !5
}

define i32 @function_401030(i8* %format, ...) {
dec_label_pc_401030:
  %0 = call i32 (i8*, ...) @printf(i8* %format), !insn.addr !6
  %1 = sext i32 %0 to i64, !insn.addr !6
  %2 = trunc i64 %1 to i32, !insn.addr !6
  ret i32 %2, !insn.addr !6
}

declare i64 @1()

define i64 @_start(i64 %arg1, i64 %arg2, i64 %arg3, i64 %arg4, i64 %arg5, i64 %arg6) {
dec_label_pc_401040:
  %stack_var_-16 = alloca i64
  %stack_var_-8 = alloca i64
  %stack_var_8 = alloca i64
  %stack_var_0 = alloca i64
  store i64 %arg6, i64* %stack_var_0
  %0 = load i64, i64* %stack_var_0, !insn.addr !7
  %1 = load i64, i64* @rax, !insn.addr !8
  store i64 %1, i64* %stack_var_-8, !insn.addr !8
  %2 = ptrtoint i64* %stack_var_-8 to i64, !insn.addr !9
  store i64 %2, i64* %stack_var_-16, !insn.addr !9
  %3 = trunc i64 %arg5 to i32, !insn.addr !10
  %4 = trunc i64 %arg5 to i32, !insn.addr !10
  %5 = xor i32 %3, %4, !insn.addr !10
  %6 = zext i32 %5 to i64, !insn.addr !10
  %7 = trunc i64 %arg4 to i32, !insn.addr !11
  %8 = trunc i64 %arg4 to i32, !insn.addr !11
  %9 = xor i32 %7, %8, !insn.addr !11
  %10 = zext i32 %9 to i64, !insn.addr !11
  %11 = trunc i64 %0 to i32, !insn.addr !12
  %12 = bitcast i64* %stack_var_8 to i8**, !insn.addr !12
  %13 = inttoptr i64 %10 to void ()*, !insn.addr !12
  %14 = inttoptr i64 %6 to void ()*, !insn.addr !12
  %15 = inttoptr i64 %arg3 to void ()*, !insn.addr !12
  %16 = call i32 @__libc_start_main(i64 4198721, i32 %11, i8** %12, void ()* %13, void ()* %14, void ()* %15), !insn.addr !12
  %17 = call i64 @__asm_hlt(), !insn.addr !13
  unreachable, !insn.addr !13
}

declare i64 @2()

define i64 @_dl_relocate_static_pie() {
dec_label_pc_401070:
  %0 = load i64, i64* @rax, !insn.addr !14
  ret i64 %0, !insn.addr !14
}

define i64 @deregister_tm_clones() {
dec_label_pc_401080:
  store i64 4210728, i64* @rdi, !insn.addr !15
  store i64 4210728, i64* @rax, !insn.addr !16
  %0 = sub i64 4210728, 4210728, !insn.addr !17
  %1 = icmp eq i64 %0, 0, !insn.addr !17
  br i1 %1, label %dec_label_pc_4010a8, label %dec_label_pc_401093, !insn.addr !18

dec_label_pc_401093:                              ; preds = %dec_label_pc_401080
  %2 = load i64, i64* inttoptr (i64 4210664 to i64*), !insn.addr !19
  store i64 %2, i64* @rax, !insn.addr !19
  %3 = icmp eq i64 %2, 0, !insn.addr !20
  br i1 %3, label %dec_label_pc_4010a8, label %dec_label_pc_40109f, !insn.addr !21

dec_label_pc_40109f:                              ; preds = %dec_label_pc_401093
  %4 = load i64, i64* @rdi, !insn.addr !22
  %5 = call i64 @_ITM_deregisterTMCloneTable(i64 %4), !insn.addr !22
  ret i64 %5, !insn.addr !22

dec_label_pc_4010a8:                              ; preds = %dec_label_pc_401093, %dec_label_pc_401080
  %6 = load i64, i64* @rax, !insn.addr !23
  ret i64 %6, !insn.addr !23
}

define i64 @register_tm_clones() {
dec_label_pc_4010b0:
  store i64 4210728, i64* @rdi, !insn.addr !24
  %0 = sub i64 4210728, 4210728, !insn.addr !25
  %1 = lshr i64 %0, 63, !insn.addr !26
  %2 = ashr i64 %0, 3, !insn.addr !27
  store i64 %2, i64* @rax, !insn.addr !27
  %3 = add i64 %1, %2, !insn.addr !28
  %4 = ashr i64 %3, 1, !insn.addr !29
  %5 = icmp eq i64 %4, 0, !insn.addr !29
  store i64 %4, i64* @rsi, !insn.addr !29
  br i1 %5, label %dec_label_pc_4010e8, label %dec_label_pc_4010d4, !insn.addr !30

dec_label_pc_4010d4:                              ; preds = %dec_label_pc_4010b0
  %6 = load i64, i64* @global_var_403ff8, !insn.addr !31
  store i64 %6, i64* @rax, !insn.addr !31
  %7 = icmp eq i64 %6, 0, !insn.addr !32
  br i1 %7, label %dec_label_pc_4010e8, label %dec_label_pc_4010e0, !insn.addr !33

dec_label_pc_4010e0:                              ; preds = %dec_label_pc_4010d4
  %8 = load i64, i64* @rdi, !insn.addr !34
  %9 = load i64, i64* @rsi, !insn.addr !34
  %10 = call i64 @_ITM_registerTMCloneTable(i64 %8, i64 %9), !insn.addr !34
  ret i64 %10, !insn.addr !34

dec_label_pc_4010e8:                              ; preds = %dec_label_pc_4010d4, %dec_label_pc_4010b0
  %11 = load i64, i64* @rax, !insn.addr !35
  ret i64 %11, !insn.addr !35
}

define i64 @__do_global_dtors_aux() {
dec_label_pc_4010f0:
  %stack_var_-8 = alloca i64
  %0 = load i8, i8* inttoptr (i64 4210724 to i8*), !insn.addr !36
  %1 = icmp eq i8 %0, 0, !insn.addr !36
  %2 = icmp eq i1 %1, false, !insn.addr !37
  br i1 %2, label %dec_label_pc_401110, label %dec_label_pc_4010fd, !insn.addr !37

dec_label_pc_4010fd:                              ; preds = %dec_label_pc_4010f0
  %3 = load i64, i64* @rbp, !insn.addr !38
  store i64 %3, i64* %stack_var_-8, !insn.addr !38
  %4 = call i64 @deregister_tm_clones(), !insn.addr !39
  store i8 1, i8* bitcast (i64* @global_var_404024 to i8*), !insn.addr !40
  ret i64 %4, !insn.addr !41

dec_label_pc_401110:                              ; preds = %dec_label_pc_4010f0
  %5 = load i64, i64* @rax, !insn.addr !42
  ret i64 %5, !insn.addr !42
}

define i64 @frame_dummy() {
dec_label_pc_401120:
  %0 = call i64 @register_tm_clones(), !insn.addr !43
  ret i64 %0, !insn.addr !43
}

define i64 @add(i32* %arg1, i64 %arg2) {
dec_label_pc_401126:
  %stack_var_-8 = alloca i64
  %0 = load i64, i64* @rbp, !insn.addr !44
  store i64 %0, i64* %stack_var_-8, !insn.addr !44
  %1 = trunc i64 %arg2 to i32, !insn.addr !45
  %2 = zext i32 %1 to i64, !insn.addr !45
  %3 = trunc i64 %2 to i8, !insn.addr !46
  %4 = load i32, i32* bitcast (i64* @rdi to i32*), !insn.addr !47
  %5 = zext i32 %4 to i64, !insn.addr !47
  %6 = sext i8 %3 to i64, !insn.addr !48
  %7 = trunc i64 %6 to i32, !insn.addr !49
  %8 = trunc i64 %5 to i32, !insn.addr !49
  %9 = add i32 %7, %8, !insn.addr !49
  %10 = zext i32 %9 to i64, !insn.addr !49
  ret i64 %10, !insn.addr !50
}

declare i64 @3()

define i64 @main(i64 %argc, i8** %argv) {
dec_label_pc_401141:
  %stack_var_-32 = alloca i32
  %stack_var_-8 = alloca i64
  %0 = load i64, i64* @rbp, !insn.addr !51
  store i64 %0, i64* %stack_var_-8, !insn.addr !51
  store i32 1, i32* %stack_var_-32, !insn.addr !52
  %1 = sext i8 2 to i64, !insn.addr !53
  %2 = trunc i64 %1 to i32, !insn.addr !54
  %3 = zext i32 %2 to i64, !insn.addr !54
  %4 = call i64 @add(i32* %stack_var_-32, i64 %3), !insn.addr !55
  %5 = trunc i64 %4 to i32, !insn.addr !56
  %6 = sext i8 2 to i64, !insn.addr !57
  %7 = trunc i64 %6 to i32, !insn.addr !58
  %8 = zext i32 %7 to i64, !insn.addr !58
  %9 = call i64 @add(i32* %stack_var_-32, i64 %8), !insn.addr !59
  %10 = zext i32 %5 to i64, !insn.addr !60
  %11 = trunc i64 %10 to i32, !insn.addr !61
  %12 = zext i32 %11 to i64, !insn.addr !61
  %13 = inttoptr i64 ptrtoint ([4 x i8]* @global_var_402010 to i64) to i8*, !insn.addr !62
  %14 = call i32 (i8*, ...) @printf(i8* %13, i64 %12), !insn.addr !62
  ret i64 0, !insn.addr !63
}

declare i64 @4()

define i64 @_fini() {
dec_label_pc_4011a4:
  %0 = load i64, i64* @rax, !insn.addr !64
  ret i64 %0, !insn.addr !64
}

declare i32 @__libc_start_main(i64, i32, i8**, void ()*, void ()*, void ()*)

declare i64 @5()

declare i64 @_ITM_deregisterTMCloneTable(i64)

declare i64 @6()

declare void @__gmon_start__()

declare i64 @7()

declare i64 @_ITM_registerTMCloneTable(i64, i64)

declare i64 @8()

declare i32 @printf(i8*, ...)

declare i64 @9()

declare void @__pseudo_call(i64)

declare void @__pseudo_return(i64)

declare void @__pseudo_branch(i64)

declare void @__pseudo_cond_branch(i1, i64)

declare void @__frontend_reg_store.fpr(i3, x86_fp80)

declare x86_fp80 @__frontend_reg_load.fpr(i3)

; Function Attrs: nounwind readnone speculatable
declare i8 @llvm.ctpop.i8(i8) #0

declare i64 @__asm_hlt()

declare void @10()

attributes #0 = { nounwind readnone speculatable }

!0 = !{i64 4198404}
!1 = !{i64 4198408}
!2 = !{i64 4198415}
!3 = !{i64 4198418}
!4 = !{i64 4198420}
!5 = !{i64 4198426}
!6 = !{i64 4198448}
!7 = !{i64 4198473}
!8 = !{i64 4198481}
!9 = !{i64 4198482}
!10 = !{i64 4198483}
!11 = !{i64 4198486}
!12 = !{i64 4198495}
!13 = !{i64 4198501}
!14 = !{i64 4198516}
!15 = !{i64 4198528}
!16 = !{i64 4198535}
!17 = !{i64 4198542}
!18 = !{i64 4198545}
!19 = !{i64 4198547}
!20 = !{i64 4198554}
!21 = !{i64 4198557}
!22 = !{i64 4198559}
!23 = !{i64 4198568}
!24 = !{i64 4198576}
!25 = !{i64 4198590}
!26 = !{i64 4198596}
!27 = !{i64 4198600}
!28 = !{i64 4198604}
!29 = !{i64 4198607}
!30 = !{i64 4198610}
!31 = !{i64 4198612}
!32 = !{i64 4198619}
!33 = !{i64 4198622}
!34 = !{i64 4198624}
!35 = !{i64 4198632}
!36 = !{i64 4198644}
!37 = !{i64 4198651}
!38 = !{i64 4198653}
!39 = !{i64 4198657}
!40 = !{i64 4198662}
!41 = !{i64 4198670}
!42 = !{i64 4198672}
!43 = !{i64 4198692}
!44 = !{i64 4198694}
!45 = !{i64 4198702}
!46 = !{i64 4198704}
!47 = !{i64 4198711}
!48 = !{i64 4198713}
!49 = !{i64 4198717}
!50 = !{i64 4198720}
!51 = !{i64 4198721}
!52 = !{i64 4198729}
!53 = !{i64 4198740}
!54 = !{i64 4198748}
!55 = !{i64 4198753}
!56 = !{i64 4198758}
!57 = !{i64 4198769}
!58 = !{i64 4198777}
!59 = !{i64 4198782}
!60 = !{i64 4198790}
!61 = !{i64 4198793}
!62 = !{i64 4198805}
!63 = !{i64 4198816}
!64 = !{i64 4198832}
*** IR Dump After Unreachable functions optimization ***
source_filename = "test"
target datalayout = "e-m:e-p:64:64-i64:64-f80:128-n8:16:32:64-S128"

@cf = internal global i1 false
@pf = internal global i1 false
@az = internal global i1 false
@zf = internal global i1 false
@sf = internal global i1 false
@tf = internal global i1 false
@if = internal global i1 false
@df = internal global i1 false
@of = internal global i1 false
@iopl = internal global i2 0
@nt = internal global i1 false
@rf = internal global i1 false
@vm = internal global i1 false
@ac = internal global i1 false
@vif = internal global i1 false
@vip = internal global i1 false
@id = internal global i1 false
@rflags = internal global i64 0
@ss = internal global i16 0
@cs = internal global i16 0
@ds = internal global i16 0
@es = internal global i16 0
@fs = internal global i16 0
@gs = internal global i16 0
@st0 = internal global x86_fp80 0xK00000000000000000000
@st1 = internal global x86_fp80 0xK00000000000000000000
@st2 = internal global x86_fp80 0xK00000000000000000000
@st3 = internal global x86_fp80 0xK00000000000000000000
@st4 = internal global x86_fp80 0xK00000000000000000000
@st5 = internal global x86_fp80 0xK00000000000000000000
@st6 = internal global x86_fp80 0xK00000000000000000000
@st7 = internal global x86_fp80 0xK00000000000000000000
@fpu_stat_IE = internal global i1 false
@fpu_stat_DE = internal global i1 false
@fpu_stat_ZE = internal global i1 false
@fpu_stat_OE = internal global i1 false
@fpu_stat_UE = internal global i1 false
@fpu_stat_PE = internal global i1 false
@fpu_stat_SF = internal global i1 false
@fpu_stat_ES = internal global i1 false
@fpu_stat_C0 = internal global i1 false
@fpu_stat_C1 = internal global i1 false
@fpu_stat_C2 = internal global i1 false
@fpu_stat_C3 = internal global i1 false
@fpu_stat_TOP = internal global i3 0
@fpu_stat_B = internal global i1 false
@fpu_control_IM = internal global i1 false
@fpu_control_DM = internal global i1 false
@fpu_control_ZM = internal global i1 false
@fpu_control_OM = internal global i1 false
@fpu_control_UM = internal global i1 false
@fpu_control_PM = internal global i1 false
@fpu_control_PC = internal global i2 0
@fpu_control_RC = internal global i2 0
@fpu_control_X = internal global i1 false
@fp0 = internal global double 0.000000e+00
@fp1 = internal global double 0.000000e+00
@fp2 = internal global double 0.000000e+00
@fp3 = internal global double 0.000000e+00
@fp4 = internal global double 0.000000e+00
@fp5 = internal global double 0.000000e+00
@fp6 = internal global double 0.000000e+00
@fp7 = internal global double 0.000000e+00
@k0 = internal global i64 0
@k1 = internal global i64 0
@k2 = internal global i64 0
@k3 = internal global i64 0
@k4 = internal global i64 0
@k5 = internal global i64 0
@k6 = internal global i64 0
@k7 = internal global i64 0
@mm0 = internal global i64 0
@mm1 = internal global i64 0
@mm2 = internal global i64 0
@mm3 = internal global i64 0
@mm4 = internal global i64 0
@mm5 = internal global i64 0
@mm6 = internal global i64 0
@mm7 = internal global i64 0
@xmm0 = internal global i128 0
@xmm1 = internal global i128 0
@xmm2 = internal global i128 0
@xmm3 = internal global i128 0
@xmm4 = internal global i128 0
@xmm5 = internal global i128 0
@xmm6 = internal global i128 0
@xmm7 = internal global i128 0
@xmm8 = internal global i128 0
@xmm9 = internal global i128 0
@xmm10 = internal global i128 0
@xmm11 = internal global i128 0
@xmm12 = internal global i128 0
@xmm13 = internal global i128 0
@xmm14 = internal global i128 0
@xmm15 = internal global i128 0
@xmm16 = internal global i128 0
@xmm17 = internal global i128 0
@xmm18 = internal global i128 0
@xmm19 = internal global i128 0
@xmm20 = internal global i128 0
@xmm21 = internal global i128 0
@xmm22 = internal global i128 0
@xmm23 = internal global i128 0
@xmm24 = internal global i128 0
@xmm25 = internal global i128 0
@xmm26 = internal global i128 0
@xmm27 = internal global i128 0
@xmm28 = internal global i128 0
@xmm29 = internal global i128 0
@xmm30 = internal global i128 0
@xmm31 = internal global i128 0
@ymm0 = internal global i256 0
@ymm1 = internal global i256 0
@ymm2 = internal global i256 0
@ymm3 = internal global i256 0
@ymm4 = internal global i256 0
@ymm5 = internal global i256 0
@ymm6 = internal global i256 0
@ymm7 = internal global i256 0
@ymm8 = internal global i256 0
@ymm9 = internal global i256 0
@ymm10 = internal global i256 0
@ymm11 = internal global i256 0
@ymm12 = internal global i256 0
@ymm13 = internal global i256 0
@ymm14 = internal global i256 0
@ymm15 = internal global i256 0
@ymm16 = internal global i256 0
@ymm17 = internal global i256 0
@ymm18 = internal global i256 0
@ymm19 = internal global i256 0
@ymm20 = internal global i256 0
@ymm21 = internal global i256 0
@ymm22 = internal global i256 0
@ymm23 = internal global i256 0
@ymm24 = internal global i256 0
@ymm25 = internal global i256 0
@ymm26 = internal global i256 0
@ymm27 = internal global i256 0
@ymm28 = internal global i256 0
@ymm29 = internal global i256 0
@ymm30 = internal global i256 0
@ymm31 = internal global i256 0
@zmm0 = internal global i512 0
@zmm1 = internal global i512 0
@zmm2 = internal global i512 0
@zmm3 = internal global i512 0
@zmm4 = internal global i512 0
@zmm5 = internal global i512 0
@zmm6 = internal global i512 0
@zmm7 = internal global i512 0
@zmm8 = internal global i512 0
@zmm9 = internal global i512 0
@zmm10 = internal global i512 0
@zmm11 = internal global i512 0
@zmm12 = internal global i512 0
@zmm13 = internal global i512 0
@zmm14 = internal global i512 0
@zmm15 = internal global i512 0
@zmm16 = internal global i512 0
@zmm17 = internal global i512 0
@zmm18 = internal global i512 0
@zmm19 = internal global i512 0
@zmm20 = internal global i512 0
@zmm21 = internal global i512 0
@zmm22 = internal global i512 0
@zmm23 = internal global i512 0
@zmm24 = internal global i512 0
@zmm25 = internal global i512 0
@zmm26 = internal global i512 0
@zmm27 = internal global i512 0
@zmm28 = internal global i512 0
@zmm29 = internal global i512 0
@zmm30 = internal global i512 0
@zmm31 = internal global i512 0
@bnd0 = internal global i128 0
@bnd1 = internal global i128 0
@bnd2 = internal global i128 0
@bnd3 = internal global i128 0
@dr0 = internal global i64 0
@dr1 = internal global i64 0
@dr2 = internal global i64 0
@dr3 = internal global i64 0
@dr4 = internal global i64 0
@dr5 = internal global i64 0
@dr6 = internal global i64 0
@dr7 = internal global i64 0
@dr8 = internal global i64 0
@dr9 = internal global i64 0
@dr10 = internal global i64 0
@dr11 = internal global i64 0
@dr12 = internal global i64 0
@dr13 = internal global i64 0
@dr14 = internal global i64 0
@dr15 = internal global i64 0
@cr0 = internal global i64 0
@cr1 = internal global i64 0
@cr2 = internal global i64 0
@cr3 = internal global i64 0
@cr4 = internal global i64 0
@cr5 = internal global i64 0
@cr6 = internal global i64 0
@cr7 = internal global i64 0
@cr8 = internal global i64 0
@cr9 = internal global i64 0
@cr10 = internal global i64 0
@cr11 = internal global i64 0
@cr12 = internal global i64 0
@cr13 = internal global i64 0
@cr14 = internal global i64 0
@cr15 = internal global i64 0
@fpsw = internal global i64 0
@rax = internal global i64 0
@rcx = internal global i64 0
@rdx = internal global i64 0
@rbx = internal global i64 0
@rsp = internal global i64 0
@rbp = internal global i64 0
@rsi = internal global i64 0
@rdi = internal global i64 0
@r8 = internal global i64 0
@r9 = internal global i64 0
@r10 = internal global i64 0
@r11 = internal global i64 0
@r12 = internal global i64 0
@r13 = internal global i64 0
@r14 = internal global i64 0
@r15 = internal global i64 0
@rip = internal global i64 0
@riz = internal global i64 0
@global_var_403ff8 = global i64 0
@global_var_404024 = external global i64
@global_var_402010 = constant [4 x i8] c"%d\0A\00"
@0 = external global i32

declare i64 @1()

declare i64 @2()

define i64 @add(i32* %arg1, i64 %arg2) {
dec_label_pc_401126:
  %stack_var_-8 = alloca i64
  %0 = load i64, i64* @rbp, !insn.addr !0
  store i64 %0, i64* %stack_var_-8, !insn.addr !0
  %1 = trunc i64 %arg2 to i32, !insn.addr !1
  %2 = zext i32 %1 to i64, !insn.addr !1
  %3 = trunc i64 %2 to i8, !insn.addr !2
  %4 = load i32, i32* bitcast (i64* @rdi to i32*), !insn.addr !3
  %5 = zext i32 %4 to i64, !insn.addr !3
  %6 = sext i8 %3 to i64, !insn.addr !4
  %7 = trunc i64 %6 to i32, !insn.addr !5
  %8 = trunc i64 %5 to i32, !insn.addr !5
  %9 = add i32 %7, %8, !insn.addr !5
  %10 = zext i32 %9 to i64, !insn.addr !5
  ret i64 %10, !insn.addr !6
}

declare i64 @3()

define i64 @main(i64 %argc, i8** %argv) {
dec_label_pc_401141:
  %stack_var_-32 = alloca i32
  %stack_var_-8 = alloca i64
  %0 = load i64, i64* @rbp, !insn.addr !7
  store i64 %0, i64* %stack_var_-8, !insn.addr !7
  store i32 1, i32* %stack_var_-32, !insn.addr !8
  %1 = sext i8 2 to i64, !insn.addr !9
  %2 = trunc i64 %1 to i32, !insn.addr !10
  %3 = zext i32 %2 to i64, !insn.addr !10
  %4 = call i64 @add(i32* %stack_var_-32, i64 %3), !insn.addr !11
  %5 = trunc i64 %4 to i32, !insn.addr !12
  %6 = sext i8 2 to i64, !insn.addr !13
  %7 = trunc i64 %6 to i32, !insn.addr !14
  %8 = zext i32 %7 to i64, !insn.addr !14
  %9 = call i64 @add(i32* %stack_var_-32, i64 %8), !insn.addr !15
  %10 = zext i32 %5 to i64, !insn.addr !16
  %11 = trunc i64 %10 to i32, !insn.addr !17
  %12 = zext i32 %11 to i64, !insn.addr !17
  %13 = inttoptr i64 ptrtoint ([4 x i8]* @global_var_402010 to i64) to i8*, !insn.addr !18
  %14 = call i32 (i8*, ...) @printf(i8* %13, i64 %12), !insn.addr !18
  ret i64 0, !insn.addr !19
}

declare i64 @4()

declare i32 @__libc_start_main(i64, i32, i8**, void ()*, void ()*, void ()*)

declare i64 @5()

declare i64 @_ITM_deregisterTMCloneTable(i64)

declare i64 @6()

declare void @__gmon_start__()

declare i64 @7()

declare i64 @_ITM_registerTMCloneTable(i64, i64)

declare i64 @8()

declare i32 @printf(i8*, ...)

declare i64 @9()

declare void @__pseudo_call(i64)

declare void @__pseudo_return(i64)

declare void @__pseudo_branch(i64)

declare void @__pseudo_cond_branch(i1, i64)

declare void @__frontend_reg_store.fpr(i3, x86_fp80)

declare x86_fp80 @__frontend_reg_load.fpr(i3)

; Function Attrs: nounwind readnone speculatable
declare i8 @llvm.ctpop.i8(i8) #0

declare i64 @__asm_hlt()

declare void @10()

attributes #0 = { nounwind readnone speculatable }

!0 = !{i64 4198694}
!1 = !{i64 4198702}
!2 = !{i64 4198704}
!3 = !{i64 4198711}
!4 = !{i64 4198713}
!5 = !{i64 4198717}
!6 = !{i64 4198720}
!7 = !{i64 4198721}
!8 = !{i64 4198729}
!9 = !{i64 4198740}
!10 = !{i64 4198748}
!11 = !{i64 4198753}
!12 = !{i64 4198758}
!13 = !{i64 4198769}
!14 = !{i64 4198777}
!15 = !{i64 4198782}
!16 = !{i64 4198790}
!17 = !{i64 4198793}
!18 = !{i64 4198805}
!19 = !{i64 4198816}
*** IR Dump After LLVM instruction optimization ***
source_filename = "test"
target datalayout = "e-m:e-p:64:64-i64:64-f80:128-n8:16:32:64-S128"

@cf = internal global i1 false
@pf = internal global i1 false
@az = internal global i1 false
@zf = internal global i1 false
@sf = internal global i1 false
@tf = internal global i1 false
@if = internal global i1 false
@df = internal global i1 false
@of = internal global i1 false
@iopl = internal global i2 0
@nt = internal global i1 false
@rf = internal global i1 false
@vm = internal global i1 false
@ac = internal global i1 false
@vif = internal global i1 false
@vip = internal global i1 false
@id = internal global i1 false
@rflags = internal global i64 0
@ss = internal global i16 0
@cs = internal global i16 0
@ds = internal global i16 0
@es = internal global i16 0
@fs = internal global i16 0
@gs = internal global i16 0
@st0 = internal global x86_fp80 0xK00000000000000000000
@st1 = internal global x86_fp80 0xK00000000000000000000
@st2 = internal global x86_fp80 0xK00000000000000000000
@st3 = internal global x86_fp80 0xK00000000000000000000
@st4 = internal global x86_fp80 0xK00000000000000000000
@st5 = internal global x86_fp80 0xK00000000000000000000
@st6 = internal global x86_fp80 0xK00000000000000000000
@st7 = internal global x86_fp80 0xK00000000000000000000
@fpu_stat_IE = internal global i1 false
@fpu_stat_DE = internal global i1 false
@fpu_stat_ZE = internal global i1 false
@fpu_stat_OE = internal global i1 false
@fpu_stat_UE = internal global i1 false
@fpu_stat_PE = internal global i1 false
@fpu_stat_SF = internal global i1 false
@fpu_stat_ES = internal global i1 false
@fpu_stat_C0 = internal global i1 false
@fpu_stat_C1 = internal global i1 false
@fpu_stat_C2 = internal global i1 false
@fpu_stat_C3 = internal global i1 false
@fpu_stat_TOP = internal global i3 0
@fpu_stat_B = internal global i1 false
@fpu_control_IM = internal global i1 false
@fpu_control_DM = internal global i1 false
@fpu_control_ZM = internal global i1 false
@fpu_control_OM = internal global i1 false
@fpu_control_UM = internal global i1 false
@fpu_control_PM = internal global i1 false
@fpu_control_PC = internal global i2 0
@fpu_control_RC = internal global i2 0
@fpu_control_X = internal global i1 false
@fp0 = internal global double 0.000000e+00
@fp1 = internal global double 0.000000e+00
@fp2 = internal global double 0.000000e+00
@fp3 = internal global double 0.000000e+00
@fp4 = internal global double 0.000000e+00
@fp5 = internal global double 0.000000e+00
@fp6 = internal global double 0.000000e+00
@fp7 = internal global double 0.000000e+00
@k0 = internal global i64 0
@k1 = internal global i64 0
@k2 = internal global i64 0
@k3 = internal global i64 0
@k4 = internal global i64 0
@k5 = internal global i64 0
@k6 = internal global i64 0
@k7 = internal global i64 0
@mm0 = internal global i64 0
@mm1 = internal global i64 0
@mm2 = internal global i64 0
@mm3 = internal global i64 0
@mm4 = internal global i64 0
@mm5 = internal global i64 0
@mm6 = internal global i64 0
@mm7 = internal global i64 0
@xmm0 = internal global i128 0
@xmm1 = internal global i128 0
@xmm2 = internal global i128 0
@xmm3 = internal global i128 0
@xmm4 = internal global i128 0
@xmm5 = internal global i128 0
@xmm6 = internal global i128 0
@xmm7 = internal global i128 0
@xmm8 = internal global i128 0
@xmm9 = internal global i128 0
@xmm10 = internal global i128 0
@xmm11 = internal global i128 0
@xmm12 = internal global i128 0
@xmm13 = internal global i128 0
@xmm14 = internal global i128 0
@xmm15 = internal global i128 0
@xmm16 = internal global i128 0
@xmm17 = internal global i128 0
@xmm18 = internal global i128 0
@xmm19 = internal global i128 0
@xmm20 = internal global i128 0
@xmm21 = internal global i128 0
@xmm22 = internal global i128 0
@xmm23 = internal global i128 0
@xmm24 = internal global i128 0
@xmm25 = internal global i128 0
@xmm26 = internal global i128 0
@xmm27 = internal global i128 0
@xmm28 = internal global i128 0
@xmm29 = internal global i128 0
@xmm30 = internal global i128 0
@xmm31 = internal global i128 0
@ymm0 = internal global i256 0
@ymm1 = internal global i256 0
@ymm2 = internal global i256 0
@ymm3 = internal global i256 0
@ymm4 = internal global i256 0
@ymm5 = internal global i256 0
@ymm6 = internal global i256 0
@ymm7 = internal global i256 0
@ymm8 = internal global i256 0
@ymm9 = internal global i256 0
@ymm10 = internal global i256 0
@ymm11 = internal global i256 0
@ymm12 = internal global i256 0
@ymm13 = internal global i256 0
@ymm14 = internal global i256 0
@ymm15 = internal global i256 0
@ymm16 = internal global i256 0
@ymm17 = internal global i256 0
@ymm18 = internal global i256 0
@ymm19 = internal global i256 0
@ymm20 = internal global i256 0
@ymm21 = internal global i256 0
@ymm22 = internal global i256 0
@ymm23 = internal global i256 0
@ymm24 = internal global i256 0
@ymm25 = internal global i256 0
@ymm26 = internal global i256 0
@ymm27 = internal global i256 0
@ymm28 = internal global i256 0
@ymm29 = internal global i256 0
@ymm30 = internal global i256 0
@ymm31 = internal global i256 0
@zmm0 = internal global i512 0
@zmm1 = internal global i512 0
@zmm2 = internal global i512 0
@zmm3 = internal global i512 0
@zmm4 = internal global i512 0
@zmm5 = internal global i512 0
@zmm6 = internal global i512 0
@zmm7 = internal global i512 0
@zmm8 = internal global i512 0
@zmm9 = internal global i512 0
@zmm10 = internal global i512 0
@zmm11 = internal global i512 0
@zmm12 = internal global i512 0
@zmm13 = internal global i512 0
@zmm14 = internal global i512 0
@zmm15 = internal global i512 0
@zmm16 = internal global i512 0
@zmm17 = internal global i512 0
@zmm18 = internal global i512 0
@zmm19 = internal global i512 0
@zmm20 = internal global i512 0
@zmm21 = internal global i512 0
@zmm22 = internal global i512 0
@zmm23 = internal global i512 0
@zmm24 = internal global i512 0
@zmm25 = internal global i512 0
@zmm26 = internal global i512 0
@zmm27 = internal global i512 0
@zmm28 = internal global i512 0
@zmm29 = internal global i512 0
@zmm30 = internal global i512 0
@zmm31 = internal global i512 0
@bnd0 = internal global i128 0
@bnd1 = internal global i128 0
@bnd2 = internal global i128 0
@bnd3 = internal global i128 0
@dr0 = internal global i64 0
@dr1 = internal global i64 0
@dr2 = internal global i64 0
@dr3 = internal global i64 0
@dr4 = internal global i64 0
@dr5 = internal global i64 0
@dr6 = internal global i64 0
@dr7 = internal global i64 0
@dr8 = internal global i64 0
@dr9 = internal global i64 0
@dr10 = internal global i64 0
@dr11 = internal global i64 0
@dr12 = internal global i64 0
@dr13 = internal global i64 0
@dr14 = internal global i64 0
@dr15 = internal global i64 0
@cr0 = internal global i64 0
@cr1 = internal global i64 0
@cr2 = internal global i64 0
@cr3 = internal global i64 0
@cr4 = internal global i64 0
@cr5 = internal global i64 0
@cr6 = internal global i64 0
@cr7 = internal global i64 0
@cr8 = internal global i64 0
@cr9 = internal global i64 0
@cr10 = internal global i64 0
@cr11 = internal global i64 0
@cr12 = internal global i64 0
@cr13 = internal global i64 0
@cr14 = internal global i64 0
@cr15 = internal global i64 0
@fpsw = internal global i64 0
@rax = internal global i64 0
@rcx = internal global i64 0
@rdx = internal global i64 0
@rbx = internal global i64 0
@rsp = internal global i64 0
@rbp = internal global i64 0
@rsi = internal global i64 0
@rdi = internal global i64 0
@r8 = internal global i64 0
@r9 = internal global i64 0
@r10 = internal global i64 0
@r11 = internal global i64 0
@r12 = internal global i64 0
@r13 = internal global i64 0
@r14 = internal global i64 0
@r15 = internal global i64 0
@rip = internal global i64 0
@riz = internal global i64 0
@global_var_403ff8 = global i64 0
@global_var_404024 = external global i64
@global_var_402010 = constant [4 x i8] c"%d\0A\00"
@0 = external global i32

declare i64 @1()

declare i64 @2()

define i64 @add(i32* %arg1, i64 %arg2) {
dec_label_pc_401126:
  %stack_var_-8 = alloca i64
  %0 = load i64, i64* @rbp, !insn.addr !0
  store i64 %0, i64* %stack_var_-8, !insn.addr !0
  %1 = trunc i64 %arg2 to i32, !insn.addr !1
  %2 = zext i32 %1 to i64, !insn.addr !1
  %3 = trunc i64 %2 to i8, !insn.addr !2
  %4 = load i32, i32* bitcast (i64* @rdi to i32*), !insn.addr !3
  %5 = zext i32 %4 to i64, !insn.addr !3
  %6 = sext i8 %3 to i64, !insn.addr !4
  %7 = trunc i64 %6 to i32, !insn.addr !5
  %8 = trunc i64 %5 to i32, !insn.addr !5
  %9 = add i32 %7, %8, !insn.addr !5
  %10 = zext i32 %9 to i64, !insn.addr !5
  ret i64 %10, !insn.addr !6
}

declare i64 @3()

define i64 @main(i64 %argc, i8** %argv) {
dec_label_pc_401141:
  %stack_var_-32 = alloca i32
  %stack_var_-8 = alloca i64
  %0 = load i64, i64* @rbp, !insn.addr !7
  store i64 %0, i64* %stack_var_-8, !insn.addr !7
  store i32 1, i32* %stack_var_-32, !insn.addr !8
  %1 = sext i8 2 to i64, !insn.addr !9
  %2 = trunc i64 %1 to i32, !insn.addr !10
  %3 = zext i32 %2 to i64, !insn.addr !10
  %4 = call i64 @add(i32* %stack_var_-32, i64 %3), !insn.addr !11
  %5 = trunc i64 %4 to i32, !insn.addr !12
  %6 = sext i8 2 to i64, !insn.addr !13
  %7 = trunc i64 %6 to i32, !insn.addr !14
  %8 = zext i32 %7 to i64, !insn.addr !14
  %9 = call i64 @add(i32* %stack_var_-32, i64 %8), !insn.addr !15
  %10 = zext i32 %5 to i64, !insn.addr !16
  %11 = trunc i64 %10 to i32, !insn.addr !17
  %12 = zext i32 %11 to i64, !insn.addr !17
  %13 = inttoptr i64 ptrtoint ([4 x i8]* @global_var_402010 to i64) to i8*, !insn.addr !18
  %14 = call i32 (i8*, ...) @printf(i8* %13, i64 %12), !insn.addr !18
  ret i64 0, !insn.addr !19
}

declare i64 @4()

declare i32 @__libc_start_main(i64, i32, i8**, void ()*, void ()*, void ()*)

declare i64 @5()

declare i64 @_ITM_deregisterTMCloneTable(i64)

declare i64 @6()

declare void @__gmon_start__()

declare i64 @7()

declare i64 @_ITM_registerTMCloneTable(i64, i64)

declare i64 @8()

declare i32 @printf(i8*, ...)

declare i64 @9()

declare void @__pseudo_call(i64)

declare void @__pseudo_return(i64)

declare void @__pseudo_branch(i64)

declare void @__pseudo_cond_branch(i1, i64)

declare void @__frontend_reg_store.fpr(i3, x86_fp80)

declare x86_fp80 @__frontend_reg_load.fpr(i3)

; Function Attrs: nounwind readnone speculatable
declare i8 @llvm.ctpop.i8(i8) #0

declare i64 @__asm_hlt()

declare void @10()

attributes #0 = { nounwind readnone speculatable }

!0 = !{i64 4198694}
!1 = !{i64 4198702}
!2 = !{i64 4198704}
!3 = !{i64 4198711}
!4 = !{i64 4198713}
!5 = !{i64 4198717}
!6 = !{i64 4198720}
!7 = !{i64 4198721}
!8 = !{i64 4198729}
!9 = !{i64 4198740}
!10 = !{i64 4198748}
!11 = !{i64 4198753}
!12 = !{i64 4198758}
!13 = !{i64 4198769}
!14 = !{i64 4198777}
!15 = !{i64 4198782}
!16 = !{i64 4198790}
!17 = !{i64 4198793}
!18 = !{i64 4198805}
!19 = !{i64 4198816}
*** IR Dump After Make all registers local ***
source_filename = "test"
target datalayout = "e-m:e-p:64:64-i64:64-f80:128-n8:16:32:64-S128"

@cf = internal global i1 false
@pf = internal global i1 false
@az = internal global i1 false
@zf = internal global i1 false
@sf = internal global i1 false
@tf = internal global i1 false
@if = internal global i1 false
@df = internal global i1 false
@of = internal global i1 false
@iopl = internal global i2 0
@nt = internal global i1 false
@rf = internal global i1 false
@vm = internal global i1 false
@ac = internal global i1 false
@vif = internal global i1 false
@vip = internal global i1 false
@id = internal global i1 false
@rflags = internal global i64 0
@ss = internal global i16 0
@cs = internal global i16 0
@ds = internal global i16 0
@es = internal global i16 0
@fs = internal global i16 0
@gs = internal global i16 0
@st0 = internal global x86_fp80 0xK00000000000000000000
@st1 = internal global x86_fp80 0xK00000000000000000000
@st2 = internal global x86_fp80 0xK00000000000000000000
@st3 = internal global x86_fp80 0xK00000000000000000000
@st4 = internal global x86_fp80 0xK00000000000000000000
@st5 = internal global x86_fp80 0xK00000000000000000000
@st6 = internal global x86_fp80 0xK00000000000000000000
@st7 = internal global x86_fp80 0xK00000000000000000000
@fpu_stat_IE = internal global i1 false
@fpu_stat_DE = internal global i1 false
@fpu_stat_ZE = internal global i1 false
@fpu_stat_OE = internal global i1 false
@fpu_stat_UE = internal global i1 false
@fpu_stat_PE = internal global i1 false
@fpu_stat_SF = internal global i1 false
@fpu_stat_ES = internal global i1 false
@fpu_stat_C0 = internal global i1 false
@fpu_stat_C1 = internal global i1 false
@fpu_stat_C2 = internal global i1 false
@fpu_stat_C3 = internal global i1 false
@fpu_stat_TOP = internal global i3 0
@fpu_stat_B = internal global i1 false
@fpu_control_IM = internal global i1 false
@fpu_control_DM = internal global i1 false
@fpu_control_ZM = internal global i1 false
@fpu_control_OM = internal global i1 false
@fpu_control_UM = internal global i1 false
@fpu_control_PM = internal global i1 false
@fpu_control_PC = internal global i2 0
@fpu_control_RC = internal global i2 0
@fpu_control_X = internal global i1 false
@fp0 = internal global double 0.000000e+00
@fp1 = internal global double 0.000000e+00
@fp2 = internal global double 0.000000e+00
@fp3 = internal global double 0.000000e+00
@fp4 = internal global double 0.000000e+00
@fp5 = internal global double 0.000000e+00
@fp6 = internal global double 0.000000e+00
@fp7 = internal global double 0.000000e+00
@k0 = internal global i64 0
@k1 = internal global i64 0
@k2 = internal global i64 0
@k3 = internal global i64 0
@k4 = internal global i64 0
@k5 = internal global i64 0
@k6 = internal global i64 0
@k7 = internal global i64 0
@mm0 = internal global i64 0
@mm1 = internal global i64 0
@mm2 = internal global i64 0
@mm3 = internal global i64 0
@mm4 = internal global i64 0
@mm5 = internal global i64 0
@mm6 = internal global i64 0
@mm7 = internal global i64 0
@xmm0 = internal global i128 0
@xmm1 = internal global i128 0
@xmm2 = internal global i128 0
@xmm3 = internal global i128 0
@xmm4 = internal global i128 0
@xmm5 = internal global i128 0
@xmm6 = internal global i128 0
@xmm7 = internal global i128 0
@xmm8 = internal global i128 0
@xmm9 = internal global i128 0
@xmm10 = internal global i128 0
@xmm11 = internal global i128 0
@xmm12 = internal global i128 0
@xmm13 = internal global i128 0
@xmm14 = internal global i128 0
@xmm15 = internal global i128 0
@xmm16 = internal global i128 0
@xmm17 = internal global i128 0
@xmm18 = internal global i128 0
@xmm19 = internal global i128 0
@xmm20 = internal global i128 0
@xmm21 = internal global i128 0
@xmm22 = internal global i128 0
@xmm23 = internal global i128 0
@xmm24 = internal global i128 0
@xmm25 = internal global i128 0
@xmm26 = internal global i128 0
@xmm27 = internal global i128 0
@xmm28 = internal global i128 0
@xmm29 = internal global i128 0
@xmm30 = internal global i128 0
@xmm31 = internal global i128 0
@ymm0 = internal global i256 0
@ymm1 = internal global i256 0
@ymm2 = internal global i256 0
@ymm3 = internal global i256 0
@ymm4 = internal global i256 0
@ymm5 = internal global i256 0
@ymm6 = internal global i256 0
@ymm7 = internal global i256 0
@ymm8 = internal global i256 0
@ymm9 = internal global i256 0
@ymm10 = internal global i256 0
@ymm11 = internal global i256 0
@ymm12 = internal global i256 0
@ymm13 = internal global i256 0
@ymm14 = internal global i256 0
@ymm15 = internal global i256 0
@ymm16 = internal global i256 0
@ymm17 = internal global i256 0
@ymm18 = internal global i256 0
@ymm19 = internal global i256 0
@ymm20 = internal global i256 0
@ymm21 = internal global i256 0
@ymm22 = internal global i256 0
@ymm23 = internal global i256 0
@ymm24 = internal global i256 0
@ymm25 = internal global i256 0
@ymm26 = internal global i256 0
@ymm27 = internal global i256 0
@ymm28 = internal global i256 0
@ymm29 = internal global i256 0
@ymm30 = internal global i256 0
@ymm31 = internal global i256 0
@zmm0 = internal global i512 0
@zmm1 = internal global i512 0
@zmm2 = internal global i512 0
@zmm3 = internal global i512 0
@zmm4 = internal global i512 0
@zmm5 = internal global i512 0
@zmm6 = internal global i512 0
@zmm7 = internal global i512 0
@zmm8 = internal global i512 0
@zmm9 = internal global i512 0
@zmm10 = internal global i512 0
@zmm11 = internal global i512 0
@zmm12 = internal global i512 0
@zmm13 = internal global i512 0
@zmm14 = internal global i512 0
@zmm15 = internal global i512 0
@zmm16 = internal global i512 0
@zmm17 = internal global i512 0
@zmm18 = internal global i512 0
@zmm19 = internal global i512 0
@zmm20 = internal global i512 0
@zmm21 = internal global i512 0
@zmm22 = internal global i512 0
@zmm23 = internal global i512 0
@zmm24 = internal global i512 0
@zmm25 = internal global i512 0
@zmm26 = internal global i512 0
@zmm27 = internal global i512 0
@zmm28 = internal global i512 0
@zmm29 = internal global i512 0
@zmm30 = internal global i512 0
@zmm31 = internal global i512 0
@bnd0 = internal global i128 0
@bnd1 = internal global i128 0
@bnd2 = internal global i128 0
@bnd3 = internal global i128 0
@dr0 = internal global i64 0
@dr1 = internal global i64 0
@dr2 = internal global i64 0
@dr3 = internal global i64 0
@dr4 = internal global i64 0
@dr5 = internal global i64 0
@dr6 = internal global i64 0
@dr7 = internal global i64 0
@dr8 = internal global i64 0
@dr9 = internal global i64 0
@dr10 = internal global i64 0
@dr11 = internal global i64 0
@dr12 = internal global i64 0
@dr13 = internal global i64 0
@dr14 = internal global i64 0
@dr15 = internal global i64 0
@cr0 = internal global i64 0
@cr1 = internal global i64 0
@cr2 = internal global i64 0
@cr3 = internal global i64 0
@cr4 = internal global i64 0
@cr5 = internal global i64 0
@cr6 = internal global i64 0
@cr7 = internal global i64 0
@cr8 = internal global i64 0
@cr9 = internal global i64 0
@cr10 = internal global i64 0
@cr11 = internal global i64 0
@cr12 = internal global i64 0
@cr13 = internal global i64 0
@cr14 = internal global i64 0
@cr15 = internal global i64 0
@fpsw = internal global i64 0
@rax = internal global i64 0
@rcx = internal global i64 0
@rdx = internal global i64 0
@rbx = internal global i64 0
@rsp = internal global i64 0
@rbp = internal global i64 0
@rsi = internal global i64 0
@rdi = internal global i64 0
@r8 = internal global i64 0
@r9 = internal global i64 0
@r10 = internal global i64 0
@r11 = internal global i64 0
@r12 = internal global i64 0
@r13 = internal global i64 0
@r14 = internal global i64 0
@r15 = internal global i64 0
@rip = internal global i64 0
@riz = internal global i64 0
@global_var_403ff8 = global i64 0
@global_var_404024 = external global i64
@global_var_402010 = constant [4 x i8] c"%d\0A\00"
@0 = external global i32

declare i64 @1()

declare i64 @2()

define i64 @add(i32* %arg1, i64 %arg2) {
dec_label_pc_401126:
  %rdi = alloca i64
  %rbp = alloca i64
  %stack_var_-8 = alloca i64
  %0 = load i64, i64* %rbp, !insn.addr !0
  store i64 %0, i64* %stack_var_-8, !insn.addr !0
  %1 = trunc i64 %arg2 to i32, !insn.addr !1
  %2 = zext i32 %1 to i64, !insn.addr !1
  %3 = trunc i64 %2 to i8, !insn.addr !2
  %4 = bitcast i64* %rdi to i32*
  %5 = load i32, i32* %4, !insn.addr !3
  %6 = zext i32 %5 to i64, !insn.addr !3
  %7 = sext i8 %3 to i64, !insn.addr !4
  %8 = trunc i64 %7 to i32, !insn.addr !5
  %9 = trunc i64 %6 to i32, !insn.addr !5
  %10 = add i32 %8, %9, !insn.addr !5
  %11 = zext i32 %10 to i64, !insn.addr !5
  ret i64 %11, !insn.addr !6
}

declare i64 @3()

define i64 @main(i64 %argc, i8** %argv) {
dec_label_pc_401141:
  %rbp = alloca i64
  %stack_var_-32 = alloca i32
  %stack_var_-8 = alloca i64
  %0 = load i64, i64* %rbp, !insn.addr !7
  store i64 %0, i64* %stack_var_-8, !insn.addr !7
  store i32 1, i32* %stack_var_-32, !insn.addr !8
  %1 = sext i8 2 to i64, !insn.addr !9
  %2 = trunc i64 %1 to i32, !insn.addr !10
  %3 = zext i32 %2 to i64, !insn.addr !10
  %4 = call i64 @add(i32* %stack_var_-32, i64 %3), !insn.addr !11
  %5 = trunc i64 %4 to i32, !insn.addr !12
  %6 = sext i8 2 to i64, !insn.addr !13
  %7 = trunc i64 %6 to i32, !insn.addr !14
  %8 = zext i32 %7 to i64, !insn.addr !14
  %9 = call i64 @add(i32* %stack_var_-32, i64 %8), !insn.addr !15
  %10 = zext i32 %5 to i64, !insn.addr !16
  %11 = trunc i64 %10 to i32, !insn.addr !17
  %12 = zext i32 %11 to i64, !insn.addr !17
  %13 = inttoptr i64 ptrtoint ([4 x i8]* @global_var_402010 to i64) to i8*, !insn.addr !18
  %14 = call i32 (i8*, ...) @printf(i8* %13, i64 %12), !insn.addr !18
  ret i64 0, !insn.addr !19
}

declare i64 @4()

declare i32 @__libc_start_main(i64, i32, i8**, void ()*, void ()*, void ()*)

declare i64 @5()

declare i64 @_ITM_deregisterTMCloneTable(i64)

declare i64 @6()

declare void @__gmon_start__()

declare i64 @7()

declare i64 @_ITM_registerTMCloneTable(i64, i64)

declare i64 @8()

declare i32 @printf(i8*, ...)

declare i64 @9()

declare void @__pseudo_call(i64)

declare void @__pseudo_return(i64)

declare void @__pseudo_branch(i64)

declare void @__pseudo_cond_branch(i1, i64)

declare void @__frontend_reg_store.fpr(i3, x86_fp80)

declare x86_fp80 @__frontend_reg_load.fpr(i3)

; Function Attrs: nounwind readnone speculatable
declare i8 @llvm.ctpop.i8(i8) #0

declare i64 @__asm_hlt()

declare void @10()

attributes #0 = { nounwind readnone speculatable }

!0 = !{i64 4198694}
!1 = !{i64 4198702}
!2 = !{i64 4198704}
!3 = !{i64 4198711}
!4 = !{i64 4198713}
!5 = !{i64 4198717}
!6 = !{i64 4198720}
!7 = !{i64 4198721}
!8 = !{i64 4198729}
!9 = !{i64 4198740}
!10 = !{i64 4198748}
!11 = !{i64 4198753}
!12 = !{i64 4198758}
!13 = !{i64 4198769}
!14 = !{i64 4198777}
!15 = !{i64 4198782}
!16 = !{i64 4198790}
!17 = !{i64 4198793}
!18 = !{i64 4198805}
!19 = !{i64 4198816}
*** IR Dump After Value protection optimization ***
source_filename = "test"
target datalayout = "e-m:e-p:64:64-i64:64-f80:128-n8:16:32:64-S128"

@cf = internal global i1 false
@pf = internal global i1 false
@az = internal global i1 false
@zf = internal global i1 false
@sf = internal global i1 false
@tf = internal global i1 false
@if = internal global i1 false
@df = internal global i1 false
@of = internal global i1 false
@iopl = internal global i2 0
@nt = internal global i1 false
@rf = internal global i1 false
@vm = internal global i1 false
@ac = internal global i1 false
@vif = internal global i1 false
@vip = internal global i1 false
@id = internal global i1 false
@rflags = internal global i64 0
@ss = internal global i16 0
@cs = internal global i16 0
@ds = internal global i16 0
@es = internal global i16 0
@fs = internal global i16 0
@gs = internal global i16 0
@st0 = internal global x86_fp80 0xK00000000000000000000
@st1 = internal global x86_fp80 0xK00000000000000000000
@st2 = internal global x86_fp80 0xK00000000000000000000
@st3 = internal global x86_fp80 0xK00000000000000000000
@st4 = internal global x86_fp80 0xK00000000000000000000
@st5 = internal global x86_fp80 0xK00000000000000000000
@st6 = internal global x86_fp80 0xK00000000000000000000
@st7 = internal global x86_fp80 0xK00000000000000000000
@fpu_stat_IE = internal global i1 false
@fpu_stat_DE = internal global i1 false
@fpu_stat_ZE = internal global i1 false
@fpu_stat_OE = internal global i1 false
@fpu_stat_UE = internal global i1 false
@fpu_stat_PE = internal global i1 false
@fpu_stat_SF = internal global i1 false
@fpu_stat_ES = internal global i1 false
@fpu_stat_C0 = internal global i1 false
@fpu_stat_C1 = internal global i1 false
@fpu_stat_C2 = internal global i1 false
@fpu_stat_C3 = internal global i1 false
@fpu_stat_TOP = internal global i3 0
@fpu_stat_B = internal global i1 false
@fpu_control_IM = internal global i1 false
@fpu_control_DM = internal global i1 false
@fpu_control_ZM = internal global i1 false
@fpu_control_OM = internal global i1 false
@fpu_control_UM = internal global i1 false
@fpu_control_PM = internal global i1 false
@fpu_control_PC = internal global i2 0
@fpu_control_RC = internal global i2 0
@fpu_control_X = internal global i1 false
@fp0 = internal global double 0.000000e+00
@fp1 = internal global double 0.000000e+00
@fp2 = internal global double 0.000000e+00
@fp3 = internal global double 0.000000e+00
@fp4 = internal global double 0.000000e+00
@fp5 = internal global double 0.000000e+00
@fp6 = internal global double 0.000000e+00
@fp7 = internal global double 0.000000e+00
@k0 = internal global i64 0
@k1 = internal global i64 0
@k2 = internal global i64 0
@k3 = internal global i64 0
@k4 = internal global i64 0
@k5 = internal global i64 0
@k6 = internal global i64 0
@k7 = internal global i64 0
@mm0 = internal global i64 0
@mm1 = internal global i64 0
@mm2 = internal global i64 0
@mm3 = internal global i64 0
@mm4 = internal global i64 0
@mm5 = internal global i64 0
@mm6 = internal global i64 0
@mm7 = internal global i64 0
@xmm0 = internal global i128 0
@xmm1 = internal global i128 0
@xmm2 = internal global i128 0
@xmm3 = internal global i128 0
@xmm4 = internal global i128 0
@xmm5 = internal global i128 0
@xmm6 = internal global i128 0
@xmm7 = internal global i128 0
@xmm8 = internal global i128 0
@xmm9 = internal global i128 0
@xmm10 = internal global i128 0
@xmm11 = internal global i128 0
@xmm12 = internal global i128 0
@xmm13 = internal global i128 0
@xmm14 = internal global i128 0
@xmm15 = internal global i128 0
@xmm16 = internal global i128 0
@xmm17 = internal global i128 0
@xmm18 = internal global i128 0
@xmm19 = internal global i128 0
@xmm20 = internal global i128 0
@xmm21 = internal global i128 0
@xmm22 = internal global i128 0
@xmm23 = internal global i128 0
@xmm24 = internal global i128 0
@xmm25 = internal global i128 0
@xmm26 = internal global i128 0
@xmm27 = internal global i128 0
@xmm28 = internal global i128 0
@xmm29 = internal global i128 0
@xmm30 = internal global i128 0
@xmm31 = internal global i128 0
@ymm0 = internal global i256 0
@ymm1 = internal global i256 0
@ymm2 = internal global i256 0
@ymm3 = internal global i256 0
@ymm4 = internal global i256 0
@ymm5 = internal global i256 0
@ymm6 = internal global i256 0
@ymm7 = internal global i256 0
@ymm8 = internal global i256 0
@ymm9 = internal global i256 0
@ymm10 = internal global i256 0
@ymm11 = internal global i256 0
@ymm12 = internal global i256 0
@ymm13 = internal global i256 0
@ymm14 = internal global i256 0
@ymm15 = internal global i256 0
@ymm16 = internal global i256 0
@ymm17 = internal global i256 0
@ymm18 = internal global i256 0
@ymm19 = internal global i256 0
@ymm20 = internal global i256 0
@ymm21 = internal global i256 0
@ymm22 = internal global i256 0
@ymm23 = internal global i256 0
@ymm24 = internal global i256 0
@ymm25 = internal global i256 0
@ymm26 = internal global i256 0
@ymm27 = internal global i256 0
@ymm28 = internal global i256 0
@ymm29 = internal global i256 0
@ymm30 = internal global i256 0
@ymm31 = internal global i256 0
@zmm0 = internal global i512 0
@zmm1 = internal global i512 0
@zmm2 = internal global i512 0
@zmm3 = internal global i512 0
@zmm4 = internal global i512 0
@zmm5 = internal global i512 0
@zmm6 = internal global i512 0
@zmm7 = internal global i512 0
@zmm8 = internal global i512 0
@zmm9 = internal global i512 0
@zmm10 = internal global i512 0
@zmm11 = internal global i512 0
@zmm12 = internal global i512 0
@zmm13 = internal global i512 0
@zmm14 = internal global i512 0
@zmm15 = internal global i512 0
@zmm16 = internal global i512 0
@zmm17 = internal global i512 0
@zmm18 = internal global i512 0
@zmm19 = internal global i512 0
@zmm20 = internal global i512 0
@zmm21 = internal global i512 0
@zmm22 = internal global i512 0
@zmm23 = internal global i512 0
@zmm24 = internal global i512 0
@zmm25 = internal global i512 0
@zmm26 = internal global i512 0
@zmm27 = internal global i512 0
@zmm28 = internal global i512 0
@zmm29 = internal global i512 0
@zmm30 = internal global i512 0
@zmm31 = internal global i512 0
@bnd0 = internal global i128 0
@bnd1 = internal global i128 0
@bnd2 = internal global i128 0
@bnd3 = internal global i128 0
@dr0 = internal global i64 0
@dr1 = internal global i64 0
@dr2 = internal global i64 0
@dr3 = internal global i64 0
@dr4 = internal global i64 0
@dr5 = internal global i64 0
@dr6 = internal global i64 0
@dr7 = internal global i64 0
@dr8 = internal global i64 0
@dr9 = internal global i64 0
@dr10 = internal global i64 0
@dr11 = internal global i64 0
@dr12 = internal global i64 0
@dr13 = internal global i64 0
@dr14 = internal global i64 0
@dr15 = internal global i64 0
@cr0 = internal global i64 0
@cr1 = internal global i64 0
@cr2 = internal global i64 0
@cr3 = internal global i64 0
@cr4 = internal global i64 0
@cr5 = internal global i64 0
@cr6 = internal global i64 0
@cr7 = internal global i64 0
@cr8 = internal global i64 0
@cr9 = internal global i64 0
@cr10 = internal global i64 0
@cr11 = internal global i64 0
@cr12 = internal global i64 0
@cr13 = internal global i64 0
@cr14 = internal global i64 0
@cr15 = internal global i64 0
@fpsw = internal global i64 0
@rax = internal global i64 0
@rcx = internal global i64 0
@rdx = internal global i64 0
@rbx = internal global i64 0
@rsp = internal global i64 0
@rbp = internal global i64 0
@rsi = internal global i64 0
@rdi = internal global i64 0
@r8 = internal global i64 0
@r9 = internal global i64 0
@r10 = internal global i64 0
@r11 = internal global i64 0
@r12 = internal global i64 0
@r13 = internal global i64 0
@r14 = internal global i64 0
@r15 = internal global i64 0
@rip = internal global i64 0
@riz = internal global i64 0
@global_var_403ff8 = global i64 0
@global_var_404024 = external global i64
@global_var_402010 = constant [4 x i8] c"%d\0A\00"
@0 = external global i32

declare i64 @1()

declare i64 @2()

define i64 @add(i32* %arg1, i64 %arg2) {
dec_label_pc_401126:
  %rdi = alloca i64
  %0 = call i64 @__decompiler_undefined_function_0()
  store i64 %0, i64* %rdi
  %rbp = alloca i64
  %1 = call i64 @__decompiler_undefined_function_0()
  store i64 %1, i64* %rbp
  %stack_var_-8 = alloca i64
  %2 = call i64 @__decompiler_undefined_function_0()
  store i64 %2, i64* %stack_var_-8
  %3 = load i64, i64* %rbp, !insn.addr !0
  store i64 %3, i64* %stack_var_-8, !insn.addr !0
  %4 = trunc i64 %arg2 to i32, !insn.addr !1
  %5 = zext i32 %4 to i64, !insn.addr !1
  %6 = trunc i64 %5 to i8, !insn.addr !2
  %7 = bitcast i64* %rdi to i32*
  %8 = load i32, i32* %7, !insn.addr !3
  %9 = zext i32 %8 to i64, !insn.addr !3
  %10 = sext i8 %6 to i64, !insn.addr !4
  %11 = trunc i64 %10 to i32, !insn.addr !5
  %12 = trunc i64 %9 to i32, !insn.addr !5
  %13 = add i32 %11, %12, !insn.addr !5
  %14 = zext i32 %13 to i64, !insn.addr !5
  ret i64 %14, !insn.addr !6
}

declare i64 @3()

define i64 @main(i64 %argc, i8** %argv) {
dec_label_pc_401141:
  %rbp = alloca i64
  %0 = call i64 @__decompiler_undefined_function_0()
  store i64 %0, i64* %rbp
  %stack_var_-32 = alloca i32
  %1 = call i32 @__decompiler_undefined_function_1()
  store i32 %1, i32* %stack_var_-32
  %stack_var_-8 = alloca i64
  %2 = call i64 @__decompiler_undefined_function_0()
  store i64 %2, i64* %stack_var_-8
  %3 = load i64, i64* %rbp, !insn.addr !7
  store i64 %3, i64* %stack_var_-8, !insn.addr !7
  store i32 1, i32* %stack_var_-32, !insn.addr !8
  %4 = sext i8 2 to i64, !insn.addr !9
  %5 = trunc i64 %4 to i32, !insn.addr !10
  %6 = zext i32 %5 to i64, !insn.addr !10
  %7 = call i64 @add(i32* %stack_var_-32, i64 %6), !insn.addr !11
  %8 = trunc i64 %7 to i32, !insn.addr !12
  %9 = sext i8 2 to i64, !insn.addr !13
  %10 = trunc i64 %9 to i32, !insn.addr !14
  %11 = zext i32 %10 to i64, !insn.addr !14
  %12 = call i64 @add(i32* %stack_var_-32, i64 %11), !insn.addr !15
  %13 = zext i32 %8 to i64, !insn.addr !16
  %14 = trunc i64 %13 to i32, !insn.addr !17
  %15 = zext i32 %14 to i64, !insn.addr !17
  %16 = inttoptr i64 ptrtoint ([4 x i8]* @global_var_402010 to i64) to i8*, !insn.addr !18
  %17 = call i32 (i8*, ...) @printf(i8* %16, i64 %15), !insn.addr !18
  ret i64 0, !insn.addr !19
}

declare i64 @4()

declare i32 @__libc_start_main(i64, i32, i8**, void ()*, void ()*, void ()*)

declare i64 @5()

declare i64 @_ITM_deregisterTMCloneTable(i64)

declare i64 @6()

declare void @__gmon_start__()

declare i64 @7()

declare i64 @_ITM_registerTMCloneTable(i64, i64)

declare i64 @8()

declare i32 @printf(i8*, ...)

declare i64 @9()

declare void @__pseudo_call(i64)

declare void @__pseudo_return(i64)

declare void @__pseudo_branch(i64)

declare void @__pseudo_cond_branch(i1, i64)

declare void @__frontend_reg_store.fpr(i3, x86_fp80)

declare x86_fp80 @__frontend_reg_load.fpr(i3)

; Function Attrs: nounwind readnone speculatable
declare i8 @llvm.ctpop.i8(i8) #0

declare i64 @__asm_hlt()

declare void @10()

declare i64 @__decompiler_undefined_function_0()

declare i32 @__decompiler_undefined_function_1()

attributes #0 = { nounwind readnone speculatable }

!0 = !{i64 4198694}
!1 = !{i64 4198702}
!2 = !{i64 4198704}
!3 = !{i64 4198711}
!4 = !{i64 4198713}
!5 = !{i64 4198717}
!6 = !{i64 4198720}
!7 = !{i64 4198721}
!8 = !{i64 4198729}
!9 = !{i64 4198740}
!10 = !{i64 4198748}
!11 = !{i64 4198753}
!12 = !{i64 4198758}
!13 = !{i64 4198769}
!14 = !{i64 4198777}
!15 = !{i64 4198782}
!16 = !{i64 4198790}
!17 = !{i64 4198793}
!18 = !{i64 4198805}
!19 = !{i64 4198816}
*** IR Dump After Combine redundant instructions ***
define i64 @add(i32* %arg1, i64 %arg2) {
dec_label_pc_401126:
  %rdi = alloca i64, align 8
  %0 = call i64 @__decompiler_undefined_function_0()
  store i64 %0, i64* %rdi, align 8
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = bitcast i64* %rdi to i32*
  %5 = load i32, i32* %4, align 8, !insn.addr !1
  %sext = shl i32 %3, 24
  %6 = ashr exact i32 %sext, 24, !insn.addr !2
  %7 = add i32 %6, %5, !insn.addr !2
  %8 = zext i32 %7 to i64, !insn.addr !2
  ret i64 %8, !insn.addr !3
}
*** IR Dump After Combine redundant instructions ***
define i64 @main(i64 %argc, i8** %argv) {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  store i32 %1, i32* %stack_var_-32, align 4
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !4
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !6
  %5 = and i64 %3, 4294967295, !insn.addr !7
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !8
  ret i64 0, !insn.addr !9
}
*** IR Dump After Simplify the CFG ***
define i64 @add(i32* %arg1, i64 %arg2) {
dec_label_pc_401126:
  %rdi = alloca i64, align 8
  %0 = call i64 @__decompiler_undefined_function_0()
  store i64 %0, i64* %rdi, align 8
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = bitcast i64* %rdi to i32*
  %5 = load i32, i32* %4, align 8, !insn.addr !1
  %sext = shl i32 %3, 24
  %6 = ashr exact i32 %sext, 24, !insn.addr !2
  %7 = add i32 %6, %5, !insn.addr !2
  %8 = zext i32 %7 to i64, !insn.addr !2
  ret i64 %8, !insn.addr !3
}
*** IR Dump After Simplify the CFG ***
define i64 @main(i64 %argc, i8** %argv) {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  store i32 %1, i32* %stack_var_-32, align 4
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !4
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !6
  %5 = and i64 %3, 4294967295, !insn.addr !7
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !8
  ret i64 0, !insn.addr !9
}
*** IR Dump After Early CSE ***
define i64 @add(i32* %arg1, i64 %arg2) {
dec_label_pc_401126:
  %rdi = alloca i64, align 8
  %0 = call i64 @__decompiler_undefined_function_0()
  store i64 %0, i64* %rdi, align 8
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = bitcast i64* %rdi to i32*
  %5 = load i32, i32* %4, align 8, !insn.addr !1
  %sext = shl i32 %3, 24
  %6 = ashr exact i32 %sext, 24, !insn.addr !2
  %7 = add i32 %6, %5, !insn.addr !2
  %8 = zext i32 %7 to i64, !insn.addr !2
  ret i64 %8, !insn.addr !3
}
*** IR Dump After Early CSE ***
define i64 @main(i64 %argc, i8** %argv) {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  store i32 %1, i32* %stack_var_-32, align 4
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !4
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !6
  %5 = and i64 %3, 4294967295, !insn.addr !7
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !8
  ret i64 0, !insn.addr !9
}
*** IR Dump After Global Variable Optimizer ***
source_filename = "test"
target datalayout = "e-m:e-p:64:64-i64:64-f80:128-n8:16:32:64-S128"

@global_var_403ff8 = local_unnamed_addr global i64 0
@global_var_402010 = constant [4 x i8] c"%d\0A\00"

define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %rdi = alloca i64, align 8
  %0 = call i64 @__decompiler_undefined_function_0()
  store i64 %0, i64* %rdi, align 8
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = bitcast i64* %rdi to i32*
  %5 = load i32, i32* %4, align 8, !insn.addr !1
  %sext = shl i32 %3, 24
  %6 = ashr exact i32 %sext, 24, !insn.addr !2
  %7 = add i32 %6, %5, !insn.addr !2
  %8 = zext i32 %7 to i64, !insn.addr !2
  ret i64 %8, !insn.addr !3
}

define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  store i32 %1, i32* %stack_var_-32, align 4
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !4
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !6
  %5 = and i64 %3, 4294967295, !insn.addr !7
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !8
  ret i64 0, !insn.addr !9
}

declare i32 @printf(i8*, ...) local_unnamed_addr

declare i64 @__decompiler_undefined_function_0() local_unnamed_addr

declare i32 @__decompiler_undefined_function_1() local_unnamed_addr

!0 = !{i64 4198704}
!1 = !{i64 4198711}
!2 = !{i64 4198717}
!3 = !{i64 4198720}
!4 = !{i64 4198729}
!5 = !{i64 4198753}
!6 = !{i64 4198782}
!7 = !{i64 4198793}
!8 = !{i64 4198805}
!9 = !{i64 4198816}
*** IR Dump After Promote Memory to Register ***
define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %rdi = alloca i64, align 8
  %0 = call i64 @__decompiler_undefined_function_0()
  store i64 %0, i64* %rdi, align 8
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = bitcast i64* %rdi to i32*
  %5 = load i32, i32* %4, align 8, !insn.addr !1
  %sext = shl i32 %3, 24
  %6 = ashr exact i32 %sext, 24, !insn.addr !2
  %7 = add i32 %6, %5, !insn.addr !2
  %8 = zext i32 %7 to i64, !insn.addr !2
  ret i64 %8, !insn.addr !3
}
*** IR Dump After Promote Memory to Register ***
define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  store i32 %1, i32* %stack_var_-32, align 4
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !4
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !6
  %5 = and i64 %3, 4294967295, !insn.addr !7
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !8
  ret i64 0, !insn.addr !9
}
*** IR Dump After Combine redundant instructions ***
define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %rdi = alloca i64, align 8
  %0 = call i64 @__decompiler_undefined_function_0()
  store i64 %0, i64* %rdi, align 8
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = bitcast i64* %rdi to i32*
  %5 = load i32, i32* %4, align 8, !insn.addr !1
  %sext = shl i32 %3, 24
  %6 = ashr exact i32 %sext, 24, !insn.addr !2
  %7 = add i32 %6, %5, !insn.addr !2
  %8 = zext i32 %7 to i64, !insn.addr !2
  ret i64 %8, !insn.addr !3
}
*** IR Dump After Combine redundant instructions ***
define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  store i32 %1, i32* %stack_var_-32, align 4
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !4
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !6
  %5 = and i64 %3, 4294967295, !insn.addr !7
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !8
  ret i64 0, !insn.addr !9
}
*** IR Dump After Simplify the CFG ***
define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %rdi = alloca i64, align 8
  %0 = call i64 @__decompiler_undefined_function_0()
  store i64 %0, i64* %rdi, align 8
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = bitcast i64* %rdi to i32*
  %5 = load i32, i32* %4, align 8, !insn.addr !1
  %sext = shl i32 %3, 24
  %6 = ashr exact i32 %sext, 24, !insn.addr !2
  %7 = add i32 %6, %5, !insn.addr !2
  %8 = zext i32 %7 to i64, !insn.addr !2
  ret i64 %8, !insn.addr !3
}
*** IR Dump After Simplify the CFG ***
define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  store i32 %1, i32* %stack_var_-32, align 4
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !4
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !6
  %5 = and i64 %3, 4294967295, !insn.addr !7
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !8
  ret i64 0, !insn.addr !9
}
*** IR Dump After Early CSE ***
define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %rdi = alloca i64, align 8
  %0 = call i64 @__decompiler_undefined_function_0()
  store i64 %0, i64* %rdi, align 8
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = bitcast i64* %rdi to i32*
  %5 = load i32, i32* %4, align 8, !insn.addr !1
  %sext = shl i32 %3, 24
  %6 = ashr exact i32 %sext, 24, !insn.addr !2
  %7 = add i32 %6, %5, !insn.addr !2
  %8 = zext i32 %7 to i64, !insn.addr !2
  ret i64 %8, !insn.addr !3
}
*** IR Dump After Early CSE ***
define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  store i32 %1, i32* %stack_var_-32, align 4
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !4
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !6
  %5 = and i64 %3, 4294967295, !insn.addr !7
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !8
  ret i64 0, !insn.addr !9
}
*** IR Dump After Jump Threading ***
define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %rdi = alloca i64, align 8
  %0 = call i64 @__decompiler_undefined_function_0()
  store i64 %0, i64* %rdi, align 8
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = bitcast i64* %rdi to i32*
  %5 = load i32, i32* %4, align 8, !insn.addr !1
  %sext = shl i32 %3, 24
  %6 = ashr exact i32 %sext, 24, !insn.addr !2
  %7 = add i32 %6, %5, !insn.addr !2
  %8 = zext i32 %7 to i64, !insn.addr !2
  ret i64 %8, !insn.addr !3
}
*** IR Dump After Jump Threading ***
define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  store i32 %1, i32* %stack_var_-32, align 4
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !4
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !6
  %5 = and i64 %3, 4294967295, !insn.addr !7
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !8
  ret i64 0, !insn.addr !9
}
*** IR Dump After Value Propagation ***
define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %rdi = alloca i64, align 8
  %0 = call i64 @__decompiler_undefined_function_0()
  store i64 %0, i64* %rdi, align 8
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = bitcast i64* %rdi to i32*
  %5 = load i32, i32* %4, align 8, !insn.addr !1
  %sext = shl i32 %3, 24
  %6 = ashr exact i32 %sext, 24, !insn.addr !2
  %7 = add i32 %6, %5, !insn.addr !2
  %8 = zext i32 %7 to i64, !insn.addr !2
  ret i64 %8, !insn.addr !3
}
*** IR Dump After Value Propagation ***
define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  store i32 %1, i32* %stack_var_-32, align 4
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !4
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !6
  %5 = and i64 %3, 4294967295, !insn.addr !7
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !8
  ret i64 0, !insn.addr !9
}
*** IR Dump After Simplify the CFG ***
define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %rdi = alloca i64, align 8
  %0 = call i64 @__decompiler_undefined_function_0()
  store i64 %0, i64* %rdi, align 8
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = bitcast i64* %rdi to i32*
  %5 = load i32, i32* %4, align 8, !insn.addr !1
  %sext = shl i32 %3, 24
  %6 = ashr exact i32 %sext, 24, !insn.addr !2
  %7 = add i32 %6, %5, !insn.addr !2
  %8 = zext i32 %7 to i64, !insn.addr !2
  ret i64 %8, !insn.addr !3
}
*** IR Dump After Simplify the CFG ***
define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  store i32 %1, i32* %stack_var_-32, align 4
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !4
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !6
  %5 = and i64 %3, 4294967295, !insn.addr !7
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !8
  ret i64 0, !insn.addr !9
}
*** IR Dump After Combine redundant instructions ***
define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %rdi = alloca i64, align 8
  %0 = call i64 @__decompiler_undefined_function_0()
  store i64 %0, i64* %rdi, align 8
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = bitcast i64* %rdi to i32*
  %5 = load i32, i32* %4, align 8, !insn.addr !1
  %sext = shl i32 %3, 24
  %6 = ashr exact i32 %sext, 24, !insn.addr !2
  %7 = add i32 %6, %5, !insn.addr !2
  %8 = zext i32 %7 to i64, !insn.addr !2
  ret i64 %8, !insn.addr !3
}
*** IR Dump After Combine redundant instructions ***
define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  store i32 %1, i32* %stack_var_-32, align 4
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !4
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !6
  %5 = and i64 %3, 4294967295, !insn.addr !7
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !8
  ret i64 0, !insn.addr !9
}
*** IR Dump After Simplify the CFG ***
define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %rdi = alloca i64, align 8
  %0 = call i64 @__decompiler_undefined_function_0()
  store i64 %0, i64* %rdi, align 8
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = bitcast i64* %rdi to i32*
  %5 = load i32, i32* %4, align 8, !insn.addr !1
  %sext = shl i32 %3, 24
  %6 = ashr exact i32 %sext, 24, !insn.addr !2
  %7 = add i32 %6, %5, !insn.addr !2
  %8 = zext i32 %7 to i64, !insn.addr !2
  ret i64 %8, !insn.addr !3
}
*** IR Dump After Simplify the CFG ***
define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  store i32 %1, i32* %stack_var_-32, align 4
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !4
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !6
  %5 = and i64 %3, 4294967295, !insn.addr !7
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !8
  ret i64 0, !insn.addr !9
}
*** IR Dump After Reassociate expressions ***
define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %rdi = alloca i64, align 8
  %0 = call i64 @__decompiler_undefined_function_0()
  store i64 %0, i64* %rdi, align 8
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = bitcast i64* %rdi to i32*
  %5 = load i32, i32* %4, align 8, !insn.addr !1
  %sext = shl i32 %3, 24
  %6 = ashr exact i32 %sext, 24, !insn.addr !2
  %7 = add i32 %5, %6, !insn.addr !2
  %8 = zext i32 %7 to i64, !insn.addr !2
  ret i64 %8, !insn.addr !3
}
*** IR Dump After Reassociate expressions ***
define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  store i32 %1, i32* %stack_var_-32, align 4
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !4
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !6
  %5 = and i64 %3, 4294967295, !insn.addr !7
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !8
  ret i64 0, !insn.addr !9
}
*** IR Dump After Canonicalize natural loops ***
define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %rdi = alloca i64, align 8
  %0 = call i64 @__decompiler_undefined_function_0()
  store i64 %0, i64* %rdi, align 8
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = bitcast i64* %rdi to i32*
  %5 = load i32, i32* %4, align 8, !insn.addr !1
  %sext = shl i32 %3, 24
  %6 = ashr exact i32 %sext, 24, !insn.addr !2
  %7 = add i32 %5, %6, !insn.addr !2
  %8 = zext i32 %7 to i64, !insn.addr !2
  ret i64 %8, !insn.addr !3
}
*** IR Dump After Canonicalize natural loops ***
define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  store i32 %1, i32* %stack_var_-32, align 4
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !4
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !6
  %5 = and i64 %3, 4294967295, !insn.addr !7
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !8
  ret i64 0, !insn.addr !9
}
*** IR Dump After LCSSA Verifier ***
define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %rdi = alloca i64, align 8
  %0 = call i64 @__decompiler_undefined_function_0()
  store i64 %0, i64* %rdi, align 8
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = bitcast i64* %rdi to i32*
  %5 = load i32, i32* %4, align 8, !insn.addr !1
  %sext = shl i32 %3, 24
  %6 = ashr exact i32 %sext, 24, !insn.addr !2
  %7 = add i32 %5, %6, !insn.addr !2
  %8 = zext i32 %7 to i64, !insn.addr !2
  ret i64 %8, !insn.addr !3
}
*** IR Dump After Loop-Closed SSA Form Pass ***
define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %rdi = alloca i64, align 8
  %0 = call i64 @__decompiler_undefined_function_0()
  store i64 %0, i64* %rdi, align 8
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = bitcast i64* %rdi to i32*
  %5 = load i32, i32* %4, align 8, !insn.addr !1
  %sext = shl i32 %3, 24
  %6 = ashr exact i32 %sext, 24, !insn.addr !2
  %7 = add i32 %5, %6, !insn.addr !2
  %8 = zext i32 %7 to i64, !insn.addr !2
  ret i64 %8, !insn.addr !3
}
*** IR Dump After LCSSA Verifier ***
define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  store i32 %1, i32* %stack_var_-32, align 4
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !4
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !6
  %5 = and i64 %3, 4294967295, !insn.addr !7
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !8
  ret i64 0, !insn.addr !9
}
*** IR Dump After Loop-Closed SSA Form Pass ***
define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  store i32 %1, i32* %stack_var_-32, align 4
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !4
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !6
  %5 = and i64 %3, 4294967295, !insn.addr !7
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !8
  ret i64 0, !insn.addr !9
}
*** IR Dump After Canonicalize natural loops ***
define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %rdi = alloca i64, align 8
  %0 = call i64 @__decompiler_undefined_function_0()
  store i64 %0, i64* %rdi, align 8
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = bitcast i64* %rdi to i32*
  %5 = load i32, i32* %4, align 8, !insn.addr !1
  %sext = shl i32 %3, 24
  %6 = ashr exact i32 %sext, 24, !insn.addr !2
  %7 = add i32 %5, %6, !insn.addr !2
  %8 = zext i32 %7 to i64, !insn.addr !2
  ret i64 %8, !insn.addr !3
}
*** IR Dump After LCSSA Verifier ***
define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %rdi = alloca i64, align 8
  %0 = call i64 @__decompiler_undefined_function_0()
  store i64 %0, i64* %rdi, align 8
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = bitcast i64* %rdi to i32*
  %5 = load i32, i32* %4, align 8, !insn.addr !1
  %sext = shl i32 %3, 24
  %6 = ashr exact i32 %sext, 24, !insn.addr !2
  %7 = add i32 %5, %6, !insn.addr !2
  %8 = zext i32 %7 to i64, !insn.addr !2
  ret i64 %8, !insn.addr !3
}
*** IR Dump After Loop-Closed SSA Form Pass ***
define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %rdi = alloca i64, align 8
  %0 = call i64 @__decompiler_undefined_function_0()
  store i64 %0, i64* %rdi, align 8
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = bitcast i64* %rdi to i32*
  %5 = load i32, i32* %4, align 8, !insn.addr !1
  %sext = shl i32 %3, 24
  %6 = ashr exact i32 %sext, 24, !insn.addr !2
  %7 = add i32 %5, %6, !insn.addr !2
  %8 = zext i32 %7 to i64, !insn.addr !2
  ret i64 %8, !insn.addr !3
}
*** IR Dump After Canonicalize natural loops ***
define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  store i32 %1, i32* %stack_var_-32, align 4
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !4
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !6
  %5 = and i64 %3, 4294967295, !insn.addr !7
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !8
  ret i64 0, !insn.addr !9
}
*** IR Dump After LCSSA Verifier ***
define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  store i32 %1, i32* %stack_var_-32, align 4
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !4
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !6
  %5 = and i64 %3, 4294967295, !insn.addr !7
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !8
  ret i64 0, !insn.addr !9
}
*** IR Dump After Loop-Closed SSA Form Pass ***
define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  store i32 %1, i32* %stack_var_-32, align 4
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !4
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !6
  %5 = and i64 %3, 4294967295, !insn.addr !7
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !8
  ret i64 0, !insn.addr !9
}
*** IR Dump After Canonicalize natural loops ***
define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %rdi = alloca i64, align 8
  %0 = call i64 @__decompiler_undefined_function_0()
  store i64 %0, i64* %rdi, align 8
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = bitcast i64* %rdi to i32*
  %5 = load i32, i32* %4, align 8, !insn.addr !1
  %sext = shl i32 %3, 24
  %6 = ashr exact i32 %sext, 24, !insn.addr !2
  %7 = add i32 %5, %6, !insn.addr !2
  %8 = zext i32 %7 to i64, !insn.addr !2
  ret i64 %8, !insn.addr !3
}
*** IR Dump After LCSSA Verifier ***
define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %rdi = alloca i64, align 8
  %0 = call i64 @__decompiler_undefined_function_0()
  store i64 %0, i64* %rdi, align 8
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = bitcast i64* %rdi to i32*
  %5 = load i32, i32* %4, align 8, !insn.addr !1
  %sext = shl i32 %3, 24
  %6 = ashr exact i32 %sext, 24, !insn.addr !2
  %7 = add i32 %5, %6, !insn.addr !2
  %8 = zext i32 %7 to i64, !insn.addr !2
  ret i64 %8, !insn.addr !3
}
*** IR Dump After Loop-Closed SSA Form Pass ***
define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %rdi = alloca i64, align 8
  %0 = call i64 @__decompiler_undefined_function_0()
  store i64 %0, i64* %rdi, align 8
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = bitcast i64* %rdi to i32*
  %5 = load i32, i32* %4, align 8, !insn.addr !1
  %sext = shl i32 %3, 24
  %6 = ashr exact i32 %sext, 24, !insn.addr !2
  %7 = add i32 %5, %6, !insn.addr !2
  %8 = zext i32 %7 to i64, !insn.addr !2
  ret i64 %8, !insn.addr !3
}
*** IR Dump After Canonicalize natural loops ***
define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  store i32 %1, i32* %stack_var_-32, align 4
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !4
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !6
  %5 = and i64 %3, 4294967295, !insn.addr !7
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !8
  ret i64 0, !insn.addr !9
}
*** IR Dump After LCSSA Verifier ***
define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  store i32 %1, i32* %stack_var_-32, align 4
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !4
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !6
  %5 = and i64 %3, 4294967295, !insn.addr !7
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !8
  ret i64 0, !insn.addr !9
}
*** IR Dump After Loop-Closed SSA Form Pass ***
define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  store i32 %1, i32* %stack_var_-32, align 4
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !4
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !6
  %5 = and i64 %3, 4294967295, !insn.addr !7
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !8
  ret i64 0, !insn.addr !9
}
*** IR Dump After LCSSA Verifier ***
define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %rdi = alloca i64, align 8
  %0 = call i64 @__decompiler_undefined_function_0()
  store i64 %0, i64* %rdi, align 8
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = bitcast i64* %rdi to i32*
  %5 = load i32, i32* %4, align 8, !insn.addr !1
  %sext = shl i32 %3, 24
  %6 = ashr exact i32 %sext, 24, !insn.addr !2
  %7 = add i32 %5, %6, !insn.addr !2
  %8 = zext i32 %7 to i64, !insn.addr !2
  ret i64 %8, !insn.addr !3
}
*** IR Dump After Loop-Closed SSA Form Pass ***
define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %rdi = alloca i64, align 8
  %0 = call i64 @__decompiler_undefined_function_0()
  store i64 %0, i64* %rdi, align 8
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = bitcast i64* %rdi to i32*
  %5 = load i32, i32* %4, align 8, !insn.addr !1
  %sext = shl i32 %3, 24
  %6 = ashr exact i32 %sext, 24, !insn.addr !2
  %7 = add i32 %5, %6, !insn.addr !2
  %8 = zext i32 %7 to i64, !insn.addr !2
  ret i64 %8, !insn.addr !3
}
*** IR Dump After LCSSA Verifier ***
define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  store i32 %1, i32* %stack_var_-32, align 4
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !4
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !6
  %5 = and i64 %3, 4294967295, !insn.addr !7
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !8
  ret i64 0, !insn.addr !9
}
*** IR Dump After Loop-Closed SSA Form Pass ***
define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  store i32 %1, i32* %stack_var_-32, align 4
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !4
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !6
  %5 = and i64 %3, 4294967295, !insn.addr !7
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !8
  ret i64 0, !insn.addr !9
}
*** IR Dump After Combine redundant instructions ***
define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %rdi = alloca i64, align 8
  %0 = call i64 @__decompiler_undefined_function_0()
  store i64 %0, i64* %rdi, align 8
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = bitcast i64* %rdi to i32*
  %5 = load i32, i32* %4, align 8, !insn.addr !1
  %sext = shl i32 %3, 24
  %6 = ashr exact i32 %sext, 24, !insn.addr !2
  %7 = add i32 %5, %6, !insn.addr !2
  %8 = zext i32 %7 to i64, !insn.addr !2
  ret i64 %8, !insn.addr !3
}
*** IR Dump After Combine redundant instructions ***
define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  store i32 %1, i32* %stack_var_-32, align 4
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !4
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !6
  %5 = and i64 %3, 4294967295, !insn.addr !7
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !8
  ret i64 0, !insn.addr !9
}
*** IR Dump After Canonicalize natural loops ***
define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %rdi = alloca i64, align 8
  %0 = call i64 @__decompiler_undefined_function_0()
  store i64 %0, i64* %rdi, align 8
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = bitcast i64* %rdi to i32*
  %5 = load i32, i32* %4, align 8, !insn.addr !1
  %sext = shl i32 %3, 24
  %6 = ashr exact i32 %sext, 24, !insn.addr !2
  %7 = add i32 %5, %6, !insn.addr !2
  %8 = zext i32 %7 to i64, !insn.addr !2
  ret i64 %8, !insn.addr !3
}
*** IR Dump After LCSSA Verifier ***
define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %rdi = alloca i64, align 8
  %0 = call i64 @__decompiler_undefined_function_0()
  store i64 %0, i64* %rdi, align 8
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = bitcast i64* %rdi to i32*
  %5 = load i32, i32* %4, align 8, !insn.addr !1
  %sext = shl i32 %3, 24
  %6 = ashr exact i32 %sext, 24, !insn.addr !2
  %7 = add i32 %5, %6, !insn.addr !2
  %8 = zext i32 %7 to i64, !insn.addr !2
  ret i64 %8, !insn.addr !3
}
*** IR Dump After Loop-Closed SSA Form Pass ***
define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %rdi = alloca i64, align 8
  %0 = call i64 @__decompiler_undefined_function_0()
  store i64 %0, i64* %rdi, align 8
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = bitcast i64* %rdi to i32*
  %5 = load i32, i32* %4, align 8, !insn.addr !1
  %sext = shl i32 %3, 24
  %6 = ashr exact i32 %sext, 24, !insn.addr !2
  %7 = add i32 %5, %6, !insn.addr !2
  %8 = zext i32 %7 to i64, !insn.addr !2
  ret i64 %8, !insn.addr !3
}
*** IR Dump After Canonicalize natural loops ***
define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  store i32 %1, i32* %stack_var_-32, align 4
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !4
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !6
  %5 = and i64 %3, 4294967295, !insn.addr !7
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !8
  ret i64 0, !insn.addr !9
}
*** IR Dump After LCSSA Verifier ***
define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  store i32 %1, i32* %stack_var_-32, align 4
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !4
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !6
  %5 = and i64 %3, 4294967295, !insn.addr !7
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !8
  ret i64 0, !insn.addr !9
}
*** IR Dump After Loop-Closed SSA Form Pass ***
define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  store i32 %1, i32* %stack_var_-32, align 4
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !4
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !6
  %5 = and i64 %3, 4294967295, !insn.addr !7
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !8
  ret i64 0, !insn.addr !9
}
*** IR Dump After Canonicalize natural loops ***
define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %rdi = alloca i64, align 8
  %0 = call i64 @__decompiler_undefined_function_0()
  store i64 %0, i64* %rdi, align 8
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = bitcast i64* %rdi to i32*
  %5 = load i32, i32* %4, align 8, !insn.addr !1
  %sext = shl i32 %3, 24
  %6 = ashr exact i32 %sext, 24, !insn.addr !2
  %7 = add i32 %5, %6, !insn.addr !2
  %8 = zext i32 %7 to i64, !insn.addr !2
  ret i64 %8, !insn.addr !3
}
*** IR Dump After Canonicalize natural loops ***
define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  store i32 %1, i32* %stack_var_-32, align 4
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !4
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !6
  %5 = and i64 %3, 4294967295, !insn.addr !7
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !8
  ret i64 0, !insn.addr !9
}
*** IR Dump After Canonicalize natural loops ***
define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %rdi = alloca i64, align 8
  %0 = call i64 @__decompiler_undefined_function_0()
  store i64 %0, i64* %rdi, align 8
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = bitcast i64* %rdi to i32*
  %5 = load i32, i32* %4, align 8, !insn.addr !1
  %sext = shl i32 %3, 24
  %6 = ashr exact i32 %sext, 24, !insn.addr !2
  %7 = add i32 %5, %6, !insn.addr !2
  %8 = zext i32 %7 to i64, !insn.addr !2
  ret i64 %8, !insn.addr !3
}
*** IR Dump After Loop Load Elimination ***
define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %rdi = alloca i64, align 8
  %0 = call i64 @__decompiler_undefined_function_0()
  store i64 %0, i64* %rdi, align 8
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = bitcast i64* %rdi to i32*
  %5 = load i32, i32* %4, align 8, !insn.addr !1
  %sext = shl i32 %3, 24
  %6 = ashr exact i32 %sext, 24, !insn.addr !2
  %7 = add i32 %5, %6, !insn.addr !2
  %8 = zext i32 %7 to i64, !insn.addr !2
  ret i64 %8, !insn.addr !3
}
*** IR Dump After Canonicalize natural loops ***
define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  store i32 %1, i32* %stack_var_-32, align 4
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !4
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !6
  %5 = and i64 %3, 4294967295, !insn.addr !7
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !8
  ret i64 0, !insn.addr !9
}
*** IR Dump After Loop Load Elimination ***
define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  store i32 %1, i32* %stack_var_-32, align 4
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !4
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !6
  %5 = and i64 %3, 4294967295, !insn.addr !7
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !8
  ret i64 0, !insn.addr !9
}
*** IR Dump After LCSSA Verifier ***
define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %rdi = alloca i64, align 8
  %0 = call i64 @__decompiler_undefined_function_0()
  store i64 %0, i64* %rdi, align 8
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = bitcast i64* %rdi to i32*
  %5 = load i32, i32* %4, align 8, !insn.addr !1
  %sext = shl i32 %3, 24
  %6 = ashr exact i32 %sext, 24, !insn.addr !2
  %7 = add i32 %5, %6, !insn.addr !2
  %8 = zext i32 %7 to i64, !insn.addr !2
  ret i64 %8, !insn.addr !3
}
*** IR Dump After Loop-Closed SSA Form Pass ***
define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %rdi = alloca i64, align 8
  %0 = call i64 @__decompiler_undefined_function_0()
  store i64 %0, i64* %rdi, align 8
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = bitcast i64* %rdi to i32*
  %5 = load i32, i32* %4, align 8, !insn.addr !1
  %sext = shl i32 %3, 24
  %6 = ashr exact i32 %sext, 24, !insn.addr !2
  %7 = add i32 %5, %6, !insn.addr !2
  %8 = zext i32 %7 to i64, !insn.addr !2
  ret i64 %8, !insn.addr !3
}
*** IR Dump After LCSSA Verifier ***
define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  store i32 %1, i32* %stack_var_-32, align 4
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !4
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !6
  %5 = and i64 %3, 4294967295, !insn.addr !7
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !8
  ret i64 0, !insn.addr !9
}
*** IR Dump After Loop-Closed SSA Form Pass ***
define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  store i32 %1, i32* %stack_var_-32, align 4
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !4
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !6
  %5 = and i64 %3, 4294967295, !insn.addr !7
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !8
  ret i64 0, !insn.addr !9
}
*** IR Dump After Canonicalize natural loops ***
define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %rdi = alloca i64, align 8
  %0 = call i64 @__decompiler_undefined_function_0()
  store i64 %0, i64* %rdi, align 8
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = bitcast i64* %rdi to i32*
  %5 = load i32, i32* %4, align 8, !insn.addr !1
  %sext = shl i32 %3, 24
  %6 = ashr exact i32 %sext, 24, !insn.addr !2
  %7 = add i32 %5, %6, !insn.addr !2
  %8 = zext i32 %7 to i64, !insn.addr !2
  ret i64 %8, !insn.addr !3
}
*** IR Dump After LCSSA Verifier ***
define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %rdi = alloca i64, align 8
  %0 = call i64 @__decompiler_undefined_function_0()
  store i64 %0, i64* %rdi, align 8
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = bitcast i64* %rdi to i32*
  %5 = load i32, i32* %4, align 8, !insn.addr !1
  %sext = shl i32 %3, 24
  %6 = ashr exact i32 %sext, 24, !insn.addr !2
  %7 = add i32 %5, %6, !insn.addr !2
  %8 = zext i32 %7 to i64, !insn.addr !2
  ret i64 %8, !insn.addr !3
}
*** IR Dump After Loop-Closed SSA Form Pass ***
define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %rdi = alloca i64, align 8
  %0 = call i64 @__decompiler_undefined_function_0()
  store i64 %0, i64* %rdi, align 8
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = bitcast i64* %rdi to i32*
  %5 = load i32, i32* %4, align 8, !insn.addr !1
  %sext = shl i32 %3, 24
  %6 = ashr exact i32 %sext, 24, !insn.addr !2
  %7 = add i32 %5, %6, !insn.addr !2
  %8 = zext i32 %7 to i64, !insn.addr !2
  ret i64 %8, !insn.addr !3
}
*** IR Dump After Canonicalize natural loops ***
define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  store i32 %1, i32* %stack_var_-32, align 4
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !4
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !6
  %5 = and i64 %3, 4294967295, !insn.addr !7
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !8
  ret i64 0, !insn.addr !9
}
*** IR Dump After LCSSA Verifier ***
define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  store i32 %1, i32* %stack_var_-32, align 4
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !4
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !6
  %5 = and i64 %3, 4294967295, !insn.addr !7
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !8
  ret i64 0, !insn.addr !9
}
*** IR Dump After Loop-Closed SSA Form Pass ***
define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  store i32 %1, i32* %stack_var_-32, align 4
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !4
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !6
  %5 = and i64 %3, 4294967295, !insn.addr !7
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !8
  ret i64 0, !insn.addr !9
}
*** IR Dump After Canonicalize natural loops ***
define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %rdi = alloca i64, align 8
  %0 = call i64 @__decompiler_undefined_function_0()
  store i64 %0, i64* %rdi, align 8
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = bitcast i64* %rdi to i32*
  %5 = load i32, i32* %4, align 8, !insn.addr !1
  %sext = shl i32 %3, 24
  %6 = ashr exact i32 %sext, 24, !insn.addr !2
  %7 = add i32 %5, %6, !insn.addr !2
  %8 = zext i32 %7 to i64, !insn.addr !2
  ret i64 %8, !insn.addr !3
}
*** IR Dump After LCSSA Verifier ***
define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %rdi = alloca i64, align 8
  %0 = call i64 @__decompiler_undefined_function_0()
  store i64 %0, i64* %rdi, align 8
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = bitcast i64* %rdi to i32*
  %5 = load i32, i32* %4, align 8, !insn.addr !1
  %sext = shl i32 %3, 24
  %6 = ashr exact i32 %sext, 24, !insn.addr !2
  %7 = add i32 %5, %6, !insn.addr !2
  %8 = zext i32 %7 to i64, !insn.addr !2
  ret i64 %8, !insn.addr !3
}
*** IR Dump After Loop-Closed SSA Form Pass ***
define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %rdi = alloca i64, align 8
  %0 = call i64 @__decompiler_undefined_function_0()
  store i64 %0, i64* %rdi, align 8
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = bitcast i64* %rdi to i32*
  %5 = load i32, i32* %4, align 8, !insn.addr !1
  %sext = shl i32 %3, 24
  %6 = ashr exact i32 %sext, 24, !insn.addr !2
  %7 = add i32 %5, %6, !insn.addr !2
  %8 = zext i32 %7 to i64, !insn.addr !2
  ret i64 %8, !insn.addr !3
}
*** IR Dump After Canonicalize natural loops ***
define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  store i32 %1, i32* %stack_var_-32, align 4
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !4
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !6
  %5 = and i64 %3, 4294967295, !insn.addr !7
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !8
  ret i64 0, !insn.addr !9
}
*** IR Dump After LCSSA Verifier ***
define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  store i32 %1, i32* %stack_var_-32, align 4
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !4
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !6
  %5 = and i64 %3, 4294967295, !insn.addr !7
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !8
  ret i64 0, !insn.addr !9
}
*** IR Dump After Loop-Closed SSA Form Pass ***
define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  store i32 %1, i32* %stack_var_-32, align 4
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !4
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !6
  %5 = and i64 %3, 4294967295, !insn.addr !7
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !8
  ret i64 0, !insn.addr !9
}
*** IR Dump After Canonicalize natural loops ***
define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %rdi = alloca i64, align 8
  %0 = call i64 @__decompiler_undefined_function_0()
  store i64 %0, i64* %rdi, align 8
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = bitcast i64* %rdi to i32*
  %5 = load i32, i32* %4, align 8, !insn.addr !1
  %sext = shl i32 %3, 24
  %6 = ashr exact i32 %sext, 24, !insn.addr !2
  %7 = add i32 %5, %6, !insn.addr !2
  %8 = zext i32 %7 to i64, !insn.addr !2
  ret i64 %8, !insn.addr !3
}
*** IR Dump After LCSSA Verifier ***
define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %rdi = alloca i64, align 8
  %0 = call i64 @__decompiler_undefined_function_0()
  store i64 %0, i64* %rdi, align 8
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = bitcast i64* %rdi to i32*
  %5 = load i32, i32* %4, align 8, !insn.addr !1
  %sext = shl i32 %3, 24
  %6 = ashr exact i32 %sext, 24, !insn.addr !2
  %7 = add i32 %5, %6, !insn.addr !2
  %8 = zext i32 %7 to i64, !insn.addr !2
  ret i64 %8, !insn.addr !3
}
*** IR Dump After Loop-Closed SSA Form Pass ***
define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %rdi = alloca i64, align 8
  %0 = call i64 @__decompiler_undefined_function_0()
  store i64 %0, i64* %rdi, align 8
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = bitcast i64* %rdi to i32*
  %5 = load i32, i32* %4, align 8, !insn.addr !1
  %sext = shl i32 %3, 24
  %6 = ashr exact i32 %sext, 24, !insn.addr !2
  %7 = add i32 %5, %6, !insn.addr !2
  %8 = zext i32 %7 to i64, !insn.addr !2
  ret i64 %8, !insn.addr !3
}
*** IR Dump After Canonicalize natural loops ***
define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  store i32 %1, i32* %stack_var_-32, align 4
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !4
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !6
  %5 = and i64 %3, 4294967295, !insn.addr !7
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !8
  ret i64 0, !insn.addr !9
}
*** IR Dump After LCSSA Verifier ***
define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  store i32 %1, i32* %stack_var_-32, align 4
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !4
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !6
  %5 = and i64 %3, 4294967295, !insn.addr !7
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !8
  ret i64 0, !insn.addr !9
}
*** IR Dump After Loop-Closed SSA Form Pass ***
define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  store i32 %1, i32* %stack_var_-32, align 4
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !4
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !6
  %5 = and i64 %3, 4294967295, !insn.addr !7
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !8
  ret i64 0, !insn.addr !9
}
*** IR Dump After Global Value Numbering ***
define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %rdi = alloca i64, align 8
  %0 = call i64 @__decompiler_undefined_function_0()
  store i64 %0, i64* %rdi, align 8
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = bitcast i64* %rdi to i32*
  %5 = trunc i64 %0 to i32
  %sext = shl i32 %3, 24
  %6 = ashr exact i32 %sext, 24, !insn.addr !1
  %7 = add i32 %5, %6, !insn.addr !1
  %8 = zext i32 %7 to i64, !insn.addr !1
  ret i64 %8, !insn.addr !2
}
*** IR Dump After Global Value Numbering ***
define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  store i32 %1, i32* %stack_var_-32, align 4
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !3
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !4
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %5 = and i64 %3, 4294967295, !insn.addr !6
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !7
  ret i64 0, !insn.addr !8
}
*** IR Dump After Sparse Conditional Constant Propagation ***
define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %rdi = alloca i64, align 8
  %0 = call i64 @__decompiler_undefined_function_0()
  store i64 %0, i64* %rdi, align 8
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = bitcast i64* %rdi to i32*
  %5 = trunc i64 %0 to i32
  %sext = shl i32 %3, 24
  %6 = ashr exact i32 %sext, 24, !insn.addr !1
  %7 = add i32 %5, %6, !insn.addr !1
  %8 = zext i32 %7 to i64, !insn.addr !1
  ret i64 %8, !insn.addr !2
}
*** IR Dump After Sparse Conditional Constant Propagation ***
define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  store i32 %1, i32* %stack_var_-32, align 4
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !3
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !4
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %5 = and i64 %3, 4294967295, !insn.addr !6
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !7
  ret i64 0, !insn.addr !8
}
*** IR Dump After Combine redundant instructions ***
define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %0 = call i64 @__decompiler_undefined_function_0()
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = trunc i64 %0 to i32
  %sext = shl i32 %3, 24
  %5 = ashr exact i32 %sext, 24, !insn.addr !1
  %6 = add i32 %5, %4, !insn.addr !1
  %7 = zext i32 %6 to i64, !insn.addr !1
  ret i64 %7, !insn.addr !2
}
*** IR Dump After Combine redundant instructions ***
define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  store i32 %1, i32* %stack_var_-32, align 4
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !3
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !4
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %5 = and i64 %3, 4294967295, !insn.addr !6
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !7
  ret i64 0, !insn.addr !8
}
*** IR Dump After Jump Threading ***
define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %0 = call i64 @__decompiler_undefined_function_0()
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = trunc i64 %0 to i32
  %sext = shl i32 %3, 24
  %5 = ashr exact i32 %sext, 24, !insn.addr !1
  %6 = add i32 %5, %4, !insn.addr !1
  %7 = zext i32 %6 to i64, !insn.addr !1
  ret i64 %7, !insn.addr !2
}
*** IR Dump After Jump Threading ***
define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  store i32 %1, i32* %stack_var_-32, align 4
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !3
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !4
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %5 = and i64 %3, 4294967295, !insn.addr !6
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !7
  ret i64 0, !insn.addr !8
}
*** IR Dump After Value Propagation ***
define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %0 = call i64 @__decompiler_undefined_function_0()
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = trunc i64 %0 to i32
  %sext = shl i32 %3, 24
  %5 = ashr exact i32 %sext, 24, !insn.addr !1
  %6 = add i32 %5, %4, !insn.addr !1
  %7 = zext i32 %6 to i64, !insn.addr !1
  ret i64 %7, !insn.addr !2
}
*** IR Dump After Value Propagation ***
define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  store i32 %1, i32* %stack_var_-32, align 4
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !3
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !4
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %5 = and i64 %3, 4294967295, !insn.addr !6
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !7
  ret i64 0, !insn.addr !8
}
*** IR Dump After Dead Store Elimination ***
define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %0 = call i64 @__decompiler_undefined_function_0()
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = trunc i64 %0 to i32
  %sext = shl i32 %3, 24
  %5 = ashr exact i32 %sext, 24, !insn.addr !1
  %6 = add i32 %5, %4, !insn.addr !1
  %7 = zext i32 %6 to i64, !insn.addr !1
  ret i64 %7, !insn.addr !2
}
*** IR Dump After Dead Store Elimination ***
define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !3
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !4
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %5 = and i64 %3, 4294967295, !insn.addr !6
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !7
  ret i64 0, !insn.addr !8
}
*** IR Dump After Demanded bits analysis ***
define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %0 = call i64 @__decompiler_undefined_function_0()
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = trunc i64 %0 to i32
  %sext = shl i32 %3, 24
  %5 = ashr exact i32 %sext, 24, !insn.addr !1
  %6 = add i32 %5, %4, !insn.addr !1
  %7 = zext i32 %6 to i64, !insn.addr !1
  ret i64 %7, !insn.addr !2
}
*** IR Dump After Bit-Tracking Dead Code Elimination ***
define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %0 = call i64 @__decompiler_undefined_function_0()
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = trunc i64 %0 to i32
  %sext = shl i32 %3, 24
  %5 = ashr exact i32 %sext, 24, !insn.addr !1
  %6 = add i32 %5, %4, !insn.addr !1
  %7 = zext i32 %6 to i64, !insn.addr !1
  ret i64 %7, !insn.addr !2
}
*** IR Dump After Demanded bits analysis ***
define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !3
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !4
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %5 = and i64 %3, 4294967295, !insn.addr !6
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !7
  ret i64 0, !insn.addr !8
}
*** IR Dump After Bit-Tracking Dead Code Elimination ***
define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !3
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !4
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %5 = and i64 %3, 4294967295, !insn.addr !6
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !7
  ret i64 0, !insn.addr !8
}
*** IR Dump After Aggressive Dead Code Elimination ***
define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %0 = call i64 @__decompiler_undefined_function_0()
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = trunc i64 %0 to i32
  %sext = shl i32 %3, 24
  %5 = ashr exact i32 %sext, 24, !insn.addr !1
  %6 = add i32 %5, %4, !insn.addr !1
  %7 = zext i32 %6 to i64, !insn.addr !1
  ret i64 %7, !insn.addr !2
}
*** IR Dump After Aggressive Dead Code Elimination ***
define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !3
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !4
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %5 = and i64 %3, 4294967295, !insn.addr !6
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !7
  ret i64 0, !insn.addr !8
}
*** IR Dump After Simplify the CFG ***
define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %0 = call i64 @__decompiler_undefined_function_0()
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = trunc i64 %0 to i32
  %sext = shl i32 %3, 24
  %5 = ashr exact i32 %sext, 24, !insn.addr !1
  %6 = add i32 %5, %4, !insn.addr !1
  %7 = zext i32 %6 to i64, !insn.addr !1
  ret i64 %7, !insn.addr !2
}
*** IR Dump After Simplify the CFG ***
define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !3
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !4
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %5 = and i64 %3, 4294967295, !insn.addr !6
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !7
  ret i64 0, !insn.addr !8
}
*** IR Dump After Combine redundant instructions ***
define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %0 = call i64 @__decompiler_undefined_function_0()
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = trunc i64 %0 to i32
  %sext = shl i32 %3, 24
  %5 = ashr exact i32 %sext, 24, !insn.addr !1
  %6 = add i32 %5, %4, !insn.addr !1
  %7 = zext i32 %6 to i64, !insn.addr !1
  ret i64 %7, !insn.addr !2
}
*** IR Dump After Combine redundant instructions ***
define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !3
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !4
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %5 = and i64 %3, 4294967295, !insn.addr !6
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !7
  ret i64 0, !insn.addr !8
}
*** IR Dump After Strip Unused Function Prototypes ***
source_filename = "test"
target datalayout = "e-m:e-p:64:64-i64:64-f80:128-n8:16:32:64-S128"

@global_var_403ff8 = local_unnamed_addr global i64 0
@global_var_402010 = constant [4 x i8] c"%d\0A\00"

define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %0 = call i64 @__decompiler_undefined_function_0()
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = trunc i64 %0 to i32
  %sext = shl i32 %3, 24
  %5 = ashr exact i32 %sext, 24, !insn.addr !1
  %6 = add i32 %5, %4, !insn.addr !1
  %7 = zext i32 %6 to i64, !insn.addr !1
  ret i64 %7, !insn.addr !2
}

define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !3
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !4
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %5 = and i64 %3, 4294967295, !insn.addr !6
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !7
  ret i64 0, !insn.addr !8
}

declare i32 @printf(i8*, ...) local_unnamed_addr

declare i64 @__decompiler_undefined_function_0() local_unnamed_addr

declare i32 @__decompiler_undefined_function_1() local_unnamed_addr

!0 = !{i64 4198704}
!1 = !{i64 4198717}
!2 = !{i64 4198720}
!3 = !{i64 4198729}
!4 = !{i64 4198753}
!5 = !{i64 4198782}
!6 = !{i64 4198793}
!7 = !{i64 4198805}
!8 = !{i64 4198816}
*** IR Dump After Dead Global Elimination ***
source_filename = "test"
target datalayout = "e-m:e-p:64:64-i64:64-f80:128-n8:16:32:64-S128"

@global_var_403ff8 = local_unnamed_addr global i64 0
@global_var_402010 = constant [4 x i8] c"%d\0A\00"

define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %0 = call i64 @__decompiler_undefined_function_0()
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = trunc i64 %0 to i32
  %sext = shl i32 %3, 24
  %5 = ashr exact i32 %sext, 24, !insn.addr !1
  %6 = add i32 %5, %4, !insn.addr !1
  %7 = zext i32 %6 to i64, !insn.addr !1
  ret i64 %7, !insn.addr !2
}

define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !3
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !4
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %5 = and i64 %3, 4294967295, !insn.addr !6
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !7
  ret i64 0, !insn.addr !8
}

declare i32 @printf(i8*, ...) local_unnamed_addr

declare i64 @__decompiler_undefined_function_0() local_unnamed_addr

declare i32 @__decompiler_undefined_function_1() local_unnamed_addr

!0 = !{i64 4198704}
!1 = !{i64 4198717}
!2 = !{i64 4198720}
!3 = !{i64 4198729}
!4 = !{i64 4198753}
!5 = !{i64 4198782}
!6 = !{i64 4198793}
!7 = !{i64 4198805}
!8 = !{i64 4198816}
*** IR Dump After Merge Duplicate Global Constants ***
source_filename = "test"
target datalayout = "e-m:e-p:64:64-i64:64-f80:128-n8:16:32:64-S128"

@global_var_403ff8 = local_unnamed_addr global i64 0
@global_var_402010 = constant [4 x i8] c"%d\0A\00"

define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %0 = call i64 @__decompiler_undefined_function_0()
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = trunc i64 %0 to i32
  %sext = shl i32 %3, 24
  %5 = ashr exact i32 %sext, 24, !insn.addr !1
  %6 = add i32 %5, %4, !insn.addr !1
  %7 = zext i32 %6 to i64, !insn.addr !1
  ret i64 %7, !insn.addr !2
}

define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !3
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !4
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %5 = and i64 %3, 4294967295, !insn.addr !6
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !7
  ret i64 0, !insn.addr !8
}

declare i32 @printf(i8*, ...) local_unnamed_addr

declare i64 @__decompiler_undefined_function_0() local_unnamed_addr

declare i32 @__decompiler_undefined_function_1() local_unnamed_addr

!0 = !{i64 4198704}
!1 = !{i64 4198717}
!2 = !{i64 4198720}
!3 = !{i64 4198729}
!4 = !{i64 4198753}
!5 = !{i64 4198782}
!6 = !{i64 4198793}
!7 = !{i64 4198805}
!8 = !{i64 4198816}
*** IR Dump After Simple constant propagation ***
define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %0 = call i64 @__decompiler_undefined_function_0()
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = trunc i64 %0 to i32
  %sext = shl i32 %3, 24
  %5 = ashr exact i32 %sext, 24, !insn.addr !1
  %6 = add i32 %5, %4, !insn.addr !1
  %7 = zext i32 %6 to i64, !insn.addr !1
  ret i64 %7, !insn.addr !2
}
*** IR Dump After Simple constant propagation ***
define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !3
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !4
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %5 = and i64 %3, 4294967295, !insn.addr !6
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !7
  ret i64 0, !insn.addr !8
}
*** IR Dump After Combine redundant instructions ***
define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %0 = call i64 @__decompiler_undefined_function_0()
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = trunc i64 %0 to i32
  %sext = shl i32 %3, 24
  %5 = ashr exact i32 %sext, 24, !insn.addr !1
  %6 = add i32 %5, %4, !insn.addr !1
  %7 = zext i32 %6 to i64, !insn.addr !1
  ret i64 %7, !insn.addr !2
}
*** IR Dump After Combine redundant instructions ***
define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !3
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !4
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %5 = and i64 %3, 4294967295, !insn.addr !6
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !7
  ret i64 0, !insn.addr !8
}
*** IR Dump After Combine redundant instructions ***
define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %0 = call i64 @__decompiler_undefined_function_0()
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = trunc i64 %0 to i32
  %sext = shl i32 %3, 24
  %5 = ashr exact i32 %sext, 24, !insn.addr !1
  %6 = add i32 %5, %4, !insn.addr !1
  %7 = zext i32 %6 to i64, !insn.addr !1
  ret i64 %7, !insn.addr !2
}
*** IR Dump After Combine redundant instructions ***
define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !3
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !4
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %5 = and i64 %3, 4294967295, !insn.addr !6
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !7
  ret i64 0, !insn.addr !8
}
*** IR Dump After Simplify the CFG ***
define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %0 = call i64 @__decompiler_undefined_function_0()
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = trunc i64 %0 to i32
  %sext = shl i32 %3, 24
  %5 = ashr exact i32 %sext, 24, !insn.addr !1
  %6 = add i32 %5, %4, !insn.addr !1
  %7 = zext i32 %6 to i64, !insn.addr !1
  ret i64 %7, !insn.addr !2
}
*** IR Dump After Simplify the CFG ***
define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !3
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !4
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %5 = and i64 %3, 4294967295, !insn.addr !6
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !7
  ret i64 0, !insn.addr !8
}
*** IR Dump After Early CSE ***
define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %0 = call i64 @__decompiler_undefined_function_0()
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = trunc i64 %0 to i32
  %sext = shl i32 %3, 24
  %5 = ashr exact i32 %sext, 24, !insn.addr !1
  %6 = add i32 %5, %4, !insn.addr !1
  %7 = zext i32 %6 to i64, !insn.addr !1
  ret i64 %7, !insn.addr !2
}
*** IR Dump After Early CSE ***
define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !3
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !4
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %5 = and i64 %3, 4294967295, !insn.addr !6
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !7
  ret i64 0, !insn.addr !8
}
*** IR Dump After Global Variable Optimizer ***
source_filename = "test"
target datalayout = "e-m:e-p:64:64-i64:64-f80:128-n8:16:32:64-S128"

@global_var_403ff8 = local_unnamed_addr global i64 0
@global_var_402010 = constant [4 x i8] c"%d\0A\00"

define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %0 = call i64 @__decompiler_undefined_function_0()
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = trunc i64 %0 to i32
  %sext = shl i32 %3, 24
  %5 = ashr exact i32 %sext, 24, !insn.addr !1
  %6 = add i32 %5, %4, !insn.addr !1
  %7 = zext i32 %6 to i64, !insn.addr !1
  ret i64 %7, !insn.addr !2
}

define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !3
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !4
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %5 = and i64 %3, 4294967295, !insn.addr !6
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !7
  ret i64 0, !insn.addr !8
}

declare i32 @printf(i8*, ...) local_unnamed_addr

declare i64 @__decompiler_undefined_function_0() local_unnamed_addr

declare i32 @__decompiler_undefined_function_1() local_unnamed_addr

!0 = !{i64 4198704}
!1 = !{i64 4198717}
!2 = !{i64 4198720}
!3 = !{i64 4198729}
!4 = !{i64 4198753}
!5 = !{i64 4198782}
!6 = !{i64 4198793}
!7 = !{i64 4198805}
!8 = !{i64 4198816}
*** IR Dump After Promote Memory to Register ***
define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %0 = call i64 @__decompiler_undefined_function_0()
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = trunc i64 %0 to i32
  %sext = shl i32 %3, 24
  %5 = ashr exact i32 %sext, 24, !insn.addr !1
  %6 = add i32 %5, %4, !insn.addr !1
  %7 = zext i32 %6 to i64, !insn.addr !1
  ret i64 %7, !insn.addr !2
}
*** IR Dump After Promote Memory to Register ***
define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !3
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !4
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %5 = and i64 %3, 4294967295, !insn.addr !6
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !7
  ret i64 0, !insn.addr !8
}
*** IR Dump After Combine redundant instructions ***
define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %0 = call i64 @__decompiler_undefined_function_0()
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = trunc i64 %0 to i32
  %sext = shl i32 %3, 24
  %5 = ashr exact i32 %sext, 24, !insn.addr !1
  %6 = add i32 %5, %4, !insn.addr !1
  %7 = zext i32 %6 to i64, !insn.addr !1
  ret i64 %7, !insn.addr !2
}
*** IR Dump After Combine redundant instructions ***
define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !3
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !4
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %5 = and i64 %3, 4294967295, !insn.addr !6
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !7
  ret i64 0, !insn.addr !8
}
*** IR Dump After Simplify the CFG ***
define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %0 = call i64 @__decompiler_undefined_function_0()
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = trunc i64 %0 to i32
  %sext = shl i32 %3, 24
  %5 = ashr exact i32 %sext, 24, !insn.addr !1
  %6 = add i32 %5, %4, !insn.addr !1
  %7 = zext i32 %6 to i64, !insn.addr !1
  ret i64 %7, !insn.addr !2
}
*** IR Dump After Simplify the CFG ***
define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !3
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !4
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %5 = and i64 %3, 4294967295, !insn.addr !6
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !7
  ret i64 0, !insn.addr !8
}
*** IR Dump After Early CSE ***
define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %0 = call i64 @__decompiler_undefined_function_0()
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = trunc i64 %0 to i32
  %sext = shl i32 %3, 24
  %5 = ashr exact i32 %sext, 24, !insn.addr !1
  %6 = add i32 %5, %4, !insn.addr !1
  %7 = zext i32 %6 to i64, !insn.addr !1
  ret i64 %7, !insn.addr !2
}
*** IR Dump After Early CSE ***
define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !3
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !4
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %5 = and i64 %3, 4294967295, !insn.addr !6
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !7
  ret i64 0, !insn.addr !8
}
*** IR Dump After Jump Threading ***
define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %0 = call i64 @__decompiler_undefined_function_0()
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = trunc i64 %0 to i32
  %sext = shl i32 %3, 24
  %5 = ashr exact i32 %sext, 24, !insn.addr !1
  %6 = add i32 %5, %4, !insn.addr !1
  %7 = zext i32 %6 to i64, !insn.addr !1
  ret i64 %7, !insn.addr !2
}
*** IR Dump After Jump Threading ***
define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !3
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !4
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %5 = and i64 %3, 4294967295, !insn.addr !6
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !7
  ret i64 0, !insn.addr !8
}
*** IR Dump After Value Propagation ***
define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %0 = call i64 @__decompiler_undefined_function_0()
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = trunc i64 %0 to i32
  %sext = shl i32 %3, 24
  %5 = ashr exact i32 %sext, 24, !insn.addr !1
  %6 = add i32 %5, %4, !insn.addr !1
  %7 = zext i32 %6 to i64, !insn.addr !1
  ret i64 %7, !insn.addr !2
}
*** IR Dump After Value Propagation ***
define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !3
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !4
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %5 = and i64 %3, 4294967295, !insn.addr !6
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !7
  ret i64 0, !insn.addr !8
}
*** IR Dump After Simplify the CFG ***
define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %0 = call i64 @__decompiler_undefined_function_0()
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = trunc i64 %0 to i32
  %sext = shl i32 %3, 24
  %5 = ashr exact i32 %sext, 24, !insn.addr !1
  %6 = add i32 %5, %4, !insn.addr !1
  %7 = zext i32 %6 to i64, !insn.addr !1
  ret i64 %7, !insn.addr !2
}
*** IR Dump After Simplify the CFG ***
define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !3
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !4
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %5 = and i64 %3, 4294967295, !insn.addr !6
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !7
  ret i64 0, !insn.addr !8
}
*** IR Dump After Combine redundant instructions ***
define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %0 = call i64 @__decompiler_undefined_function_0()
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = trunc i64 %0 to i32
  %sext = shl i32 %3, 24
  %5 = ashr exact i32 %sext, 24, !insn.addr !1
  %6 = add i32 %5, %4, !insn.addr !1
  %7 = zext i32 %6 to i64, !insn.addr !1
  ret i64 %7, !insn.addr !2
}
*** IR Dump After Combine redundant instructions ***
define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !3
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !4
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %5 = and i64 %3, 4294967295, !insn.addr !6
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !7
  ret i64 0, !insn.addr !8
}
*** IR Dump After Simplify the CFG ***
define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %0 = call i64 @__decompiler_undefined_function_0()
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = trunc i64 %0 to i32
  %sext = shl i32 %3, 24
  %5 = ashr exact i32 %sext, 24, !insn.addr !1
  %6 = add i32 %5, %4, !insn.addr !1
  %7 = zext i32 %6 to i64, !insn.addr !1
  ret i64 %7, !insn.addr !2
}
*** IR Dump After Simplify the CFG ***
define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !3
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !4
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %5 = and i64 %3, 4294967295, !insn.addr !6
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !7
  ret i64 0, !insn.addr !8
}
*** IR Dump After Reassociate expressions ***
define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %0 = call i64 @__decompiler_undefined_function_0()
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = trunc i64 %0 to i32
  %sext = shl i32 %3, 24
  %5 = ashr exact i32 %sext, 24, !insn.addr !1
  %6 = add i32 %4, %5, !insn.addr !1
  %7 = zext i32 %6 to i64, !insn.addr !1
  ret i64 %7, !insn.addr !2
}
*** IR Dump After Reassociate expressions ***
define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !3
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !4
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %5 = and i64 %3, 4294967295, !insn.addr !6
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !7
  ret i64 0, !insn.addr !8
}
*** IR Dump After Canonicalize natural loops ***
define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %0 = call i64 @__decompiler_undefined_function_0()
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = trunc i64 %0 to i32
  %sext = shl i32 %3, 24
  %5 = ashr exact i32 %sext, 24, !insn.addr !1
  %6 = add i32 %4, %5, !insn.addr !1
  %7 = zext i32 %6 to i64, !insn.addr !1
  ret i64 %7, !insn.addr !2
}
*** IR Dump After Canonicalize natural loops ***
define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !3
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !4
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %5 = and i64 %3, 4294967295, !insn.addr !6
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !7
  ret i64 0, !insn.addr !8
}
*** IR Dump After LCSSA Verifier ***
define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %0 = call i64 @__decompiler_undefined_function_0()
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = trunc i64 %0 to i32
  %sext = shl i32 %3, 24
  %5 = ashr exact i32 %sext, 24, !insn.addr !1
  %6 = add i32 %4, %5, !insn.addr !1
  %7 = zext i32 %6 to i64, !insn.addr !1
  ret i64 %7, !insn.addr !2
}
*** IR Dump After Loop-Closed SSA Form Pass ***
define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %0 = call i64 @__decompiler_undefined_function_0()
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = trunc i64 %0 to i32
  %sext = shl i32 %3, 24
  %5 = ashr exact i32 %sext, 24, !insn.addr !1
  %6 = add i32 %4, %5, !insn.addr !1
  %7 = zext i32 %6 to i64, !insn.addr !1
  ret i64 %7, !insn.addr !2
}
*** IR Dump After LCSSA Verifier ***
define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !3
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !4
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %5 = and i64 %3, 4294967295, !insn.addr !6
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !7
  ret i64 0, !insn.addr !8
}
*** IR Dump After Loop-Closed SSA Form Pass ***
define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !3
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !4
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %5 = and i64 %3, 4294967295, !insn.addr !6
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !7
  ret i64 0, !insn.addr !8
}
*** IR Dump After Canonicalize natural loops ***
define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %0 = call i64 @__decompiler_undefined_function_0()
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = trunc i64 %0 to i32
  %sext = shl i32 %3, 24
  %5 = ashr exact i32 %sext, 24, !insn.addr !1
  %6 = add i32 %4, %5, !insn.addr !1
  %7 = zext i32 %6 to i64, !insn.addr !1
  ret i64 %7, !insn.addr !2
}
*** IR Dump After LCSSA Verifier ***
define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %0 = call i64 @__decompiler_undefined_function_0()
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = trunc i64 %0 to i32
  %sext = shl i32 %3, 24
  %5 = ashr exact i32 %sext, 24, !insn.addr !1
  %6 = add i32 %4, %5, !insn.addr !1
  %7 = zext i32 %6 to i64, !insn.addr !1
  ret i64 %7, !insn.addr !2
}
*** IR Dump After Loop-Closed SSA Form Pass ***
define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %0 = call i64 @__decompiler_undefined_function_0()
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = trunc i64 %0 to i32
  %sext = shl i32 %3, 24
  %5 = ashr exact i32 %sext, 24, !insn.addr !1
  %6 = add i32 %4, %5, !insn.addr !1
  %7 = zext i32 %6 to i64, !insn.addr !1
  ret i64 %7, !insn.addr !2
}
*** IR Dump After Canonicalize natural loops ***
define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !3
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !4
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %5 = and i64 %3, 4294967295, !insn.addr !6
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !7
  ret i64 0, !insn.addr !8
}
*** IR Dump After LCSSA Verifier ***
define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !3
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !4
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %5 = and i64 %3, 4294967295, !insn.addr !6
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !7
  ret i64 0, !insn.addr !8
}
*** IR Dump After Loop-Closed SSA Form Pass ***
define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !3
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !4
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %5 = and i64 %3, 4294967295, !insn.addr !6
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !7
  ret i64 0, !insn.addr !8
}
*** IR Dump After Canonicalize natural loops ***
define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %0 = call i64 @__decompiler_undefined_function_0()
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = trunc i64 %0 to i32
  %sext = shl i32 %3, 24
  %5 = ashr exact i32 %sext, 24, !insn.addr !1
  %6 = add i32 %4, %5, !insn.addr !1
  %7 = zext i32 %6 to i64, !insn.addr !1
  ret i64 %7, !insn.addr !2
}
*** IR Dump After LCSSA Verifier ***
define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %0 = call i64 @__decompiler_undefined_function_0()
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = trunc i64 %0 to i32
  %sext = shl i32 %3, 24
  %5 = ashr exact i32 %sext, 24, !insn.addr !1
  %6 = add i32 %4, %5, !insn.addr !1
  %7 = zext i32 %6 to i64, !insn.addr !1
  ret i64 %7, !insn.addr !2
}
*** IR Dump After Loop-Closed SSA Form Pass ***
define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %0 = call i64 @__decompiler_undefined_function_0()
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = trunc i64 %0 to i32
  %sext = shl i32 %3, 24
  %5 = ashr exact i32 %sext, 24, !insn.addr !1
  %6 = add i32 %4, %5, !insn.addr !1
  %7 = zext i32 %6 to i64, !insn.addr !1
  ret i64 %7, !insn.addr !2
}
*** IR Dump After Canonicalize natural loops ***
define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !3
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !4
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %5 = and i64 %3, 4294967295, !insn.addr !6
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !7
  ret i64 0, !insn.addr !8
}
*** IR Dump After LCSSA Verifier ***
define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !3
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !4
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %5 = and i64 %3, 4294967295, !insn.addr !6
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !7
  ret i64 0, !insn.addr !8
}
*** IR Dump After Loop-Closed SSA Form Pass ***
define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !3
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !4
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %5 = and i64 %3, 4294967295, !insn.addr !6
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !7
  ret i64 0, !insn.addr !8
}
*** IR Dump After LCSSA Verifier ***
define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %0 = call i64 @__decompiler_undefined_function_0()
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = trunc i64 %0 to i32
  %sext = shl i32 %3, 24
  %5 = ashr exact i32 %sext, 24, !insn.addr !1
  %6 = add i32 %4, %5, !insn.addr !1
  %7 = zext i32 %6 to i64, !insn.addr !1
  ret i64 %7, !insn.addr !2
}
*** IR Dump After Loop-Closed SSA Form Pass ***
define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %0 = call i64 @__decompiler_undefined_function_0()
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = trunc i64 %0 to i32
  %sext = shl i32 %3, 24
  %5 = ashr exact i32 %sext, 24, !insn.addr !1
  %6 = add i32 %4, %5, !insn.addr !1
  %7 = zext i32 %6 to i64, !insn.addr !1
  ret i64 %7, !insn.addr !2
}
*** IR Dump After LCSSA Verifier ***
define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !3
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !4
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %5 = and i64 %3, 4294967295, !insn.addr !6
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !7
  ret i64 0, !insn.addr !8
}
*** IR Dump After Loop-Closed SSA Form Pass ***
define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !3
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !4
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %5 = and i64 %3, 4294967295, !insn.addr !6
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !7
  ret i64 0, !insn.addr !8
}
*** IR Dump After Combine redundant instructions ***
define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %0 = call i64 @__decompiler_undefined_function_0()
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = trunc i64 %0 to i32
  %sext = shl i32 %3, 24
  %5 = ashr exact i32 %sext, 24, !insn.addr !1
  %6 = add i32 %5, %4, !insn.addr !1
  %7 = zext i32 %6 to i64, !insn.addr !1
  ret i64 %7, !insn.addr !2
}
*** IR Dump After Combine redundant instructions ***
define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !3
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !4
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %5 = and i64 %3, 4294967295, !insn.addr !6
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !7
  ret i64 0, !insn.addr !8
}
*** IR Dump After Canonicalize natural loops ***
define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %0 = call i64 @__decompiler_undefined_function_0()
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = trunc i64 %0 to i32
  %sext = shl i32 %3, 24
  %5 = ashr exact i32 %sext, 24, !insn.addr !1
  %6 = add i32 %5, %4, !insn.addr !1
  %7 = zext i32 %6 to i64, !insn.addr !1
  ret i64 %7, !insn.addr !2
}
*** IR Dump After LCSSA Verifier ***
define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %0 = call i64 @__decompiler_undefined_function_0()
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = trunc i64 %0 to i32
  %sext = shl i32 %3, 24
  %5 = ashr exact i32 %sext, 24, !insn.addr !1
  %6 = add i32 %5, %4, !insn.addr !1
  %7 = zext i32 %6 to i64, !insn.addr !1
  ret i64 %7, !insn.addr !2
}
*** IR Dump After Loop-Closed SSA Form Pass ***
define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %0 = call i64 @__decompiler_undefined_function_0()
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = trunc i64 %0 to i32
  %sext = shl i32 %3, 24
  %5 = ashr exact i32 %sext, 24, !insn.addr !1
  %6 = add i32 %5, %4, !insn.addr !1
  %7 = zext i32 %6 to i64, !insn.addr !1
  ret i64 %7, !insn.addr !2
}
*** IR Dump After Canonicalize natural loops ***
define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !3
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !4
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %5 = and i64 %3, 4294967295, !insn.addr !6
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !7
  ret i64 0, !insn.addr !8
}
*** IR Dump After LCSSA Verifier ***
define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !3
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !4
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %5 = and i64 %3, 4294967295, !insn.addr !6
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !7
  ret i64 0, !insn.addr !8
}
*** IR Dump After Loop-Closed SSA Form Pass ***
define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !3
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !4
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %5 = and i64 %3, 4294967295, !insn.addr !6
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !7
  ret i64 0, !insn.addr !8
}
*** IR Dump After Canonicalize natural loops ***
define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %0 = call i64 @__decompiler_undefined_function_0()
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = trunc i64 %0 to i32
  %sext = shl i32 %3, 24
  %5 = ashr exact i32 %sext, 24, !insn.addr !1
  %6 = add i32 %5, %4, !insn.addr !1
  %7 = zext i32 %6 to i64, !insn.addr !1
  ret i64 %7, !insn.addr !2
}
*** IR Dump After Canonicalize natural loops ***
define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !3
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !4
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %5 = and i64 %3, 4294967295, !insn.addr !6
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !7
  ret i64 0, !insn.addr !8
}
*** IR Dump After Canonicalize natural loops ***
define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %0 = call i64 @__decompiler_undefined_function_0()
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = trunc i64 %0 to i32
  %sext = shl i32 %3, 24
  %5 = ashr exact i32 %sext, 24, !insn.addr !1
  %6 = add i32 %5, %4, !insn.addr !1
  %7 = zext i32 %6 to i64, !insn.addr !1
  ret i64 %7, !insn.addr !2
}
*** IR Dump After Loop Load Elimination ***
define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %0 = call i64 @__decompiler_undefined_function_0()
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = trunc i64 %0 to i32
  %sext = shl i32 %3, 24
  %5 = ashr exact i32 %sext, 24, !insn.addr !1
  %6 = add i32 %5, %4, !insn.addr !1
  %7 = zext i32 %6 to i64, !insn.addr !1
  ret i64 %7, !insn.addr !2
}
*** IR Dump After Canonicalize natural loops ***
define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !3
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !4
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %5 = and i64 %3, 4294967295, !insn.addr !6
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !7
  ret i64 0, !insn.addr !8
}
*** IR Dump After Loop Load Elimination ***
define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !3
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !4
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %5 = and i64 %3, 4294967295, !insn.addr !6
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !7
  ret i64 0, !insn.addr !8
}
*** IR Dump After LCSSA Verifier ***
define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %0 = call i64 @__decompiler_undefined_function_0()
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = trunc i64 %0 to i32
  %sext = shl i32 %3, 24
  %5 = ashr exact i32 %sext, 24, !insn.addr !1
  %6 = add i32 %5, %4, !insn.addr !1
  %7 = zext i32 %6 to i64, !insn.addr !1
  ret i64 %7, !insn.addr !2
}
*** IR Dump After Loop-Closed SSA Form Pass ***
define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %0 = call i64 @__decompiler_undefined_function_0()
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = trunc i64 %0 to i32
  %sext = shl i32 %3, 24
  %5 = ashr exact i32 %sext, 24, !insn.addr !1
  %6 = add i32 %5, %4, !insn.addr !1
  %7 = zext i32 %6 to i64, !insn.addr !1
  ret i64 %7, !insn.addr !2
}
*** IR Dump After LCSSA Verifier ***
define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !3
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !4
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %5 = and i64 %3, 4294967295, !insn.addr !6
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !7
  ret i64 0, !insn.addr !8
}
*** IR Dump After Loop-Closed SSA Form Pass ***
define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !3
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !4
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %5 = and i64 %3, 4294967295, !insn.addr !6
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !7
  ret i64 0, !insn.addr !8
}
*** IR Dump After Canonicalize natural loops ***
define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %0 = call i64 @__decompiler_undefined_function_0()
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = trunc i64 %0 to i32
  %sext = shl i32 %3, 24
  %5 = ashr exact i32 %sext, 24, !insn.addr !1
  %6 = add i32 %5, %4, !insn.addr !1
  %7 = zext i32 %6 to i64, !insn.addr !1
  ret i64 %7, !insn.addr !2
}
*** IR Dump After LCSSA Verifier ***
define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %0 = call i64 @__decompiler_undefined_function_0()
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = trunc i64 %0 to i32
  %sext = shl i32 %3, 24
  %5 = ashr exact i32 %sext, 24, !insn.addr !1
  %6 = add i32 %5, %4, !insn.addr !1
  %7 = zext i32 %6 to i64, !insn.addr !1
  ret i64 %7, !insn.addr !2
}
*** IR Dump After Loop-Closed SSA Form Pass ***
define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %0 = call i64 @__decompiler_undefined_function_0()
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = trunc i64 %0 to i32
  %sext = shl i32 %3, 24
  %5 = ashr exact i32 %sext, 24, !insn.addr !1
  %6 = add i32 %5, %4, !insn.addr !1
  %7 = zext i32 %6 to i64, !insn.addr !1
  ret i64 %7, !insn.addr !2
}
*** IR Dump After Canonicalize natural loops ***
define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !3
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !4
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %5 = and i64 %3, 4294967295, !insn.addr !6
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !7
  ret i64 0, !insn.addr !8
}
*** IR Dump After LCSSA Verifier ***
define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !3
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !4
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %5 = and i64 %3, 4294967295, !insn.addr !6
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !7
  ret i64 0, !insn.addr !8
}
*** IR Dump After Loop-Closed SSA Form Pass ***
define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !3
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !4
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %5 = and i64 %3, 4294967295, !insn.addr !6
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !7
  ret i64 0, !insn.addr !8
}
*** IR Dump After Canonicalize natural loops ***
define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %0 = call i64 @__decompiler_undefined_function_0()
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = trunc i64 %0 to i32
  %sext = shl i32 %3, 24
  %5 = ashr exact i32 %sext, 24, !insn.addr !1
  %6 = add i32 %5, %4, !insn.addr !1
  %7 = zext i32 %6 to i64, !insn.addr !1
  ret i64 %7, !insn.addr !2
}
*** IR Dump After LCSSA Verifier ***
define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %0 = call i64 @__decompiler_undefined_function_0()
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = trunc i64 %0 to i32
  %sext = shl i32 %3, 24
  %5 = ashr exact i32 %sext, 24, !insn.addr !1
  %6 = add i32 %5, %4, !insn.addr !1
  %7 = zext i32 %6 to i64, !insn.addr !1
  ret i64 %7, !insn.addr !2
}
*** IR Dump After Loop-Closed SSA Form Pass ***
define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %0 = call i64 @__decompiler_undefined_function_0()
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = trunc i64 %0 to i32
  %sext = shl i32 %3, 24
  %5 = ashr exact i32 %sext, 24, !insn.addr !1
  %6 = add i32 %5, %4, !insn.addr !1
  %7 = zext i32 %6 to i64, !insn.addr !1
  ret i64 %7, !insn.addr !2
}
*** IR Dump After Canonicalize natural loops ***
define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !3
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !4
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %5 = and i64 %3, 4294967295, !insn.addr !6
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !7
  ret i64 0, !insn.addr !8
}
*** IR Dump After LCSSA Verifier ***
define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !3
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !4
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %5 = and i64 %3, 4294967295, !insn.addr !6
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !7
  ret i64 0, !insn.addr !8
}
*** IR Dump After Loop-Closed SSA Form Pass ***
define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !3
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !4
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %5 = and i64 %3, 4294967295, !insn.addr !6
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !7
  ret i64 0, !insn.addr !8
}
*** IR Dump After Canonicalize natural loops ***
define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %0 = call i64 @__decompiler_undefined_function_0()
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = trunc i64 %0 to i32
  %sext = shl i32 %3, 24
  %5 = ashr exact i32 %sext, 24, !insn.addr !1
  %6 = add i32 %5, %4, !insn.addr !1
  %7 = zext i32 %6 to i64, !insn.addr !1
  ret i64 %7, !insn.addr !2
}
*** IR Dump After LCSSA Verifier ***
define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %0 = call i64 @__decompiler_undefined_function_0()
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = trunc i64 %0 to i32
  %sext = shl i32 %3, 24
  %5 = ashr exact i32 %sext, 24, !insn.addr !1
  %6 = add i32 %5, %4, !insn.addr !1
  %7 = zext i32 %6 to i64, !insn.addr !1
  ret i64 %7, !insn.addr !2
}
*** IR Dump After Loop-Closed SSA Form Pass ***
define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %0 = call i64 @__decompiler_undefined_function_0()
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = trunc i64 %0 to i32
  %sext = shl i32 %3, 24
  %5 = ashr exact i32 %sext, 24, !insn.addr !1
  %6 = add i32 %5, %4, !insn.addr !1
  %7 = zext i32 %6 to i64, !insn.addr !1
  ret i64 %7, !insn.addr !2
}
*** IR Dump After Canonicalize natural loops ***
define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !3
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !4
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %5 = and i64 %3, 4294967295, !insn.addr !6
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !7
  ret i64 0, !insn.addr !8
}
*** IR Dump After LCSSA Verifier ***
define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !3
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !4
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %5 = and i64 %3, 4294967295, !insn.addr !6
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !7
  ret i64 0, !insn.addr !8
}
*** IR Dump After Loop-Closed SSA Form Pass ***
define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !3
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !4
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %5 = and i64 %3, 4294967295, !insn.addr !6
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !7
  ret i64 0, !insn.addr !8
}
*** IR Dump After Global Value Numbering ***
define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %0 = call i64 @__decompiler_undefined_function_0()
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = trunc i64 %0 to i32
  %sext = shl i32 %3, 24
  %5 = ashr exact i32 %sext, 24, !insn.addr !1
  %6 = add i32 %5, %4, !insn.addr !1
  %7 = zext i32 %6 to i64, !insn.addr !1
  ret i64 %7, !insn.addr !2
}
*** IR Dump After Global Value Numbering ***
define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !3
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !4
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %5 = and i64 %3, 4294967295, !insn.addr !6
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !7
  ret i64 0, !insn.addr !8
}
*** IR Dump After Sparse Conditional Constant Propagation ***
define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %0 = call i64 @__decompiler_undefined_function_0()
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = trunc i64 %0 to i32
  %sext = shl i32 %3, 24
  %5 = ashr exact i32 %sext, 24, !insn.addr !1
  %6 = add i32 %5, %4, !insn.addr !1
  %7 = zext i32 %6 to i64, !insn.addr !1
  ret i64 %7, !insn.addr !2
}
*** IR Dump After Sparse Conditional Constant Propagation ***
define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !3
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !4
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %5 = and i64 %3, 4294967295, !insn.addr !6
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !7
  ret i64 0, !insn.addr !8
}
*** IR Dump After Combine redundant instructions ***
define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %0 = call i64 @__decompiler_undefined_function_0()
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = trunc i64 %0 to i32
  %sext = shl i32 %3, 24
  %5 = ashr exact i32 %sext, 24, !insn.addr !1
  %6 = add i32 %5, %4, !insn.addr !1
  %7 = zext i32 %6 to i64, !insn.addr !1
  ret i64 %7, !insn.addr !2
}
*** IR Dump After Combine redundant instructions ***
define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !3
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !4
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %5 = and i64 %3, 4294967295, !insn.addr !6
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !7
  ret i64 0, !insn.addr !8
}
*** IR Dump After Jump Threading ***
define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %0 = call i64 @__decompiler_undefined_function_0()
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = trunc i64 %0 to i32
  %sext = shl i32 %3, 24
  %5 = ashr exact i32 %sext, 24, !insn.addr !1
  %6 = add i32 %5, %4, !insn.addr !1
  %7 = zext i32 %6 to i64, !insn.addr !1
  ret i64 %7, !insn.addr !2
}
*** IR Dump After Jump Threading ***
define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !3
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !4
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %5 = and i64 %3, 4294967295, !insn.addr !6
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !7
  ret i64 0, !insn.addr !8
}
*** IR Dump After Value Propagation ***
define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %0 = call i64 @__decompiler_undefined_function_0()
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = trunc i64 %0 to i32
  %sext = shl i32 %3, 24
  %5 = ashr exact i32 %sext, 24, !insn.addr !1
  %6 = add i32 %5, %4, !insn.addr !1
  %7 = zext i32 %6 to i64, !insn.addr !1
  ret i64 %7, !insn.addr !2
}
*** IR Dump After Value Propagation ***
define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !3
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !4
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %5 = and i64 %3, 4294967295, !insn.addr !6
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !7
  ret i64 0, !insn.addr !8
}
*** IR Dump After Dead Store Elimination ***
define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %0 = call i64 @__decompiler_undefined_function_0()
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = trunc i64 %0 to i32
  %sext = shl i32 %3, 24
  %5 = ashr exact i32 %sext, 24, !insn.addr !1
  %6 = add i32 %5, %4, !insn.addr !1
  %7 = zext i32 %6 to i64, !insn.addr !1
  ret i64 %7, !insn.addr !2
}
*** IR Dump After Dead Store Elimination ***
define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !3
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !4
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %5 = and i64 %3, 4294967295, !insn.addr !6
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !7
  ret i64 0, !insn.addr !8
}
*** IR Dump After Demanded bits analysis ***
define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %0 = call i64 @__decompiler_undefined_function_0()
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = trunc i64 %0 to i32
  %sext = shl i32 %3, 24
  %5 = ashr exact i32 %sext, 24, !insn.addr !1
  %6 = add i32 %5, %4, !insn.addr !1
  %7 = zext i32 %6 to i64, !insn.addr !1
  ret i64 %7, !insn.addr !2
}
*** IR Dump After Bit-Tracking Dead Code Elimination ***
define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %0 = call i64 @__decompiler_undefined_function_0()
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = trunc i64 %0 to i32
  %sext = shl i32 %3, 24
  %5 = ashr exact i32 %sext, 24, !insn.addr !1
  %6 = add i32 %5, %4, !insn.addr !1
  %7 = zext i32 %6 to i64, !insn.addr !1
  ret i64 %7, !insn.addr !2
}
*** IR Dump After Demanded bits analysis ***
define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !3
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !4
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %5 = and i64 %3, 4294967295, !insn.addr !6
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !7
  ret i64 0, !insn.addr !8
}
*** IR Dump After Bit-Tracking Dead Code Elimination ***
define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !3
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !4
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %5 = and i64 %3, 4294967295, !insn.addr !6
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !7
  ret i64 0, !insn.addr !8
}
*** IR Dump After Aggressive Dead Code Elimination ***
define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %0 = call i64 @__decompiler_undefined_function_0()
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = trunc i64 %0 to i32
  %sext = shl i32 %3, 24
  %5 = ashr exact i32 %sext, 24, !insn.addr !1
  %6 = add i32 %5, %4, !insn.addr !1
  %7 = zext i32 %6 to i64, !insn.addr !1
  ret i64 %7, !insn.addr !2
}
*** IR Dump After Aggressive Dead Code Elimination ***
define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !3
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !4
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %5 = and i64 %3, 4294967295, !insn.addr !6
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !7
  ret i64 0, !insn.addr !8
}
*** IR Dump After Simplify the CFG ***
define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %0 = call i64 @__decompiler_undefined_function_0()
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = trunc i64 %0 to i32
  %sext = shl i32 %3, 24
  %5 = ashr exact i32 %sext, 24, !insn.addr !1
  %6 = add i32 %5, %4, !insn.addr !1
  %7 = zext i32 %6 to i64, !insn.addr !1
  ret i64 %7, !insn.addr !2
}
*** IR Dump After Simplify the CFG ***
define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !3
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !4
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %5 = and i64 %3, 4294967295, !insn.addr !6
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !7
  ret i64 0, !insn.addr !8
}
*** IR Dump After Combine redundant instructions ***
define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %0 = call i64 @__decompiler_undefined_function_0()
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = trunc i64 %0 to i32
  %sext = shl i32 %3, 24
  %5 = ashr exact i32 %sext, 24, !insn.addr !1
  %6 = add i32 %5, %4, !insn.addr !1
  %7 = zext i32 %6 to i64, !insn.addr !1
  ret i64 %7, !insn.addr !2
}
*** IR Dump After Combine redundant instructions ***
define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !3
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !4
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %5 = and i64 %3, 4294967295, !insn.addr !6
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !7
  ret i64 0, !insn.addr !8
}
*** IR Dump After Strip Unused Function Prototypes ***
source_filename = "test"
target datalayout = "e-m:e-p:64:64-i64:64-f80:128-n8:16:32:64-S128"

@global_var_403ff8 = local_unnamed_addr global i64 0
@global_var_402010 = constant [4 x i8] c"%d\0A\00"

define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %0 = call i64 @__decompiler_undefined_function_0()
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = trunc i64 %0 to i32
  %sext = shl i32 %3, 24
  %5 = ashr exact i32 %sext, 24, !insn.addr !1
  %6 = add i32 %5, %4, !insn.addr !1
  %7 = zext i32 %6 to i64, !insn.addr !1
  ret i64 %7, !insn.addr !2
}

define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !3
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !4
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %5 = and i64 %3, 4294967295, !insn.addr !6
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !7
  ret i64 0, !insn.addr !8
}

declare i32 @printf(i8*, ...) local_unnamed_addr

declare i64 @__decompiler_undefined_function_0() local_unnamed_addr

declare i32 @__decompiler_undefined_function_1() local_unnamed_addr

!0 = !{i64 4198704}
!1 = !{i64 4198717}
!2 = !{i64 4198720}
!3 = !{i64 4198729}
!4 = !{i64 4198753}
!5 = !{i64 4198782}
!6 = !{i64 4198793}
!7 = !{i64 4198805}
!8 = !{i64 4198816}
*** IR Dump After Dead Global Elimination ***
source_filename = "test"
target datalayout = "e-m:e-p:64:64-i64:64-f80:128-n8:16:32:64-S128"

@global_var_403ff8 = local_unnamed_addr global i64 0
@global_var_402010 = constant [4 x i8] c"%d\0A\00"

define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %0 = call i64 @__decompiler_undefined_function_0()
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = trunc i64 %0 to i32
  %sext = shl i32 %3, 24
  %5 = ashr exact i32 %sext, 24, !insn.addr !1
  %6 = add i32 %5, %4, !insn.addr !1
  %7 = zext i32 %6 to i64, !insn.addr !1
  ret i64 %7, !insn.addr !2
}

define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !3
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !4
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %5 = and i64 %3, 4294967295, !insn.addr !6
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !7
  ret i64 0, !insn.addr !8
}

declare i32 @printf(i8*, ...) local_unnamed_addr

declare i64 @__decompiler_undefined_function_0() local_unnamed_addr

declare i32 @__decompiler_undefined_function_1() local_unnamed_addr

!0 = !{i64 4198704}
!1 = !{i64 4198717}
!2 = !{i64 4198720}
!3 = !{i64 4198729}
!4 = !{i64 4198753}
!5 = !{i64 4198782}
!6 = !{i64 4198793}
!7 = !{i64 4198805}
!8 = !{i64 4198816}
*** IR Dump After Merge Duplicate Global Constants ***
source_filename = "test"
target datalayout = "e-m:e-p:64:64-i64:64-f80:128-n8:16:32:64-S128"

@global_var_403ff8 = local_unnamed_addr global i64 0
@global_var_402010 = constant [4 x i8] c"%d\0A\00"

define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %0 = call i64 @__decompiler_undefined_function_0()
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = trunc i64 %0 to i32
  %sext = shl i32 %3, 24
  %5 = ashr exact i32 %sext, 24, !insn.addr !1
  %6 = add i32 %5, %4, !insn.addr !1
  %7 = zext i32 %6 to i64, !insn.addr !1
  ret i64 %7, !insn.addr !2
}

define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !3
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !4
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %5 = and i64 %3, 4294967295, !insn.addr !6
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !7
  ret i64 0, !insn.addr !8
}

declare i32 @printf(i8*, ...) local_unnamed_addr

declare i64 @__decompiler_undefined_function_0() local_unnamed_addr

declare i32 @__decompiler_undefined_function_1() local_unnamed_addr

!0 = !{i64 4198704}
!1 = !{i64 4198717}
!2 = !{i64 4198720}
!3 = !{i64 4198729}
!4 = !{i64 4198753}
!5 = !{i64 4198782}
!6 = !{i64 4198793}
!7 = !{i64 4198805}
!8 = !{i64 4198816}
*** IR Dump After Simple constant propagation ***
define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %0 = call i64 @__decompiler_undefined_function_0()
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = trunc i64 %0 to i32
  %sext = shl i32 %3, 24
  %5 = ashr exact i32 %sext, 24, !insn.addr !1
  %6 = add i32 %5, %4, !insn.addr !1
  %7 = zext i32 %6 to i64, !insn.addr !1
  ret i64 %7, !insn.addr !2
}
*** IR Dump After Simple constant propagation ***
define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !3
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !4
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %5 = and i64 %3, 4294967295, !insn.addr !6
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !7
  ret i64 0, !insn.addr !8
}
*** IR Dump After Combine redundant instructions ***
define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %0 = call i64 @__decompiler_undefined_function_0()
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = trunc i64 %0 to i32
  %sext = shl i32 %3, 24
  %5 = ashr exact i32 %sext, 24, !insn.addr !1
  %6 = add i32 %5, %4, !insn.addr !1
  %7 = zext i32 %6 to i64, !insn.addr !1
  ret i64 %7, !insn.addr !2
}
*** IR Dump After Combine redundant instructions ***
define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !3
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !4
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %5 = and i64 %3, 4294967295, !insn.addr !6
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !7
  ret i64 0, !insn.addr !8
}
*** IR Dump After LLVM instruction optimization ***
source_filename = "test"
target datalayout = "e-m:e-p:64:64-i64:64-f80:128-n8:16:32:64-S128"

@global_var_403ff8 = local_unnamed_addr global i64 0
@global_var_402010 = constant [4 x i8] c"%d\0A\00"

define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %0 = call i64 @__decompiler_undefined_function_0()
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = trunc i64 %0 to i32
  %sext = shl i32 %3, 24
  %5 = ashr exact i32 %sext, 24, !insn.addr !1
  %6 = add i32 %5, %4, !insn.addr !1
  %7 = zext i32 %6 to i64, !insn.addr !1
  ret i64 %7, !insn.addr !2
}

define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !3
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !4
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %5 = and i64 %3, 4294967295, !insn.addr !6
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !7
  ret i64 0, !insn.addr !8
}

declare i32 @printf(i8*, ...) local_unnamed_addr

declare i64 @__decompiler_undefined_function_0() local_unnamed_addr

declare i32 @__decompiler_undefined_function_1() local_unnamed_addr

!0 = !{i64 4198704}
!1 = !{i64 4198717}
!2 = !{i64 4198720}
!3 = !{i64 4198729}
!4 = !{i64 4198753}
!5 = !{i64 4198782}
!6 = !{i64 4198793}
!7 = !{i64 4198805}
!8 = !{i64 4198816}
*** IR Dump After Simple types recovery optimization ***
source_filename = "test"
target datalayout = "e-m:e-p:64:64-i64:64-f80:128-n8:16:32:64-S128"

@global_var_403ff8 = local_unnamed_addr global i64 0
@global_var_402010 = constant [4 x i8] c"%d\0A\00"

define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %0 = call i64 @__decompiler_undefined_function_0()
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = trunc i64 %0 to i32
  %sext = shl i32 %3, 24
  %5 = ashr exact i32 %sext, 24, !insn.addr !1
  %6 = add i32 %5, %4, !insn.addr !1
  %7 = zext i32 %6 to i64, !insn.addr !1
  ret i64 %7, !insn.addr !2
}

define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !3
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !4
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %5 = and i64 %3, 4294967295, !insn.addr !6
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !7
  ret i64 0, !insn.addr !8
}

declare i32 @printf(i8*, ...) local_unnamed_addr

declare i64 @__decompiler_undefined_function_0() local_unnamed_addr

declare i32 @__decompiler_undefined_function_1() local_unnamed_addr

!0 = !{i64 4198704}
!1 = !{i64 4198717}
!2 = !{i64 4198720}
!3 = !{i64 4198729}
!4 = !{i64 4198753}
!5 = !{i64 4198782}
!6 = !{i64 4198793}
!7 = !{i64 4198805}
!8 = !{i64 4198816}
*** IR Dump After Stack pointer operations optimization ***
source_filename = "test"
target datalayout = "e-m:e-p:64:64-i64:64-f80:128-n8:16:32:64-S128"

@global_var_403ff8 = local_unnamed_addr global i64 0
@global_var_402010 = constant [4 x i8] c"%d\0A\00"

define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %0 = call i64 @__decompiler_undefined_function_0()
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = trunc i64 %0 to i32
  %sext = shl i32 %3, 24
  %5 = ashr exact i32 %sext, 24, !insn.addr !1
  %6 = add i32 %5, %4, !insn.addr !1
  %7 = zext i32 %6 to i64, !insn.addr !1
  ret i64 %7, !insn.addr !2
}

define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !3
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !4
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %5 = and i64 %3, 4294967295, !insn.addr !6
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !7
  ret i64 0, !insn.addr !8
}

declare i32 @printf(i8*, ...) local_unnamed_addr

declare i64 @__decompiler_undefined_function_0() local_unnamed_addr

declare i32 @__decompiler_undefined_function_1() local_unnamed_addr

!0 = !{i64 4198704}
!1 = !{i64 4198717}
!2 = !{i64 4198720}
!3 = !{i64 4198729}
!4 = !{i64 4198753}
!5 = !{i64 4198782}
!6 = !{i64 4198793}
!7 = !{i64 4198805}
!8 = !{i64 4198816}
*** IR Dump After Instruction idioms optimization ***
define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %0 = call i64 @__decompiler_undefined_function_0()
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = trunc i64 %0 to i32
  %sext = mul i32 %3, 16777216
  %5 = ashr exact i32 %sext, 24, !insn.addr !1
  %6 = add i32 %5, %4, !insn.addr !1
  %7 = zext i32 %6 to i64, !insn.addr !1
  ret i64 %7, !insn.addr !2
}
*** IR Dump After Instruction idioms optimization ***
define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !3
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !4
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %5 = and i64 %3, 4294967295, !insn.addr !6
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !7
  ret i64 0, !insn.addr !8
}
*** IR Dump After Combine redundant instructions ***
define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %0 = call i64 @__decompiler_undefined_function_0()
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = trunc i64 %0 to i32
  %sext = shl i32 %3, 24
  %5 = ashr exact i32 %sext, 24, !insn.addr !1
  %6 = add i32 %5, %4, !insn.addr !1
  %7 = zext i32 %6 to i64, !insn.addr !1
  ret i64 %7, !insn.addr !2
}
*** IR Dump After Combine redundant instructions ***
define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !3
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !4
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %5 = and i64 %3, 4294967295, !insn.addr !6
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !7
  ret i64 0, !insn.addr !8
}
*** IR Dump After LLVM instruction optimization ***
source_filename = "test"
target datalayout = "e-m:e-p:64:64-i64:64-f80:128-n8:16:32:64-S128"

@global_var_403ff8 = local_unnamed_addr global i64 0
@global_var_402010 = constant [4 x i8] c"%d\0A\00"

define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %0 = call i64 @__decompiler_undefined_function_0()
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = trunc i64 %0 to i32
  %sext = shl i32 %3, 24
  %5 = ashr exact i32 %sext, 24, !insn.addr !1
  %6 = add i32 %5, %4, !insn.addr !1
  %7 = zext i32 %6 to i64, !insn.addr !1
  ret i64 %7, !insn.addr !2
}

define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !3
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !4
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %5 = and i64 %3, 4294967295, !insn.addr !6
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !7
  ret i64 0, !insn.addr !8
}

declare i32 @printf(i8*, ...) local_unnamed_addr

declare i64 @__decompiler_undefined_function_0() local_unnamed_addr

declare i32 @__decompiler_undefined_function_1() local_unnamed_addr

!0 = !{i64 4198704}
!1 = !{i64 4198717}
!2 = !{i64 4198720}
!3 = !{i64 4198729}
!4 = !{i64 4198753}
!5 = !{i64 4198782}
!6 = !{i64 4198793}
!7 = !{i64 4198805}
!8 = !{i64 4198816}
*** IR Dump After Instruction idioms optimization ***
define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %0 = call i64 @__decompiler_undefined_function_0()
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = trunc i64 %0 to i32
  %sext = mul i32 %3, 16777216
  %5 = ashr exact i32 %sext, 24, !insn.addr !1
  %6 = add i32 %5, %4, !insn.addr !1
  %7 = zext i32 %6 to i64, !insn.addr !1
  ret i64 %7, !insn.addr !2
}
*** IR Dump After Instruction idioms optimization ***
define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !3
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !4
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %5 = and i64 %3, 4294967295, !insn.addr !6
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !7
  ret i64 0, !insn.addr !8
}
*** IR Dump After Phi removal ***
source_filename = "test"
target datalayout = "e-m:e-p:64:64-i64:64-f80:128-n8:16:32:64-S128"

@global_var_403ff8 = local_unnamed_addr global i64 0
@global_var_402010 = constant [4 x i8] c"%d\0A\00"

define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %0 = call i64 @__decompiler_undefined_function_0()
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = trunc i64 %0 to i32
  %sext = mul i32 %3, 16777216
  %5 = ashr exact i32 %sext, 24, !insn.addr !1
  %6 = add i32 %5, %4, !insn.addr !1
  %7 = zext i32 %6 to i64, !insn.addr !1
  ret i64 %7, !insn.addr !2
}

define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !3
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !4
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %5 = and i64 %3, 4294967295, !insn.addr !6
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !7
  ret i64 0, !insn.addr !8
}

declare i32 @printf(i8*, ...) local_unnamed_addr

declare i64 @__decompiler_undefined_function_0() local_unnamed_addr

declare i32 @__decompiler_undefined_function_1() local_unnamed_addr

!0 = !{i64 4198704}
!1 = !{i64 4198717}
!2 = !{i64 4198720}
!3 = !{i64 4198729}
!4 = !{i64 4198753}
!5 = !{i64 4198782}
!6 = !{i64 4198793}
!7 = !{i64 4198805}
!8 = !{i64 4198816}
*** IR Dump After Code sinking ***
define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %0 = call i64 @__decompiler_undefined_function_0()
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = trunc i64 %0 to i32
  %sext = mul i32 %3, 16777216
  %5 = ashr exact i32 %sext, 24, !insn.addr !1
  %6 = add i32 %5, %4, !insn.addr !1
  %7 = zext i32 %6 to i64, !insn.addr !1
  ret i64 %7, !insn.addr !2
}
*** IR Dump After Code sinking ***
define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !3
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !4
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %5 = and i64 %3, 4294967295, !insn.addr !6
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !7
  ret i64 0, !insn.addr !8
}
*** IR Dump After Module Verifier ***
define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %0 = call i64 @__decompiler_undefined_function_0()
  %1 = call i64 @__decompiler_undefined_function_0()
  %2 = call i64 @__decompiler_undefined_function_0()
  %3 = trunc i64 %arg2 to i32, !insn.addr !0
  %4 = trunc i64 %0 to i32
  %sext = mul i32 %3, 16777216
  %5 = ashr exact i32 %sext, 24, !insn.addr !1
  %6 = add i32 %5, %4, !insn.addr !1
  %7 = zext i32 %6 to i64, !insn.addr !1
  ret i64 %7, !insn.addr !2
}
*** IR Dump After Module Verifier ***
define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %0 = call i64 @__decompiler_undefined_function_0()
  %stack_var_-32 = alloca i32, align 4
  %1 = call i32 @__decompiler_undefined_function_1()
  %2 = call i64 @__decompiler_undefined_function_0()
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !3
  %3 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !4
  %4 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %5 = and i64 %3, 4294967295, !insn.addr !6
  %6 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %5), !insn.addr !7
  ret i64 0, !insn.addr !8
}
*** IR Dump After Value protection optimization ***
source_filename = "test"
target datalayout = "e-m:e-p:64:64-i64:64-f80:128-n8:16:32:64-S128"

@global_var_403ff8 = local_unnamed_addr global i64 0
@global_var_402010 = constant [4 x i8] c"%d\0A\00"

define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %0 = alloca i64
  %1 = load i64, i64* %0
  %2 = trunc i64 %arg2 to i32, !insn.addr !0
  %3 = trunc i64 %1 to i32
  %sext = mul i32 %2, 16777216
  %4 = ashr exact i32 %sext, 24, !insn.addr !1
  %5 = add i32 %4, %3, !insn.addr !1
  %6 = zext i32 %5 to i64, !insn.addr !1
  ret i64 %6, !insn.addr !2
}

define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %stack_var_-32 = alloca i32, align 4
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !3
  %0 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !4
  %1 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %2 = and i64 %0, 4294967295, !insn.addr !6
  %3 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %2), !insn.addr !7
  ret i64 0, !insn.addr !8
}

declare i32 @printf(i8*, ...) local_unnamed_addr

!0 = !{i64 4198704}
!1 = !{i64 4198717}
!2 = !{i64 4198720}
!3 = !{i64 4198729}
!4 = !{i64 4198753}
!5 = !{i64 4198782}
!6 = !{i64 4198793}
!7 = !{i64 4198805}
!8 = !{i64 4198816}
*** IR Dump After Generate the current LLVM IR ***
source_filename = "test"
target datalayout = "e-m:e-p:64:64-i64:64-f80:128-n8:16:32:64-S128"

@global_var_403ff8 = local_unnamed_addr global i64 0
@global_var_402010 = constant [4 x i8] c"%d\0A\00"

define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %0 = alloca i64
  %1 = load i64, i64* %0
  %2 = trunc i64 %arg2 to i32, !insn.addr !0
  %3 = trunc i64 %1 to i32
  %sext = mul i32 %2, 16777216
  %4 = ashr exact i32 %sext, 24, !insn.addr !1
  %5 = add i32 %4, %3, !insn.addr !1
  %6 = zext i32 %5 to i64, !insn.addr !1
  ret i64 %6, !insn.addr !2
}

define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %stack_var_-32 = alloca i32, align 4
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !3
  %0 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !4
  %1 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %2 = and i64 %0, 4294967295, !insn.addr !6
  %3 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %2), !insn.addr !7
  ret i64 0, !insn.addr !8
}

declare i32 @printf(i8*, ...) local_unnamed_addr

!0 = !{i64 4198704}
!1 = !{i64 4198717}
!2 = !{i64 4198720}
!3 = !{i64 4198729}
!4 = !{i64 4198753}
!5 = !{i64 4198782}
!6 = !{i64 4198793}
!7 = !{i64 4198805}
!8 = !{i64 4198816}
*** IR Dump After Generate the current bitcode ***
source_filename = "test"
target datalayout = "e-m:e-p:64:64-i64:64-f80:128-n8:16:32:64-S128"

@global_var_403ff8 = local_unnamed_addr global i64 0
@global_var_402010 = constant [4 x i8] c"%d\0A\00"

define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %0 = alloca i64
  %1 = load i64, i64* %0
  %2 = trunc i64 %arg2 to i32, !insn.addr !0
  %3 = trunc i64 %1 to i32
  %sext = mul i32 %2, 16777216
  %4 = ashr exact i32 %sext, 24, !insn.addr !1
  %5 = add i32 %4, %3, !insn.addr !1
  %6 = zext i32 %5 to i64, !insn.addr !1
  ret i64 %6, !insn.addr !2
}

define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %stack_var_-32 = alloca i32, align 4
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !3
  %0 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !4
  %1 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %2 = and i64 %0, 4294967295, !insn.addr !6
  %3 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %2), !insn.addr !7
  ret i64 0, !insn.addr !8
}

declare i32 @printf(i8*, ...) local_unnamed_addr

!0 = !{i64 4198704}
!1 = !{i64 4198717}
!2 = !{i64 4198720}
!3 = !{i64 4198729}
!4 = !{i64 4198753}
!5 = !{i64 4198782}
!6 = !{i64 4198793}
!7 = !{i64 4198805}
!8 = !{i64 4198816}
*** IR Dump After LLVM IR -> HLL ***
source_filename = "test"
target datalayout = "e-m:e-p:64:64-i64:64-f80:128-n8:16:32:64-S128"

@global_var_403ff8 = local_unnamed_addr global i64 0
@global_var_402010 = constant [4 x i8] c"%d\0A\00"

define i64 @add(i32* %arg1, i64 %arg2) local_unnamed_addr {
dec_label_pc_401126:
  %var2 = alloca i64
  %var1 = load i64, i64* %var2
  %0 = trunc i64 %arg2 to i32, !insn.addr !0
  %1 = trunc i64 %var1 to i32
  %sext = mul i32 %0, 16777216
  %2 = ashr exact i32 %sext, 24, !insn.addr !1
  %3 = add i32 %2, %1, !insn.addr !1
  %4 = zext i32 %3 to i64, !insn.addr !1
  ret i64 %4, !insn.addr !2
}

define i64 @main(i64 %argc, i8** %argv) local_unnamed_addr {
dec_label_pc_401141:
  %stack_var_-32 = alloca i32, align 4
  store i32 1, i32* %stack_var_-32, align 4, !insn.addr !3
  %var1 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !4
  %0 = call i64 @add(i32* nonnull %stack_var_-32, i64 2), !insn.addr !5
  %1 = and i64 %var1, 4294967295, !insn.addr !6
  %2 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([4 x i8], [4 x i8]* @global_var_402010, i64 0, i64 0), i64 %1), !insn.addr !7
  ret i64 0, !insn.addr !8
}

declare i32 @printf(i8*, ...) local_unnamed_addr

!0 = !{i64 4198704}
!1 = !{i64 4198717}
!2 = !{i64 4198720}
!3 = !{i64 4198729}
!4 = !{i64 4198753}
!5 = !{i64 4198782}
!6 = !{i64 4198793}
!7 = !{i64 4198805}
!8 = !{i64 4198816}
